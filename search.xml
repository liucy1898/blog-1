<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Activiti6.0用户指引中文版]]></title>
    <url>%2Fblog%2F2018%2F12%2F05%2FActiviti6-0%E7%94%A8%E6%88%B7%E6%8C%87%E5%BC%95%E4%B8%AD%E6%96%87%E7%89%88%2F</url>
    <content type="text"><![CDATA[1. 引导1.1. License 许可Activiti 是在 Apache V2 license 许可下发布的. 1.2. 下载http://activiti.org/download.html 1.3. 源代码该发行版以 jar 文件的形式包含了大多数源代码, Activiti 的源代码可以在 https://github.com/Activiti/Activiti 找到. 1.4. Required software 必需的软件1.4.1. JDK 7+Activiti 需要 JDK 版本高于或等于 7, 前往 Oracle Java SE downloads 进行下载. 在该页面上有相关的下载说明, 可以通过在命令行运行 java -version 命令来验证安装是否成功. 该命令会打印出安装的 JDK 版本. 1.4.2. IDE2. Getting Started 启动2.1. One minute version 一分钟版在从 Activiti website 下载了 Activiti UI 的 WAR 包之后, 按照这些步骤去以默认配置运行样例. 你需要安装 Java runtime 和 Apache Tomcat(实际上, 任意一个 web 容器都可以正常运行, 因为我们只依赖与 Servlet 的能力, 但我们主要在 Tomcat 上进行测试) 将下载的 activiti-app.war 文件复制到 Tomcat 的 webapps 路径下 通过 bin 路径下的 startup.sh 或 startop.bat 启动 Tomcat 当 Tomcat 启动后, 打开浏览器并前往 http://localhost:8080/activiti-app, 使用账号 admin, 密码 test 登录 这样就可以了, ActivitiUI 应用默认使用基于内存的 H2 数据库 2.2 Activiti setup Activiti 的安装要安装 Activiti, 需要安装 Java runtime 和 Apache Tomcat, 并且确认系统变量 JAVA_HOME 已经正确的设置, 具体设置的方式取决于你的操作系统. 只需要将 war 文件从 Activiti 下载页面下载到 Tomcat 安装路径下的 webapps 路径就可以让 Activiti UI 和 REST 应用启动. 默认情况下 UI 应用使用内存数据库运行. 示例用户: userId Password Security roles admin test admin 现在可以访问的应用: Webapp Name URL Description Activiti UI http://localhost:8080/activiti-app 流程引擎用户控制台, 通过该工具可以开启新的流程, 分配任务, 查看和认领任务等 需要注意的是, Activiti UI 项目实例的启动只是一个简单快速演示功能的方式, 并不是说只能使用这种方式使用 Activiti. Activiti 只是一个 jar 文件, 可以嵌入到任何 Java 环境中, 比如 swing, Tomcat, JBoss, WebSphere 等. 或者也可以选择将Activiti作为一个典型的独立BPM服务器来运行, 只要能在 Java 中完成的, 就能使用 Activiti. 2.3. Activiti database setup 数据库安装如同在一分钟版示例说的, Activiti UI 应用默认使用内存数据库 H2. 要让 Activiti UI 应用使用独立的 H2 或者其他的数据库, 可以修改 WEB-INF/classes/META-INF/activiti-app 路径下的 activiti-app.properties 文件 2.4 Include the Activiti jar and its denpendices 包含 jar 及其依赖为了包含 Activiti jar 和它的依赖库, 我们决定使用 maven, 因为它简化了我们双方的依赖管理. 根据引导 http://www.activiti.org/community.html#maven.repository 来引入必要的依赖. 作为选择, 如果你不想使用 maven, 可以直接在项目中引入 jar 文件. Activiti 下载的压缩包包含一个文件夹 libs, 其中包含了所有 Activiti jar 文件(以及源代码 jar). 依赖不是通过这种方式提供的, Activiti 必须的依赖如下所示(使用 mvn dependency:tree 生成): org.activiti:activiti-engine:jar:6.x +- org.activiti:activiti-bpmn-converter:jar:6.x:compile | \- org.activiti:activiti-bpmn-model:jar:6.x:compile | +- com.fasterxml.jackson.core:jackson-core:jar:2.2.3:compile | \- com.fasterxml.jackson.core:jackson-databind:jar:2.2.3:compile | \- com.fasterxml.jackson.core:jackson-annotations:jar:2.2.3:compile +- org.activiti:activiti-process-validation:jar:6.x:compile +- org.activiti:activiti-image-generator:jar:6.x:compile +- org.apache.commons:commons-email:jar:1.2:compile | +- javax.mail:mail:jar:1.4.1:compile | \- javax.activation:activation:jar:1.1:compile +- org.apache.commons:commons-lang3:jar:3.3.2:compile +- org.mybatis:mybatis:jar:3.3.0:compile +- org.springframework:spring-beans:jar:4.1.6.RELEASE:compile | \- org.springframework:spring-core:jar:4.1.6.RELEASE:compile +- joda-time:joda-time:jar:2.6:compile +- org.slf4j:slf4j-api:jar:1.7.6:compile +- org.slf4j:jcl-over-slf4j:jar:1.7.6:compile 注意, 如果需要使用 mail service task 才需要引入 mail 依赖 jar. 所有的依赖可以很轻松的通过使用 mvn denpendency:cpoy-dependencies 在 activiti源代码 上下载. 2.5. Next steps 下一步3. Configuration 配置3.1. Creating a ProcessEngine 创建一个流程引擎Activiti 流程引擎通过 XML 文件 activiti.cfg.xml 配置, 需要注意的是不适用于 Spring 风格下的流程引擎创建. 获取 流程引擎 最简单的方式是使用 org.activiti.engine.ProcessEngines 类: 1ProcessEngine processEngine = ProcessEngines.getDefauleProcesEngine(); 这样的方式会在 classpath 上寻找 activiti.cfg.xml 文件, 并且基于文件中的配置去构造引擎. 下面的片段展示了一个配置文件的样例, 后面的章节会给出配置参数的详细介绍. 1234567891011121314151617181920&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="jdbcUrl" value="jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000" /&gt; &lt;property name="jdbcDriver" value="org.h2.Driver" /&gt; &lt;property name="jdbcUsername" value="sa" /&gt; &lt;property name="jdbcPassword" value="" /&gt; &lt;property name="databaseSchemaUpdate" value="true" /&gt; &lt;property name="asyncExecutorActivate" value="false" /&gt; &lt;property name="mailServerHost" value="mail.my-corp.com" /&gt; &lt;property name="mailServerPort" value="5025" /&gt; &lt;/bean&gt;&lt;/beans&gt; 值得注意的是, 这个 XML 配置文件实际上是一个 Spring 配置文件. 这并不意味着 Activiti 只能运行在 Spring 环境中. 我们仅仅是在内部利用 Spring 解析和依赖注入的能力来构建引擎. ProcessEngineConfiguration 对象也可以被配置文件编程式的创建, 也可以用一个不同 bean id. 12345678910// 基于默认配置文件 activiti.cfg.xmlProcessEngineConfiguration.createProcessEngineConfigurationFromResourceDefault();// 指定路径ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource);// 指定路径和提取的 bean idProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName);// 指定输入流ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream);// 指定输入流和 bean idProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName); 与此同时, 也可以不使用配置文件, 直接通过默认创建配置(参考不同的支持类) 12ProcessEngineConfiguraion.createStandaloneProcessEngineConfiguration();ProcessEngineConfiguraion.createStandaloneInMemProcessEngineConfiguration(); 所有这些 ProcessEngineConfiguraion.createXXX() 方法返回一个后续可调整的 ProcessEngineConfiguraion 方便链式调用, 在调用 buildProcessEngine() 操作后, 就会创建一个 ProcessEngine 12345ProcessEngine processEngine = ProcessEngineConfiguraion.createStandaloneInMemProcessEngineConfiguration() .setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_FALSE) .setJdbcUrl("jdbc:h2:mem:my-own-db;DB_CLOSE_DELAY=1000") .setAsyncExcutorActivate(false) .buildProcessEngine(); 3.2. ProcessEngineConfiguration beanactiviti.cfg.xml 必须包含一个 id 为 processEngineConfiguraion 的 bean 123&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;!-- ... --&gt;&lt;/bean&gt; 这个 bean 会用来构建 ProceeEngine, 有多个类可以用来定义 processEngineConfiguration, 这些类代表了不同的环境, 并且设置了对应的默认值. 最佳的实践是选择与你当前环境最符合的类, 这样可以少配置几个引擎的参数, 下面是当前可用的类: org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration: 这个 ProcessEngine 单独运行, Activiti 会自己处理事务, 默认情况下, 数据库只会在引擎启动的时候检查(并且如果没有 Activiti 的表或者表的版本不正确时会抛出异常); org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration: 这是一个方便的单元测试类, Activiti 会自己控制事务, 默认使用一个基于内存的 H2 数据库, 数据库分别会在启动和关闭的时候创建以及销毁, 当使用它的时候, 或许不需要额外的配置(除了使用 job 执行器或者邮件功能以外); org.activiti.spring.SpringProcessEngineConfiguration: 在 Spring 环境下使用流程引擎, 参考 Spring 集成; org.activiti.engine.impl.cfg.JtaProcessEngineConfiguration: 单独运行的流程引擎, 并使用 JTA 事务. 3.3. Database Configuration 数据库配置有两种方式配置数据库给 Activiti 引擎使用, 第一种方式是定义 JDBC 的数据库配置文件 jdbcUrl: 数据库连接 jdbcDriver: 驱动类 jdbcUsername: 数据库用户名 jdbcPassword: 数据库用户密码 基于 JDBC 配置文件构造出的数据源将默认使用 MyBatis 连接池, 下面的配置可以用来构造连接池: jdbcMaxActiveConnections: 任意时间数据库连接池中的最大连接数, 默认为 10; jdbcMaxIdleConnections: 连接池中处于空闲状态的连接的最大值; jdbcMaxCheckoutTime: 连接被取出使用的最长时间, 超过时间会被强制回收. 默认为20000(20 秒); jdbcMaxWaitTime: 这是一个底层配置, 当获得的时间较长时, 给连接池一个打印日志并重新尝试获得连接的机会, 默认为20000(20 秒). 数据库连接池默认配置: 1234&lt;property name="jdbcUrl" value="jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000" /&gt;&lt;property name="jdbcDriver" value="org.h2.Driver" /&gt;&lt;property name="jdbcUsername" value="sa" /&gt;&lt;property name="jdbcPassword" value="" /&gt; 我们的基准表明, MyBatis 连接池在大量并发请求下并不是最有效率的, 因此, 建议使用 javax.sql.DataSource 的实现 并且注入到 ProcessEngine 配置中(比如 DBCP, C3P0, Hikari, Tomcat Connection Pool等): 123456789101112&lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" &gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/activiti" /&gt; &lt;property name="username" value="activiti" /&gt; &lt;property name="password" value="activiti" /&gt; &lt;property name="defaultAutoCommit" value="false" /&gt;&lt;/bean&gt;&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; ... 注意, Activiti 并没有包含这些数据源, 因此你必须确保这些类库在你的类路径下. 不管是采用 JDBC 还是 DataSource 的方式, 下面的配置可以被设置: databaseType: 通常是不需要去单独制定这项配置, 因为会被数据库连接的元数据自动分析出来, 只有当自动制定失败的时候才需要被设置. 可能的值有 {h2, mysql, oracle, postgres, mssql, db2}. 这项配置会决定哪些创建/删除脚本和查询语句会被使用. 参考 支持数据库章节 了解支持哪些类型. databaseSchemaUpdate: 允许设置的策略去决定数据库表在流程启动和结束的时候被如何处理: false(默认): 当 ProcessEngine 启动的时候, 检查数据库表的版本是否匹配依赖库的版本, 并在不匹配的时候抛出异常; true: 在 ProcessEngine 构建时, 执行检查, 如果有需要就执行更新, 如果数据库表不存在, 就重新创建; create-drop: 在 ProcessEngine 启动的时候创建数据库表, 并且在 ProcessEngine 关闭的时候删除数据库表.]]></content>
      <categories>
        <category>Activiti</category>
        <category>工作流</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti工作流引擎]]></title>
    <url>%2Fblog%2F2018%2F11%2F26%2FActiviti%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前段时间入职字节跳动, 目前负责 Lark 工作流审批功能的开发, 选用工作流引擎 Activiti 进行开发, 因此在此记录下对 Activiti 的学习过程. 概念 工作流引擎是用来驱动业务, 按照流程图次逐步流转的核心框架, 在复杂多变的场景下采用工作流引擎可以大大降低业务部署成本. 通过标准的业务流程模型作为业务与开发工作的桥梁, 有效减少业务团队与技术交流的障碍. 工作流引擎最早用于企业 OA, CRM, 流程审批等系统的流程审批.现在的工作流引擎已经大量运用到互联网电商, 金融出行, 中台支撑等. 工作流引擎在互联网公司快速盛行, 掌握工作流引擎技术可以提升技术架构和业务建模能力. 目录: 工作流入门 Activiti 6.0 源码浅析 Activiti 6.0 引擎配置 Activiti 6.0 核心 API 数据设计与模型映射 BPMN 2.0 规范 集成 SpringBoot 2.0 搭建工作流平台 1. 工作流入门1.1 工作流介绍1.1.1 出差流程审批业务场景: 审批流程模型化: 从一个开始节点, 经过多个任务节点和分支节点, 最终流向结束节点. 1.1.2 电商购物流程 抽象成泳道图: 节点 抽象名称 功能 电商购物流程 泳池(Pool) 用户/电商平台/仓储物流 泳道(Line) 校验库存 服务任务(Service Task) 不需要人工参与, 需要系统自动化完成的操作节点 1.1.3 工作流是什么 工作流:是对工作流程以及各个步骤之间的业务规则的抽象, 概括描述. 工作流建模:将工作流程中的工作如何前后组织在一起的逻辑和规则, 在计算机中以恰当的模型表达并对其实施计算. 要解决的问题:为实现某个业务目标, 利用计算机在多个参与者之间按某种预定规则自动传递文档, 信息或任务. 关键词 概念 工作流管理系统 处理工作流的电脑软件系统, 主要功能是通过计算机技术的支持去定义, 执行和管理工作流, 协调工作流执行过程中工作之间以及群体之间的信息交互 计算机支持的协同工作 研究一个群体如何在计算机的帮助下实现协同工作的, 工作流属于计算机支持的协同工作的一部分 工作流管理联盟 工作流技术标准化的工业组织, 发布了用于工作流管理系统之间互操作的工作流参考模型, 并相继制定了一些列工业标准 1.1.4 为什么需要工作流日常开发中经常遇到的问题: 产品需求遗漏, 开发上线之后需求经常改; 业务代码复杂, 开发时间紧迫; 代码后期维护不足, 逐渐难以维护. 使用工作流能够带来的改变: 可以快速响应, 灵活调整线上产品流程; 业务和开发基于流程模型沟通, 基于业务建模快速部署; 流程可视化, 方便查看流程的运行进展. 使用工作流对团队的作用: 提高效率, 减少等待; 规范行为, 落实制度; 协同内外, 快速响应; 监控全面, 提升执行. 1.2 工作流技术选型 二者都是成熟的工作流框架 jBPM Activiti Hibernate ByBatis Drools Flow JBPM4 JPA Spring Message RESTful 1.3 Activiti6.0 快速体验1.3.1 准备物料 Activiti 软件包: activiti-6.0.0.zip JDK Servlet 容器 (如 Tomcat) 安装 sdkman12345curl -s "https://get.sdkman.io" | bashsource "$HOME/.sdkman/bin/sdkman-init.sh"sdk version 安装 JDK12345sdk install java 8u161-oraclejava -versionecho $JAVA_HOME 安装 Tomcat1234567wget http://mirror.bit.edu.cn/apache/tomcat/tomcat/8/v8.0.50/bin/apache-tomcat-8.0.50.ziptar -zxvf apache-tomcat-8.0.50.zip./apache-tomcat-8.0.50/bin/startup.shjdp-mlv 部署 Activiti123456wget https://github.com/Activiti/Activiti/releases/download/activiti-6.0.0/activiti-6.0.0.ziptar -zxvf activiti-6.0.0.zipcp activiti-6.0.0/wars/activiti-app.war apache-tomcat-8.0.50/webappscp activiti-6.0.0/wars/activiti-admin.war apache-tomcat-8.0.50/webapps 此时打开浏览器, 输入 http://localhost:8080/activiti-app 即可进入流程引擎的登录界面 账号: admin 密码: test 1.3.2 设计一个审批流程设计如下流程: 开始 -&gt; TL 审批 -&gt; HR 审批 -&gt; 结束 流程参与者 ID Email Name admin admin Administrator userdev userdev@126.com userdevDEV userhr userhr@126.com userhrHR usertl usertl@126.com usertlTL 2. 源码概述12345git clone git@github.com:DestinyWang/Activiti.gitgit checkout -b study6 activiti-6.0.0mvn clean test-compile 路径 功能 Activiti/activiti-engine/src/main/java/org/activiti/engine/cfg Activiti 的启动依赖 activiti.cfg.xml, 在该目录完成 Activiti/activiti-engine/src/main/java/org/activiti/engine/compatibility Activiti 从 5 升级到 6 的时候有部分不兼容, 在该目录完成适配 Activiti/activiti-engine/src/main/java/org/activiti/engine/debug 调试相关目录 Activiti/activiti-engine/src/main/java/org/activiti/engine/delegate 需要制定的节点 Task 都需要实现 JavaDelegate Activiti/activiti-engine/src/main/java/org/activiti/engine/event 定义了事件和监听机制 Activiti/activiti-engine/src/main/java/org/activiti/engine/form 通用表单 Activiti/activiti-engine/src/main/java/org/activiti/engine/history 历史数据归档 Activiti/activiti-engine/src/main/java/org/activiti/engine/identity 身份认证相关操作 Activiti/activiti-engine/src/main/java/org/activiti/engine/impl 各个接口层的实现 Activiti/activiti-engine/src/main/java/org/activiti/engine/logging LogMDC 将重要的变量(如流程 id 放在上下文, logback 可以打印出来) Activiti/activiti-engine/src/main/java/org/activiti/engine/management 管理相关 Activiti/activiti-engine/src/main/java/org/activiti/engine/parse 流程文件是 xml, 需要解析和验证 Activiti/activiti-engine/src/main/java/org/activiti/engine/query 抽象了一些查询接口, 基于 mybatis Activiti/activiti-engine/src/main/java/org/activiti/engine/repository 抽象流程部署到数据库的过程 Activiti/activiti-engine/src/main/java/org/activiti/engine/runtime 与 history 相对应, 是流程在流转过程中的数据 Activiti/activiti-engine/src/main/java/org/activiti/engine/task 每个流程在需要人工处理的时候都会对应一个 task Activiti/activiti-engine/src/main/java/org/activiti/engine/test 支持集成测试的帮助类 核心模块: module/activiti-engine: 核心引擎 module/activiti-spring: Spring 集成模块 module/activiti-spring-boot: SpringBoot 集成模块 module/activiti-rest: 对外提供 rest api 模块 module/activiti-form-engine: 表单引擎模块 module/activiti-ldap: 集成 ldap 用户模块 Activiti-engine 依赖的模块: bpmn-converter: 模型转换 process-validation: 流程校验 image-generator: 流程图绘制(BPMN 转 PNG) dmn-api: 决策标准 form-api/form-model: form 表单相关 2.1 基于源码运行 activiti-app2.1.1 启动 activiti-app12345cd modules/activiti-ui/activiti-appmvn clean tomcat7:runopen http://localhost:9999/activi-app 2.2 剖析 activiti-appactiviti-ui 的组成: activiti-app: 集成发布的 war 工程 activiti-app-conf: UI 独立域业务外的配置 activiti-app-logic: UI 的业务逻辑 activiti-app-rest: 提供接口的 rest api 3. HelloWorld 填写审批信息: 姓名, 时间, 是否提交 主管审批: 审批结果, 备注 审批结果, 备注 3.1 在 IDEA 中完成流程图的设计并配置 配置点: 节点 id, 名称; 对每个网关的分支做判断(基于填写信息); Task 节点接收的表单信息. 3.1.2 Task 节点接收的表单信息填写申请信息 Id Name Type Expression Variable Default Date Pattern Readable Writable Required Values message 申请信息 string True name 申请人姓名 string True submitTime 提交时间 date yyyy-MM-dd True submitType 确认申请 string True 主管审批 Id Name Type Expression Variable Default Date Pattern Readable Writable Required Values tlApprove 主管审批结果 string false tlMessage 主管审批备注 string true 人事审批 Id Name Type Expression Variable Default Date Pattern Readable Writable Required Values hrApprove 人事审批结果 string true hrMessage 人事审批备注 string true 3.1.3 排他网关配置 排他网关需要对流入网关的某个值做判断, 从而决定流程后续的流向 flow3 配置${submitType==&quot;Y&quot; || submitType==&quot;y&quot;} flow4 配置${submitType==&quot;N&quot; || submitType==&quot;n&quot;} flow6 配置${tlApprove == &quot;Y&quot; || tlApprove == &quot;y&quot;} flow7 配置${tlApprove == &quot;N&quot; || tlApprove == &quot;n&quot;} flow9 配置${hrApprove == &quot;Y&quot; || tlApprove == &quot;y&quot;} flow10 配置${hrApprove == &quot;N&quot; || tlApprove == &quot;n&quot;} 配置后的流程图 3.2 helloworld程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class DemoMain &#123; private static final Logger logger = LoggerFactory.getLogger(DemoMain.class); public static void main(String[] args) throws ParseException &#123; logger.info("----- 启动我们的程序 -----"); // 1. 创建流程引擎 ProcessEngine processEngine = getProcessEngine(); // 2. 部署流程定义文件 ProcessDefinition processDefinition = getProcessDefinition(processEngine); // 3. 启动运行流程 ProcessInstance processInstance = getProcessInstance(processEngine, processDefinition); // 4. 处理流程任务 processTask(processEngine, processInstance); logger.info("----- 结束我们的程序 -----"); &#125; /** * 处理流程任务 * * @param processEngine 流程引擎 * @param processInstance 流程实例 * @throws ParseException */ private static void processTask(ProcessEngine processEngine, ProcessInstance processInstance) throws ParseException &#123; Scanner scanner = new Scanner(System.in); while (processInstance != null &amp;&amp; !processInstance.isEnded()) &#123; logger.info("processInstanceId: [&#123;&#125;]", processInstance.getId()); logger.info("processInstance.processInstanceId: [&#123;&#125;]", processInstance.getProcessInstanceId()); TaskService taskService = processEngine.getTaskService(); List&lt;Task&gt; list = taskService.createTaskQuery().list(); logger.info("待处理任务数量: [&#123;&#125;]", list.size()); for (Task task : list) &#123; logger.info("待处理任务: [&#123;&#125;]", task.getName()); Map&lt;String, Object&gt; variables = getVariables(processEngine, scanner, task); taskService.complete(task.getId(), variables); processInstance = processEngine.getRuntimeService() .createProcessInstanceQuery() .processInstanceId(processInstance.getId()) .singleResult(); logger.info("当前 ProcessInstance :&#123;&#125;", processInstance); &#125; &#125; scanner.close(); &#125; /** * 获取变量 * * @param processEngine * @param scanner * @param task * @return * @throws ParseException */ private static Map&lt;String, Object&gt; getVariables(ProcessEngine processEngine, Scanner scanner, Task task) throws ParseException &#123; FormService formService = processEngine.getFormService(); TaskFormData taskFormData = formService.getTaskFormData(task.getId()); List&lt;FormProperty&gt; formProperties = taskFormData.getFormProperties(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); for (FormProperty property : formProperties) &#123; String line = null; if (StringFormType.class.isInstance(property.getType())) &#123; // 如果是 String 类型, 不需要做任何格式化 logger.info("请输入 [&#123;&#125;] ?", property.getName()); line = scanner.nextLine(); variables.put(property.getId(), line); &#125; else if (DateFormType.class.isInstance(property.getType())) &#123; // 如果是日期类型 logger.info("请输入 [&#123;&#125;] ?, 格式 (yyyy-MM-dd)", property.getName()); line = scanner.nextLine(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd"); Date date = simpleDateFormat.parse(line); variables.put(property.getId(), date); &#125; else &#123; logger.info("类型不支持: &#123;&#125;", property.getType()); &#125; logger.info("您输入的内容是 [&#123;&#125;]", line); &#125; return variables; &#125; private static ProcessInstance getProcessInstance(ProcessEngine processEngine, ProcessDefinition processDefinition) &#123; RuntimeService runtimeService = processEngine.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceById(processDefinition.getId()); logger.info("启动流程: [&#123;&#125;]", processInstance.getProcessDefinitionKey()); return processInstance; &#125; private static ProcessDefinition getProcessDefinition(ProcessEngine processEngine) &#123; RepositoryService repositoryService = processEngine.getRepositoryService(); DeploymentBuilder deploymentBuilder = repositoryService.createDeployment(); deploymentBuilder.addClasspathResource("SecondApprove.bpmn20.xml"); Deployment deployment = deploymentBuilder.deploy(); String deploymentId = deployment.getId(); // deploymentId: 1 logger.info("deploymentId: [&#123;&#125;]", deploymentId); ProcessDefinition processDefinition = repositoryService. createProcessDefinitionQuery(). deploymentId(deploymentId) .singleResult(); // processDefinition.getId() 是 SecondApprove:1:4, 根据部署 id 和流程 id 组装出的数据 logger.info("流程定义文件: [&#123;&#125;], 流程 id: [&#123;&#125;]", processDefinition.getName(), processDefinition.getId()); return processDefinition; &#125; private static ProcessEngine getProcessEngine() &#123; ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration(); ProcessEngine processEngine = configuration.buildProcessEngine(); String name = processEngine.getName(); String version = ProcessEngine.VERSION; logger.info("流程引擎名称: [&#123;&#125;], 版本: [&#123;&#125;]", name, version); return processEngine; &#125;&#125; 4. Activiti 引擎配置4.1 流程引擎配置流程引擎配置的载体就是 ProcessEngineConfiguration 及其子类, Activiti 是通过 activiti.cfg.xml 来完成配置 然后构建出流程引擎 ProcessEngine, 最终获取业务开发中需要的各个 Service. ProcessorEngineConfiguration: 查找并解析 XML 配置文件 activiti.cfg.xml 提供多个静态方法创建配置对象 实现几个基于不同场景的子类, 配置方式灵活 123456789101112131415161718&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/activitiDB?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8"/&gt; &lt;property name="jdbcUsername" value="root"/&gt; &lt;property name="jdbcPassword" value="root"/&gt; &lt;!-- false: 不会自动创建表, 没有表, 则抛异常 --&gt; &lt;!-- create-drop: 先删除, 再创建表 --&gt; &lt;!-- true: 没有表时，自动创建--&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;/bean&gt;&lt;/beans&gt; ProcessEngineConfigurationImpl: 抽象类, 配置了 ProcessEngineConfiguration 大部分属性;StandaloneProcessEngineConfiguration: 独立部署运行, 可以通过 new 的方式创建;SpringProcessEngineConfiguration: 完成与 Spring 的集成, 同时扩展了数据源配置, 事务, 自动装载部署文件的目录. 4.2 数据库配置 缺省配置默认使用 H2 内存数据库; 配置 JDBC 属性, 使用 MyBatis 提供的连接池; 配置 DataSource, 可自选第三方实现. 配置 JDBC 属性使用 MyBatis 提供的连接池 基本属性 连接池配置 jdbcUrl jdbcMaxActiveConnections(最大活跃连接数) jdbcDriver jdbcMaxIdleConnections(最大空闲连接数) jdbcUsername jdbcMaxCheckoutTime(最大) jdbcPassword jdbcMaxWaitTIme(最大等待时间) 配置第三方实现的 DataSource Druid: 为监控而生的数据库连接池 Dbcp: Tomcat 自带 HikariCP: 极速数据源连接池, Spring 默认 4.2.1 Druid 数据源连接池123456789101112131415161718&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- false: 不会自动创建表, 没有表, 则抛异常 --&gt; &lt;!-- create-drop: 先删除, 再创建表 --&gt; &lt;!-- true: 没有表时，自动创建--&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt;&lt;/bean&gt;&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/activitiDB"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;property name="initialSize" value="1"/&gt; &lt;property name="maxActive" value="20"/&gt; &lt;property name="filters" value="stat,slf4f"/&gt;&lt;/bean&gt; 4.2.2 数据库更新策略 配置 databaseSchemaUpdate: false: 启动时检查数据库版本, 发生不匹配则抛出异常(线上默认) true: 启动时自动检查并更新数据库表, 不存在会创建(开发环境默认) create-drop: 启动时创建数据库表结构, 结束时删除表结构 4.3 日志和数据记录配置4.3.1 日志组件的关系及 MDC 日志分类 描述 分类内容 日志门面 直接应用在程序中记录日志的组件 slf4j, commons-logging, log4j 日志实现 日志门面不能直接打日志, 需要日志实现 logback, log4j, log4j2, Java util logging 桥接方式 有些特殊需求, 例如需要 slf4j 作为门面, 但需要以 log4j 作为实现 slf4j-log4j12, slf4j-jdk14, … 改变依赖 将原有门面的功能委托给其他实现, 主要用于解决历史软件内部依赖的改变 jcl-over-slf4j, log4j-over-slf4j, … 配置开启 MDC(Mapped Diagnostic Context): 可以理解为将上下文数据存储在 ThreadLocal 中 默认没有开启, 需要手动设置 LogMDC.setMDCEnable(true) 配置 logback.xml, 日志模板添加 %X{mdcProcessInstanceID}, 即打印当前 instance 的 id 流程只有在执行过程出现异常的时候才会记录 MDC 信息 4.3.1.1 默认日志输出测试类123456789101112131415161718public class ConfigMDCTest &#123; /** * 自动构建 ProcessEngine */ @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test @Deployment(resources = &#123;"my-process.bpmn20.xml"&#125;) public void test() &#123; ProcessInstance processInstance = activitiRule.getRuntimeService().startProcessInstanceByKey("my-process"); assertNotNull(processInstance); Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); assertEquals("Activiti is awesome!", task.getName()); activitiRule.getTaskService().complete(task.getId()); &#125;&#125; logback.xml1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="utf-8" ?&gt;&lt;configuration debug="false" scan="true" scanPeriod="30 seconds"&gt; &lt;property name="log.dir" value="target/logs"/&gt; &lt;property name="encoding" value="UTF-8"/&gt; &lt;property name="plain" value="%msg%n"/&gt; &lt;property name="std" value="%d&#123;HH:mm:ss.SSS&#125; [%thread] [%level] %msg %X&#123;user&#125; %logger&#123;10&#125;.%M:%L%n"/&gt; &lt;property name="normal" value="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;10&#125;.%M:%L - %msg%n"/&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;std&#125;&lt;/pattern&gt; &lt;charset&gt;$&#123;encoding&#125;&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; ... &lt;root&gt; &lt;appender-ref ref="stdout"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt;&lt;/configuration&gt; 日志输出00:19:43.624 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 00:19:45.162 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 00:19:45.174 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.mysql.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:19:45.176 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:19:46.466 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.mysql.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:19:46.466 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:19:46.922 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.mysql.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:19:46.922 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:19:47.035 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 4.3.1.2 MDC 日志输出测试类1234567891011121314151617public class ConfigMDCTest &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test @Deployment(resources = &#123;"my-process.bpmn20.xml"&#125;) public void test() &#123; // 开启 MDC, 整个过程在正常情况下是不会激活 MDC 的 LogMDC.setMDCEnabled(true); ProcessInstance processInstance = activitiRule.getRuntimeService().startProcessInstanceByKey("my-process"); assertNotNull(processInstance); Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); assertEquals("Activiti is awesome!", task.getName()); activitiRule.getTaskService().complete(task.getId()); &#125;&#125; BPMN 流程图1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!-- org.destiny.activiti.delegate.MDCErrorDelegate 是一个会自动抛出异常 "test only" 的JavaDelegate --&gt; &lt;serviceTask id="someTask" activiti:class="org.destiny.activiti.delegate.MDCErrorDelegate"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; logback12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="utf-8" ?&gt;&lt;configuration debug="false" scan="true" scanPeriod="30 seconds"&gt; &lt;property name="log.dir" value="target/logs"/&gt; &lt;property name="encoding" value="UTF-8"/&gt; &lt;property name="plain" value="%msg%n"/&gt; &lt;property name="std" value="%d&#123;HH:mm:ss.SSS&#125; [%thread] [%level] %msg %X&#123;user&#125; %logger&#123;10&#125;.%M:%L%n"/&gt; &lt;!-- - MDC 配置: - ProcessDefinitionId: 流程定义 id - executionId: - mdcProcessInstanceId: 流程实例 id - mdcBusinessKey: 业务 key --&gt; &lt;property name="mdc" value="%d&#123;HH:mm:ss.SSS&#125; [%thread] [%level] %msg ProcessDefinitionId=%X&#123;mdcProcessDefinitionID&#125; executionId=%X&#123;mdcExecutionId&#125; mdcProcessInstanceId=%X&#123;mdcProcessInstanceId&#125; mdcBusinessKey=%X&#123;mdcBusinessKey&#125; %logger&#123;10&#125;.%M:%L%n"/&gt; &lt;property name="normal" value="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;10&#125;.%M:%L - %msg%n"/&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;!-- 此处将默认值输出由 std 改为 mdc --&gt; &lt;!--&lt;pattern&gt;$&#123;std&#125;&lt;/pattern&gt;--&gt; &lt;pattern&gt;$&#123;mdc&#125;&lt;/pattern&gt; &lt;!--&lt;pattern&gt;$&#123;mdc&#125;&lt;/pattern&gt;--&gt; &lt;charset&gt;$&#123;encoding&#125;&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; ... &lt;root&gt; &lt;appender-ref ref="stdout"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt;&lt;/configuration&gt; 日志输出00:32:57.204 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 00:32:58.659 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 00:32:58.671 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.mysql.create.engine.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:32:58.673 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:33:00.219 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.mysql.create.history.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:33:00.220 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:33:00.657 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.mysql.create.identity.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:33:00.657 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:33:00.771 [main] [INFO] ProcessEngine default created ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 00:33:00.932 [main] [INFO] MDCErrorDelegate.execute ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.d.MDCErrorDelegate.execute:24 00:33:00.935 [main] [ERROR] Error while closing command context ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.CommandContext.logException:122 java.lang.RuntimeException: test only ... 可以看到, 在 ERROR 行中, 打印出了 MDC 信息 4.3.1.3 使用拦截器让每个流程节点都把 MDC 信息打印出来新建拦截器12345678910111213141516171819202122232425262728public class MDCCommandInvoker extends DebugCommandInvoker &#123; /** * 先判断可运行的对象是不是 Activiti 支持的 Operation * 如果是, 将它强转, 并取出执行对象并输出 * * @param runnable */ @Override public void executeOperation(Runnable runnable) &#123; boolean mdcEnabled = LogMDC.isMDCEnabled(); LogMDC.setMDCEnabled(true); if (runnable instanceof AbstractOperation) &#123; AbstractOperation operation = (AbstractOperation) runnable; if (operation.getExecution() != null) &#123; // 如果是可操作对象, 将该信息放入 MDC 上下文对象 LogMDC.putMDCExecution(operation.getExecution()); &#125; &#125; super.executeOperation(runnable); LogMDC.clear(); if (!mdcEnabled) &#123; // 如果 MDC 原本不生效, 需要将 MDC 重新置为 false LogMDC.setMDCEnabled(false); &#125; &#125;&#125; 配置该拦截器 修改默认配置文件 activiti.cfg.xml, 新增该 MDCCommandInvoker 123456789101112131415161718&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/activitiDB?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=false"/&gt; &lt;property name="jdbcUsername" value="root"/&gt; &lt;property name="jdbcPassword" value="123456"/&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;property name="commandInvoker" ref="commandInvoker"/&gt; &lt;/bean&gt; &lt;bean id="commandInvoker" class="org.destiny.activiti.interceptor.MDCCommandInvoker"/&gt;&lt;/beans&gt; 最终产出日志00:56:35.631 [main] [INFO] Loading XML bean definitions from class path resource [activiti_mdc.cfg.xml] ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 00:56:37.141 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 00:56:37.153 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.mysql.create.engine.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:56:37.154 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:56:38.655 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.mysql.create.history.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:56:38.656 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:56:39.109 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.mysql.create.identity.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:56:39.110 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:56:39.218 [main] [INFO] ProcessEngine default created ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 00:56:39.403 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.407 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.409 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.410 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.411 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.412 [main] [INFO] 4 (process instance) └── 5 : start -&gt; someTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.412 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.412 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.497 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.501 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.502 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.503 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.504 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.504 [main] [INFO] 4 (process instance) └── 5 : someTask -&gt; end, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.505 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.505 [main] [INFO] 4 (process instance) └── 5 : end (EndEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.505 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.506 [main] [INFO] 4 (process instance) └── 5 : end (EndEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.507 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.507 [main] [INFO] 4 (process instance) └── 5 : end (EndEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 可以看到最终所有级别的日志都输出了 MDC 信息 4.3.2 配置历史记录级别配置 HistoryLevel: none: 不记录历史记录, 性能高, 流程结束后不可读取; activiti: 归档流程实例和活动实例, 流程变量不同步; audit: 默认值, 在 activiti 基础上同步变量值, 保存表单属性; full: 性能较差, 记录所有实例和变量细节变化. 4.3.3 配置基于 DB 的事件日志配置 Event Logging 实验性的事件记录机制, 性能影响较大; 开启默认记录所有数据的变化过程, 导致表记录快速增长; 日志内容基于 JSON 格式, 建议存入 MongoDB, Elastic Search; 4.4 命令拦截器的配置4.4.1 命令模式与责任链模式4.4.1.1 Command 命令拦截器使用命令模式实现, 多个拦截器会组成一个拦截器链, 实现了责任链模式 Command: 命令接口 ConcreteCommand: 命令实现, 构造命令的时候, 需要传入接受者, 即 Received Receiver: Client 在实现 Command 接口的时候传入 Invoker: 调用者, 最终调用 ConcreteCommand 对象 4.4.1.2 Chain of Responsibility customPre, default, customPost 中 execute() 的实现基本都是调用了 next 的 execute(), 只有 CommandInvoker 真正完成了执行器. CustomPre: default 之前的拦截器 default: Activiti 默认的 CommandInterceptor CustomPost: default 之后的拦截器 CommandInvoker: 最终的命令执行者 4.4.2 命令拦截器的配置 配置Interceptor customProCommandInterceptors: 配置在默认拦截器之前 customPostCommandInterceptors: 配置在默认拦截器之后 commandInvoker: 配置在最后的执行器 4.4.3 示例 需求实现一个可以统计所有命令完成时间的拦截器 拦截器实现12345678910111213141516public class DurationCommandInterceptor extends AbstractCommandInterceptor &#123; private static final Logger logger = LoggerFactory.getLogger(DurationCommandInterceptor.class); @Override public &lt;T&gt; T execute(CommandConfig config, Command&lt;T&gt; command) &#123; // 记录当前时间 long start = System.currentTimeMillis(); try &#123; return this.getNext().execute(config, command); &#125; finally &#123; long duration = System.currentTimeMillis() - start; logger.info("&#123;&#125; 执行时长: &#123;&#125; 毫秒", command.getClass().getSimpleName(), duration); &#125; &#125;&#125; 配置文件1234567891011121314151617&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;property name="commandInvoker" ref="commandInvoker"/&gt; &lt;property name="customPreCommandInterceptors"&gt; &lt;list&gt; &lt;bean class="org.destiny.activiti.interceptor.DurationCommandInterceptor"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="commandInvoker" class="org.destiny.activiti.interceptor.MDCCommandInvoker"/&gt;&lt;/beans&gt; 日志输出10:10:09.371 [main] [INFO] SchemaOperationsProcessEngineBuild 执行时长: 113 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.372 [main] [INFO] ProcessEngine default created ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 10:10:09.391 [main] [INFO] ValidateExecutionRelatedEntityCountCfgCmd 执行时长: 14 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.394 [main] [INFO] 执行时长: 1 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.401 [main] [INFO] GetNextIdBlockCmd 执行时长: 4 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.508 [main] [INFO] GetProcessDefinitionInfoCmd 执行时长: 2 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.513 [main] [INFO] DeployCmd 执行时长: 116 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.616 [main] [INFO] CompleteTaskCmd 执行时长: 22 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.630 [main] [INFO] DeleteDeploymentCmd 执行时长: 14 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 4.5 作业执行器 Job Executor4.5.1 作业执行器的配置 asyncExecutorActivate: 激活作业执行器 asyncExecutorXXX: 异步执行器的属性配置 asyncExecutor: 异步执行器 bean 定时开始事件 timeDate: 指定启动时间 timeDuration: 指定持续时间间隔后执行 timeCycle:R5/P1DT1H 指定时间段后周期执行 4.5.2 配置自定义线程池 corePoolSize: 核心线程数 maxPoolSize: 最大线程数 queueCapacity: 阻塞队列大小 如果核心线程数没满, 每当有一个任务, 不管原有线程是否空闲都会开启一个新的线程去执行, 直到达到核心线程数;如果所有核心线程都在运行, 每当有一个任务, 会先放在阻塞队列等待, 直到核心线程执行完上一个任务, 会取阻塞队列第一个任务继续执行;如果队列已满, 会继续创建新的线程, 直到达到最大线程数;如果最大线程数和队列都已满, 此时会执行拒绝策略. 4.5.3 流程定义定时启动流程4.5.4 Demo配置异步执行器12345678910111213141516171819202122232425262728293031323334&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;property name="commandInvoker" ref="commandInvoker"/&gt; &lt;!-- 打开异步执行器 --&gt; &lt;property name="asyncExecutorActivate" value="true"/&gt; &lt;property name="asyncExecutor" value="asyncExecutor"/&gt; &lt;!-- 事件监听 --&gt; &lt;property name="eventListeners"&gt; &lt;list&gt; &lt;bean class="org.destiny.activiti.listener.JobEventListener"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="asyncExecutor" class="org.activiti.engine.impl.asyncexecutor.DefaultAsyncJobExecutor"&gt; &lt;property name="executorService" ref="executorService"/&gt; &lt;/bean&gt; &lt;bean id="executorService" class="org.springframework.scheduling.concurrent.ThreadPoolExecutorFactoryBean"&gt; &lt;property name="threadNamePrefix" value="activiti-job-"/&gt; &lt;property name="corePoolSize" value="5"/&gt; &lt;property name="maxPoolSize" value="20"/&gt; &lt;property name="queueCapacity" value="100"/&gt; &lt;property name="rejectedExecutionHandler"&gt; &lt;bean class="java.util.concurrent.ThreadPoolExecutor$AbortPolicy"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="commandInvoker" class="org.destiny.activiti.interceptor.MDCCommandInvoker"/&gt;&lt;/beans&gt; 流程定义文件12345678910111213&lt;process id="my-process"&gt; &lt;!--&lt;startEvent id="start"/&gt;--&gt; &lt;startEvent id="start"&gt; &lt;timerEventDefinition&gt; &lt;!-- 每 10 秒执行一次, 共执行 5 次 --&gt; &lt;timeCycle&gt;R5/PT10S&lt;/timeCycle&gt; &lt;/timerEventDefinition&gt; &lt;/startEvent&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt;&lt;/process&gt; 添加监听器12345678910111213141516171819public class JobEventListener implements ActivitiEventListener &#123; public static final Logger logger = LoggerFactory.getLogger(JobEventListener.class); @Override public void onEvent(ActivitiEvent event) &#123; ActivitiEventType eventType = event.getType(); String name = eventType.name(); if (name.startsWith("TIMER") || name.startsWith("JOB")) &#123; logger.info("监听 Job 事件: &#123;&#125; \t &#123;&#125;", eventType, event.getProcessInstanceId()); &#125; &#125; @Override public boolean isFailOnException() &#123; return false; &#125;&#125; 日志输出11:34:50.048 [main] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:34:50.056 [main] [INFO] start ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.c.ConfigJobTest.test:33 11:34:50.080 [main] [INFO] 定时任务 TimerJobEntity [id=4], 默认重试次数: 3 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.c.ConfigJobTest.test:36 11:34:50.080 [main] [INFO] jobList.size: 1 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.c.ConfigJobTest.test:38 11:35:09.981 [activiti-job-1] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:09.990 [activiti-job-1] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:09.990 [activiti-job-1] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:19.950 [activiti-job-2] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:19.951 [activiti-job-2] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:19.951 [activiti-job-2] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:29.958 [activiti-job-3] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:29.959 [activiti-job-3] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:29.960 [activiti-job-3] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:39.966 [activiti-job-4] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:39.970 [activiti-job-4] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:39.971 [activiti-job-4] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:49.975 [activiti-job-5] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:49.975 [activiti-job-5] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 4.6 Activiti 与 Spring 集成4.6.1 集成 Spring 配置 添加依赖: 12345&lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt;&lt;/dependency&gt; 基于 Spring 的默认配置: activiti-context.xml, 如果配置该文件, Activiti 在启动过程中就会查找基于 Spring 的 ProcessEngineConfiguration 对象; Activiti 核心服务注入 Spring 容器 4.6.2 基于 Spring 对 Activiti 的管理4.6.2.1 集成 Spring 事务管理器activiti-context.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.spring.SpringProcessEngineConfiguration"&gt; &lt;!-- Spring 需要单独配置 DataSource --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="transactionManager" ref="transactionManager"/&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;/bean&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="driverClassName" value="org.h2.Driver"/&gt; &lt;property name="url" value="jdbc:h2:mem:activiti"/&gt; &lt;property name="username" value="sa"/&gt; &lt;property name="password" value=""/&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 流程引擎对象 --&gt; &lt;bean id="processEngine" class="org.activiti.spring.ProcessEngineFactoryBean"&gt; &lt;property name="processEngineConfiguration" ref="processEngineConfiguration"/&gt; &lt;/bean&gt; &lt;!-- 将服务暴露给 Spring --&gt; &lt;bean id="runtimeService" factory-bean="processEngine" factory-method="getRuntimeService"/&gt; &lt;bean id="repositoryService" factory-bean="processEngine" factory-method="getRepositoryService"/&gt; &lt;bean id="formService" factory-bean="processEngine" factory-method="getFormService"/&gt; &lt;bean id="taskService" factory-bean="processEngine" factory-method="getTaskService"/&gt; &lt;bean id="historyService" factory-bean="processEngine" factory-method="getHistoryService"/&gt; &lt;!-- 配置 activitiRule 用于测试 --&gt; &lt;bean id="activitiRule" class="org.activiti.engine.test.ActivitiRule"&gt; &lt;property name="processEngine" ref="processEngine"/&gt; &lt;/bean&gt;&lt;/beans&gt; 4.6.2.2 定义文件表达式中使用 Spring BeanHelloBean12345678public class HelloBean &#123; private static final Logger logger = LoggerFactory.getLogger(HelloBean.class); public void sayHello() &#123; logger.info("sayHello"); &#125;&#125; my-process-spring.bpmn20.xml123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="helloBean"/&gt; &lt;!-- 从 Spring 容器中查找 Hello bean, 并且调用 sayHello() 方法 --&gt; &lt;serviceTask id="helloBean" activiti:expression="$&#123;helloBean.sayHello()&#125;"/&gt; &lt;sequenceFlow id="flow3" sourceRef="helloBean" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试类12345678910111213141516171819202122232425262728@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"classpath:activiti-context.xml"&#125;)public class ConfigSpringTest &#123; public static final Logger logger = LoggerFactory.getLogger(ConfigSpringTest.class); @Rule @Autowired public ActivitiRule activitiRule; @Autowired private RuntimeService runtimeService; @Autowired private TaskService taskService; @Test @Deployment(resources = &#123;"my-process-spring.bpmn20.xml"&#125;) public void test() &#123; ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); Task task = taskService.createTaskQuery().processInstanceId(processInstance.getId()).singleResult(); taskService.complete(task.getId()); logger.info("processInstance: [&#123;&#125;]", processInstance); logger.info("task: [&#123;&#125;]", task); &#125;&#125; 4.6.2.3 自动部署资源文件4.6.3 基于 Spring 的流程单元测试 添加依赖 spring-test 辅助测试 Rule: ActivitiRule 辅助测试 TestCase: SpringActivitiTestCase 5. Activiti 核心 API 服务名称 功能 RepositoryServie 负责对静态文件的管理, 涉及部署对象和资源对象, 其二者是一对多的关系 RuntimeService 负责对流程进行控制的服务, 可以对流程实例完成启动, 暂停, 挂起等操作 TaskService 负责管理运行中的 UserTask(人工任务) IdentityService 负责对用户和用户组的管理 FormService 负责解析流程定义中的表单, 对表单的数据类型做渲染 HistoryService 提供了对运行结束的流程实例的查询和删除操作 ManagementService 提供了对流程引擎基础的管理, 提供对定时任务 Job 的管理, 获取表结构, 表明的操作 DynamicBpmnService 提供了对动态的流程定义模型做修改 5.1 RepositoryService 管理流程定义文件 xml 及静态资源服务 对特定的流程的暂停和激活 流程定义启动权限管理 部署文件构造器 DeploymentBuilder 部署文件查询器 DeploymentQuery 流程定义文件查询对象 ProcessDefinitionQuery 流程部署文件对象 Deployment 流程定义文件对象 ProcessDefinition 流程定义的 Java 格式 BpmnModel RepositoryService API: 方法名 功能 createDeployment 添加资源文件 deleteDeployment 删除资源文件 setDeploymentCategory 指定分类名称 createProcessDefinitionQuery 创建流程定义查询对象 createNativeProcessDefinitionQuery 通过 SQL 查询流程定义对象 suspendProcessDefinitionByXX 通过某些条件暂停/挂起流程定义对象, 使之不能再生成新的流程实例 activateProcessDefinitionByXX 通过某些条件激活流程定义对象, 使之可以继续生成新的流程实例 getProcssDiagram 获取流程图的数据流 getBpmnModel 获取 BpmnModel 对象 addCandidateStarterUser 设置某个流程文件只能由指定的用户去启动 addCandidateStarterGroup 设置某个流程文件只能由指定的用户组去启动 … … 5.1.1 ProcessDefinitionId 的含义1234567891011121314151617181920212223242526272829303132333435363738@Testpublic void testRepository() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); DeploymentBuilder deploymentBuilder1 = repositoryService.createDeployment(); deploymentBuilder1 // 一个部署对象就记录了一次部署 .name("测试部署资源1") // 设置名称 .addClasspathResource("org/destiny/activiti/my-process.bpmn20.xml") .addClasspathResource("org/destiny/activiti/SecondApprove.bpmn20.xml") .deploy(); // 完成部署 DeploymentBuilder deploymentBuilder2 = repositoryService.createDeployment(); deploymentBuilder2 // 一个部署对象就记录了一次部署 .name("测试部署资源2") // 设置名称 .addClasspathResource("org/destiny/activiti/my-process.bpmn20.xml") .addClasspathResource("org/destiny/activiti/SecondApprove.bpmn20.xml") .deploy(); // 完成部署 // 查询部署对象 List&lt;Deployment&gt; deploymentList = repositoryService.createDeploymentQuery() .orderByDeploymenTime().asc() .list(); logger.info("size of deploymentList: &#123;&#125;", deploymentList.size()); for (Deployment deployment : deploymentList) &#123; logger.info("deployment: &#123;&#125;", deployment); &#125; // 流程定义 List&lt;ProcessDefinition&gt; processDefinitionList = repositoryService .createProcessDefinitionQuery() .orderByProcessDefinitionKey().asc() .listPage(0, 100); for (ProcessDefinition processDefinition : processDefinitionList) &#123; logger.info("processDefinition: &#123;&#125;, version: &#123;&#125;, key: &#123;&#125;, name: &#123;&#125;", processDefinition, processDefinition.getVersion(), processDefinition.getKey(), processDefinition.getName()); &#125;&#125; 生成的日志: 08:42:45,507 [main] INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [activiti.cfg.xml] 08:42:47,193 [main] INFO org.activiti.engine.compatibility.DefaultActiviti5CompatibilityHandlerFactory - Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. 08:42:47,207 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql 08:42:47,268 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql 08:42:47,274 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql 08:42:47,280 [main] INFO org.activiti.engine.impl.ProcessEngineImpl - ProcessEngine default created 08:42:49,736 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - size of deploymentList: 2 08:42:49,736 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - deployment: DeploymentEntity[id=1, name=测试部署资源1] 08:42:49,736 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - deployment: DeploymentEntity[id=7, name=测试部署资源2] 08:42:49,742 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[SecondApprove:1:5], version: 1, key: SecondApprove, name: 二级审批 08:42:49,742 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[SecondApprove:2:11], version: 2, key: SecondApprove, name: 二级审批 08:42:49,742 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[my-process:1:6], version: 1, key: my-process, name: null 08:42:49,743 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[my-process:2:12], version: 2, key: my-process, name: null 两个 DeploymentEntity, 一个 id 为 1, 一个 id 为 7, id 的设置使用全局自增, 说明在两个 Deployment 对象的部署过程中插入了 6 条记录: 1 个部署记录; 2 个流程定义记录; 2 个 xml 文件对应的数据流记录; 1 个流程定义所生成的图片记录;(my-process 没有生成图片) 5.1.2 流程挂起/激活测试代码: 1234567891011121314151617181920212223@Test@org.activiti.engine.test.Deployment(resources = "org/destiny/activiti/my-process.bpmn20.xml")public void testSuspend() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().singleResult(); String processDefinitionId = processDefinition.getId(); logger.info("processDefinitionId: &#123;&#125;", processDefinitionId); repositoryService.suspendProcessDefinitionById(processDefinitionId); try &#123; logger.info("开始启动"); activitiRule.getRuntimeService().startProcessInstanceById(processDefinitionId); logger.info("启动成功"); &#125; catch (Exception e) &#123; logger.error("启动失败, 原因: &#123;&#125;", e.getMessage()); &#125; repositoryService.activateProcessDefinitionById(processDefinitionId); logger.info("激活后开始启动"); activitiRule.getRuntimeService().startProcessInstanceById(processDefinitionId); logger.info("激活后启动成功");&#125; 输出日志: 09:12:42,071 [main] INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [activiti.cfg.xml] 09:12:43,614 [main] INFO org.activiti.engine.compatibility.DefaultActiviti5CompatibilityHandlerFactory - Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. 09:12:43,627 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql 09:12:43,682 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql 09:12:43,688 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql 09:12:43,692 [main] INFO org.activiti.engine.impl.ProcessEngineImpl - ProcessEngine default created 09:12:43,882 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinitionId: my-process:1:3 09:12:43,887 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 开始启动 09:12:43,893 [main] ERROR org.activiti.engine.impl.interceptor.CommandContext - Error while closing command context org.activiti.engine.ActivitiException: Cannot start process instance. Process definition null (id = my-process:1:3) is suspended at org.activiti.engine.impl.util.ProcessInstanceHelper.createAndStartProcessInstance(ProcessInstanceHelper.java:67) at org.activiti.engine.impl.util.ProcessInstanceHelper.createAndStartProcessInstance(ProcessInstanceHelper.java:51) at org.activiti.engine.impl.cmd.StartProcessInstanceCmd.createAndStartProcessInstance(StartProcessInstanceCmd.java:109) at org.activiti.engine.impl.cmd.StartProcessInstanceCmd.execute(StartProcessInstanceCmd.java:102) at org.activiti.engine.impl.cmd.StartProcessInstanceCmd.execute(StartProcessInstanceCmd.java:37) at org.activiti.engine.impl.interceptor.CommandInvoker$1.run(CommandInvoker.java:37) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperation(CommandInvoker.java:78) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperations(CommandInvoker.java:57) at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:42) at org.activiti.engine.impl.interceptor.TransactionContextInterceptor.execute(TransactionContextInterceptor.java:48) at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:63) at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:29) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:44) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:39) at org.activiti.engine.impl.RuntimeServiceImpl.startProcessInstanceById(RuntimeServiceImpl.java:114) at org.destiny.activiti.coreapi.RepositoryServiceTest.testSuspend(RepositoryServiceTest.java:86) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.activiti.engine.test.ActivitiRule$1.evaluate(ActivitiRule.java:116) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) 09:12:43,895 [main] ERROR org.destiny.activiti.coreapi.RepositoryServiceTest - 启动失败, 原因: Cannot start process instance. Process definition null (id = my-process:1:3) is suspended 09:12:43,897 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 激活后开始启动 09:12:43,923 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 激活后启动成功 5.1.3 绑定用户/用户组 测试代码: 123456789101112131415161718192021222324252627282930/** * 测试用户组 * repositoryService 只提供了构建关系的方式, 具体的校验逻辑需要自己完成 * 可以取出用户/用户组信息, 自行通过逻辑判断 */@Test@org.activiti.engine.test.Deployment(resources = "org/destiny/activiti/my-process.bpmn20.xml")public void testCandidateStarter() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().singleResult(); String processDefinitionId = processDefinition.getId(); logger.info("processDefinitionId: &#123;&#125;", processDefinitionId); // userId/groupM 是对应的用户/用户组管理服务中创建的 id repositoryService.addCandidateStarterUser(processDefinitionId, "user"); repositoryService.addCandidateStarterGroup(processDefinitionId, "groupM"); List&lt;IdentityLink&gt; identityLinkList = repositoryService.getIdentityLinksForProcessDefinition(processDefinitionId); for (IdentityLink identityLink : identityLinkList) &#123; logger.info("删除前: identityLink: [&#123;&#125;]", identityLink); &#125; repositoryService.deleteCandidateStarterGroup(processDefinitionId, "groupM"); repositoryService.deleteCandidateStarterUser(processDefinitionId, "user"); List&lt;IdentityLink&gt; identityLinkList1 = repositoryService.getIdentityLinksForProcessDefinition(processDefinitionId); for (IdentityLink identityLink : identityLinkList1) &#123; logger.info("删除后: identityLink: [&#123;&#125;]", identityLink); &#125;&#125; 日志输出: 10:08:35,380 [main] INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [activiti.cfg.xml] 10:08:36,784 [main] INFO org.activiti.engine.compatibility.DefaultActiviti5CompatibilityHandlerFactory - Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. 10:08:36,796 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql 10:08:36,842 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql 10:08:36,846 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql 10:08:36,849 [main] INFO org.activiti.engine.impl.ProcessEngineImpl - ProcessEngine default created 10:08:37,009 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinitionId: my-process:1:3 10:08:37,016 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 删除前: identityLink: [IdentityLinkEntity[id=4, type=candidate, userId=user, processDefId=my-process:1:3]] 10:08:37,016 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 删除前: identityLink: [IdentityLinkEntity[id=5, type=candidate, groupId=groupM, processDefId=my-process:1:3]] 5.2 RuntimeService 流程运行控制服务功能: 启动流程及对流程数据的控制 流程实例(ProcessInstance)与执行流(Execution)查询(当创建实例的时候, 一般也会创建一个执行流) 触发流程操作, 接受信号的消息 Runtime 启动流程及变量管理: 启动流程的常用方式(id, key, message) 启动流程可选参数: businessKey variables tenantId 变量(variables)的设置和获取 5.2.1 基本操作5.2.1.1 根据流程定义 key 启动流程 每次流程部署时, 对应 ProcessDefintion 的 id 和 version 都会改变, 根据 ProcessDefintionKey 默认取最后一个版本的数据 1234567891011@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testStartProcess() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance);&#125; 5.2.1.2 根据流程定义 id 使用 ProcessDefintionId 进行获取的时候, 需要先通过 RepositoryService 获取到对应的 id 1234567891011121314/** * 根据流程定义 id 启动流程 */@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testStartProcessById() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().singleResult(); RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); ProcessInstance processInstance = runtimeService.startProcessInstanceById(processDefinition.getId(), variables); log.info("processInstance: &#123;&#125;", processInstance);&#125; 5.2.1.3 通过 ProcessInstanceBuilder 完成流程的设置以及启动12345678910111213@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testProcessBuilder() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); ProcessInstance processInstance = runtimeService.createProcessInstanceBuilder() .businessKey("businessKey001") .processDefinitionKey("my-process") .variables(variables) .start(); log.info("processInstance: &#123;&#125;", processInstance);&#125; 5.2.1.4 设置和获取流程变量1234567891011121314151617@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testVariables() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); variables.put("key2", "value2"); variables.put("key3", "value3"); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance); // 覆盖原有内容 runtimeService.setVariable(processInstance.getId(), "key3", "newValue4"); runtimeService.setVariable(processInstance.getId(), "key4", "value4"); // 根据流程实例 id 获取流程变量 Map&lt;String, Object&gt; map = runtimeService.getVariables(processInstance.getId()); log.info("variable map: &#123;&#125;", map);&#125; 日志输出: 11:55:06.844 [main] [INFO] variable map: {key1=value1, key2=value2, key3=newValue4, key4=value4} o.d.a.c.RuntimeServiceTest.testVariables:94 5.2.1.5 对流程实例的查询123456789101112@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testProcessInstanceQuery() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance); ProcessInstance processInstance1 = runtimeService.createProcessInstanceQuery() .processInstanceId(processInstance.getId()) .singleResult(); log.info("processInstance1: &#123;&#125;", processInstance1);&#125; 5.2.1.6 对执行流的查询12345678910111213@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testExecutionQuery() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance); List&lt;Execution&gt; executionList = runtimeService.createExecutionQuery() .listPage(0, 100); for (Execution execution : executionList) &#123; log.info("execution: &#123;&#125;", execution); &#125;&#125; 5.2.2 流程实例与执行流 流程实例(ProcessInstance) 表示一次工作流业务的数据实体, 当每次启动流程的时候, 生成一个流程实例 执行流(Execution) 表示流程实例中具体的执行路径, 如果简单的流程只有一条执行路径, 那么此时流程实例和执行流是一对一的关系 流程实例接口继承与执行流 5.2.3 流程触发 使用 trigger 触发 receiveTask 节点 触发信号捕获事件 singalEventRecivied(信号可以全局发送) 触发消息捕获事件 messageEventReceived(消息只能针对某一个流程实例) 5.2.3.1 流程触发 trigger 流程配置文件12345678910111213141516&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!--&lt;userTask id="someTask" name="Activiti is awesome!"/&gt;--&gt; &lt;receiveTask id="someTask"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567891011121314151617@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-trigger.bpmn20.xml"&#125;)public void testTrigger() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); // 开始流程后流程实例就会在 receiveTask 节点等待处理 Execution execution = runtimeService.createExecutionQuery() .activityId("someTask") .singleResult(); log.info("execution: &#123;&#125;", execution); runtimeService.trigger(execution.getId()); // 再次查询 execution = runtimeService.createExecutionQuery() .activityId("someTask") .singleResult(); log.info("execution: &#123;&#125;", execution);&#125; 输出日志1214:59:58.256 [main] [INFO] execution: Execution[ id &apos;5&apos; ] - activity &apos;someTask - parent &apos;4&apos; o.d.a.c.RuntimeServiceTest.testTrigger:13714:59:58.291 [main] [INFO] execution: null o.d.a.c.RuntimeServiceTest.testTrigger:142] 当完成了触发之后, 执行对象已经执行完成 5.2.3.2 流程触发 singalEventReceived 流程开始后, 流程会暂停在中间节点(SingalCatchingEvent), 当它获取到信号时间的时候, 才会继续流转 流程定义文件12345678910111213141516171819&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;signal id="signalStart" name="my-signal"/&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="signal-received"/&gt; &lt;!-- 定义捕获边界事件, 当该节点接收到 my-signal 信号后会继续向后流转 --&gt; &lt;intermediateCatchEvent id="signal-received"&gt; &lt;signalEventDefinition signalRef="signalStart"/&gt; &lt;/intermediateCatchEvent&gt; &lt;!--&lt;userTask id="someTask" name="Activiti is awesome!"/&gt;--&gt; &lt;sequenceFlow id="flow2" sourceRef="signal-received" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码123456789101112131415161718@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-signal.bpmn20.xml"&#125;)public void testSignalEventReceived() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); // 查询数据库是否有一个正在等待信号的节点 Execution execution = runtimeService.createExecutionQuery() .signalEventSubscriptionName("my-signal") .singleResult(); log.info("execution: &#123;&#125;", execution); // 触发信号 runtimeService.signalEventReceived("my-signal"); // 重新执行查询 execution = runtimeService.createExecutionQuery() .signalEventSubscriptionName("my-signal") .singleResult(); log.info("execution: &#123;&#125;", execution);&#125; 日志输出15:14:42.184 [main] [INFO] execution: Execution[ id &apos;5&apos; ] - activity &apos;signal-received - parent &apos;4&apos; o.d.a.c.RuntimeServiceTest.testSignalEventReceived:155 15:14:42.216 [main] [INFO] execution: null o.d.a.c.RuntimeServiceTest.testSignalEventReceived:163 5.2.3.3 流程触发 messageEventReceived 消息触发与信号触发非常相似, 唯一的不同是: 信号与具体的流程实例无关, 消息在执行过程中必须制定流程实例 id 流程定义文件12345678910111213141516171819&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;message id="messageStart" name="my-message"/&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="message-received"/&gt; &lt;!-- 定义捕获边界事件, 当该节点接收到 my-message 消息后会继续向后流转 --&gt; &lt;intermediateCatchEvent id="message-received"&gt; &lt;messageEventDefinition messageRef="messageStart"/&gt; &lt;/intermediateCatchEvent&gt; &lt;!--&lt;userTask id="someTask" name="Activiti is awesome!"/&gt;--&gt; &lt;sequenceFlow id="flow2" sourceRef="message-received" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码123456789101112131415161718@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-message.bpmn20.xml"&#125;)public void testMessageEventReceived() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); // 查询数据库是否有一个正在等待信号的节点 Execution execution = runtimeService.createExecutionQuery() .messageEventSubscriptionName("my-message") // 查询订阅了该信号的执行流 .singleResult(); log.info("execution: &#123;&#125;", execution); // 触发消息, 不同于信号的触发, message 在触发时需要指定 executionId runtimeService.messageEventReceived("my-message", execution.getId()); // 重新执行查询 execution = runtimeService.createExecutionQuery() .messageEventSubscriptionName("my-message") .singleResult(); log.info("execution: &#123;&#125;", execution);&#125; 日志输出15:37:52.024 [main] [INFO] execution: Execution[ id &apos;5&apos; ] - activity &apos;message-received - parent &apos;4&apos; o.d.a.c.RuntimeServiceTest.testMessageEventReceived:175 15:37:52.054 [main] [INFO] execution: null o.d.a.c.RuntimeServiceTest.testMessageEventReceived:183 5.2.3.4 流程基于 message 启动流程定义12345678910111213141516171819&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;!-- 此时既可以基于 key 启动, 也可以基于 message 启动 --&gt; &lt;message id="messageStart" name="my-message"/&gt; &lt;process id="my-process"&gt; &lt;!-- 需要将 messageEventDefinition 放在开始节点 --&gt; &lt;startEvent id="start"&gt; &lt;messageEventDefinition messageRef="messageStart"/&gt; &lt;/startEvent&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-message-start.bpmn20.xml"&#125;)public void testMessageStart() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByMessage("my-message"); log.info("processInstance: &#123;&#125;", processInstance);&#125; 日志输出15:45:12.844 [main] [INFO] processInstance: ProcessInstance[5] o.d.a.c.RuntimeServiceTest.testMessageStart:195 基于 message 启动流程时, ProcessInstance 的 id 是 5, 意味着在流程订阅表中多插入了一条数据, 在实际启动过程中, 还是通过 message 找到 ProcessDefinition 的 key, 最终根据 key 来启动 5.3 TaskService 任务管理服务TaskService 提供的功能: 对用户任务管理和流程的控制 设置用户任务的权限信息(拥有者/候选人/办理人) 针对用户任务添加任务附件, 任务评论和事件记录 TaskService 对 Task 管理与流程控制: Task 对象的创建, 删除 查询 Task, 并驱动 Task 节点完成执行 Task 相关参数变量设置 local 变量 非 local 变量 5.3.1 基本操作5.3.1.1 获取 task/ 设置变量/ 驱动完成流程定义文件1234567891011121314151617181920&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!-- 添加候选人 --&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:candidateUsers="destiny,destiny1,destiny2"&gt; &lt;!-- 添加描述, message 会根据上下文中传入的 message 变量值去替换 --&gt; &lt;documentation&gt; some task $&#123;message&#125; &lt;/documentation&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码12345678910111213141516171819202122232425262728293031323334@Test @Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;) public void testTaskService() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); TaskService taskService = activitiRule.getTaskService(); // 部署流程定义文件 ProcessInstance processInstance = activitiRule.getRuntimeService() .startProcessInstanceByKey("my-process", variables); Task task = taskService.createTaskQuery().singleResult(); log.info("task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); log.info("task.description: &#123;&#125;", task.getDescription()); // 设置变量 taskService.setVariable(task.getId(), "k1", "v1"); taskService.setVariableLocal(task.getId(), "localK1", "localV1"); // local 只在 task 范围可见 Map&lt;String, Object&gt; taskServiceVariables = taskService.getVariables(task.getId()); Map&lt;String, Object&gt; taskServiceVariablesLocal = taskService.getVariablesLocal(task.getId()); // 根据流程获取 Map&lt;String, Object&gt; processVariables = activitiRule.getRuntimeService().getVariables(task.getExecutionId()); log.info("taskServiceVariables: &#123;&#125;", taskServiceVariables); // &#123;k1=v1, localK1=localV1, message=my test message&#125; log.info("taskServiceVariablesLocal: &#123;&#125;", taskServiceVariablesLocal); // &#123;localK1=localV1&#125; log.info("processVariables: &#123;&#125;", processVariables); // &#123;k1=v1, message=my test message&#125; Map&lt;String, Object&gt; completeVar = Maps.newHashMap(); completeVar.put("cKey1", "cValue1"); taskService.complete(task.getId(), completeVar); Task task1 = taskService.createTaskQuery().taskId(task.getId()).singleResult(); log.info("task1: &#123;&#125;", task1); &#125; 日志输出16:13:26.654 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 16:13:28.438 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 16:13:28.451 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:13:28.527 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:13:28.535 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:13:28.541 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 16:13:28.793 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.796 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.798 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.799 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.800 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.800 [main] [INFO] 4 (process instance) └── 6 : start -&gt; someTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.802 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.802 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.878 [main] [INFO] task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;some task my test message&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Mon Dec 03 16:13:28 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;6&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;9&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskService:33 16:13:28.878 [main] [INFO] task.description: some task my test message o.d.a.c.TaskServiceTest.testTaskService:34 16:13:28.893 [main] [INFO] taskServiceVariables: {k1=v1, localK1=localV1, message=my test message} o.d.a.c.TaskServiceTest.testTaskService:46 16:13:28.893 [main] [INFO] taskServiceVariablesLocal: {localK1=localV1} o.d.a.c.TaskServiceTest.testTaskService:47 16:13:28.893 [main] [INFO] processVariables: {k1=v1, message=my test message} o.d.a.c.TaskServiceTest.testTaskService:48 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : someTask -&gt; end, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] task1: null o.d.a.c.TaskServiceTest.testTaskService:55 5.3.1.2 TaskService 设置 Task 权限信息 候选用户(candidateUser) 和候选组(candidateGroup) 指定拥有人(Owner)和办理人(Assignee) 通过 claim 设置办理人(发现 task 已经有指定办理人且不是 claim 指定的人就会抛出异常) 流程定义1234567891011121314151617181920&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!-- 添加候选人 --&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:candidateUsers="destiny,destiny1,destiny2"&gt; &lt;!-- 添加描述, message 会根据上下文中传入的 message 变量值去替换 --&gt; &lt;documentation&gt; some task $&#123;message&#125; &lt;/documentation&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;)public void testTaskServiceUser() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); TaskService taskService = activitiRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); log.info("task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); log.info("task.description: &#123;&#125;", task.getDescription()); taskService.setOwner(task.getId(), "user1"); // 可能存在覆盖已有代办放的问题, 因此不推荐 // taskService.setAssignee(task.getId(), "destiny"); // 查询在候选人列表, 且未指定办理人的 task 列表 List&lt;Task&gt; taskList = taskService.createTaskQuery() .taskCandidateOrAssigned("destiny") .taskUnassigned() .listPage(0, 100); // 使用 claim 设置候选人 for (Task task1 : taskList) &#123; try &#123; taskService.claim(task1.getId(), "destiny"); &#125; catch (Exception e) &#123; log.warn(e.getMessage(), e); &#125; &#125; // 查看当前 task 的所有用户关系内容 List&lt;IdentityLink&gt; identityLinkList = taskService.getIdentityLinksForTask(task.getId()); for (IdentityLink identityLink : identityLinkList) &#123; log.info("identityLink: &#123;&#125;", identityLink); &#125; // 完成任务, 首先找到处于代办状态的所有 task List&lt;Task&gt; destinys = taskService.createTaskQuery().taskAssignee("destiny").listPage(0, 100); for (Task destiny : destinys) &#123; variables.clear(); variables.put("cKey1", "cValue1"); taskService.complete(destiny.getId(), variables); &#125; destinys = taskService.createTaskQuery().taskAssignee("destiny").listPage(0, 100); log.info("是否存在: &#123;&#125;", CollectionUtils.isEmpty(destinys));&#125; 输出日志16:41:28.534 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 16:41:30.373 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 16:41:30.385 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:41:30.443 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:41:30.449 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:41:30.453 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 16:41:30.631 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.636 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.638 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.638 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.639 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.640 [main] [INFO] 4 (process instance) └── 6 : start -&gt; someTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.640 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.641 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.715 [main] [INFO] task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;some task my test message&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Mon Dec 03 16:41:30 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;6&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;9&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskServiceUser:69 16:41:30.715 [main] [INFO] task.description: some task my test message o.d.a.c.TaskServiceTest.testTaskServiceUser:70 16:41:30.739 [main] [INFO] identityLink: IdentityLinkEntity[id=10, type=candidate, userId=destiny, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=12, type=candidate, userId=destiny1, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=14, type=candidate, userId=destiny2, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=null, type=assignee, userId=destiny, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=null, type=owner, userId=user1, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.749 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.751 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.752 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.753 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.754 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.754 [main] [INFO] 4 (process instance) └── 6 : someTask -&gt; end, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.755 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.755 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.755 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.755 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.757 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.757 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.770 [main] [INFO] 是否存在: true o.d.a.c.TaskServiceTest.testTaskServiceUser:106 5.3.2 TaskService 设置 Task 附加信息 任务附件(Attachment)创建与查询 任务评论(Comment)创建与查询 事件记录(Event)创建于查询 5.3.2.1 任务附件(Attachment)创建与查询流程定义同上 测试代码12345678910111213141516@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;)public void testTaskAttachment() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); TaskService taskService = activitiRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); // 可以上传数据流或 url Attachment attachment = taskService.createAttachment("url", task.getId(), task.getProcessInstanceId(), "name", "desc", "/url/test.png"); log.info("attachment: &#123;&#125;", attachment); List&lt;Attachment&gt; taskAttachments = taskService.getTaskAttachments(task.getId()); for (Attachment taskAttachment : taskAttachments) &#123; log.info("taskAttachment: &#123;&#125;", ToStringBuilder.reflectionToString(taskAttachment, ToStringStyle.JSON_STYLE)); &#125;&#125; 日志输出17:12:47.043 [main] [INFO] attachment: org.activiti.engine.impl.persistence.entity.AttachmentEntityImpl@72b16078 o.d.a.c.TaskServiceTest.testTaskAttachment:119 17:12:47.050 [main] [INFO] taskAttachment: {&quot;name&quot;:&quot;name&quot;,&quot;description&quot;:&quot;desc&quot;,&quot;type&quot;:&quot;url&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;url&quot;:&quot;/url/test.png&quot;,&quot;contentId&quot;:null,&quot;content&quot;:null,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:12:47 CST 2018&quot;,&quot;id&quot;:&quot;16&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskAttachment:122 5.3.2.2 任务评论(Comment)创建与查询流程定义同上 测试代码123456789101112131415161718192021@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;)public void testTaskComment() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); TaskService taskService = activitiRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); // 添加评论 taskService.addComment(task.getId(), task.getProcessInstanceId(), "record note1"); taskService.addComment(task.getId(), task.getProcessInstanceId(), "record note2"); List&lt;Comment&gt; taskComments = taskService.getTaskComments(task.getId()); for (Comment taskComment : taskComments) &#123; log.info("taskComment: &#123;&#125;", ToStringBuilder.reflectionToString(taskComment, ToStringStyle.JSON_STYLE)); &#125; // 事件记录 List&lt;Event&gt; taskEvents = taskService.getTaskEvents(task.getId()); for (Event taskEvent : taskEvents) &#123; log.info("taskEvent: &#123;&#125;", ToStringBuilder.reflectionToString(taskEvent, ToStringStyle.JSON_STYLE)); &#125;&#125; 日志输出17:05:17.107 [main] [INFO] taskComment: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note2&quot;,&quot;fullMessage&quot;:&quot;record note2&quot;,&quot;id&quot;:&quot;17&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:140 17:05:17.107 [main] [INFO] taskComment: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note1&quot;,&quot;fullMessage&quot;:&quot;record note1&quot;,&quot;id&quot;:&quot;16&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:140 17:05:17.109 [main] [INFO] taskEvent: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note2&quot;,&quot;fullMessage&quot;:&quot;record note2&quot;,&quot;id&quot;:&quot;17&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:146 17:05:17.110 [main] [INFO] taskEvent: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note1&quot;,&quot;fullMessage&quot;:&quot;record note1&quot;,&quot;id&quot;:&quot;16&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:146 Comment 和 Event 的区别所有对 task 的操作都会生成新的 Event 记录, comment 只是其中的一种, 比如在上例中新增 owner 或 assignee, 也会产生新的 event 记录 5.4 身份管理服务 Activiti 提供了相对比较简单的用户/用户组管理 主要功能: 管理用户(User) 管理用户组(Group) 用户与用户组的关系(Membership)(多对多关系) 5.4.1 创建用户/用户组/对应关系流程定义 此处不需要基于流程定义完成 测试代码123456789101112131415161718192021222324252627282930313233343536373839404142@Slf4jpublic class IdentityServiceTest &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test public void testIdentity() &#123; IdentityService identityService = activitiRule.getIdentityService(); User user1 = identityService.newUser("user1"); user1.setEmail("destinywk@163.com"); User user2 = identityService.newUser("user2"); user2.setEmail("destinywk@126.com"); identityService.saveUser(user1); identityService.saveUser(user2); Group group1 = identityService.newGroup("group1"); identityService.saveGroup(group1); Group group2 = identityService.newGroup("group2"); identityService.saveGroup(group2); // 创建关系 identityService.createMembership("user1", "group1"); identityService.createMembership("user2", "group1"); identityService.createMembership("user1", "group2"); List&lt;User&gt; userList = identityService.createUserQuery() .memberOfGroup("group1") .listPage(0, 100); for (User user : userList) &#123; log.info("user: &#123;&#125;", ToStringBuilder.reflectionToString(user, ToStringStyle.JSON_STYLE)); &#125; List&lt;Group&gt; groupList = identityService.createGroupQuery() .groupMember("user1").listPage(0, 100); for (Group group : groupList) &#123; log.info("group: &#123;&#125;", ToStringBuilder.reflectionToString(group, ToStringStyle.JSON_STYLE)); &#125; &#125;&#125; 日志输出17:37:12.982 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 17:37:14.894 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 17:37:14.910 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 17:37:14.971 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 17:37:14.978 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 17:37:14.982 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 17:37:15.041 [main] [INFO] user: {&quot;firstName&quot;:null,&quot;lastName&quot;:null,&quot;email&quot;:&quot;destinywk@163.com&quot;,&quot;password&quot;:null,&quot;pictureByteArrayRef&quot;:&quot;ByteArrayRef[id=null, name=null, entity=null]&quot;,&quot;id&quot;:&quot;user1&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:46 17:37:15.042 [main] [INFO] user: {&quot;firstName&quot;:null,&quot;lastName&quot;:null,&quot;email&quot;:&quot;destinywk@126.com&quot;,&quot;password&quot;:null,&quot;pictureByteArrayRef&quot;:&quot;ByteArrayRef[id=null, name=null, entity=null]&quot;,&quot;id&quot;:&quot;user2&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:46 17:37:15.048 [main] [INFO] group: {&quot;name&quot;:null,&quot;type&quot;:null,&quot;id&quot;:&quot;group1&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:52 17:37:15.048 [main] [INFO] group: {&quot;name&quot;:null,&quot;type&quot;:null,&quot;id&quot;:&quot;group2&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:52 身份管理服务的调用过程: 会将 User 封装成一个 Command, 交由命令执行器去执行, 最后调用 MyBatis 底层接口去操作 DB 5.5 表单管理服务 FormService功能: 解析流程定义中表单项的配置 提供提交表单的方式驱动用户节点流转 获取自定义外部表单 key 5.5.1流程定义123456789101112131415161718192021222324&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start" activiti:formKey="/rest/process/form/start"&gt; &lt;!-- 配置表单项 --&gt; &lt;extensionElements&gt; &lt;activiti:formProperty id="message" name="信息" type="string" required="true"/&gt; &lt;/extensionElements&gt; &lt;/startEvent&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:formKey="/rest/process/form/userTask"&gt; &lt;extensionElements&gt; &lt;!-- 配置表单项 --&gt; &lt;activiti:formProperty id="yesOrNo" name="审批" type="string" required="true"/&gt; &lt;/extensionElements&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567891011121314151617181920212223242526272829303132333435363738@Slf4jpublic class FormServiceTest &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test @Deployment(resources = &#123;"org/destiny/activiti/my-process-form.bpmn20.xml"&#125;) public void testFormService() &#123; FormService formService = activitiRule.getFormService(); // 获取流程定义文件 ProcessDefinition processDefinition = activitiRule.getRepositoryService().createProcessDefinitionQuery().singleResult(); // 获取 startForm 的 key 和 data String startFormKey = formService.getStartFormKey(processDefinition.getId()); log.info("startFormKey: &#123;&#125;", startFormKey); StartFormData startFormData = formService.getStartFormData(processDefinition.getId()); log.info("startFormKey: &#123;&#125;", ToStringBuilder.reflectionToString(startFormData, ToStringStyle.JSON_STYLE)); for (FormProperty startFormProperty : startFormData.getFormProperties()) &#123; log.info("startFormProperty: &#123;&#125;", ToStringBuilder.reflectionToString(startFormProperty, ToStringStyle.JSON_STYLE)); &#125; // 启动流程 Map&lt;String, String&gt; properties = Maps.newHashMap(); properties.put("message", "my test message"); formService.submitStartFormData(processDefinition.getId(), properties); // 查询 task Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); // 获取 taskForm 的 data TaskFormData taskFormData = formService.getTaskFormData(task.getId()); log.info("taskFormData: &#123;&#125;", ToStringBuilder.reflectionToString(taskFormData, ToStringStyle.JSON_STYLE)); for (FormProperty taskFormProperty : taskFormData.getFormProperties()) &#123; log.info("taskFormProperty: &#123;&#125;", ToStringBuilder.reflectionToString(taskFormProperty, ToStringStyle.JSON_STYLE)); &#125; &#125;&#125; 日志输出18:15:27.539 [main] [INFO] startFormKey: /rest/process/form/start o.d.a.c.FormServiceTest.testFormService:36 18:15:27.547 [main] [INFO] startFormKey: {&quot;processDefinition&quot;:&quot;ProcessDefinitionEntity[my-process:1:3]&quot;,&quot;formKey&quot;:&quot;/rest/process/form/start&quot;,&quot;deploymentId&quot;:&quot;1&quot;,&quot;formProperties&quot;:[org.activiti.engine.impl.form.FormPropertyImpl@3bde62ff]} o.d.a.c.FormServiceTest.testFormService:38 18:15:27.547 [main] [INFO] startFormProperty: {&quot;id&quot;:&quot;message&quot;,&quot;name&quot;:&quot;信息&quot;,&quot;type&quot;:&quot;org.activiti.engine.impl.form.StringFormType@2baa8d82&quot;,&quot;isRequired&quot;:true,&quot;isReadable&quot;:true,&quot;isWritable&quot;:true,&quot;value&quot;:null} o.d.a.c.FormServiceTest.testFormService:40 18:15:27.561 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.564 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.565 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.566 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.567 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.567 [main] [INFO] 4 (process instance) └── 5 : start -&gt; someTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.568 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.568 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.602 [main] [INFO] taskFormData: {&quot;task&quot;:&quot;Task[id=10, name=Activiti is awesome!]&quot;,&quot;formKey&quot;:&quot;/rest/process/form/userTask&quot;,&quot;deploymentId&quot;:&quot;1&quot;,&quot;formProperties&quot;:[org.activiti.engine.impl.form.FormPropertyImpl@4e4efc1b]} o.d.a.c.FormServiceTest.testFormService:53 18:15:27.602 [main] [INFO] taskFormProperty: {&quot;id&quot;:&quot;yesOrNo&quot;,&quot;name&quot;:&quot;审批&quot;,&quot;type&quot;:&quot;org.activiti.engine.impl.form.StringFormType@2baa8d82&quot;,&quot;isRequired&quot;:true,&quot;isReadable&quot;:true,&quot;isWritable&quot;:true,&quot;value&quot;:null} o.d.a.c.FormServiceTest.testFormService:55 5.6 HistoryService 历史数据管理服务作用: 管理流程实例哦结束后的历史数据 构建历史数据的查询对象 根据流程实例 id 删除流程历史数据 历史数据实体 描述 HistoricProcessInstance 历史流程实例实体类 HistoricVariableInstance 流程或任务变量值的实体 HistoricActivityInstance 单个活动节点执行的信息 HistoricTaskInstance 用户任务实例的信息 HistoricDetail 历史流程活动任务详细信息 HistoryService 构建历史查询对象: create[历史数据实体]Query createNative[历史数据实体]Query createProcessInstanceHistoryLogQuery: 只能查出一个流程实例的一个对象, 每次只能查出一条记录, 包含流程实体所有的其他数据, 包括task, Activiti, comment 等信息 HistoryService 删除历史操作 deleteHistoricProcessInstance, 采用级联操作, 删除与流程实例相关的所有历史信息 deleteHistoricTaskInstance, 范围相对较小, 只删除 Task 及 Task 相关的变量 5.7 ManagementService 管理服务作用: Job 任务管理 数据库相关通用操作 执行流程引擎命令(Command) 5.7.1 Job 任务管理 工作查询对象 描述 JobQuery 查询一般工作 TimerJobQuery 查询定时任务 SuspendedKobQUery 查询中断工作 DeadLetterJobQuery 查询无法执行的工作(一般重试三次) 5.7.2 数据库相关操作 查询表结构元数据 通用表查询 执行自定义的 sql 查询 5.8 DynamicBpmnService 动态流程定义服务 不推荐使用 6 数据库设计和模型映射 数据表分类 描述 ACT_GE_* 通用数据表 ACT_RE_* 流程定义存储表 ACT_ID_* 身份信息表 ACT_RU_* 运行时数据库表 ACT_HI_* 历史数据库表 6.1 MySql 建表语句 除了核心引擎是必选的, 其他两个不是必须的 核心引擎: activiti.mysql.create.engine.sql 历史数据: activiti.mysql.create.history.sql 身份信息: activiti.mysql.create.identity.sql 6.1.1 通用数据库 数据表分类 描述 ACT_GE_PROPERTY 属性表(保存流程引擎的 key-value 键值属性) ACT_GE_BYTEARRAY 资源表(存储流程定义相关的资源) 7 BPMN2.0 概述 是一套业务流程模型与符号建模标准 精准的执行语义来描述元素的操作 以 XML 为载体, 以符号可视化业务 BPMN2.0元素: 流对象 连接对象 数据 泳道 描述对象 7.1 流对象 活动(Activities): User Task, Service Task… 事件(Events): Start Event, End Event… 网关(Gateway): Exclusive Gateway… 8 Activiti 集成 Spring BootActiviti6.0 依赖的 SpringBoot 版本是 1.2.6 如果直接与 SpringBoot 2.0.0 集成的话, 会出现 ClassNotFound 等问题 因此在集成 SpringBoot 2.0.0 的时候, 需要 Activiti6.0 源码进行部分改动 升级 Activiti 6.0 依赖 SpringBoot 版本为 2.0.0 的改动 升级 SpringBoot 依赖并解决编译错误 更新 activiti-spring-boot-starter-basic 版本并安装 集成使用 Activiti 的 AutoConfiguration 功能 如果直接将 SpringBoot 2.0.0 和 activiti-spring-boot-starter-basic 6.0.0 集成, 会发生如下错误: java.lang.IllegalStateException: Failed to load ApplicationContext Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;documentationPluginsBootstrapper&apos; defined in URL [jar:file:/Users/destiny/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar!/springfox/documentation/spring/web/plugins/DocumentationPluginsBootstrapper.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;webMvcRequestHandlerProvider&apos; defined in URL [jar:file:/Users/destiny/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;requestMappingHandlerMapping&apos; defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;webMvcRequestHandlerProvider&apos; defined in URL [jar:file:/Users/destiny/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;requestMappingHandlerMapping&apos; defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;requestMappingHandlerMapping&apos; defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... Caused by: java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... 真正的原因是对应的类无法找到 8.1 修改 activiti 源码以适应 SpringBoot 2.0.0 版本升级8.1.1 将 activiti 中 SpringBoot 依赖升级到 2.0.0修改 Activiti 源码中 modules/activiti-spring-boot/pom.xml pom 文件, 将其中 1&lt;spring.boot.version&gt;1.2.6.RELEASE&lt;/spring.boot.version&gt; 修改为 1&lt;spring.boot.version&gt;2.0.0.RELEASE&lt;/spring.boot.version&gt; 然后重新编译源码, 此时以下几个类会报错 8.1.1.1 org.activiti.spring.boot.actuate.endpoint.ProcessEngineEndpoint 主要的问题是 SpringBoot 从 1 升级到 2 的时候, 对 EndPoint 的使用方式发生了改变:1.x 是继承一个抽象类 AbstractEndpoint2.x 修改为使用对应的注解 修改后的源码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package org.activiti.spring.boot.actuate.endpoint;import org.activiti.engine.ProcessEngine;import org.activiti.engine.impl.cfg.ProcessEngineConfigurationImpl;import org.activiti.engine.impl.persistence.deploy.DefaultDeploymentCache;import org.activiti.engine.impl.persistence.deploy.DeploymentCache;import org.activiti.engine.impl.persistence.deploy.ProcessDefinitionCacheEntry;import org.activiti.engine.repository.ProcessDefinition;import org.springframework.boot.actuate.endpoint.annotation.Endpoint;import org.springframework.boot.actuate.endpoint.annotation.ReadOperation;import java.util.*;/** * Registers a Boot Actuator endpoint that provides information on the * running process instance and renders BPMN diagrams of the deployed processes. * * @author Josh Long *///@ConfigurationProperties(prefix = "endpoints.activiti")@Endpoint(id = "activiti") // 使用注解 Endpointpublic class ProcessEngineEndpoint &#123; // 不再继承 AbstractEndpoint private final ProcessEngine processEngine; public ProcessEngineEndpoint(ProcessEngine processEngine) &#123; this.processEngine = processEngine; // 不再继承 Endpoint, 因此不需要调用 super 构造方法 &#125; @ReadOperation // 不需要 @Override public Map&lt;String, Object&gt; activiti() &#123; Map&lt;String, Object&gt; metrics = new HashMap&lt;String, Object&gt;(); // Process definitions metrics.put("processDefinitionCount", processEngine.getRepositoryService().createProcessDefinitionQuery().count()); // List of all process definitions List&lt;ProcessDefinition&gt; processDefinitions = processEngine.getRepositoryService().createProcessDefinitionQuery().orderByProcessDefinitionKey().asc().list(); List&lt;String&gt; processDefinitionKeys = new ArrayList&lt;String&gt;(); for (ProcessDefinition processDefinition : processDefinitions) &#123; processDefinitionKeys.add(processDefinition.getKey() + " (v" + processDefinition.getVersion() + ")"); &#125; metrics.put("deployedProcessDefinitions", processDefinitionKeys); // Process instances Map&lt;String, Object&gt; processInstanceCountMap = new HashMap&lt;String, Object&gt;(); metrics.put("runningProcessInstanceCount", processInstanceCountMap); for (ProcessDefinition processDefinition : processDefinitions) &#123; processInstanceCountMap.put(processDefinition.getKey() + " (v" + processDefinition.getVersion() + ")", processEngine.getRuntimeService().createProcessInstanceQuery().processDefinitionId(processDefinition.getId()).count()); &#125; Map&lt;String, Object&gt; completedProcessInstanceCountMap = new HashMap&lt;String, Object&gt;(); metrics.put("completedProcessInstanceCount", completedProcessInstanceCountMap); for (ProcessDefinition processDefinition : processDefinitions) &#123; completedProcessInstanceCountMap.put(processDefinition.getKey() + " (v" + processDefinition.getVersion() + ")", processEngine.getHistoryService().createHistoricProcessInstanceQuery().finished().processDefinitionId(processDefinition.getId()).count()); &#125; // Open tasks metrics.put("openTaskCount", processEngine.getTaskService().createTaskQuery().count()); metrics.put("completedTaskCount", processEngine.getHistoryService().createHistoricTaskInstanceQuery().finished().count()); // Tasks completed today metrics.put("completedTaskCountToday", processEngine.getHistoryService().createHistoricTaskInstanceQuery().finished().taskCompletedAfter( new Date(System.currentTimeMillis() - secondsForDays(1))).count()); // Process steps metrics.put("completedActivities", processEngine.getHistoryService().createHistoricActivityInstanceQuery().finished().count()); // Process definition cache DeploymentCache&lt;ProcessDefinitionCacheEntry&gt; deploymentCache = ((ProcessEngineConfigurationImpl) processEngine.getProcessEngineConfiguration()).getProcessDefinitionCache(); if (deploymentCache instanceof DefaultDeploymentCache) &#123; metrics.put("cachedProcessDefinitionCount", ((DefaultDeploymentCache) deploymentCache).size()); &#125; return metrics; &#125; private long secondsForDays(int days) &#123; int hour = 60 * 60 * 1000; int day = 24 * hour; return days * day; &#125;&#125; 8.1.1.2 org.activiti.spring.boot.actuate.endpoint.ProcessEngineMvcEndpoint 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package org.activiti.spring.boot.actuate.endpoint;import java.io.InputStream;import org.activiti.bpmn.BpmnAutoLayout;import org.activiti.bpmn.model.BpmnModel;import org.activiti.engine.RepositoryService;import org.activiti.engine.repository.ProcessDefinition;import org.activiti.image.ProcessDiagramGenerator;import org.activiti.image.impl.DefaultProcessDiagramGenerator;import org.springframework.core.io.InputStreamResource;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * Renders a valid running BPMN process definition as a BPMN diagram. * * This is duplicative of the functionality in the full REST API implementation. * * @author Joram Barrez * @author Josh Long */public class ProcessEngineMvcEndpoint &#123; // 同样不再继承 EndpointMvcAdapter private final RepositoryService repositoryService; private final ProcessEngineEndpoint processEngineEndpoint; // 创建一个 ProcessEngineEndpoint 私有变量 public ProcessEngineMvcEndpoint(ProcessEngineEndpoint processEngineEndpoint, RepositoryService repositoryService) &#123;// super(processEngineEndpoint); this.processEngineEndpoint = processEngineEndpoint; this.repositoryService = repositoryService; &#125; /** * Look up the process definition by key. For example, * this is &lt;A href="http://localhost:8080/activiti/processes/fulfillmentProcess"&gt;process-diagram for&lt;/A&gt; * a process definition named &#123;@code fulfillmentProcess&#125;. */ @RequestMapping(value = "/processes/&#123;processDefinitionKey:.*&#125;", method = RequestMethod.GET, produces = MediaType.IMAGE_JPEG_VALUE) @ResponseBody public ResponseEntity processDefinitionDiagram(@PathVariable String processDefinitionKey) &#123; ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(processDefinitionKey) .latestVersion() .singleResult(); if (processDefinition == null) &#123; return ResponseEntity.status(HttpStatus.NOT_FOUND).body(null); &#125; ProcessDiagramGenerator processDiagramGenerator = new DefaultProcessDiagramGenerator(); BpmnModel bpmnModel = repositoryService.getBpmnModel(processDefinition.getId()); if (bpmnModel.getLocationMap().size() == 0) &#123; BpmnAutoLayout autoLayout = new BpmnAutoLayout(bpmnModel); autoLayout.execute(); &#125; InputStream is = processDiagramGenerator.generateJpgDiagram(bpmnModel); return ResponseEntity.ok(new InputStreamResource(is)); &#125;&#125; 8.1.1.3 org.activiti.spring.boot.EndpointAutoConfiguration 报错原因: SpringBoot2 不再使用 AbstractEndpoint开启该表达式 AutoConfiguration 不会生效, 因此需要删除 1234567891011121314151617181920212223242526272829303132package org.activiti.spring.boot;import org.activiti.engine.ProcessEngine;import org.activiti.engine.RepositoryService;import org.activiti.spring.boot.actuate.endpoint.ProcessEngineEndpoint;import org.activiti.spring.boot.actuate.endpoint.ProcessEngineMvcEndpoint;//import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * The idea behind this module is that Spring Security could * talk to the &#123;@link org.activiti.engine.IdentityService&#125; * as required. * * @author Josh Long */@Configuration//@ConditionalOnClass (name = "org.springframework.boot.actuate.endpoint.AbstractEndpoint")public class EndpointAutoConfiguration &#123; @Bean public ProcessEngineEndpoint processEngineEndpoint(ProcessEngine engine) &#123; return new ProcessEngineEndpoint(engine); &#125; @Bean public ProcessEngineMvcEndpoint processEngineMvcEndpoint( ProcessEngineEndpoint engineEndpoint, RepositoryService repositoryService) &#123; return new ProcessEngineMvcEndpoint(engineEndpoint, repositoryService); &#125;&#125; 8.1.1.4 org.activiti.spring.boot.DataSourceProcessEngineAutoConfiguration 报错原因: ConditionalOnMissingClass 注解中的 name 已经不能使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.activiti.spring.boot;import java.io.IOException;import javax.sql.DataSource;import org.activiti.spring.SpringAsyncExecutor;import org.activiti.spring.SpringProcessEngineConfiguration;import org.springframework.boot.autoconfigure.AutoConfigureAfter;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingClass;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;/** * @author Joram Barrez * @author Josh Long */@Configuration@AutoConfigureAfter(DataSourceAutoConfiguration.class)public class DataSourceProcessEngineAutoConfiguration &#123; @Configuration// @ConditionalOnMissingClass(name= "javax.persistence.EntityManagerFactory") @ConditionalOnMissingClass(value= "javax.persistence.EntityManagerFactory") // 将 name 替换为 value @EnableConfigurationProperties(ActivitiProperties.class) public static class DataSourceProcessEngineConfiguration extends AbstractProcessEngineAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public PlatformTransactionManager transactionManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean @ConditionalOnMissingBean public SpringProcessEngineConfiguration springProcessEngineConfiguration( DataSource dataSource, PlatformTransactionManager transactionManager, SpringAsyncExecutor springAsyncExecutor) throws IOException &#123; return this.baseSpringProcessEngineConfiguration(dataSource, transactionManager, springAsyncExecutor); &#125; &#125;&#125; 8.1.1.4 org.activiti.spring.boot.SecurityAutoConfiguration 报错原因: 包结构发生改变, 导致原有的类全路径不可用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import org.activiti.engine.IdentityService;import org.activiti.rest.security.BasicAuthenticationProvider;import org.activiti.spring.security.IdentityServiceUserDetailsService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.AutoConfigureBefore;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.authentication.AuthenticationProvider;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.authentication.configurers.GlobalAuthenticationConfigurerAdapter;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;/** * Installs a Spring Security adapter for the Activiti * &#123;@link org.activiti.engine.IdentityService&#125;. * * @author Josh Long */@Configuration//@AutoConfigureBefore(org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration.class)@AutoConfigureBefore(org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration.class) // 修改类路径public class SecurityAutoConfiguration &#123; @Configuration @ConditionalOnClass( UserDetailsService.class) public static class UserDetailsServiceConfiguration extends GlobalAuthenticationConfigurerAdapter &#123; @Override public void init(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService( userDetailsService()); &#125; @Bean public UserDetailsService userDetailsService() &#123; return new IdentityServiceUserDetailsService(this.identityService); &#125; @Autowired private IdentityService identityService; &#125; @Configuration @ConditionalOnClass(name = &#123;"org.activiti.rest.service.api.RestUrls", "org.springframework.web.servlet.DispatcherServlet"&#125;) @EnableWebSecurity public static class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public AuthenticationProvider authenticationProvider() &#123; return new BasicAuthenticationProvider(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authenticationProvider(authenticationProvider()) .csrf().disable() .authorizeRequests() .anyRequest().authenticated() .and() .httpBasic(); &#125; &#125;&#125; 8.2 对 Activiti 版本做更改12345678910111213141516171819&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starters&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;activiti-spring-boot-starter-basic&lt;/artifactId&gt; &lt;!-- 在此处新增版本 --&gt; &lt;version&gt;6.0.0-boot2&lt;/version&gt; &lt;!-- &lt;properties&gt; &lt;spring.framework.version&gt;4.1.4.RELEASE&lt;/spring.framework.version&gt; &lt;/properties&gt; --&gt; ...&lt;/project&gt; 尝试执行 mvn clean install 此时 maven 会去尝试下载 6.0.0-boot2 版本, 但显然公网仓库中不会存在 [INFO] Scanning for projects... [INFO] [INFO] ----------&lt; org.activiti:activiti-spring-boot-starter-basic &gt;----------- [INFO] Building activiti-spring-boot-starter-basic 6.0.0-boot2 [INFO] --------------------------------[ jar ]--------------------------------- [WARNING] The POM for org.activiti:activiti-engine:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-spring:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-rest:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-common-rest:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-image-generator:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-bpmn-model:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-bpmn-layout:jar:6.0.0-boot2 is missing, no dependency information available [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.850 s [INFO] Finished at: 2018-12-03T23:15:57+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal on project activiti-spring-boot-starter-basic: Could not resolve dependencies for project org.activiti:activiti-spring-boot-starter-basic:jar:6.0.0-boot2: The following artifacts could not be resolved: org.activiti:activiti-engine:jar:6.0.0-boot2, org.activiti:activiti-spring:jar:6.0.0-boot2, org.activiti:activiti-rest:jar:6.0.0-boot2, org.activiti:activiti-common-rest:jar:6.0.0-boot2, org.activiti:activiti-image-generator:jar:6.0.0-boot2, org.activiti:activiti-bpmn-model:jar:6.0.0-boot2, org.activiti:activiti-bpmn-layout:jar:6.0.0-boot2: Failure to find org.activiti:activiti-engine:jar:6.0.0-boot2 in http://maven.aliyun.com/nexus/content/groups/public was cached in the local repository, resolution will not be reattempted until the update interval of nexus-aliyun has elapsed or updates are forced -&gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException 错误原因: activiti-spring-boot-starter-basic 的版本号被修改为 6.0.0-boot2, 但安装的时候, 对应的 activiti-engine 版本只有 6.0.0, 并没有 6.0.0-boot2可以将所有需要找 6.0.0-boot2 的版本修改为去找 6.0.0 将根 pom 中所有的 ${project.version} 修改为 6.0.0]]></content>
      <categories>
        <category>Activiti</category>
        <category>Java</category>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang快速入门]]></title>
    <url>%2Fblog%2F2018%2F11%2F24%2FGolang%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[6. 函数6.2 包的引出和使用原理当调用另一个文件的函数时, 就需要在调用方引入该文件所在的 package Go 代码的每一个文件都是属于一个包的, 也就是说 Go 是以包的形式来管理文件和项目目录结构的. Go 语言中, 每个文件夹下的所有 Go 源代码必须属于同一个包, 推荐与文件夹名相同. 而在 import 的时候, 只以包为基本单位而不是 Go 源码文件. 包的基本作用: 区分相同名称的函数, 变量等标识符 管理项目 控制函数, 变量等访问范围 声明 package 的基本语法:1package `包名` 引入包的基本语法1import `包路径` 在引入包路径的时候, 是从 $GOPATH/src 路径下开始引入 包的注意事项和细节 在该一个文件打包的时候, 该包对应一个文件夹, 文件的包名通常和文件所在的文件夹名一致, 且一般为小写字母; 当一个文件要使用其他包函数或变量的时候, 需要先引入对应的包package 指令在文件第一行, 然后是 import 指令在 import 包时, 路径从 $GOPATH/src 下开始, 不用带 src, 编译器会自动从 src 下开始引入. 如当执行 import fmt 的时候, 实际上是从 $GOPATH/src/fmt 进行引入. 为了让其他包的文件可以访问到本包的函数, 则需要首字母大写, 类似其他编程语言的 public, 这样才能跨包访问; 在访问其他包函数的时候, 去语法是 包名.函数名 如果报名比较长, Go 支持给包取别名, 而取别名后, 原包名就不可再使用; 在同一个包下, 不能有相同的函数名或相同的全局变量, 否则会报重复定义的错; 如果需要编译一个可执行程序文件, 就需要将这个包声明为 main, 即 package main 6.3 函数调用机制底层剖析6.3.1 运行时内存结构 在调用一个函数时, 会给该函数重新分配一个新的空间, 编译器会通过自身的处理让这个新的空间和其他栈空间分开; 在每个函数对应的栈中, 数据空间是独立的, 不会混淆; 当一个函数调用完毕后, 程序会销毁这个函数对应的栈空间. 6.3.2 return 语句 Go 函数支持返回多个值 如果返回多个值时, 在接收时, 如果希望忽略某个返回值, 可以使用 _ 符号表示忽略 如果返回值只有一个, (返回值类型列表) 可以不写 ()1234func 函数名(形参列表...) (返回值类型列表...) &#123; // 函数体 return 返回值列表&#125; 6.4 函数的递归调用 函数体内又调用了自身, 这个过程就叫做递归 递归函数需要遵守的规则: 执行一个函数时, 就创建一个新的受保护的独立内存空间(新函数栈); 函数的局部变量是独立的, 不会相互影响; 递归必须向退出的条件逼近; 当一个函数执行完毕, 或者遇到 return, 就会返回, 遵守谁调用就将结果返回给谁, 同时当函数执行完毕或者返回时, 该函数本身也会被系统销毁. 6.4.1 Fibonacci 数列123456func fibonacci(n int) int &#123; if n == 1 || n == 2 &#123; return 1 &#125; return fibonacci(n - 1) + finonacci(n - 2)&#125; 6.4.2 求函数值 f(1)=3;f(n)=2*f(n-1)+1 123456func f(n int) int &#123; if n == 1 &#123; return 3 &#125; return 2 * f(n-1) + 1&#125; 6.4.3 猴子吃桃 有一堆桃子, 猴子第一天吃了其中的一半又多吃了一个, 后面每天都吃其中的一半再多一个, 当吃到第 10 天的时候发现只有一个桃子, 求最初有多少个桃子. 1234567// peach(n) = (peach(n+1) + 1) * 2func peach(n int) int &#123; if n == 10 &#123; return 1 &#125; return (peach(n+1) + 1) * 2&#125; 6.5 函数注意事项和细节讨论 函数的形参列表可以是多个, 返回值列表也可以是多个; 形参列表和返回值列表的数据类型可以是值类型和引用类型; 函数的命名规范遵循标识符命名规范, 首字母不能使数字, 首字母大写该函数可以被其他包访问, 类似 public; 首字母小写, 只能被本包文件使用, 其他包文件不能访问, 类似 private; 函数中变量是局部的, 函数外不生效; 基本数据类型和数组默认是值传递, 即进行值拷贝, 在函数内修改, 不会影响到原来的值; 如果希望函数内的变量能修改函数外的变量, 可以传入变量的地址 &amp;变量标识符, 函数内以指针的方式操作变量; Go 语言的函数不支持重载; 在 Go 中, 函数也是一种数据类型, 可以赋值给一个变量, 则该变量就是一个函数类型的变量了, 通过该变量可以对函数调用; 既然函数时一种数据类型, 那么在 Go 中, 函数可以作为形参传递并且被调用. 为了简化数据类型定义, Go 支持自定义数据类型, 基本语法 type 自定义数据类型名 数据类型, 相当于一个别名; 支持对函数返回值命名.]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言入门(3)--面向接口]]></title>
    <url>%2Fblog%2F2018%2F11%2F18%2FGo%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8-3-%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[Go 语言面向对象只支持封装, 传统面向对象语言中靠继承和多态完成的事情在 Go 中都是通过接口来完成, 因此 Go 中的接口比传统的语言灵活很多 12345678type Traversal interface &#123; Traverse()&#125;func main() &#123; traversal := getTraversal() traversal.Traverse()&#125; 1. duck typing “像鸭子走路, 像鸭子叫(长得像鸭子), 那么它就是鸭子” 描述事物的外部行为而非内部结构 严格来说 Go 属于结构化类型系统, 类似 duck typing 1.1 python 中的 ducking typing12def download(retriever): return retriever.get("org.destiny.io") 运行时才知道传入的 retriever 有没有 get 通常需要注释来说明接口 1.2 C++ 中的 ducking typing通过模板来实现 duck typing, 编译时才知道传入的 retriever 有没有 get, 而在编写代码的时候不能直接感知, 因此也需要注释来说明接口 1234template &lt;class R&gt;string download(const R&amp; retriever) &#123; return retriever.get("org.destiny.io")&#125; 1.3 Java 中的类似代码传入的参数必须实现 Retriever 接口但不属于 duck typing 1234&lt;R extends Retriever&gt;String downlaad(R r) &#123; return r.get("org.destiny.io")&#125; 1.4 Go 语言中的 duck typing 同时需要 Readable, Appendable 怎么办 同时具有 python, C++ 的 duck typing 的灵活性 又具有 Java 的类型检查 2. 接口的定义和实现 download: 使用者 retriever: 实现者 接口由使用者定义 main.go12345678910111213type Retriever interface &#123; Get(url string) string&#125;func download(r Retriever) &#123; return r.Get("org.destiny.io")&#125;func main() &#123; var r Retriever r = mock.Retriever&#123;"this is a mock Retriever"&#125; fmt.Println(download(r))&#125; retriever.go1234567type Retriever struct &#123; Contents string&#125;func (r Retriever) Get(url string) string &#123; return r.Contents&#125; real/retriever.go12345678910111213141516171819type Retriever struct &#123; UserAgent string TimeOut time.Duration&#125;func (r Retriever) Get(url string) string &#123; resp, err := http.Get(url) if err != nil &#123; panic(err) &#125; result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil &#123; panic(err) &#125; return string(result)&#125; main/retriever.go12345func main() &#123; var r Retriever r = real.Retriever&#123;&#125; fmt.Println(download(r))&#125; 3. 接口的值类型继续上例:打印出 r 的具体类型 123456789func main() &#123; var r Retriever r = mock.Retriever&#123;"this is a mock Retriever"&#125; fmt.Printf("%T, %v\n", r, r) // mock.Retriever &#123;this is a mock Retriever&#125; r = real.Retriever&#123;&#125; // 输出的空格代表 string 类型的 UserAgent, 0s 代表 time.Duration 类型的额 TimeOut fmt.Printf("%T, %v\n", r, r) // real.Retriever &#123; 0s&#125; fmt.Println(download(r))&#125; r 中一共包含两项内容:r 的类型以及 r 的内容]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言入门(2)--面向接口]]></title>
    <url>%2Fblog%2F2018%2F11%2F06%2FGo%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8-2-%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[1. 结构体和方法 go 语言只支持封装, 不支持继承和多态 go 语言没有 class, 只有 struct 1.1 结构的创建1234type TreeNode struct &#123; Left, Right * TreeNode value int&#125; 123456789101112func main() &#123; // 创建一个 value 为 0, left, right 都为 nil 的 treeNode var root treeNode fmt.Println(root) // &#123;0 &lt;nil&gt; &lt;nil&gt;&#125; root1 := treeNode&#123;value:3, left:&amp;treeNode&#123;&#125;, right:&amp;treeNode&#123;5, nil, nil&#125;&#125; root1.right.left = new(treeNode) fmt.Println(root1) // &#123;3 0xc00000a080 0xc00000a0a0&#125; fmt.Println(*root1.left) // &amp;&#123;0 &lt;nil&gt; &lt;nil&gt;&#125; fmt.Println(*root1.right) // &amp;&#123;5 0xc00000a0c0 &lt;nil&gt;&#125; fmt.Println(*root1.right.left) // &amp;&#123;0 &lt;nil&gt; &lt;nil&gt;&#125;&#125; 1.2 结构的方法行如接受者的写法, 也是采用值传递, 也就意味着如果需要在函数内对结构体做修改, 必须采用传指针的方式 func (node treeNode) print() {...} 只能完成读操作 func (node *treeNode) setValue() {...} 才能进行修改 1234567891011121314151617181920212223242526type treeNode struct &#123; value int left, right * treeNode&#125;// 为结构体创建方法的时候, 不能直接写在结构体内部// 在函数名的前面加了一个括号, 称为接收者// 代表 print 函数并非无参, 而是必须由 treeNode 对象来调用func (node treeNode) print() &#123; fmt.Println(node.value)&#125;func main() &#123; // 创建一个 value 为 0, left, right 都为 nil 的 treeNode var root treeNode fmt.Println(root) // &#123;0 &lt;nil&gt; &lt;nil&gt;&#125; root1 := treeNode&#123;value:3, left:&amp;treeNode&#123;&#125;, right:&amp;treeNode&#123;5, nil, nil&#125;&#125; root1.right.left = new(treeNode) fmt.Println(root1) // &#123;3 0xc00000a080 0xc00000a0a0&#125; fmt.Println(*root1.left) // &amp;&#123;0 &lt;nil&gt; &lt;nil&gt;&#125; fmt.Println(*root1.right) // &amp;&#123;5 0xc00000a0c0 &lt;nil&gt;&#125; fmt.Println(*root1.right.left) // &amp;&#123;0 &lt;nil&gt; &lt;nil&gt;&#125; root.print()&#125; go 语言中的函数自身做了兼容, 调用参数的使用, 不论采用传值还是传地址, 都可以按照函数的要求自动转型 实际调用如果是传指针, 编译器会自动将结构体取地址 实际调用如果是传值, 编译器会自动将指针解引用 1234567891011121314151617func (node treeNode) print() &#123; fmt.Println(node.value)&#125;func (node treeNode) setValue(value int) &#123; node.value = value&#125;func main() &#123; pRoot := &amp;root pRoot.print() pRoot.setValue(100) aRoot := root aRoot.print() aRoot.setValue(200)&#125; 只有使用指针才能改变结构的内容nil 指针也可以调用方法 值接受者与指针接收者:要改变必须使用指针接收者结构过大也需要考虑使用指针接收者值接受者是 go 语言特有的概念值/指针接受者均可接受值/指针, 编译器会自行做修正 2. 包和封装 名字一般使用 CamelCase 首字母大写: public 首字母小写: private 而 public 和 private 的概念是针对包提出的 每个目录一个包 main 包比较特殊, 包含可执行入口 为结构定义的方法必须放在同一个包内 可以是不同的文件 3. 扩展已有类型既然 go 语言没有继承和多态, 该如何去扩充系统类型或者别人的类型: 定义别名 使用组合 1234567891011121314151617package queuetype Queue []intfunc (q *Queue) Push(v int) &#123; *q = append(*q, v)&#125;func (q *Queue) Pop() int &#123; head := (*q)[0] *q = (*q)[1:] return head&#125;func (q *Queue) IsEmpty() bool &#123; return len(*q) == 0&#125; 调用:12345678910111213141516171819package mainimport ( "demo/queue" "fmt")func main() &#123; q := queue.Queue&#123;1&#125; q.Push(2) q.Push(3) fmt.Println(q.Pop()) // 1 fmt.Println(q.Pop()) // 2 fmt.Println(q.IsEmpty()) // false fmt.Println(q.Pop()) // 3 fmt.Println(q.IsEmpty()) // true&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言入门(1)--基本语法]]></title>
    <url>%2Fblog%2F2018%2F11%2F04%2FGo%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8-1-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 安装与环境 下载: https://studygolang.com/dl Mac 默认安装在 /usr/local/go/ 路径下 2. 基本语法基本输出1234567package mainimport "fmt"func main() &#123; fmt.Println("Hello World")&#125; 2.1 变量2.1.1 定义变量 使用 var 关键字 var a, b, c var s1, s2 = &quot;abc&quot;, &quot;def&quot; 可放在函数内, 也可放在保内 在 var() 中集中定义 编译器可以自动决定类型 var q, w, e, r = 1, true, variable, &quot;a&quot; 使用 := 定义变量 z, x, v, c := 1, true, variable, &quot;a&quot; 只能在函数内使用 2.1.2 内建变量类型 bool, string (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr byte, rune(长度四个字节, 代表一个字符, 类似 char) float32, float64, complex64, complex128(复数类型) 特别需要注意 go 对复数的支持:123456789101112func euler() &#123; i := 1 // 在表示负数的时候, 虚部直接与 i 连写就可以 c1 := 3 + 4i // 如果中间加上 *, 会变成乘法表达式 c2 := 3 + 4 * i fmt.Println(c1, c2) // 输出结果: (3+4i) 7 fmt.Println(cmplx.Abs(c1)) // 输出结果: 5 // 证明欧拉定律 fmt.Printf("%.4f", cmplx.Pow(math.E, 1i * math.Pi) + 1) // 输出结果: (0.0000+0.0000i)&#125; 2.1.3 强制类型转换 go 语言只有强制类型转换, 没有隐式类型转换 12345678func triangle() &#123; var a, b int = 3, 4 var c int // 最初的方案 math.Sqrt(a * a + b * b) 会报错 // 因为 Sqrt 函数的参数和返回值都是 float64 类型的, 需要进行强制类型转换 c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c)&#125; 2.1.4 常量的定义 语法: const filename = &quot;abc.txt&quot; const 数值可作为各种类型 12345678func consts() &#123; const fileName = "abc.txt" const a, b = 3, 4 var c int // 此处不同于 var, 常量类似于文本替换, 只要不定义类型, 就可以表示成多种类型 c = int(math.Sqrt(a*a + b*b)) fmt.Println(c)&#125; 2.1.5 枚举123456789func enums() &#123; const ( cpp = 0 java = 1 python = 2 golang = 3 ) fmt.Println(cpp, java, python, golang)&#125; go 语言为这种语法做了简化12345678910func enums() &#123; const ( // iota 表示这组 const 是自增值 cpp = iota java python golang ) fmt.Println(cpp, java, python, golang) // 输出: 0 1 2 3&#125; 可以使用 iota 参与运算, 实现复杂的枚举初始值123456789101112func enums() &#123; // 使用 iota 参与运算 const ( b = 1 &lt;&lt; (10 * iota) kb mb gb tb ) fmt.Println(b, kb, mb, gb, tb) // 输出结果: 1 1024 1048576 1073741824 1099511627776&#125; 2.2 条件语句2.2.1 if else123456789func main() &#123; const filename = "abc.txt" contents, err := ioutil.ReadFile(filename) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf("%s\n", contents) &#125;&#125; go 中的条件判断可以简化成如下形式: if 条件语句中可以赋值; if 条件中赋值的变量作用域就在这个 if 中. 12345678func main() &#123; const filename = "abc.txt" if contents, err := ioutil.ReadFile(filename); err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf("%s\n", contents) &#125;&#125; 2.2.2 switch go 中的 switch 会自动 break, 除非使用 fallthrough 12345678910111213141516func grade(score int) string &#123; g := "" switch &#123; case score &lt; 60: g = "F" case score &lt; 80: g = "C" case score &lt; 90: g = "B" case score &lt;= 100: g = "A" default: panic(fmt.Sprintf("wrong score: %d", score)) &#125; return g&#125; 2.2.3 循环 for 的条件中不需要括号 for 的条件里可以省略初始条件, 结束条件, 递增表达式 12345678func convertToBin(n int) string &#123; result := "" for ; n &gt; 0; n /= 2 &#123; lsb := n % 2 result = strconv.Itoa(lsb) + result &#125; return result&#125; 省略初始条件, 相当于 while 123for scanner.Scan() &#123; fmt.Println(scanner.Text())&#125; 无限循环 123for &#123; fmt.Println("forever")&#125; 2.3 函数 函数名在前, 返回类型在后 可返回多个值 函数可以作为参数 没有默认参数, 可选参数 12345678910111213141516func eval(a, b int, op string) int &#123; result := 0 switch op &#123; case "+": result = a + b case "-": result = a - b case "*": result = a * b case "/": result = a / b default: panic("unsupported operation: " + op) &#125; return result&#125; go 语言中的函数还可以一次返回多个值1234// 当需要返回多种类型时, 所有类型需要按顺序写在参数列表后的括号中func div(a, b int) (int, int) &#123; return a / b, a % b&#125; go 语言的函数在返回多值的情况下, 可以指定变量名123func div(a, b int) (q, r int) &#123; return a / b, a % b&#125; 在接受具有多个返回值的函数执行结果时, 如果存在某些返回值不需要, 可以使用 _ 的方式12q, r = div(16, 7) // 两个返回值都需要q, _ = div(16, 7) // 只需要第一个返回值 函数指针123456789101112131415161718192021222324252627282930/* * apply 函数接收三个参数 1. 一个参数为两个 int 并且返回一个 int 的函数 * 2. 一个 int * 3. 一个 int * 并且自身返回一个int */func apply(op func(int, int) int, a, b int) int &#123; // 获取指向 op 函数的指针 pointer := reflect.ValueOf(op).Pointer() // 通过反射获取函数名 opName := runtime.FuncForPC(pointer).Name() fmt.Printf("Calling function %s with args (%d, %d)", opName, a, b) // 输出结果: Calling function main.pow with args (3, 4) fmt.Println() return op(a, b)&#125;func pow(a, b int) int &#123; return int(math.Pow(float64(a), float64(b)))&#125;func main() &#123; fmt.Println(apply(pow, 3, 4)) // 输出结果: 81&#125;// 也可以直接把 pow 函数调用处在调用处声明为匿名函数func main() &#123; fmt.Println(apply(func(a int, b int) int &#123; return int(math.Pow(float64(a), float64(b))) &#125;, 3, 4))&#125; 2.4 指针 go 语言的指针不同于 C 的指针, 不能参与运算 go 语言之后值传递一种方式 值传递与引用传递值传递: 调用方法的时候将参数做了一份拷贝, 与调用方的参数无关引用传递: 不进行拷贝, 可能会对原值进行修改123456789101112131415void pass_by_val(int a) &#123; a++;&#125;void pass_by_ref(int&amp; a) &#123; a++;&#125;int main(void) &#123; int a = 3; pass_by_val(a); printf("After pass_by_val: %d\n", a) // 3 pass_by_ref(a); printf("After pass_by_ref: %d\n", a) // 4&#125; 变量 函数 调用结果 var a int func f(a int) f 函数的会对 a 的副本进行操作, 无论如何操作都不会影响原值 var a int func f(pa *int) f 函数对 a 的修改会影响到原值 var cache Cache func f(cache Cache) cache 本身是一个指针 交换值:12345678910111213func swap(a, b *int) &#123; *b, *a = *a, *b&#125;func swap1(a, b int) (int, int) &#123; return b, a&#125;func main() &#123; a, b := 3, 4 swap(&amp;a, &amp;b) fmt.Println(a, b)&#125; 3. 内建容器3.1 数组 数量写在类型前 12345678910func main() &#123; // 如果不进行初始化, int 数组所有元素都是0 var arr1 [5]int // 使用 := 初始化的时候, 必须初始化内容 arr2 := [3]int&#123;1, 3, 5&#125; // 可以不指定长度, 由编译器去填充 arr3 := [...]int&#123;2, 4, 6, 8, 10&#125; fmt.Println(arr1, arr2, arr3)&#125; 数组是值类型, 即传参的时候会进行 copy [10]int 和 [20]int 是不同类型 与大部分语言的设计不同, 调用 func f(arr [10]int) 时会 copy 数组 在 go 语言中一般不直接使用数组, 而是切片 1234567891011func printArray(arr [5]int) &#123; for i, v := range arr &#123; println(i, v) &#125;&#125;func main() &#123; printArray(arr1) printArray(arr2) // 会报错: cannot use arr2 (type [3]int) as type [5]int in argument to printArray printArray(arr3)&#125; 上面的例子说明, 在 go 语言中, 长度为 3 的数组和长度为 5 的数组是不同的数据类型, 不能作为参数传递给 printArray 在函数调用中传递数组指针1234567891011func printArray(arr *[5]int) &#123; for i, v := range arr &#123; fmt.Println(i, v) &#125; arr[0] = 100&#125;func main() &#123; printArray(&amp;arr1) // [100, 0, 0, 0, 0] printArray(&amp;arr3) // [100, 4, 6, 8, 10]&#125; 3.2 Slice(切片) slice 本身没有数据, 是对底层 array 的一个 view 12345678func main() &#123; arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125; s := arr[2:6] fmt.Println("arr[2:6]: ", s) // [2 3 4 5] fmt.Println("arr[:6]: ", arr[:6]) // [0 1 2 3 4 5] fmt.Println("arr[2:]: ", arr[2:]) // [2 3 4 5 6 7] fmt.Println("arr[:]: ", arr[:]) // [0 1 2 3 4 5 6 7]&#125; 上例中的 s 就是一个切片, 表示数组的一个左开右闭的区间 arr: 0 1 2 3 4 5 6 7 s : ↑ ↑ slice 是一个引用类型, 对切片的修改会对原数组造成同样的修改12345678910111213func updateSlice(s []int) &#123; s[0] = 100&#125;func main() &#123; arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125; s := arr[2:6] fmt.Println(s) // [2 3 4 5] updateSlice(s) fmt.Println(arr) // [0 1 100 3 4 5 6 7] fmt.Println(s) // [100 3 4 5]&#125; slice 也可以继续生成 slice, 但不论如何生成, 都是针对同一个数组的 view 1234567891011121314func main() &#123; arr := [...]int&#123;0, 1, 2, 3, 4, 5, 6, 7&#125; s := arr[2:6] fmt.Println("arr[2:6]: ", s) // [2 3 4 5] fmt.Println("ReSlice") fmt.Println("s", s) // [2 3 4 5] fmt.Println("arr", arr) // [0 1 2 3 4 5 6 7] s = s[:6] fmt.Println("s[:6]", s) // [2 3 4 5 6 7] s = s[2:] fmt.Println("s[2:]", s) // [4 5 6 7]&#125; 3.2.1 Slice 的扩展 slice 可以向后扩展, 不能向前扩展 读取 slice 元素的时候, 不能超过 len(s), 向后扩展不能超过底层数组 cap(s) 12345678910func main() &#123; fmt.Println("Extending Slice") s1 := arr[2:6] s2 := s1[3:5] fmt.Println(s1) // [100 3 4 5] fmt.Println("len of s1", len(s1)) // 4 fmt.Println("cap of s1", cap(s1)) // 6 fmt.Println(s2) // [5 6]&#125; 在 Slice 实现中, 有三个主要的元素: ptr: 当前指向的数组元素索引 len: 当前 slice 的总长度, 如 s1:= arr[2:6], len 为 4 cap: 当前 slice 的最大长度, 为原数组 len 之后的长度, 如 s1:= arr[2:6], cap 为 2 s2 := s1[3:5] 0, 1, 2 ↓ ↓ s1 := arr[2:6] 0, 1, 2, 3, 4, 5 ↓ ↓ arr: 0, 1, 2, 3, 4, 5, 6, 7 3.2.2 向 slice 添加元素 添加元素时如果超过 cap, 系统会重新分配更大的底层数组 由于值传递的关系, append() 操作的必须接收返回值 s = append(s, val) slice 的 cap 初始值是0 , 当 slice 的底层数组需要扩容的时候, 底层数组的长度会扩充为之前的 2 倍 1234567891011func main() &#123; fmt.Println(s2) // [5 6] fmt.Println(arr) // [0 1 2 3 4 5 6 7] s3 := append(s2, 10) s4 := append(s3, 11) s5 := append(s4, 12) fmt.Println(s3) // [5 6 10] fmt.Println(s4) // [5 6 10 11] fmt.Println(s5) // [5 6 10 11 12] fmt.Println(arr) // [0 1 2 3 4 5 6 10]&#125; s2 是 arr 的一个 view, 对应 arr 的 [5, 6] 两个元素, s2 进行 append() 操作时, 由于 arr 数组后面还有空间, 则直接进行替换, 而 s3, s4 在进行 append() 操作的时候, 由于超出了 arr 数组的范围, go 会重新分配一个新的数组, 并将 arr 初始化进去再进行 append() 3.2.3 slice 复制123456func main() &#123; s1 := []int&#123;2, 4, 6, 8&#125; s2 := make([]int, 16, 32) copy(s2, s1) printSlice(s2) // [2 4 6 8 0 0 0 0 0 0 0 0 0 0 0 0], len = 16, cap = 32&#125; 3.2.4 slice 删除元素12345func main() &#123; printSlice(s2) // [2 4 6 8 0 0 0 0 0 0 0 0 0 0 0 0], len = 16, cap = 32 s2 = append(s2[:3], s2[4:]...) printSlice(s2) // [2 4 6 0 0 0 0 0 0 0 0 0 0 0 0], len = 15, cap = 3&#125; 3.2.5 pop123456789101112func main() &#123; fmt.Println("popping from front") front := s2[0] s2 = s2[1:] fmt.Println("popping from back") tail := s2[len(s2)-1] s2 = s2[:len(s2)-1] fmt.Println(front, tail) // 2 0 printSlice(s2) // [4 6 0 0 0 0 0 0 0 0 0 0 0], len = 13, cap = 31&#125; 3.3 Map定义方式: map[k]v: key 为 k, value 为 v 的 map map[k1]map[k2]v: key 为 k1, value 为一个 key 为 k2 value 为 v 的 map map 中 key 的要求: map 底层使用哈希表实现, 必须可以比较相等 除了 slice, map, function 等内建类型都可以作为 key struct 类型不包括上述字段, 也可以作为 key 1234567891011// map 的创建方式一m1 := map[string]string &#123; "name": "destiny", "course": "golang"&#125;// map 的创建方式二m2 := make(map[string]int)// map 的创建方式三var m3 map[string]int map 的遍历12345678910func main() &#123; m := map[string]string&#123; "name": "destiny", "course": "golang", &#125; for k, v := range m &#123; fmt.Println(k, v) &#125;&#125; map 获取 value123456789101112func main() &#123; m := map[string]string&#123; "name": "destiny", "course": "golang", &#125; name := m["name"] fmt.Println(name) // destiny gender := m["gender"] fmt.Println(gender) // "" 不存在的内容返回 zero value&#125; 从 map 获取 value 的时候, 不存在的 key 会返回空串, 那么我们应该如何确定这个 key 是原本就不存在还是只是在 map 中确实放置了一个空串?该接口还可以接受一个返回值, 用来判断这个 key 是否真的存在 12345678910111213141516171819func main() &#123; m := map[string]string&#123; "name": "destiny", "course": "golang", &#125; name, ok := m["name"] fmt.Println(name, ok) // destiny true gender, ok := m["gender"] fmt.Println(gender, ok) // false // 可以写成如下格式 if name, ok := m["name"]; ok &#123; fmt.Println(name, ok) // destiny true &#125; else &#123; fmt.Println("key dosen't exist") &#125;&#125; map 删除元素12345678910111213141516171819func main() &#123; m := map[string]string&#123; "name": "destiny", "course": "golang", &#125; if name, ok := m["name"]; ok &#123; fmt.Println(name, ok) // there &#125; else &#123; fmt.Println("key doesn't exist") &#125; delete(m, "name") if name, ok := m["name"]; ok &#123; fmt.Println(name, ok) &#125; else &#123; fmt.Println("key doesn't exist") // there &#125;&#125; 利用 map 寻找最长不含有重复字符的子串对于每一个字母 x lastOccurred[x]不存在, 或者 &lt;start, 则不需要处理 lastOccurred[x] &gt;= start, 更新 start 更新 lastOccurred[x], 更新 maxLength 123456789101112131415161718192021222324252627package mainimport "fmt"func lengthOfNonRepeatingSubStr(s string) int &#123; // 记录每个字符最后出现的位置 lastOccurred := make(map[byte]int) start := 0 maxLength := 0 for i, ch := range []byte(s) &#123; if lastI, ok := lastOccurred[ch]; ok &amp;&amp; lastI &gt;= start &#123; // 如果当前字符最后一次出现的位置 &gt;= start, 需要将 start 更新到该字符位置之后 start = lastOccurred[ch] + 1 &#125; if i-start+1 &gt; maxLength &#123; maxLength = i - start + 1 &#125; lastOccurred[ch] = i &#125; return maxLength&#125;func main() &#123; fmt.Println(lengthOfNonRepeatingSubStr("abcabcab")) fmt.Println(lengthOfNonRepeatingSubStr("bbbbb")) fmt.Println(lengthOfNonRepeatingSubStr("pwwkew"))&#125; 3.4 rune rune 相当于 go 语言中的 char 使用 range 遍历 pos, rune 对 使用 utf8.RuneCountInString 获得字符数量 使用 len 获得字节长度 使用 []byte 获得字节数组 123456789101112131415161718192021222324252627func main() &#123; s := "我是Destiny!" // UTF-8 fmt.Println(len(s)) // 20 fmt.Printf("%X", []byte(s)) // E68891E698AF44657374696E7921 fmt.Println() // 每个中文三个字节 for _, b := range []byte(s) &#123; fmt.Printf("%X ", b) // E6 88 91 E6 98 AF 44 65 73 74 69 6E 79 21 &#125; fmt.Println() for i, ch := range s &#123; // ch is a rune // (0: 6211) // E6 88 91 的 UTF-8 编码转换成 Unicode 后为 6211 // (3: 662F) // (6: 44) // (7: 65) // (8: 73) // (9: 74) // (10: 69) // (11: 6E) // (12: 79) // (13: 21) fmt.Printf("(%d: %X)", i, ch) &#125; fmt.Println() fmt.Println(utf8.RuneCountInString(s)) // 10&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis(1) 常见应用]]></title>
    <url>%2Fblog%2F2018%2F11%2F01%2FRedis-1-%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1. Redis 基础数据结构 此处所说的数据结构, 并不只是 Redis 对外提供可供用户使用的数据结构, 而是广义上泛指所有支撑 Redis 运行的所有数据结构. Redis 有 5 种数据结构: string(字符串) list(列表) set(集合) hash(哈希表) zset(有序集合) 1.1 stringRedis 中所有数据结构都是以一个唯一的字符串 key 作为名称. 然后通过 key 去获取对应的 value 数据, 不同类型的数据结构, 其 key 都是 string 类型, 而 value 所对应的结构以及内容不同. string 在做 value 时, 经常会用来做缓存, 例如可以将内容序列化为 JSON, 再使用 Redis 来存储, 而从应用从缓存中读取数据时, 也需要经过一次反序列化.]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java逃逸分析]]></title>
    <url>%2Fblog%2F2018%2F09%2F07%2FJava%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. 逃逸概念的引入 我们都知道, Java 创建的对象都是被分配到堆内存上, 但是事实并不是这么绝对, 通过对Java对象分配的过程分析, 可以知道有两个地方会导致 Java 中创建出来的对象并不一定分别在所认为的堆上. 这两个点分别是 Java 中的 逃逸分析 和 TLAB(Thread Local Allocation Buffer)线程私有的缓存区。 2. 逃逸分析基本概念逃逸分析, 是一种可以有效减少 Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法. 通过逃逸分析, Hotspot编译器 能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上. 在计算机语言编译器优化原理中, 逃逸分析是指分析指针动态范围的方法, 它同编译器优化原理的指针分析和外形分析相关联. 当变量(或者对象)在方法中分配后, 其指针有可能被返回或者被全局引用, 这样就会被其他过程或者线程所引用, 这种现象称作指针(或者引用)的 逃逸(Escape) . 通俗点讲, 如果一个对象的指针被多个方法或者线程引用时, 那么我们就称这个对象的指针发生了逃逸. 2.1. 具体分析逃逸分析研究对于 java 编译器有什么好处呢? 我们知道 java 对象总是在堆中被分配的, 因此 java 对象的创建和回收对系统的开销是很大的. java 语言被批评的一个地方, 也是认为 java 性能慢的一个原因就是 java 不支持栈上分配对象, JDK6里的 Swing 内存和性能消耗的瓶颈就是由于 GC 来遍历引用树并回收内存的, 如果对象的数目比较多, 将给 GC 带来较大的压力, 也间接得影响了性能. 减少临时对象在堆内分配的数量, 无疑是最有效的优化方法. java 中应用里普遍存在一种场景, 一般是在方法体内, 声明了一个局部变量, 并且该变量在方法执行生命周期内未发生逃逸, 按照 JVM 内存分配机制, 首先会在堆内存上创建类的实例(对象), 然后将此对象的引用压入调用栈, 继续执行, 这是 JVM 优化前的方式. 当然, 我们可以采用逃逸分析对 JVM 进行优化, 即针对栈的重新分配方式, 首先我们需要分析并且找到未逃逸的变量, 将该变量类的实例化内存直接在栈里分配, 无需进入堆, 分配完成之后, 继续调用栈内执行, 最后线程执行结束, 栈空间被回收, 局部变量对象也被回收, 通过这种方式的优化, 与优化前的方案主要区别在于对象的存储介质, 优化前是在堆中, 而优化后的是在栈中, 从而减少了堆中临时对象的分配(较耗时), 最终完成性能的优化. 逃逸分析实际上是 JVM 的一种为优化提供支持的分析手段, 逃逸分析的范围分为两个, 方法逃逸和线程逃逸 2.2.1 方法逃逸 不逃逸出当前方法, 就是说在一个方法内 new 出来的对象, 它的引用没有泄露到这个方法之外123456789101112131415public class Foo &#123; int a; int b; public Foo() &#123; &#125;&#125;public int bar(int a, int b) &#123; Foo foo = new Foo(); foo.a = a; foo.b = b; // foo 对象没有逃逸出 bar 方法, 只在 bar 方法里当做局部变量存在 return foo.a + foo.b;&#125; 在上面的例子中, Foo 对象就没有逃逸出 bar 方法, 只有一个局部 foo 变量引用这个对象, foo 变量既没有被当做返回值, 也没有当做另一个方法的参数. 但其实我们一般写的普通 Java Bean 都会有 getter /setter 1234567891011121314151617public class Foo &#123; int a; int b; public Foo(int a, int b) &#123; this.a = a; this.b = b; &#125; public int getA() &#123; return a; &#125; public int getB() &#123; return b; &#125;&#125; 如果在 bar() 方法里依然给 Foo 实例对象赋值, 那肯定就会调用到 Foo 的成员方法 setA(), setB(), 把局部变量 foo 的 this 作为参数传递给 foo 的成员方法, 这个时候变量 foo 确实逃逸除了 bar 方法, 而 JIT 提供了 方法内联, 在完成方法内联后, 这个参数传递实际上优化掉了. 2.2.2 线程逃逸 不逃逸出当前线程, 指的是实例对象没有被别的类引用到. 该对象的引用赋值到其他对象的字段, 或其他类的静态字段上, 没办法让它进入一个全局可见的范围, 这个时候我们认为该实例没有逃逸出当前线程 12345678910public int bar(int a, int b) &#123; Foo foo = new Foo(); foo.a = a; foo.b = b; return doBar(foo);&#125;public int doBar(Foo foo) &#123; return foo.a + foo.b;&#125; bar() 方法调用了 doBar(), 把 foo 实例作为入参传入了 doBar(), 这个时候认为 foo 逃逸除了 bar 方法, 但是 bar 和 doBar 都在一个类中, 并没有被其他类引用, 我们认为 foo 对象没有逃逸出线程. 2.3. JVM 为逃逸分析所做的优化2.3.1 标量替换 Java 中标量的意思是不能再分割的量, 如基本类型和 Reference 类型, 反之成为聚合量, 如果把一个对象拆开, 将它的成员变量分割成标量, 这个就叫标量替换. 如果逃逸分析发现一个对象不会被外部访问, 并且该对象可以被拆散, 那么经过优化后, 并不直接生成该对象, 而是在栈上创建若干个成员变量, 原本的对象就无需再堆上整体分配空间了. 栈帧内分配对象的行为成为栈上分配, 目的是减少新生代的 GC 频率, 见解提高 JVM 性能, 通过 -XX+EliminateAllcations 可以开启标量替换. 2.3.2 锁消除优化 Java 方法中返回值如果没有被其他类用到, 那这个对象就不会逃逸出线程, 我们知道变量的读写竞争的时候需要加锁访问, 如果确定该变量不会逃逸出该线程, 那同步访问控制就可以优化掉. 2.4 实操12345678910111213141516171819public class User &#123; private Sting name; private int age; // getters / setters / constructors&#125;public int bar(Foo foo) &#123; User user = new User(23); return foo.getA() + foo.getB() + user.getAge();&#125;public static void main(String[] args) &#123; Foo foo = new Foo(); for(int i = 0; i &lt; 1000000000; ++i) &#123; foo.setA(4); foo.setB(45); &#125;&#125; 2.4.1 关闭逃逸分析启动 JVM 参数 -server -XX:-DoEscapeAnalysis 使用 jmap -histo 2.4.2 打开逃逸分析JVM 参数 -server -XX:+DoEscapeAnalysis 可以看到, 只有少量的对象在堆上实例化, 大部分对象的属性被标量替换了. 3. JIT 编译在 JVM 中触发 JIT 编译是基于两个计数器: 一个方法被调用的次数 存在有分支的方法中的循环次数, 如果方法里面有一个很长的循环, 这时候需要编译到这个循环, 每一次分支的循环被调用, 该分支的计数器都会增加 增加 -XX:+PrintCompileation 参数观察 JVM 输出的编译日志 - 96 1 3 java.lang.String::equals (81 bytes) 96 4 3 java.io.UnixFileSystem::normalize (75 bytes) 97 9 3 java.lang.String::hashCode (55 bytes) 97 8 3 java.lang.Object::&lt;init&gt; (1 bytes) 97 7 3 java.lang.AbstractStringBuilder::ensureCapacityInternal (16 bytes) 98 3 3 java.lang.String::length (6 bytes) 98 10 3 java.lang.Math::min (11 bytes) 98 2 3 java.lang.System::getSecurityManager (4 bytes) 98 6 3 java.util.Arrays::copyOf (19 bytes) 98 11 n 0 java.lang.System::arraycopy (native) (static) 98 12 3 java.lang.String::indexOf (70 bytes) 98 15 3 sun.nio.cs.UTF_8$Encoder::encode (359 bytes) 99 13 4 java.lang.String::charAt (29 bytes) 99 16 3 java.lang.String::lastIndexOf (52 bytes) 99 5 3 java.util.HashMap::hash (20 bytes) 100 18 3 java.lang.String::&lt;init&gt; (82 bytes) 100 14 3 java.lang.StringBuilder::toString (17 bytes) 100 19 3 java.lang.String::startsWith (72 bytes) 100 20 1 java.util.ArrayList::size (5 bytes) 100 17 1 java.lang.ref.Reference::get (5 bytes) 101 21 1 sun.instrument.TransformerManager::getSnapshotTransformerList (5 bytes) 101 22 3 java.lang.String::startsWith (7 bytes) 101 23 3 java.lang.String::indexOf (166 bytes) 102 26 1 java.lang.Object::&lt;init&gt; (1 bytes) 102 8 3 java.lang.Object::&lt;init&gt; (1 bytes) made not entrant 102 30 3 org.destiny.demo.Foo::setA (6 bytes) 102 31 3 org.destiny.demo.Foo::setB (6 bytes) 102 32 3 org.destiny.demo.User::bar (25 bytes) 102 33 3 org.destiny.demo.User::&lt;init&gt; (10 bytes) 103 34 1 org.destiny.demo.Foo::setA (6 bytes) 103 30 3 org.destiny.demo.Foo::setA (6 bytes) made not entrant 103 35 1 org.destiny.demo.Foo::setB (6 bytes) 103 31 3 org.destiny.demo.Foo::setB (6 bytes) made not entrant 103 27 1 org.destiny.demo.Foo::getA (5 bytes) 103 28 1 org.destiny.demo.Foo::getB (5 bytes) 103 29 1 org.destiny.demo.User::getAge (5 bytes) 103 24 3 java.lang.String::endsWith (17 bytes) 103 36 4 org.destiny.demo.User::bar (25 bytes) 103 25 3 java.lang.ref.SoftReference::get (29 bytes) 104 32 3 org.destiny.demo.User::bar (25 bytes) made not entrant 104 37 1 java.lang.ThreadLocal::access$400 (5 bytes) 106 38 3 java.lang.String::indexOf (7 bytes) 106 39 3 java.lang.Character::toLowerCase (9 bytes) 106 40 3 java.lang.CharacterDataLatin1::toLowerCase (39 bytes) 108 41 % 3 org.destiny.demo.User::main @ 18 (48 bytes) 108 42 3 org.destiny.demo.User::main (48 bytes) 109 43 % 4 org.destiny.demo.User::main @ 18 (48 bytes) 112 41 % 3 org.destiny.demo.User::main @ -2 (48 bytes) made not entrant 150 43 % 4 org.destiny.demo.User::main @ -2 (48 bytes) made not entrant 编译日志分为 7 列, 依次是 时间(基于 JVM 启动的时间戳) 编译任务 id(基本递增) 编译属性 tiered_level(分为 4 级) 方法信息 占用字节数 deopt 其中, 编译属性 attribute 分为: 属性值 属性描述 % The compilation is OSR s The method is synchronized ! The method has an exception handler b Compliation occurred in blocking mode n Compliation occurred for a wrapper to a native method tiered_level: 值 描述 0 Interpreted Code 1 Simple C1 Compiled Code 2 Limited C1 Compiled Code 3 Full C1 Compiled Code 4 C2 Compile Code]]></content>
      <categories>
        <category>JVM</category>
        <category>逃逸分析</category>
      </categories>
      <tags>
        <tag>逃逸分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务总结]]></title>
    <url>%2Fblog%2F2018%2F09%2F02%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1. 定义事务能够提供一种将一个活动涉及到的所有操作纳入到一个不可分割的执行单元的机制. 组成事务的操作只有在操作均能正常执行的情况下才能提交, 只要其中任意一步执行失败, 都将导致整个操作回滚. 2. 数据库本地事务2.1 ACID 特性 描述 原子性 一个事务的所有操作, 要么全部完成, 要么全部不完成, 不会结束在中间某个环节 一致性 在一个事务执行之前和执行之后, 数据库必须保持处于一致的状态. 如果事务成功执行, 系统中所有的变化都将正确地被应用, 反之, 所有变化都将被回滚 隔离性 当不同的事务操作相同的数据的时候, 每个事务都有各自的完整数据空间, 由事务所做的修改必须与任何其他事务所做的修改隔离, 事务不会看到数据的中间状态. 持久性 只要事务成功结束, 它对数据库所做的更新就必须永久保存下来 而事务的 ACID 是通过 InnoDB 日志和锁来保证. 事务的隔离性是通过数据库锁的机制来实现; 持久性是通过 redo log(重做日志) 来实现的 原子性和一致性是通过 undo log(回滚日志) Undo log: 为了满足事务的原子性, 在操作任何数据之前, 首先将数据备份到一个地方, 然后对数据进行修改, 如果出现了错误, 或者用户执行 RollBack, 系统可以利用 Undo log 中的备份将数据恢复到事务开始之前的状态 Redo log: 记录新数据的备份, 在事务提交之前, 只要将 Redo log 持久化即可, 当系统崩溃时, 虽然数据没有持久化, 但是 Redo log 已经持久化, 系统可以根据 Redo log 的内容, 将所有数据恢复到最新状态. 3. 分布式事务3.1 分布式事务概念指事物的参与者, 支持事务的服务器, 资源服务器以及事务管理器分别位于不同的分布式系统之上. 本质上讲, 分布式事务就是为了保证不同数据库的数据一致性. 3.2 场景3.2.1 service 多个节点 随着互联网快速发展, SOA, 微服务等架构模式正在被大规模使用, 一个公司内, 用户的资产可能被分为好多个部分, 比如余额, 积分, 优惠券等 这样的话传统的单机事务实现方式无法保证积分扣减成功之后, 优惠券也能正确完成扣减操作. 3.2.2 resource 多个节点 同样, 由于单表数据过大需要进行拆分, 一次转账业务需要在北京的 MySQL 实例向 上海的 MySQL 实例转账, 同样无法保证他们能同时成功. 3.3 分布式事务基础3.3.1 CAP C: 对某个执行的客户端来说, 读操作能返回最新的写操作. 对于数据分布在不同节点上的数据来说, 如果在某个节点更新了数据, 那么在其他节点都能读取到最新的数据, 那么就成为强一致, 反之就是分布式不一致; A: 非故障的节点在一定时间内返回合理的响应(不是错误或超时), 可用性的关键在于: 合理的时间 和 合理的响应, 请求不能无限期得不到响应, 并且需要得到系统正确的返回结果; P: 当出现网络分区后, 系统依然能够正常工作. 在分布式系统中, 网络永远无法 100% 可靠, 分区是一个一定会出现的情况, 如果我们选择 AC 而放弃 P, 当分区发生时, 为了保证一致性, 这个时候必须拒绝请求, 当时 A 又不允许拒绝, 所以分布式系统理论上不可能选择 CA 架构, 只能选择 CP 或者 AP 架构. 对于 CP 来说, 放弃可用性, 追求一致性和分区容错性, 比如 Zookeeper 就是追求强一致. 对于 AP 来说, 放弃一致性(强一致), 追求分区容错和可用, 这是很多分布式系统的选择. CAP 是忽略网络延迟的, 也就是当事务提交时, 从节点 A 复制到节点 B, 但是在现实中总会有一定的时间延迟. 3.3.2 BASE基本可用, 软状态, 最终一致性的缩写 本质上是 AP 的一个扩张, 通过软状态实现基本可用和最终一致性. BA: 基本可用, 分布式系统出现故障时, 允许损失部分可用功能, 保证核心功能可用; 软状态: 允许系统中存在中间状态, 这个状态不影响系统可用性, 这里指的是 CAP 中的不一致; 最终一致性: 经过一段时间后, 所有节点数据都将达到一致. 4. 分布式事务的解决方案4.1 是否真的需要分布式事务首先要明确是否真的需要分布式事务? 是否存在由于服务拆分过细导致不合理的分布式系统设计? 可以先考虑将多个微服务聚合成一个单机服务, 避免引入不必要的成本和复杂度. 4.2 2PC 第一阶段: 事务管理器要求每个涉及到事务的数据库预提交此操作, 并反映是否可以提交 第二节点: 事务协调器要求每个数据库提交数据, 或者回滚 优点: 保证数据强一致, 实现简单; 缺点: 事务管理器存在单机风险; 整个过程存在同步阻塞; 数据可能不一致; 不支持高并发. 4.3 TCC相比 2PC, 解决了以下问题 解决了协调者单点, 引入集群 引入超时, 超时后进行补偿, 并且不会锁定整个资源, 将资源转换为业务逻辑形式 数据一致性, 有了补偿机制后, 由业务管理其控制一致性 Try 阶段: 尝试执行, 完成所有业务检查(一致性), 预留必须业务资源(准隔离性) Confirm 阶段: 确认执行真正的业务, 不做任何业务检查, 只使用 Try 阶段预留的业务资源, Confirm 操作满足幂等性. 要求具备幂等设计, Confirm 失败后需要进行重试. Cancel 阶段: 取消执行, 释放 Try 阶段预留的业务资源, 也需要满足幂等性. 4.4 本地消息表将需要分布式处理的任务通过消息日至的方式来异步执行 消息日志可以存储到本地文本, 数据库或者消息队列, 再通过业务规则或人工发起重试, 人工重试更多应用于支付系统 举一个购物的例子 当账户扣款的时候, 需要在扣款相关的服务上新增一个本地消息表, 需要把记录扣款和写入扣减商品库存的本地消息表放入同一个事务. 有个定时任务去轮询本地事务表, 把没有发送的消息扔给商品服务, 让它扣减库存, 到达商品服务后, 先写入这个服务器的事务表, 再进行扣减, 扣减成功后, 更新事务表中的状态; 商品服务器通过定时任务扫描消息表或者直接通过扣款服务吗扣款服务本地消息表进行更新; 针对特定情况, 定时扫描未成功处理的消息, 进行重新发送, 在商品服务收到消息后, 先判断是否是重复消息, 如果已经接受, 再判断是否执行, 如果执行再马上又进行通知事务, 如果未执行, 就需要重新执行需要由业务保证幂等. 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 4.5 MQ 事务还是以转账的模型举例: 1. 先发送消息 如果消息发送成功，但是扣款失败，消费端就会消费此消息，进而向Smith账户加钱。 2. 先扣款 如果扣款成功，发送消息失败，就会出现Bob扣钱了，但是Smith账户未加钱。 3. RocketMQ 的实现 发送 Prepared 消息时，会拿到消息的地址; 执行本地事物; 通过第一阶段拿到的地址去访问消息, 并修改消息的状态. 这样可以保证消息发送消息和本地事务执行成功保持原子性操作. 问题1: 如果步骤 3 失败怎么办RocketMQ会定期扫描消息集群中的事物消息，如果发现了Prepared消息，它会向消息发送端(生产者)确认，Bob的钱到底是减了还是没减呢？ 如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 12345678910111213141516// =============================发送事务消息的一系列准备工作========================================// 未决事务，MQ服务器回查客户端// 也就是上文所说的，当RocketMQ发现`Prepared消息`时，会根据这个Listener实现的策略来决断事务TransactionCheckListener transactionCheckListener = new TransactionCheckListenerImpl();// 构造事务消息的生产者TransactionMQProducer producer = new TransactionMQProducer("groupName");// 设置事务决断处理类producer.setTransactionCheckListener(transactionCheckListener);// 本地事务的处理逻辑，相当于示例中检查Bob账户并扣钱的逻辑TransactionExecuterImpl tranExecuter = new TransactionExecuterImpl();producer.start()// 构造MSG，省略构造参数Message msg = new Message(......);// 发送消息SendResult sendResult = producer.sendMessageInTransaction(msg, tranExecuter, null);producer.shutdown(); 接着查看 sendMessageInTransaction 方法的源码，总共分为3个阶段：发送 Prepared 消息、执行本地事务、发送确认消息。 1234567891011// ================================事务消息的发送过程=============================================public TransactionSendResult sendMessageInTransaction(.....) &#123; // 逻辑代码，非实际代码 // 1.发送消息 sendResult = this.send(msg); // sendResult.getSendStatus() == SEND_OK // 2.如果消息发送成功，处理与消息关联的本地事务单元 LocalTransactionState localTransactionState = tranExecuter.executeLocalTransactionBranch(msg, arg); // 3.结束事务 this.endTransaction(sendResult, localTransactionState, localException);&#125; endTransaction 方法会将请求发往 broker(mq server) 去更新事务消息的最终状态： 根据 sendResult 找到 Prepared 消息, sendResult 包含事务消息的 ID 根据 localTransaction 更新消息的最终状态 问题2: Consumer 消费失败怎么办如果 Bob 的账户的余额已经减少，且消息已经发送成功，Smith 端开始消费这条消息，这个时候就会出现消费失败和消费超时两个问题. 解决超时问题的思路就是一直重试，直到消费端消费消息成功，整个过程中有可能会出现消息重复的问题，按照前面的思路解决即可。]]></content>
      <categories>
        <category>分布式事务</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现简易JVM]]></title>
    <url>%2Fblog%2F2018%2F06%2F24%2F%E5%AE%9E%E7%8E%B0%E7%AE%80%E6%98%93JVM%2F</url>
    <content type="text"><![CDATA[1. 概述 Java 源代码经过编译生成 class 文件 在不同的操作系统上分别实现 JVM, JVM 在不同操作系统上实现差异很大, 如线程, 图形界面等, 由 JVM 屏蔽与操作系统的接口 1.1 Class 文件格式 1.1.1 魔数 &amp; 版本 &amp; 常量池个数 Magic Number 确定这是一个 Java 文件 Minor / Major Version: 版本号 16 进制 Major Version (0x34) = 52 常量池个数 (0x36) = 54 大端模式(Big-Endian): 高位在前 00 36 而不是 36 00 1.1.2 常量池 0036 代表常量池常量的个数, 后面的 07 通过查表发现含义为 ClassInfo 的 tag 值, 而 name_index 值为 2, 代表类名在第二个常量中. 第二个常量开头为 01, 查表得知是一个 Utf8 字符串, 0021 代表长度 length 值为 33. 而后面 33 个字节 63 6F 6D 2F 63 6F 64 65 72 69 73 69 6E 67 2F 65 78 61 6D 70 6C 65 2F 45 6D 70 6C 6F 79 65 65 56 31 转换成字符串之后的值为 com/coderising/example/EmployeeV1 1234CONSTANT_Class_info &#123; u1 tag; // 值为7 u2 name_index; // 名称索引&#125; 12345CONSTANT_Utf8_info &#123; u1 tag; // 值为1 u2 length; // 长度 u1 bytes[length]; // 内容&#125; 1.1.2.1 常量池实例 索引 类型 操作数 1 操作数 2 含义 #1 ClassInfo #2 #2 Utf8 org/destiny/jvm/model/Employee #3 ClassInfo #4 #4 Utf8 java/lang/Object #5 Utf8 name #6 Utf8 Ljava/lang/String #7 Utf8 age #8 Utf8 I #9 Utf8 #10 Utf8 … #11 Utf8 … #12 MethodRef #3 #13 java.lang.Object&lt;init&gt;()V #13 NameAndType #9 #14 &lt;init&gt;()V #14 Utf8 ()V #15 FieldRef #1 #16 org/destiny/jvm/model/Employee 包含一个 Ljava/lang/String 类型的变量 name #16 NameAndType #5 #6 Ljava/lang/String 类型的变量 name 1.1.3 访问标志 标志名称 标志值 含义 ACC_PUBLIC 0x0001 public 类型 ACC_FINAL 0x0002 声明为 final 类型 ACC_SUPER 0x0020 是否允许使用 invokespecial 字节码指令的新语义 ACC_INTERFACE 0x0200 声明为接口 ACC_ABSTRACT 0x0400 Abstract 类型 ACC_SYNTHETIC 0x1000 这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 注解 ACC_ENUM 0x4000 枚举 1.1.4 类索引, 父类索引类索引和父类索引都是指向常量池的索引 由于 Java 采用动态连接 动态连接是一个将符号引用解析为直接引用的过程。当java虚拟机执行字节码时，如果它遇到一个操作码，这个操作码第一次使用一个指向另一个类的符号引用 那么虚拟机就必须解析这个符号引用。在解析时，虚拟机执行两个基本任务 查找被引用的类，（如果必要的话就装载它） 将符号引用替换为直接引用，这样当它以后再次遇到相同的引用时，它就可以立即使用这个直接引用，而不必花时间再次解析这个符号引用了。 1.1.5 接口1.1.6 字段123456789u2 fields_count; // 字段数量field_info &#123; u2 access_flags; // 访问控制符 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attribute_count; // 该字段的属性数量 attribute_info attributes[attribute_count]; // 属性信息&#125; 标志字符含义 header 1 header 2 B byte C char D double F float I int J long S short Z boolean V void L 对象类型的通用前缀, 如 Ljava/lang/Object 1.1.7 方法123456789u2 methods_count; // 方法数量method_info &#123; u2 access_flags; // 访问标志 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attributes_count; // 该字段的属性数量 attribute_info attributes[attributes_count]; // 属性信息&#125; (Ljava/lang/String;)V 表示 参数为 String, 返回值为 void 的方法(Ljava/lang/String;IF)V 表示 参数为 String, int, float, 返回值为 void 的方法 1.1.8 属性 方法和字段都可能有属性 方法中可能有 Code 属性, 字段可能有 Constant Value 属性 属性中可能嵌套属性 code 属性中还可能有 Line Number Table, Local Variable Table, Stack Map Table 等属性 虚拟机的实现中还可以自定义属性 1.1.8.1 Constant Value如果某字段为静态类型(access_flag 中包含 ACC_STATIC 标志) 将会被分配 Constant Value 属性 12345ConstantValue_attribute &#123; u2 attribute_name_index; // 必须是对常量池的一个有效索引, 常量池在该索引处的项必须是 UTF8Info, 表示字符串 "ConstantValue" u4 attribute_length; // 固定为 2 u2 constantvalue_index; // 必须是对常量池的一个有效索引, 常量池在该索引处的项给出该属性表示的常量值, 可能的值有 Constant_String, Constant_Long 等&#125; 1.1.8.2 Code1234567891011121314151617Code_attribute &#123; u2 attribute_name_index; // 指向常量池, 应该是 UTF8Info, 且值为 "Code" u4 attribute_length; // 属性长度, 不包括开始的 6 个字节 u2 max_stack; // 操作数栈的最大深度 u2 max_locals; // 最大局部变量表个数 u4 code_length; // 该方法的代码长度 u1 code[code_length]; // 真正的字节码 u2 exception_table_length; // 捕获异常表的长度 &#123; u2 start_pc; // 捕获起始地址 u2 end_pc; // 捕获结束地址 u2 handler_pc; // u2 catch_type; // 异常类型 &#125; exception_table[exception_table_length]; // 捕获异常表 u2 attributes_count; // attribute_info attributes[attributes_count];&#125; Code 属性中的字节码 字节码 命令 含义 2A aload_0 从局部变量表第 0 个值压入操作数栈 B4 00 15 getfield #21 获取对象的字段值 10 1E bipush 30 将 30 压入栈中 A2 00 0E if_icmp_ge 20 将当前 1.1.8.3 LineNumbercode属性的一个子属性 可选的变长属性, 维护 Java 源代码行号与字节码行号(偏移量之间的对应关系) 123456789LineNumberTable_attribute &#123; u2 attribute_name_index; u4 attribute_length; u2 line_number_table_length; &#123; u2 start_pc; // 字节码偏移量 u2 line_number; // 行号 &#125; line_number_table[line_number_table_length];&#125; 1.1.8.4 LocalVariableTable 属性code属性的一个子属性 可选的变长属性, 维护栈帧中局部变量表中变量与 Java 源码中定义变量的关系 123456789101112LocalVariableTable_attribute &#123; u2 attribute_name_index; u4 attribute_length; u2 local_variable_table_length; &#123; u2 start_pc; // 局部变量位于 [start_pc, start_pc + length)之间 u2 length; u2 name_index; // 局部变量的名称索引 u2 descriptor_index; // 局部变量的描述符索引 u2 index; // 局部变量在栈帧中的索引 &#125; local_variable_table[local_variable_table_length];&#125; 1.2 JVM 运行时动态行为 线程中包含函数栈帧, 其中每个函数帧表示某一个函数的调用过程 在每一个函数帧的内部, JVM 又细分了 局部变量表, 操作数栈 等 局部变量和操作数栈中的变量会引用堆中的对象 常量池引用指向方法区, 方法区保存了类的元数据以及方法的字节码 1.2.1 实例Java 源码:123456789public class Test &#123; void add(int i, int j) &#123; int num = i + j; &#125; void demo() &#123; add(10, 20); &#125;&#125; 转换成字节码后:12345678910111213demo:0: aload_01: bipush 103: bipush 205: invokevirtial #28: returnadd:0: aload_11: aload_22: iadd3: istore_34: return 调用 add 函数, 生成新的函数帧 0: aload_1: 将局部变量表第 1 个变量压入操作数栈;1: aload_2: 将局部变量表第 2 个变量压入操作数栈;2: iadd: 将操作数栈顶端的两个元素弹出, 相加并将结果压入栈顶3: istore_3: 将操作数栈栈顶元素放在局部变量表第 3 个元素中4: return: 执行完毕 2. ClassLoader2.1 Java 是动态链接 C: 编译 -&gt; 链接 -&gt; 生成 .exe -&gt; 执行 函数 A 调用函数 B, 在链接时会直接在函数 A 中记录函数 B 的地址 Java: 编译 -&gt; .class -&gt; 装载执行 类 A 中使用了另一个类 B, 在 A.class 中只保存类 B 的名称, 而不会保留 B 的 “地址” 在运行时根据名称来查找类, 装载类 2.2 类加载器的委托模型 工作原理 2.3 类加载器的命名空间 类加载器 + 类名 唯一确定一个类, 只有同一个加载器加载的类才是相同的类. 2.4 验证 2.5 自定义类加载器12345678910111213141516171819202122232425262728293031public class MyClassLoader extends ClassLoader &#123; private List&lt;String&gt; classPaths = new LinkedList&lt;&gt;(); protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] byteCodes = loadByteCode(name); if (byteCodes == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, byteCodes, 0, byteCodes.length); &#125; &#125; private byte[] loadClassFile(String classFileName) &#123; for (String classPath: classPaths) &#123; String realPath = classPath + File.separatorChar + classFileName.replace('.', File.separatorChar) + ".class"; File file = new File(classFileName); if (file.exists()) &#123; try &#123; return IOUtils.toByteArray(new FileInputStream(file)); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125;&#125; DefineClass 方法 protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int length) throws ClassFormatError; 只要传递给该方法一个合法字节数组, 就可以转化成一个 Class 对象, 这就意味着可以从任何地方组装类: 磁盘 zip 文件 网络 运行时动态生成 3. 常量池3.1 常见结构 123456789101112131415161718192021222324252627282930313233CONSTANT_Class_info &#123; u1 tag; // 7 u2 name_index; &#125;CONSTANT_Utf8_info &#123; u1 tag; // 1 u2 length; // 长度 u1 bytes[length]; // content&#125;CONSTANT_String_info &#123; u1 tag; // u2 string_index;&#125;CONSTANT_Fieldref_info &#123; u1 tag; // 9 u2 class_index; // u2 name_and_type_index;&#125;CONSTANT_Methodref_info &#123; u1 tag; // 10 u2 class_index; u2 name_and_type_index;&#125;CONSTANT_NameAndType_info &#123; u1 tag; // 12 u2 class_index; u2 descriptor_index;&#125; 3.2 访问标志 标志名称 标志值 含义 ACC_PUBLIC 0x0001 public 类型 ACC_FINAL 0x0002 声明为 final 类型 ACC_SUPER 0x0020 是否允许使用 invokespecial 字节码指令的新语义 ACC_INTERFACE 0x0200 声明为接口 ACC_ABSTRACT 0x0400 Abstract 类型 ACC_SYNTHETIC 0x1000 这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 注解 ACC_ENUM 0x4000 枚举 4. 字段 &amp; 方法4.1 字段123456789u2 fields_count; // 字段数量field_info &#123; u2 access_flags; // 访问控制符 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attribute_count; // 该字段的属性数量 attribute_info attributes[attribute_count]; // 属性信息&#125; 可以看到上图中有两个字段, 分别为 String 类型的 name, 和 int 类型的 age Name Index 表示常量池中变量名称的索引 Desc Index 表示常量池中变量类型的索引 4.2 方法123456789u2 methods_count; // 方法数量method_info &#123; u2 access_flags; // 访问标志 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attributes_count; // 该字段的属性数量 attribute_info attributes[attributes_count]; // 属性信息&#125; 以第一个方法为例: Name Index 表示方法名称为 &lt;init&gt;, 即构造方法 Desc Index 表示方法签名为 (Ljava/lang/String;I)V, 即 (String, int):void 4.3 属性4.3.1 Code 属性1234567891011121314151617Code_attribute &#123; u2 attribute_name_index; // 指向常量池, 应该是 UTF8Info, 且值为 "Code" u4 attribute_length; // 属性长度, 不包括开始的 6 个字节 u2 max_stack; // 操作数栈的最大深度 u2 max_locals; // 最大局部变量表个数 u4 code_length; // 该方法的代码长度 u1 code[code_length]; // 真正的字节码 u2 exception_table_length; // 捕获异常表的长度 &#123; u2 start_pc; // 捕获起始地址 u2 end_pc; // 捕获结束地址 u2 handler_pc; // u2 catch_type; // 异常类型 &#125; exception_table[exception_table_length]; // 捕获异常表 u2 attributes_count; // 嵌套属性数量 attribute_info attributes[attributes_count]; // 嵌套属性&#125; code 属性一般由两个常见的子属性, 分别是: LineNumberTable LocalVariableTable 4.3.2 LocalLineTable通过该属性可以完成字节码与 Java 源码的行号映射 可以在 debug 的时候准确找到源码 并且抛出异常的时候堆栈信息可以找到对应行号 12345678910LineNumberTable_arrtibute &#123; u2 attribute_name_index; // 指向常量池, 必须是值为 "LineNumberTable" 的 Utf8 常量 u4 arrtibute_length; // 当前属性长度, 不包括开始的 6 个字节 u2 line_number_table_length; // line_number_table 数组元素个数 &#123; u2 start_pc; // start_pc 值必须是 code[] 数组的一个索引 u2 line_number; // 源文件的行号 &#125; line_number_table[line_number_table_length];&#125; 4.3.3 LocalVariableTableLocalVariableTable 属性建立了方法中的局部变量与源代码中的局部变量之间的对应关系。 每个 LocalVariableTable 的 local_variable_table 部分可以看做是一个数组， 每个数组项是一个叫做local_variable_info的结构， 该结构描述了某个局部变量的变量名和描述符， 还有和源代码的对应关系。 下面讲解 local_variable_info 的各个部分： start_pc 是当前 local_variable_info 所对应的局部变量的作用域的起始字节码偏移量； length 是当前 local_variable_info 所对应的局部变量的作用域的大小。 也就是从字节码偏移量 start_pc 到 start_pc+length 就是当前局部变量的作用域范围； name_index 指向常量池中的一个 CONSTANT_Utf8_info ， 该 CONSTANT_Utf8_info 描述了当前局部变量的变量名； descriptor_index 指向常量池中的一个 CONSTANT_Utf8_info ， 该 CONSTANT_Utf8_info 描述了当前局部变量的描述符； index 描述了在该方法被执行时，当前局部变量在栈中局部变量表中的位置。 由此可知， 方法中的每个局部变量都会对应一个local_variable_info 。 12345678910111213LocalVariableTable_attribute &#123; u2 attribute_name_index; // 指向常量池, 必须是值为 "LocalVariableTable_attribute" 的 Utf8 常量 u4 attribute_length; // 当前属性长度, 不包括开始的 6 个字节 u2 local_variable_table_length; // local_variable_table[] 的元素个数 &#123; u2 start_pc; // 局部变量的索引都在范围 [start_pc, start_pc + length) u2 length; u2 name_index; // 变量名索引, 在常量池中 u2 descriptor_index; // 变量描述索引(在常量池中) u2 index; // 此局部变量在当前栈帧的局部变量表中的索引 &#125; local_variable_table[local_variable_table_length]&#125; 解析以上字节码得到: start pc length slot name descript 0 15 0 this Lorg/destiny/jvm/model/Employee 0 15 1 name Ljava/lang/String 0 15 2 age I 在解析 code 属性时需要注意的两点: code 属性中包含了方法真正的字节码 code 属性中包含几个子属性, 包括 LineNumberTable, LocalVariableTable等, 也需要进行解析. 在 Field, Method, Attribute 三者中, 我们可以抽象出如下的关系: 4.3.4 Exceptions如果代码中出现了try{}catch{}块,那么try{}块内的机器指令的地址范围记录下来, 并且记录对应的catch{}块中的起始机器指令地址. 当运行时在try块中有异常抛出的话, JVM会将catch{}块对应懂得其实机器指令地址传递给PC寄存器，从而实现指令跳转. 1234567u2 exception_table_length; // 捕获异常表的长度&#123; u2 start_pc; // 捕获起始地址 u2 end_pc; // 捕获结束地址 u2 handler_pc; // u2 catch_type; // 异常类型&#125; exception_table[exception_table_length]; // 捕获异常表 exception_table 记录了该 code 属性中所有显示抛出的异常信心, 包括异常的作用于及类型. 5. 字节码指令5.1 main 方法字节码Employee 的 main 方法:1234public static final main(String[] args) &#123; Employee employee = new Employee("destiny", 24); employee.sayHello();&#125; 经过编译后的字节码: 5.1.1 newnew indexbyte1 indexbyte2 操作: 创建一个对象 (indexbyte1 &lt;&lt; 8) | indexbyte2 得到一个指向常量池的索引 BB 00 01 对应 new #1, 对应的类就是 org/destiny/jvm/model/Employee 在堆中创建一个新对象 将该对象的引用压入栈中 5.1.2 dup 操作: 复制操作数栈栈顶的值, 并压入栈中 5.1.3 ldcldc index 操作: 从运行时常量池中提取数据压入栈中 ldc #43, 43 在常量池中的值为字符串 destiny 5.1.4 bipushbipush byte 将有符号 byte 扩展为一个 int 类型的值 value, 然后将 value 压入到操作数栈中. byte 是一个立即数而非常量池引用 5.1.5 invokespecial indexbyte1 indexbyte2 操作: 对一个对象进行初始化, 父类的初始化, 调用私有方法(因为没有多态性为) (indexbyte1 &lt;&lt; 8) | indexbyte2 得到一个指向常量池的索引 invokespecial #45 常量池 #45 是一个 methodref: &lt;init&gt;:(Ljava/lang/String;I)V 需要形成新的栈帧 5.1.6 astore_n 操作: 将栈顶的 reference 类型数据保存到局部变量表中 astore_0 astore_1 astore_2 astore_3 5.1.7 aload_n 操作: 从局部变量表中加载一个 reference 类型的值到操作数栈中 aload_0 aload_1 aload_2 aload_3 5.1.8 invokevirtual indexbyte1 indexbyte2 操作: 调用实例方法, 依据实例的具体类型进行分派(多态) (indexbyte1 &lt;&lt; 8) | indexbyte2 invokevirtual #47 =&gt; sayHello: ()V 也需要形成新的栈帧 5.1.9 return 操作: 方法返回, 从当前函数栈帧退出, 无返回值. 5.2 方法指令1234public Employee(String name, int age) &#123; this.name = name; this.age = age;&#125; 5.2.1 aload_0 操作: 从局部变量表中加载 index 为 0 的 reference 类型的值到操作数栈中 5.2.2 aload_1 5.2.3 putfield indexbyte1 indexbyte2 操作: 给一个对象字段赋值 (indexbyte1 &lt;&lt; 8) | indexbyte2 putfield #15 =&gt; putfield name:Ljava/lang/String 5.3.3 iload_2 操作: 从局部变量中把 index 为 2 的 int 类型的值加载到操作数栈中 reference 类型使用 aload, int 类型使用 iload 5.4 字节码指令的设计实现使用 命令模式 来抽象该场景, 即将所有字节码指令抽象为命令对象, 基类声明 command 方法, 再根据操作数的不同泛化出不同的抽象子类 6 JVM 执行引擎 6.1 Java 命令1java -cp path1;path2 org.destiny.jvm.Employee cp: classpath(s), 默认是当前路径 class name: 系统需要找到这个类的 main 方法, 然后执行它的字节码 6.2 执行过程 加载类 工具: ClassFileLoader 目的地: 方法区 获取类的 public static void main(String[] args) 方法 从方法区寻找 执行 main 方法的字节码 字节码指令 栈帧(StackFrame) 堆(Heap) 6.3 字节码指令的分类 类型 指令 依次执行 newbipushldcdup 暂停当前栈帧并创建新栈帧 invokespecialinvokevirtual 跳转到另一行去执行 if_icmp_geif_icmplegoto 退出当前栈帧 return 7. 垃圾回收机制7.1 Java 对象的内存布局 MarkWord: 标注对象的元信息 GC 年龄 锁的标志位 ClassPointer: 指向方法区的类信息的指针 InstanceData: 类实例对象的数据 方法信息保存在方法区 padding: 填充 7.2 对象分配和垃圾回收 对象优先分配在新生代 如果 Eden 区没有足够的空间, 则触发一次 MinorGC Java 对象大多具有生命周期短暂的特点, MinorGC 非常频繁, 速度也很快 大对象直接进入老年代 可以根据参数设置阈值 长期存活对象进入老年代 每个对象都有一个年龄(age), 在 MarkWord 中 如果 age 超过阈值, 则晋升到老年代 动态年龄判断 如果在 Survivor 空间中相同年龄的所有对象大小的总数和大于 Survivor 空间的一半, 年龄大于或等于该年龄的对象可以直接进入老年代 MinorGC 时 新生代与老年代的关系]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(1)基本概念]]></title>
    <url>%2Fblog%2F2018%2F06%2F24%2FNetty-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[1. Netty 架构设计Netty应用中必不可少的组件： 组件 作用 Bootstrap / ServerBootstrap 一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。 EventLoop 为 Channel 处理 IO 操作，一个 EventLoop 可以为多个 Channel 服务。 EventLoopGroup 包含多个 EventLoopGroup Channel 一个 Socket 连接，或者其他和 IO 操作相关的组件，它和 EventLoop 一起用来参与 IO 处理。 Future / ChannelFuture 在 Netty 中所有的 IO 操作都是异步的，因此，你不能立刻得知消息是否被正确处理，但是我们可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures ,他们可以注册一个监听，当操作执行成功或失败时监听会自动触发。总之，所有的操作都会返回一个 ChannelFuture。 ChannelInitializer 当一个链接建立时，我们需要知道怎么来接收或者发送数据，当然，我们有各种各样的 Handler 实现来处理它，那么 ChannelInitializer 便是用来配置这些 Handler ，它会提供一个 ChannelPipeline，并把 Handler 加入到 ChannelPipeline。 ChannelHandler 为了支持各种协议和处理数据的方式，便诞生了 Handler 组件。Handler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。 ChannelPipeline 一个 Netty 应用基于 ChannelPipeline 机制，这种机制需要依赖于 EventLoop 和 EventLoopGroup ，因为它们三个都和事件或者事件处理相关 1.1 Netty 是如何处理连接请求和业务逻辑Netty是一个非阻塞的、事件驱动的、网络编程框架。 一个Channel会对应一个EventLoop，而一个EventLoop会对应着一个线程，也就是说，仅有一个线程在负责一个Channel的IO操作。 当一个连接到达，Netty会注册一个channel，然后EventLoopGroup会分配一个EventLoop绑定到这个channel,在这个channel的整个生命周期过程中，都会由绑定的这个EventLoop来为它服务，而这个EventLoop就是一个线程。 EventLoopGroup 和 EventLoop 的关系 1.2 BootsStrapping 我们利用 BootsStrapping 来配置 netty 应用，它有两种类型，一种用于 Client 端：BootsStrap，另一种用于Server端：ServerBootstrap，要想区别如何使用它们，你仅需要记住一个用在 Client 端，一个用在 Server 端。下面我们来详细介绍一下这两种类型的区别： ServerBootstrap 用于 Server 端，通过调用 bind() 方法来绑定到一个端口监听连接； Bootstrap 用于 Client 端，需要调用 connect() 方法来连接服务器端，但我们也可以通过调用 bind() 方法返回的 ChannelFuture 中获取 Channel 去 connect 服务器端。 客户端的 Bootstrap 一般用一个 EventLoopGroup，而服务器端的 ServerBootstrap 会用到两个（这两个也可以是同一个实例）。为何服务器端要用到两个 EventLoopGroup 呢？这么设计有明显的好处，如果一个 ServerBootstrap 有两个 EventLoopGroup，那么就可以把第一个 EventLoopGroup 用来专门负责绑定到端口监听连接事件，而把第二个 EventLoopGroup 用来处理每个接收到的连接。 1.3 ChannelHandler应用程序中用到的最多的应该就是ChannelHandler，我们可以这么想象，数据在一个ChannelPipeline中流动，而ChannelHandler便是其中的一个个的小阀门，这些数据都会经过每一个ChannelHandler并且被它处理。 一个ChannelPipeline可以把两种Handler（ChannelInboundHandler和ChannelOutboundHandler）混合在一起，当一个数据流进入ChannelPipeline时，它会从ChannelPipeline头部开始传给第一个ChannelInboundHandler，当第一个处理完后再传给下一个，一直传递到管道的尾部。与之相对应的是，当数据被写出时，它会从管道的尾部开始，先经过管道尾部的“最后”一个ChannelOutboundHandler，当它处理完成后会传递给前一个ChannelOutboundHandler。 数据在各个Handler之间传递，这需要调用方法中传递的ChanneHandlerContext来操作， 在netty的API中提供了两个基类分ChannelOutboundHandlerAdapter和ChannelOutboundHandlerAdapter，他们仅仅实现了调用ChanneHandlerContext来把消息传递给下一个Handler，因为我们只关心处理数据，因此我们的程序中可以继承这两个基类来帮助我们做这些，而我们仅需实现处理数据的部分即可。 我们知道InboundHandler和OutboundHandler在ChannelPipeline中是混合在一起的，那么它们如何区分彼此呢？其实很容易，因为它们各自实现的是不同的接口，对于inbound event，Netty会自动跳过OutboundHandler,相反若是outbound event，ChannelInboundHandler会被忽略掉。 当一个ChannelHandler被加入到ChannelPipeline中时，它便会获得一个ChannelHandlerContext的引用，而ChannelHandlerContext可以用来读写Netty中的数据流。因此，现在可以有两种方式来发送数据，一种是把数据直接写入Channel，一种是把数据写入ChannelHandlerContext，它们的区别是写入Channel的话，数据流会从Channel的头开始传递，而如果写入ChannelHandlerContext的话，数据流会流入管道中的下一个Handler。 1.4 Encoders, Decoders and Domain LogicEncoders和Decoders因为我们在网络传输时只能传输字节流，因此，才发送数据之前，我们必须把我们的message型转换为bytes，与之对应，我们在接收数据后，必须把接收到的bytes再转换成message。我们把bytes to message这个过程称作Decode(解码成我们可以理解的)，把message to bytes这个过程成为Encode。 Netty中提供了很多现成的编码/解码器，我们一般从他们的名字中便可知道他们的用途，如ByteToMessageDecoder、MessageToByteEncoder，如专门用来处理Google Protobuf协议的ProtobufEncoder、 ProtobufDecoder。 我们前面说过，具体是哪种Handler就要看它们继承的是InboundAdapter还是OutboundAdapter，对于Decoders,很容易便可以知道它是继承自ChannelInboundHandlerAdapter或 ChannelInboundHandler，因为解码的意思是把ChannelPipeline传入的bytes解码成我们可以理解的message（即Java Object），而ChannelInboundHandler正是处理Inbound Event，而Inbound Event中传入的正是字节流。Decoder会覆盖其中的“ChannelRead()”方法，在这个方法中来调用具体的decode方法解码传递过来的字节流，然后通过调用ChannelHandlerContext.fireChannelRead(decodedMessage)方法把编码好的Message传递给下一个Handler。与之类似，Encoder就不必多少了。 Domain Logic其实我们最最关心的事情就是如何处理接收到的解码后的数据，我们真正的业务逻辑便是处理接收到的数据。Netty提供了一个最常用的基类SimpleChannelInboundHandler，其中T就是这个Handler处理的数据的类型（上一个Handler已经替我们解码好了），消息到达这个Handler时，Netty会自动调用这个Handler中的channelRead0(ChannelHandlerContext,T)方法，T是传递过来的数据对象，在这个方法中我们便可以任意写我们的业务逻辑了。 2. Hello World2.1 依赖12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.0.21.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.2 Server 端 ChannelHandler我们不需要使每一个 InboundChannel 继承自 ChannelInboundHandler，因为直接继承的话需要实现 ChannelInboundHandler 中的所有接口，在一般的 Channel 中没必要这么做，只需要继承 ChannelInboundHandelAdapter，继承它的适配器就可以。 需要实现几个重要的方法，包括读取方法 channelRead(ChannelHandlerContext, ctx) 和异常处理方法 exceptionCaught(ChannelHandlerContext ctx, Throwable cause) 即可。 123456789101112131415161718192021public class HelloWorldServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("HelloWorldServerHandler.channelActive"); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("HelloWorldServerHandler.channelRead"); System.out.println(ctx.channel().remoteAddress().toString() + "-&gt; server: " + msg.toString()); ctx.write("server write: " + msg); ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 2.3 服务端需要一个 ServerBootStrap，用于引导 Netty Server 端的初始化工作。我们需要指定它的 transports，是 NIO还 是 OIO ,还需要指定端口号，安装 server 端的处理器，也就是我们之前写的 HelloWorldServerHandler ，还有一些 Option 的配置。 123456789101112131415161718192021222324252627282930313233343536373839public class HelloWorldServer &#123; private int port; public HelloWorldServer(int port) &#123; this.port = port; &#125; public void start() &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap().group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class).localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() .addLast("decoder", new StringDecoder()) .addLast("encoder", new StringEncoder()) .addLast(new HelloWorldServerHandler()); &#125; &#125;).option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture future = serverBootstrap.bind(port).sync(); future.channel().write("Hello Netty Client, I am a Server"); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; int port = 9527; new HelloWorldServer(port).start(); &#125;&#125; 2.4 Client 端 ChannelHandler整体与 HelloWorldServerHandler 类似 123456789101112131415161718public class HelloWorldClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("HelloWorldClientHandler.channelActive"); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("HelloWorldClientHandler.channelRead: ==&gt;" + msg); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 2.5 Client 端12345678910111213141516171819202122232425262728public class HelloWorldClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() .addLast("decoder", new StringDecoder()) .addLast("encoder", new StringEncoder()) .addLast(new HelloWorldClientHandler()); &#125; &#125;); ChannelFuture future = bootstrap.connect("127.0.0.1", 9527).sync(); future.channel().writeAndFlush("Hello Netty Server, I am a common client"); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 分别启动 Server 端 和 Client 端 即可看到运行结果。 具体过程如下： HelloWorldServer 启动，完成 ChannelHandler 的初始化，监听指定端口，在 ChannelFuture future = serverBootstrap.bind(port).sync() 处进行阻塞； HelloWorldClient 启动，完成 ChannelHandler 的初始化，并向 127.0.0.1:9527 发送一条信息，同时阻塞等待返回结果； HelloWorldServerHandler 读取到 HelloWorldClient 发送的消息，并写入自己的消息 ctx.write(&quot;server write: &quot; + msg) HelloWorldClientHandler 读取到 HelloWorldServerHandler； 发送的消息，打印到控制台。 3. Hello World 结构图 4. ChannelHandler、ChannelHandlerContext 和 ChannelPipeline ChannelInboundHandlerAdapter ChannelOutboundHandlerAdapter 我们平时继承的最多的就是 ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter ，这两个不是接口也不是抽象类，所以我们可以仅仅重写我们需要的方法，没有必须要实现的方法 ChannelHandler, ChannelHandlerContext , ChannelPipeline 这三者的关系很特别，相辅相成，一个 ChannelPipeline 中可以有多个 ChannelHandler 实例，而每一个 ChannelHandler 实例与 ChannelPipeline 之间的桥梁就是 ChannelHandlerContext 实例 如果能够获取到 ChannelHandlerContext 实例的话，就可以获取到需要的一切。同时，可以根据 ChannelHandlerContext 执行 ChannelHandler 中的方法 4.1 示例 首先新增两个 ChannelHandler 修改 HelloWorldClient 中的代码 4.1.1 BaseClient1Handler12345678910111213public class BaseClient1Handler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("BaseClient1Handler.channelActive"); ctx.fireChannelActive(); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("BaseClient1Handler.channelInactive"); &#125;&#125; 4.1.2 BaseClient2Handler1234567public class BaseClient2Handler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("BaseClient2Handler.channelActive"); &#125;&#125; 4.1.3 HelloWorldClient12345678910111213141516171819202122232425262728293031public class HelloWorldClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() .addLast("decoder", new StringDecoder()) .addLast("encoder", new StringEncoder())// .addLast(new HelloWorldClientHandler()); .addLast(new BaseClient1Handler()) .addLast(new BaseClient2Handler()); &#125; &#125;); ChannelFuture future = bootstrap.connect("127.0.0.1", 9527).sync(); future.channel().writeAndFlush("Hello Netty Server, I am a common client"); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 4.1.4 执行结果 此时看到，BaseClient1Handler 和 BaseClient2Handler 都执行了 channelActive() 方法。 但如果把 BaseClient1Handler 的 ctx.fireChannelActive() 去掉，那么只会有 BaseClient1Handler 执行该方法 也就是说如果一个 channelPipeline 中有多个 channelHandler 时，且这些 channelHandler 中有同样的方法时， 例如这里的 channelActive 方法，只会调用处在第一个的 channelHandler 中的 channelActive 方法， 如果你想要调用后续的 channelHandler 的同名的方法就需要调用以 &quot;fire&quot; 为开头的方法了，这样做很灵活 这样设计的优点： 每一个 handler 只需要关注自己要处理的方法，如果你不关注 channelActive 方法时，你自定义的 channelhandler 就不需要重写 channelActive 方法; 异常处理，如果 exceptionCaught 方法每个 handler 都重写了，只需有一个类捕捉到然后做处理就可以了，不需要每个 handler 都处理一遍; 灵活性，也许左侧第一个 ChannelHandler 根本不需要管理某个业务逻辑，但是从第二个 ChannelHandler 就需要关注处理某个业务需求了，那么就可以很灵活地从第二个 ChannelHandler 开始处理业务，不需要从channel中的第一个 ChannelHandler 开始处理. 5. ByteBuf网络传输的载体是 byte, 这是任何框架谁也逃脱不了的一种规定. JAVA 的 NIO 提供了 ByteBuffer, 用来完成这项任务. 读的时候，可读的区域是下标区间是 [readerIndex，writeIndex) ，可写区间的是 [writerIndex,capacity-1] ，但是 discardable 这段区间就会变得相对无用，既不能读，也不能写 从内存分配角度看，ByteBuf 可以分为两类： 堆内存字节缓冲区: 特点是内存的分配和回收速度快，可以被 JVM 自动回收，缺点是如果进行 Socket 的 I/O 读写，需要额外做一次内存复制，将堆内存对应的缓冲区复制到内核 Channel 中，性能会有一定程度的下降。 直接内存字节缓冲区: 非堆内存，它在堆外进行内存分配，相比于堆内存，它的分配和回收速度会慢一些，但是将它写入或者从 Socket Channel 中读取时，由于少了一次内存复制，速度比堆内存快。 ByteBuf 最佳实践: 在 I/O 通信线程的读写缓冲区使用 DirectByteBuf, 后端业务消息的编码模块使用 HeapByteBuf, 这样组合可以达到性能最优.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo踩坑总结]]></title>
    <url>%2Fblog%2F2018%2F05%2F20%2Fdubbo%E8%B8%A9%E5%9D%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[2. 注册服务 IP 解析异常在使用 dubbo 注册服务的时候遇到了 IP 解析错误导致无法正常访问的问题。 在实际问题中，consumer 无法连接到 provider 的服务。其具体表现为： 本机的 IP 设置为 192.168.1.116，但 dubbo 绑定的却是 dubbo://30.250.11.135:20880，本机 ping 30.250.11.135 提示连接超时，provider 可以启动成功，但是 consumer 无法连接，提示连接超时。 2.1 复现场景2.1.1 provider1234567891011121314151617181920212223&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd "&gt; &lt;!-- 具体的实现 bean --&gt; &lt;bean id="provider" class="org.destiny.dubbo.impl.ProviderImpl"/&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="demo-provider"/&gt; &lt;!-- 使用 Zookeeper 注册中心暴露服务地址 --&gt; &lt;dubbo:registry address="zookeeper://10.211.55.4:2181"/&gt; &lt;!-- 用 dubbo 协议在 20880 端口暴露服务 --&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt; &lt;!-- 增加暴露远程服务配置，写操作可以设置 retries=0 避免重复调用 SOA 服务 --&gt; &lt;dubbo:service retries="0" interface="org.destiny.dubbo.Provider" ref="provider"/&gt;&lt;/beans&gt; provider 的启动日志如下： 2.1.2 consumer12345678910111213141516171819&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd "&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="demo-consumer"/&gt; &lt;!-- 使用 Zookeeper 注册中心暴露服务地址 --&gt; &lt;dubbo:registry address="zookeeper://10.211.55.4:2181"/&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt; &lt;!-- 生成远程代理，可以像本地使用 bean 一样使用 demoService，检查级联依赖默认为 true，当有依赖服务的时候，需要根据需求进行设置 --&gt; &lt;dubbo:reference id="consumer" interface="org.destiny.dubbo.Provider" check="false"/&gt;&lt;/beans&gt; consumer 启动日志如下： 2.2 定位问题 在 provider 启动时，定位到日志中第一次出现 30.250.11.135 的的位置： current host 然后全局搜索 current host，定位到对应源码：com.alibaba.dubbo.common.logger.support.FailsafeLogger 怀疑 NetUtils.getLocalHost() 获取到的 IP 就是 30.250.11.135 单独执行 System.out.println(NetUtils.getLocalHost())，发现结果确实是 30.250.11.135 此时结果已经很明确了，是 NetUtils.getLocalHost() 返回的 IP 地址已经错误，导致上面的问题发生。 2.3 分析问题通过阅读 dubbo 相关部分源码，其大致运行过程如下： dubbo 在获取本地 IP 的时候，先调用 NetUtils.getLocalHost()，如果该方法返回一个合法的地址，则直接认为是一本地 IP 的地址。 如果 NetUtils.getLocalHost() 没有返回合法地址，则会遍历本地所有网卡，并返回第一个合法的 IP 作为本地 IP。 而问题就出在 NetUtils.getLocalHost() 返回的并不是真正的本机 IP，却被 dubbo 误认为正确。 NetUtils.getLocalHost() 的原理是通过获取本机的 hostname，然后对此 hostname 做解析，从而获取 IP 地址； 而如果在本机的 /etc/hosts/ 文件中对这个主机名指向了一个错误的 IP 地址，那么 NetUtils.getLocalHost() 就会返回这个错误的 IP 地址； 如果 hostname 是到 DNS 中去解析的，而碰巧 DNS 也是错误的，那么返回的同样是错误的 IP。 因此就可以解释我们遇到的问题了： provider 实际上是运行在 A 地址上，但是 dubbo 检测到本地的 IP 是 B，然后在 Zookeeper 上注册自己服务地址的时候，使用的是 B 地址，那么当 consumer 连接到 Zookeeper 上的时候，查询到 provider 是在 B 地址上，但显然 B 地址上没有该服务，甚至根本无法连接到。因此就出现了该问题。 这个地址就是一开始被 dubbo 意外解析到的 30.250.11.135。 2.4 解决问题 先检查 /etc/hosts 文件中设置的 A 地址指向哪里 再检查 DNS 解析出的地址 /etc/hosts 文件修改前： 向 /etc/hosts 文件中追加 destiny 127.0.0.1 /etc/hosts 文件修改后： 2.5 引申 —— 如何在 Java 代码中正确的读取本地 IP 地址目前最普遍的方法是使用 `InetAddress.getLocalHost().getHostAddress()` 获取 但该方法只能获取简单网络环境下的 IP 地址 如果当前的网络环境比较复杂，存在多个网卡，则会被忽视 比如列出我当前本机的 ifconfig 命令直接结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374$ ifconfiglo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384 options=1203&lt;RXCSUM,TXCSUM,TXSTATUS,SW_TIMESTAMP&gt; inet 127.0.0.1 netmask 0xff000000 inet6 ::1 prefixlen 128 inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1 nd6 options=201&lt;PERFORMNUD,DAD&gt;gif0: flags=8010&lt;POINTOPOINT,MULTICAST&gt; mtu 1280stf0: flags=0&lt;&gt; mtu 1280XHC20: flags=0&lt;&gt; mtu 0en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ether 98:01:a7:a2:9a:c1 inet6 fe80::1ca6:7ed1:3b63:235f%en0 prefixlen 64 secured scopeid 0x5 inet 192.168.1.103 netmask 0xffffff00 broadcast 192.168.1.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activep2p0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 2304 ether 0a:01:a7:a2:9a:c1 media: autoselect status: inactiveawdl0: flags=8943&lt;UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1484 ether ba:98:20:03:2e:f7 inet6 fe80::b898:20ff:fe03:2ef7%awdl0 prefixlen 64 scopeid 0x7 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activeen1: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether 6a:00:02:3e:5e:80 media: autoselect &lt;full-duplex&gt; status: inactiveen2: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether 6a:00:02:3e:5e:81 media: autoselect &lt;full-duplex&gt; status: inactivebridge0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=63&lt;RXCSUM,TXCSUM,TSO4,TSO6&gt; ether 6a:00:02:3e:5e:80 Configuration: id 0:0:0:0:0:0 priority 0 hellotime 0 fwddelay 0 maxage 0 holdcnt 0 proto stp maxaddr 100 timeout 1200 root id 0:0:0:0:0:0 priority 0 ifcost 0 port 0 ipfilter disabled flags 0x2 member: en1 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 8 priority 0 path cost 0 member: en2 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 9 priority 0 path cost 0 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: &lt;unknown type&gt; status: inactiveutun0: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 2000 inet6 fe80::a5b9:4c1f:b4b8:9414%utun0 prefixlen 64 scopeid 0xb nd6 options=201&lt;PERFORMNUD,DAD&gt;utun1: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380 inet6 fe80::3de1:6926:1140:2956%utun1 prefixlen 64 scopeid 0xc inet6 fdd5:8db9:2302:60f0:3de1:6926:1140:2956 prefixlen 64 nd6 options=201&lt;PERFORMNUD,DAD&gt;utun2: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380 inet6 fe80::4568:978c:85d3:ecd9%utun2 prefixlen 64 scopeid 0xd nd6 options=201&lt;PERFORMNUD,DAD&gt;vnic0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=3&lt;RXCSUM,TXCSUM&gt; ether 00:1c:42:00:00:08 inet 10.211.55.2 netmask 0xffffff00 broadcast 10.211.55.255 media: autoselect status: activevnic1: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=3&lt;RXCSUM,TXCSUM&gt; ether 00:1c:42:00:00:09 inet 10.37.129.2 netmask 0xffffff00 broadcast 10.37.129.255 media: autoselect status: active 可以看到有很多类型的网络接口(network interfaces)： loopback 地址: 最常见的就是 127.0.0.1，即本地回环地址，只对本机可见，一般用于调试。 site local address 地址: private 私有地址，属于本地组织内部访问，只能在本地局域网可见，同样 10.xxx.xxx.xxx 等也属于私有地址 link local 地址: 属于连接本地地址，在单独网段可用 UP BROADCAST RUNNING MULTICAST 地址：如果网卡信息中包含 UP BROADCAST RUNNING MULTICAST，则支持广播和组播 除此之外的地址都是点对点可用的刚开的 IPv4 地址 刚才提到的 InetAddress.getLocalHost().getHostAddress() 一般情况下只会在如下两种情况中返回正确结果： 只使用 wifi 只使用网线 而在复杂环境下，获取 IP 地址最好能够遍历所有的网卡，然后依次筛选，最终找到符合条件的网卡的 IP：1234567891011121314151617181920212223242526272829303132public static InetAddress getLocalHostLANAddress() throws SocketException &#123; try &#123; InetAddress candidateAddress = null; // 遍历所有网络接口 Enumeration&lt;NetworkInterface&gt; networkInterfaces = NetworkInterface.getNetworkInterfaces(); while (networkInterfaces.hasMoreElements()) &#123; NetworkInterface networkInterface = networkInterfaces.nextElement(); // 在所有的接口下再遍历 IP Enumeration&lt;InetAddress&gt; inetAddresses = networkInterface.getInetAddresses(); while (inetAddresses.hasMoreElements()) &#123; InetAddress inetAddress = inetAddresses.nextElement(); if (!inetAddress.isLoopbackAddress()) &#123; // 排除 loopback 类型地址 if (inetAddress.isSiteLocalAddress()) &#123; // 如果是 site-local 地址，直接返回 return inetAddress; &#125; else if (candidateAddress == null) &#123; // 如果是 site-local 地址未被发现，先记录候选地址 candidateAddress = inetAddress; &#125; &#125; &#125; &#125; if (candidateAddress != null) &#123; return candidateAddress; &#125; &#125;catch (Exception e) &#123; System.err.println("获取本机 IP 失败"); e.printStackTrace(); &#125; return null;&#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>踩坑总结</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene(二) —— 搭建简易搜索引擎]]></title>
    <url>%2Fblog%2F2018%2F05%2F07%2FLucene-%E4%BA%8C-%E2%80%94%E2%80%94-%E6%90%AD%E5%BB%BA%E7%AE%80%E6%98%93%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[1. 前期准备1.1 爬取数据 爬取网站数据，为实现搜索引擎做准备 wget -o /tmp/wget.log -P /root/data --no-parent --no-verbose -m -D destiny -N --convert-links --random-wait -A html,HTML https://destinywang.github.io/blog/ 将 本人个人博客 爬取的结果为： 放在浏览器中展示的效果为： 在 html 文件中，实际的文件格式如下图所示： 以此类推，可以多爬几个 HTML 文件。 1.2 HTML parser在搜索中，我们往往更关注文字部分，而对于 HTML 标签最好能够予以过滤，为此，我们使用 jericho 进行 HTML 过滤 添加依赖：123456&lt;!-- https://mvnrepository.com/artifact/net.htmlparser.jericho/jericho-html --&gt;&lt;dependency&gt; &lt;groupId&gt;net.htmlparser.jericho&lt;/groupId&gt; &lt;artifactId&gt;jericho-html&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt;&lt;/dependency&gt; 1.3 IKAnalyzer 中文分词器之前的示例中，使用的是默认的StandardAnalyzer分词器，不能有效的进行中文分词，下面演示下如何在Lucene5.0中使用IKAnalyzer分词器。 首先下载IKAnalyzer分词器源码，IKAnalyzer分词器源码托管在OSChina 不过目前项目已经停止更新了，IKAnalyzer 由于已经停止更新，所以并不支持 Lucene5，这里需要对源码做一些修改，否则启动时会抛出如下异常： 1.3.1 下载 IKAnalyzer 源码并打开1$ git clone git@gitee.com:wltea/IK-Analyzer-2012FF.git 然后在 IDE 中打开 1.3.2 修改 IKAnalyzer 源码由于Lucene5.0 API上有些变化，我们需要对IK源码做些修改 1.3.2.1 IKTokenizer 类第一处需要修改的就是IKTokenizer类，在其构造函数里把 //super(in); 这句注释掉即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * IK 中文分词 版本 5.0.1 * IK Analyzer release 5.0.1 * * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * * 源代码由林良益(linliangyi2005@gmail.com)提供 * 版权声明 2012，乌龙茶工作室 * provided by Linliangyi and copyright 2012 by Oolong studio * * */ package org.wltea.analyzer.lucene; import java.io.IOException; import java.io.Reader; import org.apache.lucene.analysis.Tokenizer; import org.apache.lucene.analysis.tokenattributes.CharTermAttribute; import org.apache.lucene.analysis.tokenattributes.OffsetAttribute; import org.apache.lucene.analysis.tokenattributes.TypeAttribute; import org.apache.lucene.util.Version; import org.wltea.analyzer.core.IKSegmenter; import org.wltea.analyzer.core.Lexeme; /** * IK分词器 Lucene Tokenizer适配器类 * 兼容Lucene 4.0版本 */ public final class IKTokenizer extends Tokenizer &#123; //IK分词器实现 private IKSegmenter _IKImplement; //词元文本属性 private final CharTermAttribute termAtt; //词元位移属性 private final OffsetAttribute offsetAtt; //词元分类属性（该属性分类参考org.wltea.analyzer.core.Lexeme中的分类常量） private final TypeAttribute typeAtt; //记录最后一个词元的结束位置 private int endPosition; private Version version = Version.LATEST; /** * Lucene 4.0 Tokenizer适配器类构造函数 * @param in * @param useSmart */ public IKTokenizer(Reader in , boolean useSmart)&#123; //super(in); offsetAtt = addAttribute(OffsetAttribute.class); termAtt = addAttribute(CharTermAttribute.class); typeAtt = addAttribute(TypeAttribute.class); _IKImplement = new IKSegmenter(input , useSmart); &#125; /* (non-Javadoc) * @see org.apache.lucene.analysis.TokenStream#incrementToken() */ @Override public boolean incrementToken() throws IOException &#123; //清除所有的词元属性 clearAttributes(); Lexeme nextLexeme = _IKImplement.next(); if(nextLexeme != null)&#123; //将Lexeme转成Attributes //设置词元文本 termAtt.append(nextLexeme.getLexemeText()); //设置词元长度 termAtt.setLength(nextLexeme.getLength()); //设置词元位移 offsetAtt.setOffset(nextLexeme.getBeginPosition(), nextLexeme.getEndPosition()); //记录分词的最后位置 endPosition = nextLexeme.getEndPosition(); //记录词元分类 typeAtt.setType(nextLexeme.getLexemeTypeString()); //返会true告知还有下个词元 return true; &#125; //返会false告知词元输出完毕 return false; &#125; /* * (non-Javadoc) * @see org.apache.lucene.analysis.Tokenizer#reset(java.io.Reader) */ @Override public void reset() throws IOException &#123; super.reset(); _IKImplement.reset(input); &#125; @Override public final void end() &#123; // set final offset int finalOffset = correctOffset(this.endPosition); offsetAtt.setOffset(finalOffset, finalOffset); &#125; &#125; 1.3.2.2 IKAnalyzercreateComponents()方法是继承Luecene的Analyzer接口的 由于Lucene5.0里把createComponents()方法的第二个参数去掉了 所以需要对该方法做同样的修改 而上文中真正抛出异常的地方也在于此。 123456789/** * 重载Analyzer接口，构造分词组件 */ @Override protected TokenStreamComponents createComponents(String text) &#123; Reader reader = new BufferedReader(new StringReader(text)); Tokenizer _IKTokenizer = new IKTokenizer(reader , this.useSmart()); return new TokenStreamComponents(_IKTokenizer); &#125; 1.3.3 将依赖安装到本地仓库1$ mvn install:install-file -DgroupId=org.wltea.analyzer -DartifactId=IKAnalyzer -Dversion=5.0 -Dpackaging=jar -Dfile=/User/destiny/.m2/repository/IKAnalyzer-5.0.jar 1.3.4 导入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.wltea.analyzer&lt;/groupId&gt; &lt;artifactId&gt;IKAnalyzer&lt;/artifactId&gt; &lt;version&gt;5.0&lt;/version&gt; &lt;/dependency&gt; 2. 核心代码2.1 HTML 对象在搜索结果中，返回给用户的主要信息包括： 文档标题 文档正文（缩略信息） URL 所以对应的实体类：123456789101112131415161718192021222324252627282930public class HtmlBean &#123; private String title; // 标题 private String content; // 正文 private String url; // URL public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125;&#125; 2.2 HTML 转换对象由于爬取的原始数据中，HTML 正文含有大量的标签，对搜索而言没有意义，因此使用 jericho 进行过滤。 12345678910111213141516171819202122232425public class HtmlBeanUtil &#123; /** * 将文件转换为 HtmlBean 页面对象 * @param file * @return */ public static HtmlBean parseHtml(File file) &#123; // 解析 HTML HtmlBean htmlBean = new HtmlBean(); try &#123; Source source = new Source(file); // 取第一个标题元素 Element firstElement = source.getFirstElement(HTMLElementName.TITLE); htmlBean.setTitle(firstElement.getTextExtractor().toString()); htmlBean.setContent(source.getTextExtractor().toString()); htmlBean.setUrl("http://" + file.getAbsolutePath()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return htmlBean; &#125;&#125; 2.3 创建索引1234567891011121314151617181920212223242526272829303132333435363738394041public class LuceneService &#123; public static final String INDEX_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/index"; public static final String DATA_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/html"; public void createIndex() &#123; try &#123; // 目录对象，需要由 Path 进行初始化 Directory directory = FSDirectory.open(Paths.get(INDEX_DIR)); // 创建分词器 Analyzer analyzer = new StandardAnalyzer(); // 由分词器对 IndexWriterConfig 进行初始化 IndexWriterConfig indexWriterConfig = new IndexWriterConfig(analyzer); indexWriterConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND); IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig); File file = new File(DATA_DIR); // 用递归的方式获取指定路径的文件列表(org.apache.commons.io) Collection&lt;File&gt; files = FileUtils.listFiles(file, TrueFileFilter.INSTANCE, TrueFileFilter.INSTANCE); // 将每个文件转换成 Document 对象 for (File file1 : files) &#123; System.out.println("file: " + file1.getName()); HtmlBean htmlBean = HtmlBeanUtil.parseHtml(file1); Document document = new Document(); document.add(new StringField("title", htmlBean.getTitle(), Field.Store.YES)); document.add(new TextField("content", htmlBean.getContent(), Field.Store.YES)); document.add(new StringField("url", htmlBean.getUrl(), Field.Store.YES)); indexWriter.addDocument(document); &#125; indexWriter.close(); &#125; catch (Exception e) &#123; System.err.println(e.getMessage()); &#125; &#125;&#125; 2.4 搜索123456789101112131415161718192021222324252627282930313233@RequestMapping("/search/&#123;keyword&#125;")public List&lt;HtmlBean&gt; search(@PathVariable(value = "keyword") String keyword) &#123; try &#123; Directory directory = FSDirectory.open(Paths.get(INDEX_DIR)); IndexReader indexReader = DirectoryReader.open(directory); IndexSearcher indexSearcher = new IndexSearcher(indexReader); // 创建中文分词器 Analyzer analyzer = new IKAnalyzer(); // 多 field 查询 MultiFieldQueryParser multiFieldQueryParser = new MultiFieldQueryParser(new String[]&#123;"title", "content"&#125;, analyzer); Query query = multiFieldQueryParser.parse(keyword); // 搜索前 10 个匹配度最高的文档 TopDocs topDocs = indexSearcher.search(query, 10); // 组装查询结果 List&lt;HtmlBean&gt; htmlBeanList = new ArrayList&lt;&gt;(); for (ScoreDoc scoreDoc : topDocs.scoreDocs) &#123; int docId = scoreDoc.doc; Document document = indexReader.document(docId); HtmlBean htmlBean = new HtmlBean(); htmlBean.setTitle(document.get("title")); htmlBean.setContent(document.get("content")); htmlBean.setUrl(document.get("url")); htmlBeanList.add(htmlBean); &#125; return htmlBeanList; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return null;&#125; 3. 使用结果]]></content>
      <categories>
        <category>Luence</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene(一) —— 快速入门]]></title>
    <url>%2Fblog%2F2018%2F05%2F05%2FLucene-%E4%B8%80-%E2%80%94%E2%80%94-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1. 搜索引擎组件1.1 索引组件为了快速搜索大量的文本，必须针对文本建立索引，将文本内容转换成能够进行快速搜索的格式。 这个过程就叫做索引操作(indexing)，输出就是索引(index) 1.1.1 获取内容使用网络爬虫或者蜘蛛程序来搜索和界定需要索引的内容。 1.1.2 建立文档获取原始内容之后，就需要对内容进行索引，首先必须将内容转换成文档，以供搜索引擎使用。 文档主要包括几个带值的域，比如标题、正文、摘要、作者和链接(URL)。 然后需要将原始内容中的文本提取出来写入各个文档。 1.1.3 文档分析搜索引擎不能直接对文本进行索引，而必须将文本分割成一系列被称为 词汇单元 的独立原子元素。 这一步骤决定文档中的文本域如何分割成 词汇单元 系列。 Lucene 提供了大量内嵌的分析器能够轻松完成这步操作。 1.1.4 文档索引在本步骤中，文档将被加入到索引列表。 1.2 搜索组件搜索处理过程就是从索引中查找单词，从而找到包含该单词的文档。 1.2.1 建立查询搜索请求会被转换成搜索引擎使用的 查询(query) 对象格式。 查询对象可能很简单，也可能很复杂。 Lucene 提供了一个称之为 查询解析器(QueryParser) 的强大开发包，用它可以根据通用查询语法将用户输入的文本处理成查询对象。查询语句可以包含 布尔运算、短语查询或通配符查询。 1.2.2 搜索查询查询检索索引并返回与查询语句匹配的文档，结果返回时按照查询请求来排序 常见的搜索理论模型： 纯布尔模型：文档不管是否匹配查询请求，都不会被评分，匹配文档与评分不相关，一条查询仅获取所有匹配文档集合的一个子集。 向量空间模型：查询语句和文档都是高维空间的向量模型，这里每一个独立的项都是一个维度，查询语句和文档之间的相关性或相似性由各个向量之间的距离计算得到。 概率模型：采用全概率的方法来计算文档和查询语句匹配的概率。 Lucene 采用了 空间向量模型和纯布尔模型。 2. 核心技术Lucene 是一个全文搜索框架 倒排索引 压缩算法 二元搜索 2.1 倒排索引 根据属性的值来查找记录，这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性，而是由属性值来确定记录的位置，因而成为倒排索引。 单词——文档矩阵 3. Lucene 的工作方法Lucene 提供的服务实际包含两部分，一入一出： 入就是写入，将提供的源（本质上是字符串）写入索引或者将其从索引中删除； 出就是读取，向用户提供全文搜索服务，让用户可以通过关键词定位源。 写入：源字符首先经过 analyzer 处理，包括：分词，拆分成一个个单词；去除 stopword 。将源中需要的信息加入 Document 的各个 Field 中，并把需要索引的 Field 索引起来，把需要存储的 Field 存储起来。 读取：用户提供关键词，经过 analyzer 处理，对处理后的关键词搜索索引，找出对应的 Document。用户根据需要从找到的 Document 中提取出需要的 Field。 document：用户提供的源是一条条记录，它们可以是文本文件、字符串或者数据库表的一条记录等等。一条记录经过索引之后，就是以一个 Document 的形式存储在索引文件中的。用户进行搜索，也是以 Document 列表的形式返回。 field：一个 Document 可以包含多个信息域，例如一篇文章可以包括标题、正文、最后修改时间等信息域，这些信息域是通过 Field 在 Document 中存储的。Field 有两个属性可选：存储和索引。通过存储属性，可以控制是否对这个 Field 进行索引。 4. 示例代码4.1 导入依赖123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!-- lucene --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queries&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- apache-common --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-lang&lt;/groupId&gt; &lt;artifactId&gt;commons-lang&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 4.2 环境准备准备 index 和 data 两个目录，分别用于存放索引和文档 data 随便从其他项目中复制了几个 LICENSE index 保持为空，当 Lucene 运行的时候会自动进行创建 4.3 创建索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class CreateIndex &#123; /* * 索引目录 */ public static final String INDEX_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/index"; /* * 文本目录 */ public static final String DATA_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/data"; public void createIndex() throws IOException &#123; // 目录对象，描述了索引的存放位置，需要由 Path 进行初始化 Directory directory = FSDirectory.open(Paths.get(INDEX_DIR)); // 创建分词器 Analyzer analyzer = new StandardAnalyzer(); // 由分词器对 IndexWriterConfig 进行初始化 IndexWriterConfig indexWriterConfig = new IndexWriterConfig(analyzer); indexWriterConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND); IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig); File file = new File(DATA_DIR); File[] files = file.listFiles(); if (files != null) &#123; // 读取并遍历文本路径下的所有文件，用于生成文档及其索引 for (File f : files) &#123; // 创建文档 Document document = new Document(); // 为文档设置 Field document.add(new StringField("filename", f.getName(), Field.Store.YES)); document.add(new TextField("content", FileUtils.readFileToString(f, Charset.defaultCharset()), Field.Store.YES)); document.add(new LongField("lastModify", f.lastModified(), Field.Store.YES)); // 写入索引 indexWriter.addDocument(document); &#125; &#125; indexWriter.close(); &#125; public static void main(String[] args) throws IOException &#123; CreateIndex createIndex = new CreateIndex(); createIndex.createIndex(); &#125;&#125; 运行完毕之后，发现 index 路径下多了一些文件，即为文档的索引。 4.4 查询索引12345678910111213141516171819202122232425262728public class SearchIndex &#123; public void search() throws IOException, ParseException &#123; // 打开索引所在路径 Directory directory = FSDirectory.open(Paths.get(CreateIndex.INDEX_DIR)); IndexReader indexReader = DirectoryReader.open(directory); IndexSearcher indexSearcher = new IndexSearcher(indexReader); QueryParser queryParser = new QueryParser("content", new StandardAnalyzer()); Query query = queryParser.parse("from"); // 找到符合条件的前 10 条 Document 的索引的集合 TopDocs search = indexSearcher.search(query, 10); // 遍历集合并打印文件名称 for (ScoreDoc scoreDoc : search.scoreDocs) &#123; int docId = scoreDoc.doc; Document document = indexReader.document(docId); String filename = document.get("filename"); System.out.println("filename: " + filename); &#125; &#125; public static void main(String[] args) throws IOException, ParseException &#123; SearchIndex searchIndex = new SearchIndex(); searchIndex.search(); &#125;&#125; 查询结果： 5. 理解索引过程核心类执行简单的索引过程需要用到以下几个类： IndexWriter Directory Analyzer Document Field 5.1 IndexWriterIndexWriter(写索引)是索引过程的核心组件，这个类负责创建新索引或者打开已有索引，以及向索引中添加、删除或者是更新被索引文档的信息。为开发者提供针对索引文件的写入操作，但不能用于读取或者搜索索引。IndexWriter 需要开辟一定的空间用来存储索引，该功能可以由 Directory 完成。 5.2 DirectoryDirectory 描述了 Lucene 索引存放的位置。它是一个抽象类，其实现类负责具体指定索引的存储路径。在上面的例子中，我们使用 FSDirectory.open() 方法来获取真实文件在文件系统中的存储路径，然后将她们依次传递给 IndexWriter 类的构造方法。 IndexWriter 不能直接索引文本，需要先由 Analyzer 将文本分割成独立的单词才行。 5.3 Analyzer文本文件在被索引之前，需要经过 Analyzer 处理，Analyzer 由 IndexWriter 的构造方法来指定，负责从被索引文本文件中提取词汇单元，并剔除剩下的无用信息。如果被索引的内容不是纯文本文件，那就需要先将其转换成文本文档。 Analyzer 是一个抽象类，其实现类中： 有的用于跳过停用词（指一些常用且不能帮助区分文档的词，如a、an、the、in 和 on 等） 有的用于把词汇转换成小写，以使得搜索过程不区分大小写 等等 分析器的分析对象为文档。 5.4 DocumentDocument 代表一些 域(Field) 的集合，可以将 Document 理解为虚拟文档，如 Web页面、邮件信息等。文档的域代表文档或者文档相关的一些元数据。 Lucene 只处理文本和数字，Lucene 的内核本身只处理 java.lang.String 和 java.io.Reader 对象和本地数字类型 Document 对象的结构比较简单，为一个多个 Field 对象的容器， Field 是指包含能被索引的文本内容的类。 5.5 Field索引中，每个文档都包含一个或者多个不同命名的域，这些域包含在 Field 类中。 每个域都有一个域名和对应的值，以及一组选项来精确控制 Lucene 索引操作各个域值。 6. 理解搜索过程核心类核心类： IndexSearcher Term Query TermQuery TocDocs 6.1 IndexSearcher用于搜索 IndexWriter 所创建的索引，可以将它看做一个以只读方式打开索引的类。 它需要利用 Directory 实例来掌握前期创建的索引，然后才能提供大量的搜索方法，最简单的搜索方法是将单个 Query 对象和 int topN 所谓该方法的参数，返回一个 TopDocs 对象。 6.2 TermTerm 是搜索功能的基本单元，与 Field 对象类似，Term 对象包含一对字符串元素：域名和单词，注意 Term 对象还与索引操作有关。 6.3 QueryLucene 含有许多具体的 Query 子类 6.4 TermQuery是 Lucene 提供的最基本的查询类型，也是简单的查询类型之一，它用来匹配指定域中包含特定值的文档。 6.5 TopDocsTopDocs 类是一个简单的容器指针，指针一般指向前 N 个排名的搜索结果，搜索结果即匹配查询条件的文档。TopDocs 会记录前 N 个结果中每个结果的 int docID 和浮点型分数。]]></content>
      <categories>
        <category>Luence</category>
      </categories>
      <tags>
        <tag>Luence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[quartz 入门]]></title>
    <url>%2Fblog%2F2018%2F04%2F25%2Fquartz-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1. 任务调度概述各种企业应用几乎都会碰到任务调度的需求。 在特定的时间点执行指定的操作。 任务调度本身涉及多线程并发、运行时间规则指定和解析、运行现场保持和恢复、线程池维护等诸多方面的问题。 2. Quartz Quartz允许开发人员灵活地定义触发器的调度时间，并可对触发器和任务进行关联映射； Quartz提供了调度运行环境的持久化和保存； Quartz还提供了组件式的侦听器、插件、线程池等功能。 2.1 Quartz基础结构Quartz对任务调度领域的问题进行了高度的抽象，提出了调度器、任务、触发器这3个核心的概念。 2.1.1 Job是一个接口，只有一个方法void execute(JobExecutionContext context)，开发者通过实现该接口来定义需要执行的任务，JobExecutionContext 类提供了调度上下文的各种信息。Job 运行时的信息保存在 JobDataMap 实例中。 2.1.2 JobDetailQuartz 在每次执行 Job 的时候，都重新创建一个 Job 实例，所以它不是直接接收一个 Job 实例，而是接收一个 Job 实现类，以便运行时通过 newInstance() 反射调用机制实例化 Job。因此需要通过一个类来描述 Job 的实现类及其他相关信息，如 Job 名称、描述、关联监听器等信息，而 JobDetail 承担了这一角色。通过该类的构造函数 JobDetail(java.lang.String name, java.lang.String group, java.lang.Class jobClass)，可以更具体地了解它的功能。该构造函数要求指定 Job 的实现类，以及任务在 Schedule 中的组名和 Job 名称。 2.1.3 Trigger描述触发 Job 执行的时间触发规则。主要有 SimpleTrigger 和 CronTrigger 这两个子类。当仅需要触发一次或者以固定间隔周期性执行的时候， SimpleTrigger 是最佳选择；而 CronTrigger 则可以通过 Cron 表达式定义出各种复杂的调度方案，如每天早上 9:00 执行，每周一、周三下午 5:00 执行等。 2.1.4 Calendarorg.quartz.Calendar 和 java.util.Calendar 不同，它是一些日历特定时间点的集合。一个 Trigger 可以和多个 Calendar 关联，以便排除或包含某些时间点。假设安排每周一早晨 10:00 执行任务，但是如果遇到法定节假日不执行任务，这时就需要在 Trigger 触发机制的基础上使用 Calendar 进行定点排除。针对不同的时间段类型，如 AnnualCalendar、MonthlyCalendar、WeeklyCalendar 分别针对每年、每月和每周进行定义。 2.1.5 Scheduler代表一个 Quartz 的独立运行容器，Trigger 和 JobDetail 可以注册到 Scheduler 中，二者在 Scheduler 中拥有各自的组及名称。组及名称是 Scheduler 查找定位容器中某个对象的依据， Trigger 的组及明恒的组合必须唯一， JobDetail 的组及名称的组合也必须唯一（但可以和 Trigger 的组及名称相同，因为二者处在不同的容器中）。Scheduler 定义了多个接口方法，允许外部通过组及名称访问和控制容器中的 Trigger 和 JobDetail。Scheduler 可以将 Trigger 绑定到某一个 JobDetail 中，这样当 Trigger 被触发时，对应的 Job 就会被执行。一个 Job 可以对应多个 Trigger，但一个 Trigger 只能对应一个 Job。可以通过 SchedulerFactory 创建一个 Scheduler 实例。Scheduler 拥有一个 SchedulerContext，保存着 Scheduler 上下文信息，可以对照 ServletContext 来理解 SchedulerContext。 Job 和 Trigger 都可以访问 SchedulerContext 内的信息。SchedulerContext 内部通过一个 Map，以键值对的方式维护这些上下文数据。SchedulerContext 为保存和获取数据提供了多个 put() 和 getXxx() 方法。可以通过 Scheduler#getContext() 方法获取 SchedulerContext 实例。 2.1.6 ThreadPoolSchedule 使用一个线程池作为任务运行的基础设施，任务通过共享线程池中的线程来提高效率。 Job 有一个 StatefulJob 子接口，代表有状态的任务。该接口是一个没有方法的标签接口，其目的是让 Quartz 知道任务类型，以便采取不同的措施。无状态任务在执行时拥有自己的 JobDataMap 复制，对 JobDataMap 的更改不会影响下次执行。而有状态任务共享同一个 JobDataMap 实例，每次任务执行时对 JobDataMap 所做的更改会保存下来。后面的执行可以看到更改。 因此，无状态任务可以并发执行，而有状态任务的 StatefulJob 不能并发执行。如果上一次的 StatefulJob 还没有执行完成，则下次的任务将阻塞等待。有状态任务比无状态任务需要考虑更多的因素，所以尽量避免使用无状态任务。 如果 Quartz 使用了数据库持久化任务调度信息，则无状态的 JobDataMap 仅会在 Scheduler 注册的任务时保存一次，而有状态任务对应的 JobDataMap 在每次执行任务后都会进行保存。 Trigger 自身也可以拥有一个 JobDataMap，其关联的 JobDataMap 可以通过 JobExecutionContext#getTrigger().getJobDataMap() 方法获取。不管是有状态还是无状态的任务，在任务执行期间对 Trigger 的 JobDataMap 所做的更改都不会进行持久化。 Quartz 拥有完善的事件和监听体系，大部分组件都拥有事件，如任务执行前事件、执行后事件、触发器触发前事件、触发器触发后事件、调度器开始事件、调度器关闭事件等。可以注册相应的监听器处理感兴趣的事件。 2.2 SimpleTriggerSimpleTrigger 有多个重载的构造函数，用于在不同场合下构造出对应的实例。 SimpleTrigger(String name, String group)：指定所属组和名称； SimpleTrigger(String name, String group, Date startTime)：指定触发的开始时间； SimpleTrigger(String name, String group, Date startTime, Date endTime, int repeatCount, long repeatInterval)：指定开始时间、结束时间、重复执行次数、时间间隔； SimpleTrigger(String name, String group, String jobName, String jobGroup, Date startTime, Date endTime, int repeatCount, long repeatInterval)：最复杂的一个构造函数，通过 jobName 和 jobGroup，使该 Trigger 和 Scheduler 中的某个任务关联起来。 2.2.1 代码实例 2.2.1.1 SimpleJob123456public class SimpleJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(jobExecutionContext.getTrigger().getName() + " triggered. time is:" + System.currentTimeMillis()); &#125;&#125; 2.2.1.2 SimpleTriggerRunner12345678910111213141516171819202122232425262728293031public class SimpleTriggerRunner &#123; public static void main(String[] args) &#123; try &#123; // 创建一个 JobDetail 实例，指定 SimpleJob JobDetail jobDetail = JobBuilder.newJob(SimpleJob.class) .withIdentity("jName", "jGroup") .build(); // 通过 SimpleTrigger 定义调度规则：【立即启动】、【每2秒运行一次】、【用运行10次】 SimpleTrigger simpleTrigger = TriggerBuilder.newTrigger() .withIdentity("tName", "tGroup") .startNow() .withSchedule( SimpleScheduleBuilder.simpleSchedule() .withIntervalInSeconds(2) // 调度间隔 .withRepeatCount(10) // 调度次数 ).build(); // 通过 SchedulerFactory 获取一个调度器实例 SchedulerFactory factory = new StdSchedulerFactory(); Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, simpleTrigger); scheduler.start(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.2.1.3 运行结果tName1 triggered. time is:1524563336613 tName1 triggered. time is:1524563338522 tName1 triggered. time is:1524563340522 tName1 triggered. time is:1524563342524 tName1 triggered. time is:1524563344523 tName1 triggered. time is:1524563346523 tName1 triggered. time is:1524563348523 tName1 triggered. time is:1524563350524 tName1 triggered. time is:1524563352524 tName1 triggered. time is:1524563354524 tName1 triggered. time is:1524563356523 2.3 使用 CronTriggerCronTrigger 能够提供比 SimpleTrigger 更有实际意义的调度方案，调度规则基于 Cron表达式。 CronTrigger 支持日历相关的周期性时间间隔（比如每月第一个周一执行），而不是简单的周期时间间隔。 2.3.1 Cron 表达式Quartz 使用类似 Linux 下的 Cron 表达式定义时间规则。Cron 表达式由 6 或 7 个空格分割的时间字段组成。 位置 时间域名 允许值 允许的特殊字符 1 秒 [0, 60) ,-*/ 2 分钟 [0, 60) ,-*/ 3 小时 [1, 24) ,-*/ 4 日期 [1, 32) ,-*?/LWC 5 月份 [1, 13) ,-*/ 6 星期 [1, 8) ,-*/LC?# 7 年（可选） 空值 或 [1970, 2100) ,-*/ 特殊字符： 特殊字符 作用 * 表示对应时间域的每一个时刻，如 * 在分钟时段就表示每分钟 ? 只能在日期和星期中使用，占位符，无意义 - 表达范围，如在小时中使用 10-12，表示从 10 点到 12 点 , 列表纸，如在星期中使用 MON,WED,FRI，表示周一、周三、周五 / x/y 表示等步长序列，x 为起始值，y 为增量步长，如在分钟中使用 0/15，表示0、15、30、45秒 L 只能在日期和星期中使用，代表 Last 的意思，日期中表示当月最后一天，星期表示周六 W 只能出现在日期中，是对前导日期的修饰，表示里该日期最近的工作日 LW 只能出现在日期中，表示当月最后一个工作日 # 只能在星期字段中使用，表示当月的某个工作日，6#3表示当月第三个周五，4#5 表示当月第五个周三，如果不存在则不触发 C 只能在日期和星期中使用，Calendar，表示计划所关联的日期。5C 在日期中相当于 5日之后的那一天，1C 在星期中相当于 周天后的那一天 示例 表达式 说明 0 0 12 * * ? 每天 12:00 运行 0 15 10 ? * * 每天 10:15 运行 0 15 10 * * ? 每天 10:15 运行 0 15 10 * * ? * 每天 10:15 运行 0 15 10 * * ? 2008 在 2008 年的每天 10:15 运行 0 * 14 * * ? 每天 14 点到 15 点每分钟运行一次，开始于 14:00，结束于 14:59 0 0/5 14 * * ? 每天 14 点到 15 点每 5 分钟运行一次，开始于 14:00，结束语 14:55 0 0/5 14,18 * * ? 每天 14 点到 15 点每 5 分钟运行一次，此外每天 18 点到 19 点每 5 分钟也运行一次 0 10,44 14 ? 3 WED 3 月的每周三的 14:10 到 14:44，每分钟运行一次 0 15 10 ? * MON-FRI 每个工作日的 10:15 运行一次 0 15 10 15 * ? 每月 15 日的 10:15 运行一次 0 15 10 L * ? 每月最后一天的 10:15 运行一次 0 15 10 ? * 6L 每月的最后一个周五的 10:15 运行一次 0 15 10 ? * 6L 2014-2016 2014、2015、2016 年每个月的最后一个周五的 10:15 运行 0 15 10 ? * 6#3 每月第三个周五的 10: 15 运行 2.3.2 示例123456789101112131415161718192021222324public class CronTriggerRunner &#123; public static void main(String[] args) &#123; try &#123; JobDetail jobDetail = new JobDetail("jName1", "jGroup1", SimpleJob.class); // 创建 CronTrigger 指定组及名称 CronTrigger cronTrigger = new CronTrigger("tName1", "tGroup1"); // 新建并设置 Cron 表达式：从每分钟的 0 秒开始，每隔5秒触发一次 CronExpression cronExpression = new CronExpression("0/5 * * * * ?"); cronTrigger.setCronExpression(cronExpression); SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, cronTrigger); scheduler.start(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.3 运行结果tName1 triggered. time is:1524645830011 tName1 triggered. time is:1524645835006 tName1 triggered. time is:1524645840006 tName1 triggered. time is:1524645845002 tName1 triggered. time is:1524645850003 tName1 triggered. time is:1524645855004 tName1 triggered. time is:1524645860003 tName1 triggered. time is:1524645865003 tName1 triggered. time is:1524645870005 tName1 triggered. time is:1524645875006 tName1 triggered. time is:1524645880000 tName1 triggered. time is:1524645885000 tName1 triggered. time is:1524645890007 tName1 triggered. time is:1524645895005 tName1 triggered. time is:1524645900005 由于打印的时间是以毫秒作为单位的，因此可以看毫秒数的倒数第4位，都是以 5 作为步长的。 2.4 Calendar在实际任务调度中，不可能一成不变地按照某个特定周期调度任务，必须考虑到现实生活中日历上的特殊日期。 下面的例子中，该任务每小时运行一次，并将 五一劳动节 和 国庆节 排除在外 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142public class CalendarExample &#123; public static void main(String[] args) throws SchedulerException &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); // 法定节日是以年作为周期的，所以使用 AnnualCalendar AnnualCalendar holidays = new AnnualCalendar(); // 五一劳动节 Calendar laborDay = new GregorianCalendar(); laborDay.add(Calendar.MONTH, 5); laborDay.add(Calendar.DATE, 1); // 国庆节 Calendar nationalDay = new GregorianCalendar(); nationalDay.add(Calendar.MONTH, 10); nationalDay.add(Calendar.DATE, 1); ArrayList&lt;Calendar&gt; calendarList = new ArrayList&lt;&gt;(); calendarList.add(laborDay); calendarList.add(nationalDay); // 排除这两个日期 holidays.setDaysExcluded(calendarList); // 向 Scheduler 注册日历 scheduler.addCalendar("holidays", holidays, false, false); // 4月1日上午10点 Date runDate = TriggerUtils.getDateOf(0, 0, 10, 1, 4); JobDetail jobDetail = new JobDetail("jName1", "jGroup1", SimpleJob.class); SimpleTrigger trigger = new SimpleTrigger( "tName1", "tGroup1", runDate, null, SimpleTrigger.REPEAT_INDEFINITELY, 60L * 60L * 1000L); // 让 Trigger 应用指定的日历规则 trigger.setCalendarName("holidays"); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); &#125; &#125; 2.5 任务调度信息存储在默认情况下，Quartz 将任务调度的运行信息保存在内存中。这种方法提供了最佳的性能，但缺乏持久性。 如果需要持久化任务调度信息，则 Quartz 允许用户通过调整其属性文件，将这些信息保存到数据库中。 2.5.1 通过配置文件调整任务调度信息Quartz JAR 文件的 org.quartz 包含了一个 quartz.properties 属性配置文件，并提供了默认属性。可以通过在类路径下新建一个 quartz.properties 文件来覆盖默认配置。 # 集群的配置，这里不使用集群 org.quartz.scheduler.instanceName = DefaultQuartzScheduler org.quartz.scheduler.rmi.export= false org.quartz.scheduler.warpJobExecutionInUserTransaction = false # 配置调度器的线程池 org.quartz.threadPool.class = org.quartz.simple.SimpleThreadPool org.quartz.threadPool.threadCount = 10 org.quartz.threadPool.threadPriority = 5 org.quartz.threadPool.threadInheritContextClassLoaderOfInitializingThread # 配置任务调度现场数据保存机制 org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore 如果任务数目很大，则可以通过增大线程池获得更好的性能。 默认情况下，Quartz 采用 org.quartz.simpl.RAMJobStore 保存任务的现场数据，而通过以下设置可以将任务调度现场数据保存到数据库中 org.quartz.jobStore.class = org.quratz.impl.jdbcjobstore.JobStoreTX # 数据库表前缀 org.quartz.jobStore.tablePrefix = QRTZ_ # 数据源名称 org.quartz.jobStore.dataSource = qzDS # 定义数据源的具体属性 org.quartz.dataSource.qzDS.driver = com.mysql.jdbc.Driver org.quartz.dataSource.qzDS.URL = jdbc:mysql://localhost:3306/quartz org.quartz.dataSource.qzDS.user = root org.quartz.dataSource.qzDS.password = 123456 org.quartz.dataSource.qzDS.maxConnections = 10 要将任务调度数据保存到数据库中，就必须使用 org.quratz.impl.jdbcjobstore.JobStoreTX，并提供相应的数据库配置信息。 用户必须事先在相应的数据库中创建 Quartz 的数据表，在 Quartz 的完整发布包的 docs/dbTables 目录下拥有对应不同数据库的 SQL 脚本。 选择自己使用的数据库对应的脚本执行即可。 执行结果： 2.5.2 查询数据库中的运行信息首先，引入依赖：1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.45&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 任务的现场保存对于上层的 Quartz 来说是完全透明的。使用该配置文件后将之前的代码重新运行，就能在数据库中看到对应的数据。 当调度程序中途停止之后，任务调度的现场数据将记录在数据库表中，在系统重启时就可以在此基础上继续任务的调度。 1234567891011121314151617181920212223242526public class JDBCJobStoreRunner &#123; public static void main(String[] args) &#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); // 获取调度器中所有的触发组 String[] triggerGroups = scheduler.getTriggerGroupNames(); // 重新恢复在 tGroup1 组中名为 tName1 的触发器的运行 for (int i = 0; i &lt; triggerGroups.length; ++ i) &#123; String[] triggerNames = scheduler.getTriggerNames(triggerGroups[i]); for (int j = 0; j &lt; triggerNames.length; ++ j) &#123; Trigger trigger = scheduler.getTrigger(triggerGroups[i], triggerNames[j]); if (trigger instanceof SimpleTrigger &amp;&amp; trigger.getFullName().equals("tGroup1.tName1")) &#123; // 恢复运行 scheduler.rescheduleJob(triggerNames[j], triggerGroups[i], trigger); &#125; &#125; &#125; scheduler.start(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 如果调度程序执行后非正常退出，就可以通过 JDBCJobStoreRunner 根据记录在数据库中的现场数据恢复任务的调度。Scheduler 中的所有 Trigger 及 JobDetail 的运行信息都会保存在数据库中，这里仅恢复 tGroup1 组中名为 tName1 的触发器。触发器采用 GROUP.TRIGGER_NAME 的全名格式，通过 Scheduler#reschduleJob(String triggerName, String groupName, Trigger trigger) 方法即可重新调度关联某个 Trigger 任务。 2.5.3 不同时期 QRTZ_SIMPLE_TRIGGERS 表的数据 执行 代码 中的 SimpleTriggerRunner 一段时间后退出 quartz 数据库状态如下 这时 QRTZ_SIMPLE_TRIGGERS 表中的数据如下 REPEAT_COUNT: 触发器器需要执行的总次数 REPEAT_INTERVAL: 调度间隔(单位：毫秒) TIMES_TRIGGERED: 触发器已经调度的次数 1234567891011121314151617181920212223242526public class JDBCJobStoreRunner &#123; public static void main(String[] args) &#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobKey jobKey = new JobKey("jName", "jGroup"); List&lt;? extends Trigger&gt; triggers = scheduler.getTriggersOfJob(jobKey); // SELECT TRIGGER_NAME, TRIGGER_GROUP FROM &#123;QRTZ_&#125;TRIGGERS WHERE SCHED_NAME = &#123;DefaultQuartzScheduler&#125; AND JOB_NAME = ? AND JOB_GROUP = ? // 其中 &#123;QRTZ_&#125; 和 &#123;DefaultQuartzScheduler&#125; 均来自 quartz.properties 的配置 // 重新恢复在jGroup1组中，名为job1_1的 job的触发器运行 if(triggers.size() &gt; 0)&#123; for (Trigger tg : triggers) &#123; // 根据类型判断 if ((tg instanceof CronTrigger) || (tg instanceof SimpleTrigger)) &#123; // 恢复job运行 scheduler.resumeJob(jobKey); &#125; &#125; scheduler.start(); &#125; &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 此时原先被中断的任务已经恢复。 可以看到，将剩余12次全部执行完成。 再次查看 QRTZ_SIMPLE_TRIGGER 表，发现触发器已经完成调度并被清除。 3. 集成 SpringSpring 为创建 Quartz 的 Scheduler、Trigger、JobDetail 提供了便利的 FactoryBean 类，以便能够在 Spring 容器中享受注入的好处。 Spring 提供了两方面的支持： 为 Quartz 的主要组件提供了更具 Bean 风格的扩展类 提供创造 Scheduler 的BeanFactory 类，方便在 Spring 环境下创建对应的组件对象，并结合 Spring 容器生命周期执行启动和停止的动作。 3.1 创建 JobDetail由于 JobDetail 使用带参构造函数，不方便通过 Spring 配置，因此 Spring 通过扩展 JobDetail 提供了更具 Bean 风格的 JobDetailFactoryBean，此外，Spring 还提供了 MethodInvokingJobDetailFactoryBean，用于将 Spring 容器中 Bean 的方法包装成 Quartz 任务，使开发者不必为 Job 创建对应的类。 3.1.1 JobDetailFactoryBean12345678910111213141516171819@Configuration@ComponentScan(basePackages = &#123;"example5"&#125;)public class QuartzConf &#123; @Bean public JobDetailFactoryBean jobDetailFactoryBean() &#123; JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); jobDetailFactoryBean.setJobClass(SimpleJob.class); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("size", 10); jobDetailFactoryBean.setJobDataAsMap(map); jobDetailFactoryBean.setApplicationContextJobDataKey("applicationContext"); return jobDetailFactoryBean; &#125;&#125; JobDetailFactoryBean 封装了 SimpleJob 任务类，并为 Job 对应的 JobDataMap 设置了一个 key 为 size，value 为 10的数据。此外，通过指定 ApplicationContextJobDataKey，让 Job 的JobDataMap 持有 Spring ApplicationContext 的引用。 jobClass：实现 Job 接口的任务类； beanName：默认为 bean 的id，显示指定 Bean 名称，对应任务的名称； jobDataAsMap：类型为 Map，为任务所对应的 JobDataMap 提供值。提供这个数据是因为用户无法在 Spring 配置文件中为 JobDataMap 类型的属性提供信息； applicationContextJobDataKey：用户可以将 Spring ApplicationContext 的引用保存到 JobDataMap 中，以便在 Job 的代码中访问 ApplicaitonContext。为了达到这个目的，用户需要指定一个 key 对应这个 ApplicationContext，如果不设置就不会将 ApplicationContext 放入 JobDataMap中； jobListenerNames：类型为 String[]，指定注册在 Scheduler 中的 JobListener 名称。 3.2 创建 TriggerSpring 按照相似的思路分为 SimpleTrigger 和 CronTrigger 提供了更具 Bean 风格的 SimpleTriggerFactoryBean 和 CronTriggerFactoryBean 的扩展类， 3.2.1 SimpleTriggerFactoryBean1234567891011121314@Bean(name = "simpleTrigger")public SimpleTriggerFactoryBean simpleTriggerFactoryBean() &#123; SimpleTriggerFactoryBean simpleTriggerFactoryBean = new SimpleTriggerFactoryBean(); simpleTriggerFactoryBean.setJobDetail(jobDetailFactoryBean().getObject()); simpleTriggerFactoryBean.setStartDelay(1000); simpleTriggerFactoryBean.setRepeatInterval(2000); simpleTriggerFactoryBean.setRepeatCount(20); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("count", 10); simpleTriggerFactoryBean.setJobDataAsMap(map); return simpleTriggerFactoryBean;&#125; 定义了一个 Trigger，该 Trigger 和 JobDetail 相关联，延迟 1 秒后启动，时间间隔为 2 秒，重复执行 20 次。 Trigger 中设置的 JobDataMap 在执行任务时必须通过以下方式获取12345public class SimpleJob implements StatefulJob &#123; public void execute(JobExecutionContext context) throws JobExecutionException &#123; Map dataMap = context.getTrigger().getJobDataMap(); &#125;&#125; 3.2.2 CronTriggerFactoryBean1234567@Bean(name = "cronTriggerFactoryBean")public CronTriggerFactoryBean cronTriggerFactoryBean() &#123; CronTriggerFactoryBean cronTriggerFactoryBean = new CronTriggerFactoryBean(); cronTriggerFactoryBean.setJobDetail(jobDetailFactoryBean().getObject()); cronTriggerFactoryBean.setCronExpression("0/5 * * * * ?"); return cronTriggerFactoryBean;&#125; 3.3 SchedulerQuartz 的 SchedulerFactory 是标准的工厂类，不太适合在 Spring 环境下使用。此外，为了保证 Scheduler 能够感知到 Spring 的生命周期，Spring 提供了 SchedulerFactory。 12345678910111213@Beanpublic SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 注册一个或多个 Trigger schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean().getObject()); // 以 Map 类型设置 SchedulerContext Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeout", 30); schedulerFactoryBean.setSchedulerContextAsMap(map); // 显示指定 Quartz 配置文件的路径 schedulerFactoryBean.setConfigLocation(new ClassPathResource("quartz.properties")); return schedulerFactoryBean;&#125; triggers：属性为 trigger[]，可以注册多个 Trigger schedulerContextAsMap：Scheduler拥有类似 ServletContext 的 SchedulerContext，允许用户以 Map 的形式设置 SchedulerContext 的参数值 configLocation：指定配置文件路径 calendars：类型为 Map，通过该属性向 Scheduler 注册 JobDetail jobDetails：类型为 JobDetail[]，通过该属性向 Scheduler 注册 JobDetail autoStartup：SchedulerFactoryBean 初始化之后是否立即启动，默认为 true startupDelay：SchedulerFactoryBean 启动后的延迟时间，默认为 0 SchedulerFactoryBean 的一项重要功能是允许用户将 Quartz 配置文件中的信息转移到 Spring 配置文件中 12345678910111213141516171819@Beanpublic SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 注册一个或多个 Trigger schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean().getObject()); // 以 Map 类型设置 SchedulerContext Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeout", 30); schedulerFactoryBean.setSchedulerContextAsMap(map); // 显示指定 Quartz 配置文件的路径 schedulerFactoryBean.setConfigLocation(new FileSystemResource("classpath:quartz.properties")); //------------------ 集成 Quartz 配置文件 ------------------// Properties properties = new Properties(); properties.setProperty("org.quartz.threadPool.class", "org.quartz.simpl.SimpleThreadPool"); properties.setProperty("org.quartz.threadPool.threadCount", "10"); schedulerFactoryBean.setQuartzProperties(properties); return schedulerFactoryBean;&#125; 3.4 测试代码此处有一个坑，就说从 Spring 容器中根据 beanName 获取的 schedulerFactoryBean 其实是 org.quartz.impl.StdScheduler 对象，如果使用 org.springframework.scheduling.quartz.SchedulerFactoryBean 会抛出以下异常 从 Spring 容器中直接获取 Scheduler 即可。1234567891011public class SimpleTriggerRunner &#123; public static void main(String[] args) throws SchedulerException &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(QuartzConf.class); // 此处一定要取 Scheduler 而不是 SchedulerFactoryBean，因为它是一个工厂bean，得到的不是它本身，而是它负责创建的 org.quartz.impl.StdScheduler 对象 Scheduler scheduler = context.getBean("schedulerFactoryBean", Scheduler.class); scheduler.start(); &#125;&#125; 4. 附录4.1 tables_mysql_innodb.sql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151-- In your Quartz properties file, you'll need to set -- org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate-- By: Ron Cordell - roncordell-- I didn't see this anywhere, so I thought I'd post it here. This is the script from Quartz to create the tables in a MySQL database, modified to use INNODB instead of MYISAM.DROP TABLE IF EXISTS QRTZ_JOB_LISTENERS;DROP TABLE IF EXISTS QRTZ_TRIGGER_LISTENERS;DROP TABLE IF EXISTS QRTZ_FIRED_TRIGGERS;DROP TABLE IF EXISTS QRTZ_PAUSED_TRIGGER_GRPS;DROP TABLE IF EXISTS QRTZ_SCHEDULER_STATE;DROP TABLE IF EXISTS QRTZ_LOCKS;DROP TABLE IF EXISTS QRTZ_SIMPLE_TRIGGERS;DROP TABLE IF EXISTS QRTZ_CRON_TRIGGERS;DROP TABLE IF EXISTS QRTZ_BLOB_TRIGGERS;DROP TABLE IF EXISTS QRTZ_TRIGGERS;DROP TABLE IF EXISTS QRTZ_JOB_DETAILS;DROP TABLE IF EXISTS QRTZ_CALENDARS;CREATE TABLE QRTZ_JOB_DETAILS(JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,DESCRIPTION VARCHAR(250) NULL,JOB_CLASS_NAME VARCHAR(250) NOT NULL,IS_DURABLE VARCHAR(1) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,IS_STATEFUL VARCHAR(1) NOT NULL,REQUESTS_RECOVERY VARCHAR(1) NOT NULL,JOB_DATA BLOB NULL,PRIMARY KEY (JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_JOB_LISTENERS (JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,JOB_LISTENER VARCHAR(200) NOT NULL,PRIMARY KEY (JOB_NAME,JOB_GROUP,JOB_LISTENER),INDEX (JOB_NAME, JOB_GROUP),FOREIGN KEY (JOB_NAME,JOB_GROUP)REFERENCES QRTZ_JOB_DETAILS(JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,DESCRIPTION VARCHAR(250) NULL,NEXT_FIRE_TIME BIGINT(13) NULL,PREV_FIRE_TIME BIGINT(13) NULL,PRIORITY INTEGER NULL,TRIGGER_STATE VARCHAR(16) NOT NULL,TRIGGER_TYPE VARCHAR(8) NOT NULL,START_TIME BIGINT(13) NOT NULL,END_TIME BIGINT(13) NULL,CALENDAR_NAME VARCHAR(200) NULL,MISFIRE_INSTR SMALLINT(2) NULL,JOB_DATA BLOB NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (JOB_NAME, JOB_GROUP),FOREIGN KEY (JOB_NAME,JOB_GROUP)REFERENCES QRTZ_JOB_DETAILS(JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_SIMPLE_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,REPEAT_COUNT BIGINT(7) NOT NULL,REPEAT_INTERVAL BIGINT(12) NOT NULL,TIMES_TRIGGERED BIGINT(10) NOT NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_CRON_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,CRON_EXPRESSION VARCHAR(120) NOT NULL,TIME_ZONE_ID VARCHAR(80),PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_BLOB_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,BLOB_DATA BLOB NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_TRIGGER_LISTENERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,TRIGGER_LISTENER VARCHAR(200) NOT NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP,TRIGGER_LISTENER),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_CALENDARS (CALENDAR_NAME VARCHAR(200) NOT NULL,CALENDAR BLOB NOT NULL,PRIMARY KEY (CALENDAR_NAME))TYPE=InnoDB;CREATE TABLE QRTZ_PAUSED_TRIGGER_GRPS (TRIGGER_GROUP VARCHAR(200) NOT NULL,PRIMARY KEY (TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_FIRED_TRIGGERS (ENTRY_ID VARCHAR(95) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,INSTANCE_NAME VARCHAR(200) NOT NULL,FIRED_TIME BIGINT(13) NOT NULL,PRIORITY INTEGER NOT NULL,STATE VARCHAR(16) NOT NULL,JOB_NAME VARCHAR(200) NULL,JOB_GROUP VARCHAR(200) NULL,IS_STATEFUL VARCHAR(1) NULL,REQUESTS_RECOVERY VARCHAR(1) NULL,PRIMARY KEY (ENTRY_ID))TYPE=InnoDB;CREATE TABLE QRTZ_SCHEDULER_STATE (INSTANCE_NAME VARCHAR(200) NOT NULL,LAST_CHECKIN_TIME BIGINT(13) NOT NULL,CHECKIN_INTERVAL BIGINT(13) NOT NULL,PRIMARY KEY (INSTANCE_NAME))TYPE=InnoDB;CREATE TABLE QRTZ_LOCKS (LOCK_NAME VARCHAR(40) NOT NULL,PRIMARY KEY (LOCK_NAME))TYPE=InnoDB;INSERT INTO QRTZ_LOCKS values('TRIGGER_ACCESS');INSERT INTO QRTZ_LOCKS values('JOB_ACCESS');INSERT INTO QRTZ_LOCKS values('CALENDAR_ACCESS');INSERT INTO QRTZ_LOCKS values('STATE_ACCESS');INSERT INTO QRTZ_LOCKS values('MISFIRE_ACCESS');commit;]]></content>
      <categories>
        <category>quartz</category>
      </categories>
      <tags>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java文件下载]]></title>
    <url>%2Fblog%2F2018%2F04%2F16%2FJava%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[今天在开发中遇到了一个需求： 在服务端保存一个Excel模板，用户通过浏览器传递不同的参数，解析参数并写入模板返回给用户以供下载。 需求本身很简单，但在开发的过程中踩了几个坑，所以记录下来。 1. 文件下载的原理 通过 HttpServletResponse.setContentType() 方法设置 Content-Type 字段的值，设置为 application/octet-stream 或 application/x-msdownload ，决定客户端服务器以那种方式来接受返回的信息 1response.setContentType("application/vnd.ms-excel"); 通过 HttpServletResponse.setHeader() 方法设置 Content-Disposition 头的值为 attachment;filename=文件名 ，浏览器通过附件的形式来获取到用户上传的文件 1response.addHeader("Content-Disposition", "attachment; filename=" + fileName); 读取下载文件，通过 HttpServletResponse.getOutputStream() 方法返回 ServletOutputStream 对象来向客户端写入附件文件的内容 1234567891011try (OutputStream out = response.getOutputStream(); BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file)); BufferedOutputStream bos = new BufferedOutputStream(out)) &#123; byte[] buff = new byte[2048]; int bytesRead; while (-1 != (bytesRead = bis.read(buff, 0, buff.length))) &#123; bos.write(buff, 0, bytesRead); &#125;&#125; catch (IOException e) &#123; logger.error(e.getMessage());&#125; 2. Http 报头 Content-disposition 的作用Content-Disposition 属性是作为对下载文件的一个标识字段。 在 rfc2616 章节19.5 Additional Features中 Content-Disposition 属性有两种类型：inline 和 attachment inline ：将文件内容直接显示在页面 attachment：弹出对话框让用户下载 2.1 inlineinline 用于直接在页面中展示该文件，常用与图片等 示例： 12345File file = new File("rfc1806.txt");String filename = file.getName();response.setHeader("Content-Type","text/plain");response.addHeader("Content-Disposition","inline;filename=" + new String(filename.getBytes(),"utf-8"));response.addHeader("Content-Length","" + file.length()); 2.2 attachmentattachment 用于通知浏览器弹出对话框以供用户下载。 示例： 12345File file = new File("rfc1806.txt");String filename = file.getName();response.setHeader("Content-Type","text/plain");response.addHeader("Content-Disposition","attachment; filename=" + new String(filename.getBytes(),"utf-8"));response.addHeader("Content-Length","" + file.length()); 3. filename 属性中文乱码如果在设置 filename 的时候直接使用中文，则会出现如下情况: 在代码中直接使用中文进行设置 相应的 HTTP Response 浏览器的弹窗 首先，产生乱码的根本问题是在 HTTP 协议中，HTTP Header要求其内容必须为 ISO-8859-1 编码。 所以，在开发中尽量使用如下方式： 1response.setHeader("Content-disposition", "attachment; filename=" + new String("中文文件名".getBytes("utf-8"), "ISO8859-1")); 得到文件名的字节数组，将字节数组转换成 IOS-8859-1 格式编码的字符串。 而不能通过如下方式： 1"中文文件名".getBytes("ISO8859-1"); 因为 IOS-8859-1 的编码表中没有汉字字符，因此无法通过以上的方式对中文字符串进行编码。 以先通过 &quot;中文文件名&quot;.getBytes(&quot;utf-8&quot;) 获取其 byte[]字节，让其按照字节来编码，即在使用 new String(&quot;中文文件名&quot;.getBytes(&quot;utf-8&quot;), &quot;ISO8859-1&quot;) 将其重新组成一个字符串，传送给浏览器。 4. 演示4.1 代码及资源路径 4.2 HTTP Response 详情 4.3 浏览器能够正确识别]]></content>
      <categories>
        <category>踩坑总结</category>
      </categories>
      <tags>
        <tag>踩坑总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)In Search of an Understandable Consensus Algorithm —— Raft算法]]></title>
    <url>%2Fblog%2F2018%2F04%2F15%2F%E7%BF%BB%E8%AF%91-In-Search-of-an-Understandable-Consensus-Algorithm-%E2%80%94%E2%80%94-Raft%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本篇博客为著名的 RAFT 一致性算法论文的中文翻译，论文名为《In search of an Understandable Consensus Algorithm (Extended Version)》(寻找一种易于理解的一致性算法) Raft 是一种用来管理日志复制的一致性算法。它和 Paxos 的性能和功能是一样的，但是它和 Paxos 的结构不一样；这使得 Raft 更容易理解并且更易于建立实际的系统。为了提高理解性，Raft 将一致性算法分为了几个部分，例如领导选取（leader selection），日志复制（log replication）和安全性（safety），同时它使用了更强的一致性来减少了必须需要考虑的状态。从用户学习的结果来看，Raft 比 Paxos 更容易学会。Raft 还包括了一种新的机制来使得动态改变集群成员，它使用重叠大多数（overlapping majorities）来保证安全。 1. 引言一致性算法允许一组机器像一个整体一样工作，即使其中的一些机器出了错误也能正常工作。正因为此，他们扮演着建立大规模可靠的软件系统的关键角色。在过去的十年中 Paxos 一直都主导着有关一致性算法的讨论：大多数一致性算法的实现都基于它或者受它影响，并且 Paxos 也成为了教学生关于一致性知识的主要工具。 不幸的是，尽管在降低它的复杂性方面做了许多努力，Paxos 依旧很难理解。并且，Paxos 需要经过复杂的修改才能应用于实际中。这些导致了系统构构建者和学生都十分头疼。 在被 Paxos 折磨之后，我们开始寻找一种在系统构建和教学上更好的新的一致性算法。我们的首要目标是让它易于理解：我们能不能定义一种面向实际系统的一致性算法并且比 Paxos 更容易学习呢？并且，我们希望这种算法能凭直觉就能明白，这对于一个系统构建者来说是十分必要的。对于一个算法，不仅仅是让它工作起来很重要，知道它是如何工作的更重要。 我们工作的结果是一种新的一致性算法，叫做 Raft。在设计 Raft 的过程中我们应用了许多专门的技巧来提升理解性，包括算法分解（分为领导选取（leader selection），日志复制（log replication）和安全性（safety）） 和 减少状态（state space reduction）（相对于 Paxos，Raft 减少了非确定性的程度和服务器互相不一致的方式）。在两所学校的43个学生的研究中发现，Raft 比 Paxos 要更容易理解：在学习了两种算法之后，其中的33个学生回答 Raft 的问题要比回答 Paxos 的问题要好。 在许多方面，Raft与现有的协商一致意见相似(最值得注意的是，Oki和Liskov的Viewstamped复制)，但它有几个新的特点: 强领导者（Strong Leader） : Raft使用一种比其他共识算法更强的领导方式。例如，日志条目只从Leader流向其他服务器。这样就简化了复制日志的管理，使Raft更容易理解。 领导选取（Leader Selection）: Raft 使用随机定时器选举领导人。这只增加了对任何协商一致算法所需的心跳的一小部分机制，同时快速地解决冲突。 成员变化（Membership Change）: Raft 为了调整集群中成员关系使用了新的联合一致性（joint consensus）的方法，这种方法中大多数不同配置的机器在转换关系的时候会交迭（overlap）。这使得在配置改变的时候，集群能够继续操作。 我们认为，Raft 在教学方面和实际实现方面比 Paxos 和其他算法更出众。 它比其他算法更简单、更容易理解； 它能满足一个实际系统的需求； 它拥有许多开源的实现并且被许多公司所使用； 它的安全特性已经被证明； 并且它的效率和其他算法相比也具有竞争力。 这篇论文剩下的部分会讲如下内容： 复制状态机（replicated state machine）问题（第2节）; 讨论 Paxos 的优缺点（第3节）; 讨论我们用的为了达到提升理解性的方法（第4节）; 陈述 Raft 一致性算法（第5~8节）; 评价 Raft 算法（第9节）; 对相关工作的讨论（第10节）。 2. 复制状态机（Replicated State Machine）复制状态机在分布式领域是一个常用且重要的技术。 通过复制服务副本，并和副本一起来协调客户端的交互，来实现容错服务。 这个方法同样提供了一个框架，来理解和设计复制管理协议。 一致性算法是在复制状态机的背景下提出来的。在这个方法中，在一组服务器的状态机产生同样的状态的副本因此即使有一些服务器崩溃了这组服务器也还能继续执行。复制状态机在分布式系统中被用于解决许多有关容错的问题。例如，GFS，HDFS还有 RAMCloud 这些大规模的系统都是用一个单独的集群领导者，使用一个单独的复制状态机来进行领导选取和存储配置信息来应对领导者的崩溃。使用复制状态机的例子有 Chubby 和 ZooKeeper。 复制状态机的架构。一致性算法管理来自客户端状态命令的复制日志。状态机处理的日志中的命令的顺序都是一致的，因此会得到相同的执行结果。 复制状态机是通过复制日志来实现的。每一台服务器保存着一份日志，日志中包含一系列的命令，状态机会按顺序执行这些命令。因为每一台计算机的状态机都是确定的，所以每个状态机的状态都是相同的，执行的命令是相同的，最后的执行结果也就是一样的了。 如何保证复制日志一致就是一致性算法的工作了。在一台服务器上，一致性模块接受客户端的命令并且把命令加入到它的日志中。它和其他服务器上的一致性模块进行通信来确保每一个日志最终包含相同序列的请求，即使有一些服务器宕机了。一旦这些命令被正确的复制了，每一个服务器的状态机都会按同样的顺序去执行它们，然后将结果返回给客户端。最终，这些服务器看起来就像一台可靠的状态机。 应用于实际系统的一致性算法一般有以下特性： 确保安全性（从来不会返回一个错误的结果），即使在所有的非拜占庭（Non-Byzantine）情况下，包括网络延迟、分区、丢包、冗余和乱序的情况下。 高可用性，只要集群中的大部分机器都能运行，可以互相通信并且可以和客户端通信，这个集群就可用。因此，一般来说，一个拥有 5 台机器的集群可以容忍其中的 2 台的失败（fail）。服务器停止工作了我们就认为它失败（fail）了，没准一会当它们拥有稳定的存储时就能从中恢复过来，重新加入到集群中。 不依赖时序保证一致性，时钟错误和极端情况下的消息延迟在最坏的情况下才会引起可用性问题。 通常情况下，一条命令能够尽可能快的在大多数节点对一轮远程调用作出相应时完成，一少部分慢的机器不会影响系统的整体性能。 3. Paxos算法的不足在过去的10年中，Leslie Lamport 的 Paxos 算法几乎已经成为了一致性算法的代名词：它是授课中最常见的算法，同时也是许多一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，例如一个单一复制日志条目（single replicated log entry）。我们把这个子集叫做单一决策 Paxos（single-decree Paxos）。之后 Paxos通过组合多个这种协议来完成一系列的决策，例如一个日志（multi-Paxos）。Paxos 确保安全性和活跃性（liveness），并且它支持集群成员的变更。它的正确性已经被证明，通常情况下也很高效。 不幸的是，Paxos 有两个致命的缺点。 Paxos 太难以理解。它的完整的解释晦涩难懂；很少有人能完全理解，只有少数人成功的读懂了它。并且大家做了许多努力来用一些简单的术语来描述它。尽管这些解释都关注于单一决策子集问题，但仍具有挑战性。在 NSDI 2012 会议上的一次非正式调查显示，我们发现大家对 Paxos 都感到不满意，其中甚至包括一些有经验的研究员。我们自己也曾深陷其中，我们在读过几篇简化它的文章并且设计了我们自己的算法之后才完全理解了 Paxos，而整个过程花费了将近一年的时间。我们假定 Paxos 的晦涩来源于它将单决策子集作为它的基础。单决策（Single-decree）Paxos 是晦涩且微妙的：它被划分为两个没有简单直观解释的阶段，并且难以独立理解。正因为如此，它不能很直观的让我们知道为什么单一决策协议能够工作。为多决策 Paxos 设计的规则又添加了额外的复杂性和精巧性。我们相信多决策问题能够分解为其它更直观的方式。 它难以在实际环境中实现。其中一个原因是，对于多决策 Paxos （multi-Paxos） ，大家还没有一个一致同意的算法。Lamport 的描述大部分都是有关于单决策 Paxos （single-decree Paxos）；他仅仅描述了实现多决策的可能的方法，缺少许多细节。有许多实现 Paxos 和优化 Paxos 的尝试，但是他们都和 Lamport 的描述有些出入。例如，Chubby 实现的是一个类似 Paxos 的算法，但是在许多情况下的细节没有公开。 另外，Paxos 的结构也是不容易在一个实际系统中进行实现的，这是单决策问题分解带来的又一个问题。例如，从许多日志条目中选出条目然后把它们融合到一个序列化的日志中并没有带来什么好处，它仅仅增加了复杂性。围绕着日志来设计一个系统是更简单、更高效的：新日志按照严格的顺序添加到日志中去。另一个问题是，Paxos 使用对等的点对点的实现作为它的核心（尽管它最终提出了一种弱领导者的形式来优化性能）。这种方法在只有一个决策被制定的情况下才显得有效，但是很少有现实中的系统使用它。如果要做许多的决策，选择一个领导人，由领带人来协调是更简单有效的方法。 因此，在实际的系统应用中和 Paxos 算法都相差很大。所有开始于 Paxos 的实现都会遇到很多问题，然后由此衍生出了许多与 Paxos 有很大不同的架构。这是既费时又容易出错的，并且理解 Paxos 的难度又非常大。Paxos 算法在它正确性的理论证明上是很好的，但是在实现上的价值就远远不足了。来自 Chubby 的实现的一条评论就能够说明： There are signiﬁcant gaps between the description of the Paxos algorithm and the needs of a real-world system... the ﬁnal system will be based on an unproven protocol 翻译：Paxos 算法的描述与实际实现之间存在巨大的鸿沟... 最终的系统往往建立在一个没有被证明的算法之上。 正因为存在这些问题，我们认为 Paxos 不仅对于系统的构建者来说不友好，同时也不利于教学。鉴于一致性算法对于大规模软件系统的重要性，我们决定试着来设计一种另外的比 Paxos 更好的一致性算法。Raft 就是这样的一个算法。 4. 易于理解的设计设计 Raft 的目标有如下几个： 它必须提供一个完整的、实际的基础来进行系统构建，为的是减少开发者的工作； 它必须在所有情况下都能保证安全可用； 它对于常规操作必须高效； 最重要的目标是：易于理解，它必须使得大多数人能够很容易的理解； 另外，它必须能让开发者有一个直观的认识，这样才能使系统构建者们去对它进行扩展。 在设计 Raft 的过程中，我们不得不在许多种方法中做出选择。当面临这种情况时，我们通常会权衡可理解性：每种方法的可理解性是如何的？（例如，它的状态空间有多复杂？它是不是有很细微的含义？）它的可读性如何？读者能不能轻易地理解这个方法和它的含义？ 我们意识到对这种可理解性的分析具有高度的主观性；尽管如此，我们使用了两种适用的方式。 第一种是众所周知的问题分解：我们尽可能将问题分解成为若干个可解决的、可被理解的小问题。例如，在 Raft 中，我们把问题分解成为了领导选取（leader election）、日志复制（log replication）、安全（safety）和成员变化（membership changes）。 我们采用的第二个方法是通过减少需要考虑的状态的数量将状态空间简化，这能够使得整个系统更加一致并且尽可能消除不确定性。特别地，日志之间不允许出现空洞，并且 Raft 限制了限制了日志不一致的可能性。尽管在大多数情况下，我们都都在试图消除不确定性，但是有时候有些情况下，不确定性使得算法更易理解。尤其是，随机化方法使得不确定性增加，但是它减少了状态空间。我们使用随机化来简化了 Raft 中的领导选取算法。 5. Raft 一致性算法Raft是一种用于管理第2节中描述的表单的复制日志的算法。表2总结了压缩格式的算法，表3列出了算法的关键属性;这些数字的组成部分是分段讨论的。 状态 表-2-1 在所有服务器上持久存在的 名称 描述 currentTerm 服务器最后知道的任期号（从0开始递增） votedFor 当前任期内收到选票的 候选人 id（如果没有就为null） log[] 日志条目；，诶个条目包含状态机的要执行命令和从 `领导者 出收到的任期号 在所有服务器上不稳定存在的 名称 描述 commitIndex 已知的被提交的最大日志条目的索引值（从0开始递增） lastApplied 被状态机执行的额最大日志条目的索引值（从0开始递增） 在领导人服务器上不稳定存在的（在选举之后初始化的） 名称 描述 nextIndex[] 对于每个服务器，记录需要发给它的下一个日志条目的索引（初始化为Leader上一条日志索引+1） natchIndex[] 对于每一个服务器，记录已经复制到该拂去其的日志的最高索引值（从0开始递增） 附加日志远程调用（AppendEntries RPC）由领导人来调用复制日志 表-2-2 参数 描述 term 领导人的任期号 leaderId 领导人的id，为了其他服务器能重定向到Leader prevLogIndex 最新日志之前的日志的索引值 prevLogTerm 最新日志之前的日志的领导人任期号 entries[] 要存储的日志条目（表示heartbeat时为空，有时会为了效率发送多条） leaderCommit 领导人提交的日志条目索引值 返回值 描述 term 当前的任期号，用于 Leader 更新自己的任期号 success 如果其他服务器包含能够匹配上 prevLogIndex 和 prevLogTerm 的日志时为真 Follower需要实现： 如果 term &lt; currentTerm 返回false 如果在 prevLogIndex 处的日志的任期号与 prevLogTerm 不匹配时，返回false 如果一条已经存在的日志与新的冲突（index 相同但任期号 term 不同），则删除已经存在的日志和它之后的所有日志 添加任何在以后日志中不存在的条目 如果 leaderCommit &gt; commitIndex，将 commitIndex 设置为 leaderCommit 和最新日志条目索引号中较小的一个 投票请求RPC（RequestVote RPC）由候选人发起收集选票 表-2-3 参数 描述 term 领导人的任期号 candidateId 请求投票的候选人id lastLogIndex 候选人最新日志条目的索引值 lastLogTerm 候选人最新日志条目对应的任期号 返回值 描述 term 当前的任期号，用于 候选人 更新自己的任期号 voteGranted 如果候选人收到选票为true 接受者需要实现 如果 term &lt; currentTerm 返回false 如果 votedFor 为空或者与 candidateId 相同，并且候选人的日志和自己的日志一样新，则给候选人投票。 服务器需要遵守的规则所有服务器 如果 commitIndex &gt; lastApplied，lastApplied 自增，将 log[lastApplied] 应用到状态机； 如果RPC的请求或者响应中包含一个 Term &gt; currentTerm，则 currentTerm 赋值为 Term，并切换状态为Follower； Follower 响应来自候选人和领导人的RPC请求 如果在超过选取 Leader 时间之前没有收到来自领导人的 AppendEntries RPC 或者没有收到候选人的投票请求，则自己转换状态为候选人 Candidate 转变为 Candidate 之后开始选举 currentTerm 自增 给自己投票 重置选举计时器 向其他服务器发送 RequestVote RPC 如果收到了来自大多数服务器的投票，则成为领导人 如果收到了来自新 Leader 的 AppendEntries RPC(heartbeat)，则成为 Follower 如果选举超时，开始新一轮选举 Leader 一旦成为领导人：想起他所有服务器发送空的 AppendEntries PRC(heartbeat)；在空闲时间重复发送以防止选举超时 如果收到来自客户端的请求，向本地日子增加条目，在该条目应用到状态机后响应客户端 对于一个 Followed 来说，如果上一次收到的日志索引大于将要收到的日志索引(nextIndex)：通过 AppendEntries RPC 将 nextIndex 之后的所有日志条目发送出去 如果发送成功：将该 Follower 的 nextIndex 和 matchIndex 更新 如果由于日志不一致导致 AppendEntries RPC 失败：nextIndex 递减并且重新发送 如果存在一个满足 N &gt; commitIndex 和 matchIndex[i] &gt;= N 并且 log[N].term == currentTerm的 N，则将 commitIndex 赋值为N Raft 一致性算法的总结（不包括成员变化和日志压缩） 表-3 Raft 算法保证这些特性任何时刻都能成立 性质 描述 选举安全原则(Election Safety) 一个任期 (Term) 内最多允许有一个 Leader 被选上 领导者只增加原则(Leader Append-Only) Leader 永远不会覆盖或删除自己的日志，只会增加条目 日志匹配原则(Log Matching) 如果两个日志在相同的索引位置上的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置的条目完全相同。 领导者完全原则(Leader Completeness) 如果一个日志条目在一个给定任期内被提交，那么这个条目一定会出现在所有任期更大的 Leader 中 状态机安全原则(State Machine Safely) 如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目 Raft 通过首先选出一个领导人来实现一致性，然后给予领导人完全管理复制日志（replicated log）的责任。领导人接收来自客户端的日志条目，并把它们复制到其他的服务器上，领带人还要告诉服务器们什么时候将日志条目应用到它们的状态机是安全的。通过选出领导人能够简化复制日志的管理工作。例如，领导人能够决定将新的日志条目放到哪，而并不需要和其他的服务器商议，数据流被简化成从领导人流向其他服务器。如果领导人宕机或者和其他服务器失去连接，就可以选取下一个领导人。 通过选出 Leader 的方法，Raft 将共识问题分解为三个相对独立的子问题，这些子问题在下面的子部分中讨论: Leader 选举: 当现有 Leader 失败时，必须选出新的 Leader。 日志复制（Log replication）： 领导人必须从客户端接收日志然后复制到集群中的其他服务器，并且强制要求其他服务器的日志保持和自己相同 安全性（Safety）： Raft 的关键的安全特性是 表-3 中提到的状态机安全原则（State Machine Safety）:如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目。5.4节阐述了 Raft 是如何保证这条原则的，解决方案涉及到一个对于选举机制另外的限制，这一部分会在 5.2节 中说明。 在说明了一致性算法之后，本章会讨论有关可用性（availability）的问题和系统中时序（timing）的问题。 5.1. Raft基础一个 Raft 集群包括若干服务器；对于一个典型的 5 服务器集群，该集群能够容忍 2 台机器不能正常工作，而整个系统保持正常。在任意的时间，每一个服务器一定会处于以下三种状态中的一个：领导人、候选人、追随者。在正常情况下，只有一个服务器是领导人，剩下的服务器是追随者。追随者们是被动的：他们不会发送任何请求，只是响应来自领导人和候选人的请求。领导人来处理所有来自客户端的请求（如果一个客户端与追随者进行通信，追随者会将信息发送给领导人）。候选人是用来选取一个新的领导人的，这一部分会在 5.2节 进行阐释。图-4 阐述了这些状态，和它们之间的转换；它们的转换会在下边进行讨论。 服务器的状态。追随者只响应其他服务器的请求。如果追随者没有收到任何消息，它会成为一个候选人并且开始一次选举。收到大多数服务器投票的候选人会成为新的领导人。领导人在它们宕机之前会一直保持领导人的状态。 时间被分为一个个的任期（term），每一个任期的开始都是领导人选举。在成功选举之后，一个领导人会在任期内管理整个集群。如果选举失败，该任期就会因为没有领带人而结束。这个转变会在不同的时间的不同服务器上观察到。 如 图-5 所示，Raft 算法将时间划分成为任意不同长度的 任期（term）。任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），就像 5.2 节 所描述的那样，一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最少要有一个领导人。 不同的服务器可能会在任期内观察到多次不同的状态转换，在某些情况下，一台服务器可能看不到一次选举或者一个完整的任期。任期在 Raft 中充当逻辑时钟的角色，并且它们允许服务器检测过期的信息，比如过时的领导人。每一台服务器都存储着一个当前任期的数字，这个数字会单调的增加。当服务器之间进行通信时，会互相交换当前任期号；如果一台服务器的当前任期号比其它服务器的小，则更新为较大的任期号。如果一个候选人或者领导人意识到它的任期号过时了，它会立刻转换为追随者状态。如果一台服务器收到的请求的任期号是过时的，那么它会拒绝此次请求。 Raft 中的服务器通过远程过程调用（RPC）来通信，基本的 Raft 一致性算法仅需要 2 种 RPC。RequestVote RPC 是候选人在选举过程中触发的（5.2节），AppendEntries RPC 是领导人触发的，为的是复制日志条目和提供一种 心跳（heartbeat） 机制（5.3节）。第7章加入了第三种 RPC 来在各个服务器之间传输 快照（snapshot）。如果服务器没有及时收到 RPC 的响应，它们会重试，并且它们能够并行的发出 RPC 来获得最好的性能。 5.2. 领导人选举Raft 使用一种 心跳机制（heartbeat） 来触发领导人的选取。当服务器启动时，它们会初始化为追随者。一太服务器会一直保持追随者的状态只要它们能够收到来自领导人或者候选人的有效 RPC。领导人会向所有追随者周期性发送 心跳（heartbeat，不带有任何日志条目的 AppendEntries RPC） 来保证它们的领导人地位。如果一个追随者在一个周期内没有收到心跳信息，就叫做 选举超时（election timeout） ,然后它就会假定没有可用的领导人并且开始一次选举来选出一个新的领导人。 为了开始选举，一个追随者会自增它的当前任期并且转换状态为候选人。然后，它会给自己投票并且给集群中的其他服务器发送 RequestVote RPC 。一个候选人会一直处于该状态，直到下列三种情形之一发生： 它赢得了选举； 另一台服务器赢得了选举； 一段时间后没有任何一台服务器赢得了选举 一个候选人如果在一个任期内收到了来自集群中大多数服务器的投票就会赢得选举。在一个任期内，一台服务器最多能给一个候选人投票，按照 先到先服务原则（first-come-first-served） （注意：在 5.4节 针对投票添加了一个额外的限制）。大多数原则使得在一个任期内最多有一个候选人能赢得选举 （表-3 中提到的选举安全原则） 。一旦有一个候选人赢得了选举，它就会成为 领导人 。然后它会像其他服务器发送心跳信息来建立自己的领导地位并且组织新的选举。 当一个 候选人 等待别人的选票时，它有可能会收到来自其他服务器发来的声明其为领导人的 AppendEntries RPC 。如果这个领导人的 任期（包含在它的 RPC 中） 比当前候选人的当前任期要大，则候选人认为该领导人合法，并且转换自己的状态为 追随者 。如果在这个 RPC 中的任期小于候选人的当前任期，则候选人会拒绝此次 RPC， 继续保持候选人 状态。 第三种情形是一个 候选人 既没有赢得选举也没有输掉选举：如果许多追随者在同一时刻都成为了候选人，选票会被分散，可能没有候选人能获得大多数的选票。当这种情形发生时，每一个候选人都会超时，并且通过自增任期号和发起另一轮 RequestVote RPC 来开始新的选举。然而，如果没有其它手段来分配选票的话，这种情形可能会无限的重复下去。 Raft 使用 随机的选举超时时间 来确保第三种情形很少发生，并且能够快速解决。为了防止在一开始是选票就被瓜分，选举超时时间是在一个固定的间隔内随机选出来的（例如，150~300ms）。这种机制使得在大多数情况下只有一个服务器会率先超时，它会在其它服务器超时之前赢得选举并且向其它服务器发送心跳信息。同样的机制被用于选票一开始被瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，在超时进行下一次选举之前一直等待。这能够减小在新的选举中一开始选票就被瓜分的可能性。9.3节 展示了这种方法能够快速的选出一个领导人。 选举是一个理解性引导我们设计替代算法的一个例子。最开始时，我们计划使用一种排名系统：给每一个候选人分配一个唯一的排名，用于在竞争的候选人之中选择领导人。如果一个候选人发现了另一个比它排名高的候选人，那么它会回到追随者的状态，这样排名高的候选人会很容易地赢得选举。但是我们发现这种方法在可用性方面有一点问题（一个低排名的服务器在高排名的服务器宕机后，需要等待超时才能再次成为候选人，但是如果它这么做的太快，它能重置选举领带人的过程）。我们对这个算法做了多次调整，但是每次调整后都会出现一些新的问题。最终我们认为随机重试的方法是更明确并且更易于理解的。 5.3.日志复制一旦选出了领导人，它就开始接收客户端的请求。每一个客户端请求都包含一条需要被 复制状态机（replicated state machine） 执行的命令。领导人把这条命令作为新的日志条目加入到它的日志中去，然后并行的向其他服务器发起 AppendEntries RPC ，要求其它服务器复制这个条目。当这个条目被安全的复制之后（下面的部分会详细阐述），领导人会将这个条目应用到它的状态机中并且会向客户端返回执行结果。如果追随者崩溃了或者运行缓慢或者是网络丢包了，领导人会无限的重试 AppendEntries RPC （甚至在它向客户端响应之后）知道所有的追随者最终存储了所有的日志条目。 图-6：日志由有序编号的日志条目组成。每个日志条目包含它被创建时的任期号（每个方块中的数字），并且包含用于状态机执行的命令。如果一个条目能够被状态机安全执行，就被认为可以提交了。 日志就像 图-6 所示那样组织的。每个日志条目存储着一条被状态机执行的命令和当这条日志条目被领导人接收时的任期号。日志条目中的任期号用来检测在不同服务器上日志的不一致性，并且能确保 图-3 中的一些特性。每个日志条目也包含一个整数索引来表示它在日志中的位置。 领导人 决定什么时候将日志条目应用到状态机是安全的；这种条目被称为 可被提交（commited） 。 Raft 保证 可被提交（commited）的日志条目 是持久化的并且最终会被所有可用的状态机执行。一旦被领导人创建的条目已经复制到了大多数的服务器上，这个条目就称为可被提交的（例如，图-6中的7号条目）。领导人日志中之前的条目都是可被提交的（commited），包括由之前的领导人创建的条目。5.4节将会讨论当领导人更替之后这条规则的应用问题的细节，并且也讨论了这种提交方式是安全的。领导人跟踪记录它所知道的被提交条目的最大索引值，并且这个索引值会包含在之后的 AppendEntries RPC 中（包括心跳 heartbeat 中），为的是让其他服务器都知道这条条目已经提交。一旦一个追随者知道了一个日志条目已经被提交，它会将该条目应用至本地的状态机（按照日志顺序）。 我们设计了 Raft 日志机制来保证不同服务器上日志的一致性。这样做不仅简化了系统的行为使得它更可预测，并且也是保证安全性不可或缺的一部分。Raft 保证以下特性，并且也保证了 表-3 中的日志匹配原则 （Log Matching Property） : 如果在不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果在不同日志中的两个条目有着相同的索引和任期号，则它们之间的所有条目都是完全一样的。 第一条特性源于 领导人 在一个任期里在给定的一个日志索引位置最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，领导人会把新日志条目紧接着之前的条目的索引位置和任期号都包含在里面。如果追随者没有在它的日志中找到相同索引和任期号的日志，它就会拒绝新的日志条目。这个一致性检查就像一个归纳步骤：一开始空的日志的状态一定是满足日志匹配原则的，一致性检查保证了当日志添加时的日志匹配原则。因此，只要 AppendEntries 返回成功的时候，领导人就知道追随者们的日志和它的是一致的了。 图-7：当最上边的领导人掌权之后，追随者日志可能有以下情况（a~f）。一个格子表示一个日志条目；格子中的数字是它的任期。一个追随者可能会丢失一些条目（a, b）；可能多出来一些未提交的条目（c, d）；或者两种情况都有（e, f）。例如，场景 f 在如下情况下就会发生：如果一台服务器在任期2时是领导人并且往它的日志中添加了一些条目，然后在将它们提交之前就宕机了，之后它很快重启了，成为了任期3的领导人，又往它的日志中添加了一些条目，然后在任期2和任期3中的条目提交之前它又宕机了并且几个任期内都一直处于宕机状态。 在一般情况下， 领导人 和 追随者们 的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而， 领导人 的崩溃会导致日志不一致（旧的领导人可能没有完全复制完日志中的所有条目）。这些不一致会导致一系列领导人和追随者崩溃。 图-7 阐述了一些 追随者 可能和 新的领导人 日志不同的情况。一个 追随者 可能会丢失掉领导人上的一些条目，也有可能包含一些 领导人 没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。 在 Raft 算法中， 领导人 通过 强制追随者们复制它的日志 来处理日志的不一致。这就意味着，在追随者上的冲突日志会被领导者的日志覆盖。5.4节会说明当添加了一个额外的限制之后这是安全的。 为了使得追随者的日志同自己的一致， 领导人 需要找到追随者同它的日志一致的地方，然后删除追随者在该位置之后的条目，然后将自己在该位置之后的条目发送给追随者。这些操作都在 AppendEntries RPC 进行一致性检查时完成。领导人给每一个追随者维护了一个 nextIndex ，它表示领导人将要发送给该追随者的下一条日志条目的索引。当一个领导人开始掌权时，它会将 nextIndex 初始化为 它的最新的日志条目索引数+1（图-7 中的 11） 。如果一个追随者的日志和领导者的不一致，AppendEntries 一致性检查会在下一次 AppendEntries RPC 时返回失败。在失败之后，领导人会将 nextIndex 递减然后重试 AppendEntries RPC 。最终 nextIndex 会达到一个领导人和追随者日志一致的地方。这时，AppendEntries 会返回成功，追随者中冲突的日志条目都被移除了，并且添加所缺少的上了领导人的日志条目。一旦 AppendEntries 返回成功，追随者和领导人的日志就一致了，这样的状态会保持到该任期结束。 如果需要的话，算法还可以进行优化来减少 AppendEntries RPC 失败的次数。例如，当拒绝了一个 AppendEntries 请求，追随者可以记录下冲突日志条目的任期号和自己存储那个任期的最早的索引。通过这些信息，领导人能够直接递减nextIndex跨过那个任期内所有的冲突条目；这样的话，一个冲突的任期需要一次 AppendEntries RPC，而不是每一个冲突条目需要一次 AppendEntries RPC。在实践中，我们怀疑这种优化是否是必要的，因为 AppendEntries 一致性检查很少失败并且也不太可能出现大量的日志条目不一致的情况。 通过这种机制，一个领导人在掌权时不需要采取另外特殊的方式来恢复日志的一致性。它只需要使用一些常规的操作，通过响应 AppendEntries 一致性检查的失败能使得日志自动的趋于一致。一个领导人从来不会覆盖或者删除自己的日志（表-3 中的领导人只增加原则）。 这个日志复制机制展示了在第2章中阐述的所希望的一致性特性：Raft 能够接受，复制并且应用新的日志条目只要大部分的服务器是正常的。在通常情况下，一条新的日志条目可以在一轮 RPC 内完成在集群的大多数服务器上的复制；并且一个速度很慢的追随者并不会影响整体的性能。]]></content>
      <categories>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>文献翻译</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft协议(1)——一致性原理分析]]></title>
    <url>%2Fblog%2F2018%2F04%2F14%2FRaft%E5%8D%8F%E8%AE%AE-1-%E2%80%94%E2%80%94%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[概述在一个由 Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人） 就像一个民主社会，领袖由民众投票选出。刚开始没有领袖，所有集群中的参与者都是群众，那么首先开启一轮大选，在大选期间所有群众都能参与竞选，这时所有群众的角色就变成了候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除领袖的候选人又变回群众角色服从领袖领导。这里提到一个概念「任期」，用术语 Term 表达。关于 Raft 协议的核心概念和术语就这么多而且和现实民主制度非常匹配，所以很容易理解。三类角色的变迁图如下，结合后面的选举过程来看很容易理解。 Raft 集群中节点状态转化 Leader 选举过程在极简的思维下，一个最小的 Raft 民主集群需要三个参与者（如下图：A、B、C），这样才可能投出多数票。初始状态 ABC 都是 Follower，然后发起选举这时有三种可能情形发生。下图中前二种都能选出 Leader，第三种则表明本轮投票无效（Split Votes），每方都投给了自己，结果没有任何一方获得多数票。之后每个参与方随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机 timeout，最先从 timeout 中恢复发起投票的一方向还在 timeout 中的另外两方请求投票，这时它们就只能投给对方了，很快达成一致。 选出 Leader 后，Leader 通过定期向所有 Follower 发送心跳信息维持其统治。若 Follower 一段时间未收到 Leader 的心跳则认为 Leader 可能已经挂了再次发起选主过程。 Leader 节点对一致性的影响Raft 协议强依赖 Leader 节点的可用性来确保集群数据的一致性。数据的流向只能从 Leader 节点向 Follower 节点转移。当 Client 向集群 Leader 节点提交数据后，Leader 节点接收到的数据处于未提交状态（Uncommitted），接着 Leader 节点会并发向所有 Follower 节点复制数据并等待接收响应，确保至少集群中超过半数节点已接收到数据后再向 Client 确认数据已接收。一旦向 Client 发出数据接收 Ack 响应后，表明此时数据状态进入已提交（Committed），Leader 节点再向 Follower 节点发通知告知该数据状态已提交。 在这个过程中，主节点可能在任意阶段挂掉，看下 Raft 协议如何针对不同阶段保障数据一致性的。 数据到达 Leader 节点前这个阶段 Leader 挂掉不影响一致性，不多说。 数据到达 Leader 节点，但未复制到 Follower 节点这个阶段 Leader 挂掉，数据属于未提交状态，Client 不会收到 Ack 会认为超时失败可安全发起重试。Follower 节点上没有该数据，重新选主后 Client 重试重新提交可成功。原来的 Leader 节点恢复后作为 Follower 加入集群重新从当前任期的新 Leader 处同步数据，强制保持和 Leader 数据一致。 数据到达 Leader 节点，成功复制到 Follower 所有节点，但还未向 Leader响应这个阶段 Leader 挂掉，虽然数据在 Follower 节点处于未提交状态（Uncommitted）但保持一致，重新选出 Leader 后可完成数据提交，此时 Client 由于不知到底提交成功没有，可重试提交。针对这种情况 Raft 要求 RPC 请求实现幂等性，也就是要实现内部去重机制。 数据到达 Leader 节点，成功复制到 Follower 部分节点，但还未向 Leader 响应接受这个阶段 Leader 挂掉，数据在 Follower 节点处于未提交状态（Uncommitted）且不一致，Raft 协议要求投票只能投给拥有最新数据的节点。所以拥有最新数据的节点会被选为 Leader 再强制同步数据到 Follower，数据不会丢失并最终一致。 数据到达 Leader 节点，成功复制到 Follower 所有或多数节点，数据在所有节点都处于已提交状态，但还未响应 Client这个阶段 Leader 挂掉，Cluster 内部数据其实已经是一致的，Client 重复重试基于幂等策略对一致性无影响。 网络分区导致的脑裂情况，出现双 Leader网络分区将原先的 Leader 节点和 Follower 节点分隔开，Follower 收不到 Leader 的心跳将发起选举产生新的 Leader。这时就产生了双 Leader，原先的 Leader 独自在一个区，向它提交数据不可能复制到多数节点所以永远提交不成功。向新的 Leader 提交数据可以提交成功，网络恢复后旧的 Leader 发现集群中有更新任期（Term）的新 Leader 则自动降级为 Follower 并从新 Leader 处同步数据达成集群数据一致。 算法以正确性、高效性、简洁性作为主要设计目标。虽然这些都是很有价值的目标，但这些目标都不会达成直到开发者写出一个可用的实现。所以我们相信可理解性同样重要。]]></content>
      <categories>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>一致性算法</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ-(5)——ActiveMQ结合Spring开发]]></title>
    <url>%2Fblog%2F2018%2F04%2F14%2FActiveMQ-5-%E2%80%94%E2%80%94ActiveMQ%E7%BB%93%E5%90%88Spring%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[步骤依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; 在Spring中配置jmsTemplate12345678910111213141516171819202122&lt;!--JMS连接池工厂--&gt;&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://localhost:61616"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"/&gt;&lt;/bean&gt;&lt;!--目的地--&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg index="0" value="spring-queue"/&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="defaultDestination" ref="destination"/&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"/&gt; &lt;/property&gt;&lt;/bean&gt; 如果是topic 添加topic的配置 修改jmsTemplate配置中的defaultDestination 12345678910111213141516171819202122&lt;!--JMS连接池工厂--&gt;&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://localhost:61616"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"/&gt;&lt;/bean&gt;&lt;!--目的地--&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg index="0" value="spring-topic"/&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="defaultDestination" ref="destination"/&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"/&gt; &lt;/property&gt;&lt;/bean&gt; 如果在Spring中配置消费者的话，就不需要启动消费者相当于注册了一个默认消息监听器 当JMS Provider接受到消息之后就会触发listener的onMessage()方法 1234567&lt;bean id="jmsContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="destination" ref="destination"/&gt; &lt;property name="messageListener" ref="messageListener"/&gt;&lt;/bean&gt;&lt;bean id="messageListener"class="org.destiny.activemq.spring.MyMessageListener"/&gt; 12345678910111213package org.destiny.activemq.spring;public class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println("receive: " + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 最佳实践 Camel框架支持大量的企业集成模式，可以大大简化集成组件间的大量服务和复杂的消息流。而Spring更注重简单性。 Spring消息发送的核心架构是JmsTemplate，隔离了像打开、关闭Session和Producer等操作。因此应用开发人员仅仅需要关注实际的业务逻辑。但JmsTemplate损害了ActiveMQ的PooledConnectionFactory对Session和消息Producer的缓存机制带来的性能提升。 新的Spring中，可以设置org.springframework.jms.connection.CachingConnectionFactory的sessionCacheSize，或者直接使用ActiveMQ的PooledConnectionFactory。 不建议使用JmsTemplate的receive()，因为JmsTemplate上的所有调用都是同步的，这意味着调用的线程会阻塞，直到方法返回，性能影响较大。 尽量使用DefaultMessageListenerContainer，它允许异步接受消息并缓存session和消息Consuer。]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(4)——Broker的启动方式]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2FActiveMQ-4-%E2%80%94%E2%80%94Broker%E7%9A%84%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Broker：相当于一个ActiveMQ服务器实例。 命令行启动参数示例 activemq start：默认使用acitvemq.xml来启动 activemq start xbean:file:../conf/activemq.xml：使用指定的配置文件来启动。 用ActiveMQ来构建Java应用用ActiveMQ Broker作为独立的消息服务器来构建JAVA应用。ActiveMQ也支持在VM中通信基于嵌入式的Broker，能够无缝集成其他Java应用。 嵌入式BrokerBrokerService启动Broker1234567public static void main(String[] args) throws Exception &#123; // 开启ActiveMQ Broker BrokerService brokerService = new BrokerService(); brokerService.setUseJmx(true); brokerService.addConnector("tcp://localhost:61616"); brokerService.start();&#125; BrokerFactory启动Broker1234567public static void main(String[] args) throws Exception &#123; // 开启ActiveMQ Broker String uri = "properties:broker.properties"; BrokerService brokerService = BrokerFactory.createBroker(new URI(uri)); brokerService.addConnector("tcp://localhost:61616"); brokerService.start();&#125; 配置文件broker.properties123useJmx=truepersistent=falsebrokerName=Cheese 利用Spring集成Broker123456789&lt;bean id="broker" class="org.apache.activemq.broker.BrokerService" init-method="start" destroy-method="stop"&gt; &lt;property name="brokerName" value="myBroker"/&gt; &lt;property name="persistent" value="false"/&gt; &lt;property name="transportConnectorURIs"&gt; &lt;list&gt; &lt;value&gt;tcp://localhost:61616&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 启动多个Broker如果需要启动多个Broker，那么需要为每个Broker设置一个名字12]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(3)——JMS可靠性机制]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2FActiveMQ-3-%E2%80%94%E2%80%94JMS%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[消息接受确认JMS消息只有在被确认之后，才认为已经被成功地消费了。消费的成功通常包含三个阶段：客户端接受消息、客户端处理消息和消息被确认。在事务性会话中，当一个事务被提交的时候，确认自动发生。在非事务性会话中，消息何时被确认取决于创建会话时的应答模式。该参数有三个可选方案： Session.AUTO_ACKNOWLEDGE当客户成功的从receive()方法返回的时候，或者从MessageListener.onMessage()方法成功返回的时候，会话自动确认客户端收到的消息。 Session.CLIENT_ACKNOWLEDGE客户端通过调用消息的acknowledge()方法确认消息。在这种模式中，确认是在会话层上进行，确认一个被消费的消息将自动确认所有已被会话消费的消息。 1Session session = connection.createSession(false, Session.CLIENT_ACKNOWLEDGE); Session.DUPS_ACKNOWLEDGE只是会话迟钝的确认消息的提交。如果JMS Provider失败，那么可能会导致一些重复的消息。如果是重复的消息，那么JMS Provider必须把消息头的JMSRedelivered字段设置为true 消息的持久性，JMS支持两种消息提交模式PERSISTENTJMS Provider永久保存消息，以保证消息不会因为JMS Provider的失败而丢失。 NON_PERSISTENT不要求JMS Provider持久保存消息 消息的临时目的地可以通过Session的createTemporaryQueue()和createTemporaryTopic()方法来创建临时目的地。他们的存在时间只限于创建他们的连接所保持的时间，只有创建该临时目的地的连接上的消息消费者才能够从临时目的地中提取消息。 本地事务在一个JMS客户端，可以使用本地事务来组合消息的发送和签收。Session接口提供了commit()和rollback()方法。 事务提交意味着生产的所有消息被发送，消费的所有消息被确认。 事务回滚意味着生产的所有消息被销毁，消费的所有消息被恢复并重新提交，除非他们已过期。 PTP模型该模型定义了客户端如何向队列发送消息，从队列接受消息。 PTP模型是基于队列的，生产者发消息到队列，消费者从队列接受消息，队列使得消息的异步传输成为可能。 特点 Session在关闭时，如果有消息已经被接受，但还没有确认，那么当消费者下次连接到相同的队列时，这些消息还会被再次接受。 如果用户在receive()方法中设定了消息选择条件，那么不符合条件的消息会留在队列中。 队列可以长久地保存消息直到消费者收到消息，消费者不需要因为担心消息丢失而时刻与队列保持激活的连接状态。 Pub/Sub模型该模型定义了如何向一个内容节点发布和订阅消息。 主题可以被认为是消息的传输中介，发布者发布消息到主题，订阅者从主题订阅消息，二者相互独立，不需要接触。 特点 消息订阅分为非持久订阅和持久订阅 非持久订阅时，只有当客户端处于激活状态才能收到某个主题的消息；离线时发布到主题的消息将会丢失。 持久订阅时，客户端向JMS Provider注册一个自己身份的ID，当客户端处于离线状态时，Provider会为这个ID保存所有发送到主题的消息。 如果用户在receive()方法中设定了消息选择条件，那么不符合条件的消息不会被接收。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(2)——JMS规范]]></title>
    <url>%2Fblog%2F2018%2F04%2F11%2FActiveMQ-2-%E2%80%94%E2%80%94JMS%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[定义JMS(Java Message Service)，Java消息服务 JMS定义了Java访问消息中间件的接口，并没有给予实现。 实现JMS接口的消息中间件成为JMSProvider，如ActiveMQ。 JMS规范 JMS message：JMS的消息，由三部分组成：消息头、消息属性、消息体 JMS Producer：消息生产者，创建和发送消息 JMS Consumer：消息消费者，接受和处理消息，消息的消费可以采用以下两种方式之一： 同步消费：通过调用消费者的receive方法从目的地中显示提取消息，receive方法可以一直阻塞到消息到达 异步消费：客户可以为消费者注册一个Listener，以定义在消息到达时所采取的动作。 JMS domains：消息传递域，JMS定义了两周消息传递域： 点对点：每个消息只能有一个消费者，生产者和消费者没有时间上的相关性，无论消费者在生产者发送消息的时候是否处于运行状态，都可以提取消息； 发布订阅：每个消息可以被多个消费者消费，生产者和消费者有时间上的相关性，订阅一个主题的消费者只能消费它订阅之后发布的消息 ConnectionFactory：连接工厂，用来创建连接对象，已连接到JMS的Provider JMS Connection：封装了客户与JMS提供者之间的一个虚拟连接 JMS Session：是生产和消费消息的一个单线程上下文 会话用于创建消息生产者、消费者和消息等。会话提供了一个事务性的上下文，在这个上下文中，一组发送和接受被组合到了一个原子操作中。 Destination：消息发送到的目的地。 Acknowledge：签收。消费者收到消息后，需要告诉JMS Provider消息已被消费。 Transaction：事务 JMS Client：用来收发消息的Java应用 JMS Message结构组成 消息头 属性 消息体 消息头消息头包含识别信息和路由信息 JMSDestination：消息发送的目的地，主要是指Queue或Topic。 JMSDeliveryMode：传送模式，持久或非持久。 持久消息应该会且只会被发送一次，JMS提供者出现故障，消息也不会丢失，会在服务器恢复之后再次传递。 非持久的消息最多会被发送一次，这意味着服务器出现故障，该消息会永远丢失。 JMSExpiration：消息过期时间，为0表示永不过期。 JMSPriority：消息优先级，数字越大，级别越高，加急消息要先于普通消息。 JMSMessageId：唯一标识。 JMSCorrelationID：用来连接到另一个消息，典型应用是在回复消息中关联到原消息。 JMSReplyTo：提供本消息回复消息的目的地址，由开发者提供 JMSType：消息的类型识别符 JMSRedelivered：如果一个客户端收到了一个设置了JMSRedelivered属性的消息，则表示客户端可能收到过该消息，但没有签收。 消息体 TextMessage：文本消息 MapMessage：映射消息 BytesMessage：二进制消息 StreamMessage：流式消息 ObjectMessage：对象消息 属性应用程序设置和添加的属性1message.setStringProperty("username", username); JMS定义的属性12// 返回所有连接支持的JMSX属性的名字connection.getMetaData().getJMSXPropertyNames(); JMS供应商特定的属性JMS定义的属性 JMSXUserID：发送消息的用户标识 JMSXAppID：发送消息的应用标识 JMSXDeliveryCount：转发消息重试次数 JMSXGroupID：消息所在的消息组的标识 JMSXGroupSeq：组内消息的序号]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(1)——概览&入门]]></title>
    <url>%2Fblog%2F2018%2F04%2F09%2FActiveMQ-1-%E2%80%94%E2%80%94%E6%A6%82%E8%A7%88-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[概览ActiveMQ简介 什么是ActiveMQ ActiveMQ的作用 ActiveMQ的特点 消息中间件的功能、特点、应用场景等 ActiveMQ安装和基本使用通过源码安装、基本的配置实例、启动、测试运行、关闭等 JMS基本概念、消息结构、可靠性机制、PTP、Pub/Sub、API结构、JMS应用开发的基本步骤、持久和非持久的Topic 同ActiveMQ构建应用 多种启动Broker的方法 单独应用的开发 结合Spring开发 ActiveMQ的Transport多种运输协议的功能、配置和使用 ActiveMQ的消息存储队列和Topic、KahaDB、AMQ、JDBC、MMS等 ActiveMQ的Network 在一台服务器上启动多个Broker 静态网络连接的功能、配置 “丢失”消息的处理 容错或可负载均衡的连接 动态网络连接等 ActiveMQ集群 队列消费者集群 Broker的集群 MasterSlave等 Destination高级特性 通配符 组合队列 配置启动的Destination 删除不活动的Destination 虚拟Destination 镜像队列 Message Dispatch高级特性 消息游标 异步发送 分发策略 优化批量控制 Message高级特性 消息属性 Advisory Message 延迟和定时消息投递 Blob消息 消息转换 Consumer高级特性 消息异步分发 消息优先级 管理持久化消息 消息分组 消息重抵策略 杂项 监控和管理 集成ActiveMQ和Tomcat ActiveMQ优化ActiveMQ简介介绍ActiveMQ是Apache推出的一款开源的、完全支持JMS和J2EE规范的JMSProvider实现的消息中间件(Message Oriented Middleware, MOM)。 作用用来帮助实现高可用、高性能、可伸缩、易用和安全的企业级面向消息服务的系统。 ActiveMQ安装和基本使用下载并安装服务端 从http://activemq.apache.org/download.html下载最新的ActiveMQ 直接解压1$ tar -zxvf apache-activemq-5.9.0-bin.tar.gz activemq 启动运行 普通启动 1234$ pwd/usr/local/activemq/bin$ ./activemq start 启动并指定日志文件 1$ ./activemq start &gt; /tmp/activemqlog 检查是否已经启动ActiveMQ默认采用61616端口提供JMS服务，使用8061端口提供管理控制台服务，执行以下命令以便检验是否已经成功启动ActiveMQ服务： 查看61616端口是否已经打开： netstat -an | grep 61616 查看控制台输出或者日志文件 直接访问ActiveMQ的管理页面：http://localhost:8161/admin，默认的用户名和密码是admin/admin 关闭ActiveMQ1$ ./activemq stop 基本的消息发送配置MAVEN所需的依赖12345678910&lt;dependency&gt; &lt;gruopId&gt;org.apache.activemq&lt;/gruopId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;gruopId&gt;org.apache.xbean&lt;/gruopId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; 消息生产者123456789101112131415161718192021222324252627public static void main(String[] args) throws JMSException, InterruptedException &#123; // 创建连接工厂，连接工程负责与ActiveMQ服务端建立连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616"); // 由连接工厂创建连接 Connection connection = connectionFactory.createConnection(); // 启动连接 connection.start(); // 通过连接创建会话 Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); // 通过会话创建目的地，名称表示对列名 Destination destination = session.createQueue("my-queue"); // 通过 session 创建生产者 MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; 100; ++i) &#123; TextMessage message = session.createTextMessage("message -- " + i); Thread.sleep(100); // 通过消息生产者发出消息 producer.send(message); System.out.println("创建成功"); &#125; session.commit(); session.close(); connection.close();&#125; 运行结果： 消息消费者123456789101112131415161718192021222324public static void main(String[] args) throws JMSException, InterruptedException &#123; // 创建连接工厂，连接工厂负责与ActiveMQ服务端建立连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616"); // 由连接工厂创建连接 Connection connection = connectionFactory.createConnection(); // 启动连接 connection.start(); // 通过连接创建会话 Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); // 通过会话创建目的地，名称表示对列名 Destination destination = session.createQueue("my-queue"); // 通过 session 创建生产者 MessageConsumer consumer = session.createConsumer(destination); for (int i = 0; i &lt; 100; ++i) &#123; TextMessage message = (TextMessage) consumer.receive(); session.commit(); System.out.println("收到消息: " + message.getText()); &#125; session.close(); connection.close();&#125; 运行结果： JMS模型]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[盘点实际项目中常用的加密算法及使用场景]]></title>
    <url>%2Fblog%2F2018%2F04%2F08%2F%E7%9B%98%E7%82%B9%E5%AE%9E%E9%99%85%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[MD5定义MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4。 特点 压缩性：任意长度的数据，算出的MD5值长度都是固定的。 容易计算：从原数据计算出MD5值很容易。 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 MD5的作用是让大容量信息在用数字签名软件签署私人密钥前被”压缩”成一种保密的格式（就是把一个任意长度的字节串变换成一定长的十六进制数字串）。除了MD5以外，其中比较有名的还有sha-1、RIPEMD以及Haval等。 应用场景一致性验证MD5的典型应用是对一段信息（Message）产生信息摘要（Message-Digest），以防止被篡改。MD5就可以为任何文件（不管其大小、格式、数量）产生一个同样独一无二的“数字指纹”，如果任何人对文件做了任何改动，其MD5值也就是对应的“数字指纹”都会发生变化。 数字签名MD5的典型应用是对一段Message(字节串)产生fingerprint(指纹），以防止被“篡改”。举个例子，你将一段话写在一个叫 readme.txt文件中，并对这个readme.txt产生一个MD5的值并记录在案，然后你可以传播这个文件给别人，别人如果修改了文件中的任何内容，你对这个文件重新计算MD5时就会发现（两个MD5值不相同）。如果再有一个第三方的认证机构，用MD5还可以防止文件作者的“抵赖”，这就是所谓的数字签名应用。 安全访问认证MD5还广泛用于操作系统的登陆认证上，如Unix、各类BSD系统登录密码、数字签名等诸多方面。如在Unix系统中用户的密码是以MD5（或其它类似的算法）经Hash运算后存储在文件系统中。当用户登录的时候，系统把用户输入的密码进行MD5 Hash运算，然后再去和保存在文件系统中的MD5值进行比较，进而确定输入的密码是否正确。通过这样的步骤，系统在并不知道用户密码的明码的情况下就可以确定用户登录系统的合法性。这可以避免用户的密码被具有系统管理员权限的用户知道。 缺点与不足2014年中国山东大学的王小云教授公布破译了MD5、HAVAL-128、 MD4和RIPEMD算法的报告。通过加速的杂凑与冲撞方法破译了MD5算法。 实践 RSA定义RSA为公钥加密体制 乙方生成两把秘钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 甲方获取乙方的公钥，然后用它对信息加密。 乙方得到加密后的信息，用私钥解密。 特点便于理解，使用广泛RSA算法是第一个能同时用于加密和数字签名的算法，也易于理解和操作。RSA是被研究得最广泛的公钥算法，从提出到现今的三十多年里，经历了各种攻击的考验，逐渐为人们接受，普遍认为是目前最优秀的公钥方案之一。 缺点与不足：加密和解密花费时间长、速度慢，只适合对少量数据进行加密为提高保密强度，RSA密钥至少为500位长，一般推荐使用1024位。这就使加密的计算量很大。为减少计算量，在传送信息时，常采用传统加密方法与公开密钥加密方法相结合的方式，即信息采用改进的DES或IDEA对话密钥加密，然后使用RSA密钥加密对话密钥和信息摘要。对方收到信息后，用不同的密钥解密并可核对信息摘要。 实践ssh口令登录1234567sequenceDiagram客户端-&gt;&gt;服务端: 口令登录服务端-&gt;&gt;客户端: 发送1024为公钥指纹客户端-&gt;&gt;服务端: 指纹保存在$HOME/.ssh/known_hosts，接受远程主机秘钥服务端-&gt;&gt;客户端: 请求输入密码客户端-&gt;&gt;服务端: 输入密码服务端-&gt;&gt;客户端: 接受或拒绝链接 ssh公钥登录12345sequenceDiagram客户端-&gt;&gt;服务端: 登录请求服务端-&gt;&gt;客户端: 发送随机字符串客户端-&gt;&gt;服务端: 发送加密后的随机字符串服务端-&gt;&gt;客户端: 接受或拒绝链接 客户端事先把自己的公钥保存在服务端的指定目录: $HOME/.ssh/authorized_keys 客户端生成秘钥: ssh-keygen，运行结束后，在$HOME/.ssh/目录下，会新生成两个文件: id_rsa.pub和id_rsa。前者是公钥，后者是私钥。 将公钥发送给远程主机: ssh-copy-id user@host]]></content>
      <categories>
        <category>加密</category>
      </categories>
      <tags>
        <tag>开发</tag>
        <tag>算法</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（二）Nginx实现动静分离]]></title>
    <url>%2Fblog%2F2018%2F04%2F03%2F%EF%BC%88%E4%BA%8C%EF%BC%89Nginx%E5%AE%9E%E7%8E%B0%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[概念在反向代理时，如果是静态资源，就直接从Nginx发布的路径中去读取，而不需要从后台服务器获取。 但这种情况下需要保证后端跟前端的程序保持一致，可以使用Rsync做服务端自动同步或者使用NFS、MFS分布式共享存储。 概念图 原理Nginx可以拦截请求 因此可以利用这一特性，将拦截到的静态请求进行重定向。 12345678910111213141516171819202122232425server &#123; listen 80; server_name destiny; access_log logs/host.access.log main; index index.html index.htm index.jsp; root /usr/local/tomcat-9.0.0-RC5-1/webapps/ROOT/; # 不区分大小写的正则匹配 location ~* .*\.(jpg|jepg|fig|png|wsf|ico)$ &#123; if(-f $request_filename) &#123; # expires 15d; break; &#125; &#125; # 不区分大小写的正则匹配 locatin ~* .*\.(html|htm|js|css)$ &#123; # expires 1d; &#125; location / &#123; proxy_pass http://10.211.55.5 &#125;&#125; 在前两个location中，没有配置后端服务器的路径Nginx就会默认去寻找root的资源 Nginx会以root为根路径，将请求的路径拼在其后去查找，如果能访问到，Nginx就可以直接将该文件返回。 如果能够查询到响应的文件，就会直接返回。 指令index(默认主页设置模块)如果URL中没有指定文件，则设置一个默认主页。 可以指定多个文件，如果第一个文件没有找到，将会查找后面指定的文件 index index.html index.htm index.jsp root请求到达后的文件根目录 123location /i/ &#123; root /spool/w3;&#125; 如果请求/i/top.gif文件，Nginx将转到/spool/w3/i/top.gif文件 在请求中root会添加这个location到它的值后面，即”/i/top.gif”并不会请求”/spool/w3/top.gif”文件，如果要实现上述类似于apache alias的功能，可以使用alias指令。 简单来说，root是拼接，alias是替换。 实现当访问静态资源的请求进入(假设为http://10.211.55.4:80/static/person.jpg)时，会被配置文件中的第一个location拦截 location会将root中配置的路径和访问路径拼接在一起，新的路径为/usr/local/tomcat-9.0.0-RC5-1/webapps/ROOT/static/person.jpg，在Nginx的路径中进行查找。 初始情况，不加Nginx的情况下启动Tomcat 访问10.211.55.4:8080即可访问Tomcat主页。 查看logs/localhost_access_log.2018-04-03.txt可以看到访问日志 此时可以看到，请求了多个静态文件。 加入Nginx将包含上图中文件的路径/usr/local/apache-tomcat-7.0.73/webapps/ROOT/配置进Nginx配置文件中的root属性。 并配置location用于拦截jpg/jepg/fig/png/wsf/ico后缀的文件。 然后sbin/nginx -s reload重启Nginx 效果展示分别重启Tomcat和Nginx后，再访问10.211.55.4(Nginx自动监听80端口并转发至8080) 删除浏览器缓存 此时再查看日志，已经请求中已经不再对静态资源进行请求]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从头搭建github博客]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2F%E4%BB%8E%E5%A4%B4%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[安装Node.js并配置Node.js环境成功界面如下： 安装git并配置git环境 注册Github并新建项目首页 新建仓库页参考其他博客的时候，很多博客中都提到 项目名必须是 github账户名.github.io 但经本人测试其实项目名称可以任意选取，如本人的仓库名就是blog，而非destinywang.github.io 设置进入项目的setting选项卡中 下拉到Github Pages，此时该项目已经被部署，可以通过提供的外网链接去访问。 安装HexoHexo中文网站 Hexo是个快捷，简介且高效的博客框架 让上百个页面在几秒内完成渲染 Hexo支持Github Flavored Markdown的所有功能 在合适的位置创建文件夹 以上操作需要在空文件夹中进行 123$ npm install hexo -g # 安装Hexo$ hexo -v # 检查Hexo是否安装成功$ hexo init # 初始化文件夹 Hexo init npm install此命令用于安装所需要的组件 hexo g首次体验Hexo hexo s此命令会在本地开启Hexo的服务器 可以在发布到github之前先在本地进行调试 然后再浏览器中输入localhost:4000/blog/如果出现如下界面就成功了 将Hexo和Github page联系起来设置本地git如果是第一次使用git的话需要设置name和email 1234$ ssh-keygen -t rsa -C &quot;your email&quot; # 生成秘钥，路径在~/.ssh下，windows用户的路径为C:\Users\Administrator\.ssh$ eval &quot;$(ssh-agent -s)&quot; # 添加秘钥到ssh-agent$ ssh-add ~/.ssh/id_rsa # 添加生成的SSH key到ssh-agent 登录github，进行设置 进入用户的setting页面 在SSH and GPG keys选项卡中添加一个ssh key，并将id_rsa.pub(公钥)的内容复制上去 配置Deployment为了保证Hexo能够正确的通过Git进行add、commit、pull、push等操作需要将本地及远程的git仓库信息进行配置 当前站点文件夹的状态： 修改_config.yml文件，将deployment部分相关的内容进行替换 type: 部署类型 repository: 远程仓库路径，即github中的仓库路径 branch: 分支名 新建一篇博客在终端中执行命令hexo new post 博客名 会在source/_posts路径下生成对应的博客文件test.md 安装hexo-deployer-git扩展文件1$ npm install hexo-deployer-git --save 编辑文章1$ vim source/_posts/test.md 打开test.md文件，按照正常的Markdown文件编辑即可 部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475$ hexo d -gINFO Start processingINFO Files loaded in 640 msINFO Generated: tags/index.htmlINFO Generated: about/index.htmlINFO Generated: 2018/04/01/jvm/index.htmlINFO Generated: 2018/04/01/test/index.htmlINFO Generated: 2018/04/01/hello-world-1/index.htmlINFO Generated: archives/index.htmlINFO Generated: tags/jvm/index.htmlINFO Generated: archives/2018/index.htmlINFO Generated: archives/2018/04/index.htmlINFO Generated: tags/java基础/index.htmlINFO Generated: index.htmlINFO Generated: 2018/04/01/hello-world/index.htmlINFO Generated: 2018/04/01/一-Nginx基本知识/index.htmlINFO Generated: tags/Nginx/index.htmlINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/avatar.gifINFO Generated: images/apple-touch-icon-next.pngINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/algolia_logo.svgINFO Generated: images/cc-by-nc.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/cc-by-sa.svgINFO Generated: images/cc-by.svgINFO Generated: images/cc-zero.svgINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/favicon-32x32-next.pngINFO Generated: images/loading.gifINFO Generated: images/logo.svgINFO Generated: images/placeholder.gifINFO Generated: images/quote-r.svgINFO Generated: images/searchicon.pngINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: images/quote-l.svgINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: images/blog-logo.jpegINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: css/main.cssINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: js/src/affix.jsINFO Generated: js/src/exturl.jsINFO Generated: js/src/algolia-search.jsINFO Generated: js/src/bootstrap.jsINFO Generated: js/src/love.jsINFO Generated: js/src/js.cookie.jsINFO Generated: js/src/post-details.jsINFO Generated: js/src/motion.jsINFO Generated: js/src/scrollspy.jsINFO Generated: js/src/scroll-cookie.jsINFO Generated: lib/font-awesome/bower.jsonINFO Generated: js/src/utils.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.min.jsINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/velocity/velocity.min.jsINFO Generated: js/src/schemes/pisces.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.pack.jsINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: lib/jquery/index.jsINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: lib/velocity/velocity.jsINFO 61 files generated in 1.13 sINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...[master 966acc9] Site updated: 2018-04-01 21:18:16 1 file changed, 1 insertion(+), 1 deletion(-)To github.com:DestinyWang/blog.git + fa066f8...966acc9 HEAD -&gt; master (forced update)Branch &apos;master&apos; set up to track remote branch &apos;master&apos; from &apos;git@github.com:DestinyWang/blog.git&apos;.INFO Deploy done: git 至此，博客已经部署成功，可以去http://用户名.github.io查看。 安装Next1$ git clone https://github.com/iissnan/hexo-theme-next themes/next 下载到站点文件夹路径下的themes/next 启用Next主体在站点目录中，打开配置文件_config.yml，修改theme: next123$ pwd~/blog$ vim _config.yml 主题设定在next主题目录下的_config.yml，修改scheme: Pisces 123$ pwd~/blog$ vim themes/next/_config.yml 语言设定Hexo提供了多种语言支持，包括简体中文zh-Hans在站点根目录下修改配置文件_config.yml中的language为zh-Hans 123$ pwd~/blog$ vim _config.yml 修改菜单栏在主题目录下修改配置文件_config.yml中的menu 123$ pwd~/blog$ vim themes/next/_config.yml 设置菜单项图标对应字段是menu_icons同样在主题目录下的_config.yml中修改 格式为item name: icon name，其中item name 与所配置的菜单名字对应，icon name是Font Awesome图标的名字。而 enable可用于控制是否显示图标，你可以设置成 false 来去掉图标。 123$ pwd~/blog$ vim themes/next/_config.yml 设置侧栏位置修改主题目录下sidebar的position值 123$ pwd~/blog$ vim themes/next/_config.yml 设置头像在站点根目录下载配置文件中新增avatar，值设置为头像的链接地址。地址可以是网络地址，也可以是本地地址（放置在source/images/目录下） 设置文章代码主题在主题目录下修改配置文件_config.yml，字段highlight_theme，默认值为nomal。可以设置为night 123$ pwd~/blog$ vim themes/next/_config.yml 添加分类在站点路径下新建页面categories 123456$ pwd~/blog$ hexo new page categories# 在 source/categories 目录中修改index.mdvim source/categories/index.md 12# 在主题的 _config.yml 中取消注释:$ vim _config.yml 在要分类的文章中加入 category 属性: 添加标签页面标签是对博客分类的方式比如一个系列的博客都是将神经网络，那么就可以给每篇博客加上神经网络的tag 1234567$ pwd~/blog$ hexo new page tagsINFO Created: ~/blog/source/tags/index.md# 在新建的index.md中添加type: &quot;tags&quot;vim source/tags/index.md 后面只需要在博客的开头中添加tags: [A, B, C]即可 成功后，标签部分的导航栏为 Aboute Me1234567$ pwd~/blog$ hexo new page aboutINFO Created: ~/blog/source/about/index.md# 在新建的index.md中添加如下内容vim source/about/index.md 成功后效果如下所示： 添加github导航条从这里选择主题 然后将代码复制到themes/next/layout/_layout.swig 123$ pwd~/blog$ vim themes/next/layout/_layout.swig 成功后的效果如下： 修改内容区域宽度默认情况Next 对内容的宽度的设定如下： 700px，当屏幕宽度 &lt; 1600px 900px，当屏幕宽度 &gt;= 1600px 移动设备下，宽度自适应 非Pisces Scheme主题修改1$ vim source/css_variables/custom.styl 修改内容： 12345// 修改成你期望的宽度$content-desktop = 700px// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px Pisces Scheme主题修改1$ vim themes\next\source\css\_schemes\Picses\_layout.styl 修改内容： 123.header &#123;width: 1150px;&#125;.container .main-inner &#123;width: 1150px;&#125;.content-wrap &#123;width: calc(100% - 260px);&#125; 设置首页不显示全文(只显示预览)打开主题路径下的_config.yml1$ vim themes/next/_config.yml 修改auto_excerpt12345# Automatically Excerpt. Not recommand.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150 将enable属性改为true 修改code代码块自定义样式1$ vim themes/next/source/css/_custom/custom.styl 取消文章目录对标题的自动编号 nexT对 markdown 语法的标题 # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 会默认进行标号分配，这样有可能会打乱文章原有标题 取消方式： 修改主题配置文件 1$ vim theme/next/_config 将 number 设为 false 结束至此，博客基本设置OK但还有很多地方可以继续挖掘 后续会持续更新]]></content>
      <tags>
        <tag>github博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（一）Nginx基本知识]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2F%EF%BC%88%E4%B8%80%EF%BC%89Nginx%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[简介Nginx是一款轻量级的Web服务器，也是一款轻量级的反向代理服务器 用途 直接支持Rails和PHP程序 作为HTTP反向代理服务器 作为负载均衡服务器 作为邮件代理服务器 帮助实现动静分离 特点高稳定、高性能、资源占用少、功能丰富、模块化结构、支持热部署 安装Nginx 依赖gcc openssl-devel pcre-devel zlib zlib-devel 1yum install gcc openssl-devel pcre-devel zlib zlib-devel 安装 $ ./configure --prefix=/usr/local/nginx --withhttp_stub_status_module $ make $ make install 常见的Nginx安装配置选项 Nginx基本运行// 测试配置文件 $ sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful // 启动 $ sbin/nginx // 停止 $ sbin/nginx -s stop $ sbin/nginx -s quit // 重启 $ sbin/nginx -s reload // 查看进程 ps -ef | grep nginx Nginx的基本配置默认启动Nginx的时候，使用的配置文件是conf/nginx.conf文件 也可以在启动Nginx的时候，通过-c来指定要去读的配置文件 常见的配置文件 文件名 用途 nginx.conf 应用程序的基本配置文件 mime.types MIME类型关联的扩展文件 fastcgi.conf 与fastcgi相关的配置，与PHP相关 proxy.conf 与proxy相关的配置（反向代理） sites.conf 配置Nginx提供的网站，包括虚拟主机 nginx.cong1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950user root;worker_processes 1;error_log logs/error.log crit;pid logs/nginx.pid; # nginx 进程号文件路径events &#123; # 事件模块 use epoll; # 文件的模型 worker_connections 24; # 每个worker的connections&#125;http &#123; # web反向代理 include mime.type; # 引入mime.type include proxy.conf; # 引入proxy.conf defualt_type application/octet-stream; # mine.type 的缺省类型 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; # 日志格式，远程地址 - 远程用户 时间 等 &apos;$status $body_bytes_sent &quot;$http_referer&quot;&apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; access_log logs/access.log main; # 使用为main的格式 upstream test.com &#123; # 负载均衡模块 server 127.0.0.1:8080 weight = 5; &#125; server &#123; lisent 80; server_name detiny; access_log logs/host.access.log main; index index.html index.htm index.jsp; root /Users/destiny/Download/apache-tomcat-9.0.1/webapps/ROOT/; location ~* .*\.(jpg|jepg|gif|png|wsf|ico)$ &#123; # 如果是图片，就去root路径查询 if(-f $request_filename) &#123; break; &#125; &#125; location / proxy_pass http://destiny.com; &#125; &#125;&#125; Nginx的进程结构启动Nginx的时候，会启动一个Master进程，这个进程不处理客户端的任何请求，主要用来产生worker进程 而每个worker进程用来处理一个Request Niginx 模块分为：核心模块、时间模块、标准HTTP模块、可选HTTP模块、邮件模块、第三方模块和补丁等。 基本模块Nginx默认的功能模块，它们提供的指令，允许使用定义Nginx基本功能的变量，在编译的时候不能被禁用，包括: 核心模块：基本功能和指令，如进程管理和安全 事件模块：在Nginx内配置网络使用的能力 配置模块：提供包含机制 常用模块Nginx常用的核心模块指令 error_log include pid user worker_cpu_affinity worker_processes error_log语法： error_log file [ debug|info|notice|warn|error|crit ] Nginx支持将不同的虚拟主机的日志记录在不同的路径 12345678910111213http &#123; error_log logs/http_error.log error; server &#123; server_name one; access_log logs/one_access.log; error_log logs/one_error.log error; &#125; server &#123; server_name two; access_log logs/two_access.log; error_log logs/two_error.log error; &#125;&#125; include从外部引入文件，支持文件通配符 pid指定pid文件，可以使用kill命令 user为了提高安全性，指定允许操作Nginx的用户 语法：user user [group] worker_cpu_affinity指定工作进程指定到某个CPU上 // 指定每个进程绑定一个CPU worker_processes 4; worker_cpu_affinity 0001 0010 0100 1000; // 指定第一个进程到CPU0/CPU2，第二个进程到CPU1/CPU3 worker_processes 2; worker_cpu_affinity 0101 1010; worker_processes一个工作进程为一个单线程的进程 如果Nginx工作在一些CPU密集型的环境中，并且你的机器拥有2块以上的CPU，则可以将worker_processes的数目设置为CPU核数。 如果你的机器运行在需要处理大量静态文件的环境，并且文件的大小总和超出了可用的内存，那么可以增加worker_processes的以便充分利用磁盘带宽。 日志模块控制Nginx如何记录请求日志 12345log_format gzip $remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot;&apos; &apos;&quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&apos;; access_log /spool/logs/nginx-access.log gzip buffer=32k; access_log语法：access_log path [format [buffer=size | off]] 默认值：access_log log/access.log combined 使用字段：http、server、location 注意： Nginx指定的用户必须有创建日志的权限 log_format语法：log_format name format [format ...] 默认值：log_format combined &quot;...&quot; 使用字段：http、server 变量名 含义 $body_bytes_sent 减去应答头后传送给客户端的字节数 $bytes_sent 传送给客户端的字节数 $connection 连接数 $msec 正在写入日志条目的当前时间 $pipe 如果请求为管道的 request_length 请求主体的长度 $request_time 从一个请求发出到Nginx工作的时间 $status 应答的状态 $time_local 写入普通日志格式的当地时间 事件模块 use connection use语法：use [ kqueue | rtsig | epoll | /dev/poll | select | poll | eventport] connections语法：worker_connections 最大连接数 = worker_processes * worker_connections // 反向代理环境下 最大连接数 = worker_processes * worker_connections / 4 原因：浏览器默认打开两个连接到服务器，Nginx使用来自相同地址池的fds与前后端相连接 HTTP模块基本配置Nginx的HTTP配置主要包括三个区块，结构如下 alias语法：alias file-path | directory-path; 使用字段：location alias是替换路径，而root是追加路径，将location后的路径追到root之后 12345location /i/ &#123; alias /spool/w3/images/&#125;请求 /i/top.gif 将返回这个文件 &quot;/spool/w3/images/top.gif&quot;。 error_page语法：error_page code [ code ... ] [ = | = answer-code ] uri | @named_location 使用字段：http、server、location、location中的if字段 这个参数可以为错误代码指定相应的错误页面 1234error_page 4040 /404.html;error_page 502 503 504 /50x.html;error_page 403 http://example.com/forbidden.html;error_page 404 = @fetch; 同样，你也可以将原有响应代码修改为另一个响应代码 12error_page 404 = 200 /empty.gif;error_page 404 = 403 /forbindden.gif; internal语法：internal 使用字段：location internal指定某个location只能被内部的请求调用，外部的调用会返回404. location区段通过指定模式来与客户端请求的URI相匹配 location [=|~|~*|^~|@] pattern { # ... } 没有修饰符，表示必须以指定的模式开始123456server &#123; server_name destiny.com; location /abc &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 http://destiny.com/abc/ http://destiny.com/abcde =，表示必须与指定的模式精准匹配123456server &#123; server_name destiny.com; location = /abc &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) 不能匹配 http://destiny.com/abc/ http://destiny.com/abcde ~，表示指定的正则表达式要区分大小写 ~表示按照正则表达式的语法与pattern进行匹配 123456server &#123; server_name destiny.com; location ~ ^/abc$ &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) 不能匹配 http://destiny.com/ABC/ http://destiny.com/abc/ http://destiny.com/abcde ~*，表示正则表达式不区分大小写123456server &#123; server_name destiny.com; location ~* ^/abc$ &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) http://destiny.com/ABC/ 不能匹配 http://destiny.com/abc/ http://destiny.com/abcde ^~，表示正则表达式不区分大小写 类似于无修饰符的行为，也是以指定模式开始，但如果模式匹配，那么久停止搜索其他模式了。 @，定义命名location区段，这些区段客户端不能访问，只可以由内部产生的请求来访问多个location的优先级问题 带有=的精准匹配 没有修饰符的精准匹配 正则表达式按照定义顺序 ^~的开头匹配 ~或~* 修饰符 没有修饰符的，如果指定字符串与URI开头匹配 Http反向代理模块 Nginx通常被用作后端服务器的反向代理，这样就可以很方便的实现动静分离，以及负载均衡，从而大大提高服务器的处理能力。 Http Proxy模块，功能很多，最常用的是proxy_pass 如果要使用proxy_cache的话，需要集成第三方的ngx_cache_purge模块，用来清除指定的URL缓存。 反向代理 普通的正向代理，为客户端提供代理服务 123456graph TDA[客户端]--&gt;|发出请求|B&#123;代理&#125;B --&gt; |代理访问并返回响应|AB --&gt; |代理访问|C[服务器A]B --&gt; |代理访问|D[服务器B]B --&gt; |代理访问|E[服务器C] 反向代理，为服务端提供代理服务 123456graph TDA[客户端A]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;B[客户端B]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;C[客户端C]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;D --&gt; |代理客户端访问|E[服务器]E --&gt; |返回请求|D Http代理模块这个模块可以转发请求到其他的服务器 location / { proxy_pass http://localhost:8080; # 转发指令，把当前的指令转发到指定路径 proxy_set_header X-Real-IP $remote_addr; # 设置http请求头 } proxy_buffer_size设置从被代理服务器(真实服务器)读取的第一部分应答的缓冲区大小 语法：proxy_buffer_size the_size通常情况下这部分应答中包含一个小的应答头 proxy_buffering为后端服务器启用响应缓冲 如果启用缓冲，Nginx假设被代理服务器能够非常快的传递响应，并将其放入缓冲区 如果禁用缓冲，从后端传来的应答将立即被传送到客户端 语法：proxy_buffering on|off proxy_pass设置被代理服务器的地址和被映射的URL 地址可以使用主机名或IP+端口号的形式]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
