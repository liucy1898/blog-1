<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入理解 Git]]></title>
    <url>%2Fblog%2F2019%2F09%2F02%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Git%2F</url>
    <content type="text"><![CDATA[1. Git 数据结构当通过 git init 初始化一个 git 项目时, 当前路径上回自动创建一个 .git 文件夹用来保存所有 git 需要用到的数据. 我们先来简单介绍一下 .git 中的主要内容: 1.1 HEAD HEAD 是一个文本文件, 保存当前工作区中的当前分支, ref: refs/heads/master 就是代表当前正在工作的分支是 master, 切换分支时 head 的内容会发生改变 1.2 config主要用于记录当前 git 仓库的配置信息, 假设通过 local 设置了其他的用户名和邮箱, 会在此处保存. 1.3 refsHEAD 中的指向是一个 refs 下的文件 refs 下包含如下几个内容: heads: 对应分支, 是一个独立的开发空间, 不同分支间的工作互不影响. 当彼此间需要集成的时候可以进行合并. HEAD 文件的内容是整个仓库当前工作在哪个分支上, 所以内容是一个引用, 指向 refs/head/ 下的某个值, 而此处可以看到, master 内是一个 40 位的 16 进制数字(42ba8f37d95fb8847e8b5639d67ad7aff7bfe0d1) 我们可以使用 git 内置的命令查看这串数字的类型, 发现这是一个 commit 对象, 也就是说 heads 中保存了当前项目的所有分支, 每个分支都指向了一个 commit 对象: 12$ git cat-file -t 42ba8f37d95fb8847e8b5639d67ad7aff7bfe0d1commit tags: 标签, 当项目开发到一定程度, 是一个关键的里程碑, 或支持了某关键特性, 就可以对特定的 commit 打上一个 tag 做标识. 1.4 objectsobjects 是 git 中非常重要的路径, 保存了 git 核心数据结构: commit 信息 objects 下内容主要分为三部分: 两位 16 进制数字开头的文件夹, 内部包含一个或多个 38 为 16 进制数字组成的文件名(b98a673367b325d7de6151286d7ceb4aa6c9d3), 其实 git 内部主要使用 40 位的 16 进制数字, 需要将该名称与文件夹名组合起来, 如上图中我们查看的是 01 下的文件: 12$ git cat-file -t 01b98a673367b325d7de6151286d7ceb4aa6c9d3tree 类型为 tree, 此时我们可以再看看它的内容: 1234$ git cat-file -p 01b98a673367b325d7de6151286d7ceb4aa6c9d3100644 blob 85aa2fa76396d11d0e3cfc3aa8d31d0d9fdb8da5 SparseArray.md100644 blob 109f7918011338d8f409e965400f4ac2a99088eb sparse-array.go100644 blob b56a4561bf11b3fe2dfe7014b01eafc175b6b99b sparse-array_test.go 可以看到这棵树中包含三个元素, blob 表示类型是文件, 而每个文件也包含一个 40 位的 hash 值, 我们再继续通过 hash 值查看其中一个元素的类型和内容: 类型是一个文件, 而内容就是一段简单的 go 代码 info: pack: git 会做自我梳理, 如果某个类型 1 的文件过于松散, 会对它进行打包, 并将打包后的文件放在 pack 中. commit, tree, blob 就是 git 数据结构中最为核心的三个元素. 1.5 commit, tree, blob 三者间的关系 每次执行 git commit, 都会创建一个 commit 对象, 每个 commit 对象除了保存前一个 commit 的地址以外, 还会对应唯一的 tree, 由于文件系统是树形结构, 这个 tree 代表了该 commit 的视图, 视图存放了当前 commit 对应本项目仓库的所有文件和文件夹的快照, 每个 commit 对象再不借助其他 commit 的情况下就可以复原出整个项目. tree: 用来表示当前 commit 视图中的一个文件夹 blob: 直接与文件内容关联, 在 git 仓库中, 只要文件内容一致, 就是一个 blob]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 高级特性]]></title>
    <url>%2Fblog%2F2019%2F08%2F31%2FGo-%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[1. 并发机制1. 协程机制总体来说, 协程是一个更加轻量级的线程, go 实现了一套协程的管理机制, 并且能将多个协程对应到不同的内核线程. Java 线程 goroutine 默认 stack 大小 JDK5 后默认 1M 初始化为 2k KSE (Kernel Space Entity) 的对应关系 1:1 M:N 如果 Thread 和 Kernel Space Entity 保持在 1:1, 由于 Kernel Entity 由 CPU 直接进行调度, 效率非常高. 但如果线程间发生切换, 会牵扯到内核线程的切换, 因此这种场景下的切换是一个比较重的操作. 因此如果一个内核线程能够对应多个协程, 那么这些协程间的切换相对就会比较简单. go 的携程调度系统采用 MPG 的模式: M: System Thread, 也就是 Kernel Entity P: Processor, go 语言实现的协程处理器 G: Goroutine, 协程 Processor 在不同的系统线程中, 并且每个 Processor 都持有一个准备运行的协程队列, Processor 会依次运行这些协程.此外, 在 go 程序运行过程中, 会有一个守护线程用于统计每个 Processor 执行完成的协程数量, 如果发现一段时间内某个 Processor 的完成数量没有变化, 说明该 Processor 当前执行的 goroutine 比较耗时, 就会向该 goroutine 的任务栈中插入一个特别的标记, 当 goroutine 执行非内联函数的时候就会读到这个标记, 并将自己插入到等候协程队列的队尾.另一个提高并发能力的机制是, 当某个协程被系统中断了(如 IO), 为了提高系统的并发能力, Processor 会把自己移动到另一个可以使用的系统线程中, 继续执行其他协程, 当中断的协程被唤醒并完成后, 它会加入到某个 Processor 的等待队列中. 1234567891011func TestGoroutine(t *testing.T) &#123; for i := 1; i &lt; 10; i++ &#123; // 此处我们使用一个匿名函数来完成输出循环变量的功能 // 只需要在调用点前加上关键字 go. 即可通过协程来执行 go func (i int) &#123; fmt.Println(i) &#125;(i) &#125; // 为保证所有协程都执行完毕, main 协程睡眠 1 秒 time.Sleep(time.Second)&#125; 然后我们就能看到如下输出 1 5 2 8 3 6 4 7 9 由于协程的调用顺序并不是严格依赖与代码逻辑的调用顺序, 因此输出的结果并不总是一致的. 1.2 共享内存并发控制共享内存是一种常见的控制并发方式 假设我们需要统计一个方法被调用的次数, 有如下错误代码: 12345678910func TestShareMem(t *testing.T) &#123; counter := 0 for i := 0; i &lt; 5000; i ++ &#123; go func() &#123; counter++ &#125;() &#125; time.Sleep(time.Second) t.Logf("counter=[%d]", counter)&#125; 我的执行结果是 4494, 相信大部分人都知道原因, 自增并不是一个原子性的操作, 因此自增操作需要通过锁来控制, go 语言提供了 sync.Mutex 用于加锁 123456789101112131415func TestShareMemThreadSafe(t *testing.T) &#123; var mut sync.Mutex counter := 0 for i := 0; i &lt; 5000; i ++ &#123; go func() &#123; // 在函数结束时释放锁 defer mut.Unlock() // 加锁 mut.Lock() counter++ &#125;() &#125; time.Sleep(time.Second) t.Logf("counter=[%d]", counter)&#125; 这样就可以得到正确的结果 此外, 除了 mutex 用于加锁, sync 包还提供了 WaitGroup 用于等待其他协程, 类似于 Java 中的 CountDownLatch, 只有当前协程等待的所有协程都表示完成, 才会继续执行下去 12345678910111213141516171819func TestWaitGroup(t *testing.T) &#123; var mut sync.Mutex var wg sync.WaitGroup counter := 0 for i := 0; i &lt; 5000; i ++ &#123; // 每执行一次调用, 都增加一个等待 wg.Add(1) go func() &#123; defer mut.Unlock() mut.Lock() counter++ // 每执行完一次调用, 调用 Done 表示完成 wg.Done() &#125;() &#125; // 会阻塞到所有协程都执行完 Done 之后 wg.Wait() t.Logf("counter=[%d]", counter)&#125; 1.3 CSP 并发机制CSP(Communicating Sequential Processes) 并发机制是 go 语言的特色之一, 其主旨是依赖于通道去完成两个通讯实体之间的协调. go 中担任通道角色的实体就是 channel, go 中的 channel 分为两种: 常规 channel, 通信的双方必须同时在 channel 上才能完成一次交互, 如果任意一方不在的时候另一方都会被阻塞直到对方完成. 带 buffer 的 channel, 内置一个缓冲队列使得通信的双方耦合度更低, 在缓冲队列未满的前提下, 消息发送方和消费方不再相互依赖, 机制类似于阻塞队列. 下面是 Java 中 FutureTask 的代码 1234567891011private static FutureTask&lt;String&gt; service() &#123; FutureTask&lt;String&gt; task = new FutureTask&lt;String&gt;(() -&gt; "Do something"); new Thread(task).start(); return task;&#125;public static void main(String[] args) &#123; FutureTask&lt;String&gt; ret = service(); System.out.println("Do something else") System.out.println(ret.get())&#125; Java 中的 FutureTask 适用于当我们执行一个 Task 的时候, 并不需要立即获得结果, 而是通知异步线程开始准备数据, 等真正需要使用的时候, 如果异步线程已经准备好就可以直接使用, 如果异步线程仍未准备好, 才会阻塞等待. 下面我们通过 channel 用 go 来实现这样的功能: 12345678910111213141516171819202122232425262728293031func service() string &#123; time.Sleep(time.Millisecond * 50) return "Done"&#125;func otherTask() &#123; fmt.Println("working on something else") time.Sleep(time.Millisecond * 100) fmt.Println("task is done")&#125;// 返回一个 channel 调用方真正需要数据了再去通道中获取// 返回 channel 的时候可能准备数据的协程还没有执行完毕func asyncService() chan string &#123; retCh := make(chan string) // 新启动一个协程去完成数据的准备工作 go func() &#123; ret := service() fmt.Println("return result") retCh &lt;- ret fmt.Println("service exited") &#125;() return retCh&#125;func TestService(t *testing.T) &#123; retCh := asyncService() otherTask() fmt.Println(&lt;- retCh) time.Sleep(time.Second)&#125; 可以看到如下结果, 此时运行时间只有 10ms, 说明在执行 otherTask() 函数的同时, asyncService() 方法已经准备好了数据 === RUN TestService working on something else return result task is done Done service exited --- PASS: TestService (1.10s) 可以看到, service exited 在最后被打印出来, 说明 asyncService 函数中新启动的协程将数据放入 channel 之后, 由于没有协程来消费, 会被一直阻塞住. channel 的声明可以通过 make 函数, 在声明时需要确定类型; 向 channel 发送数据使用 chan &lt;- 从 channel 获取数据使用 &lt;- chan 此外, 如果我们做一点小小的修改, 将 asyncService 方法中的 channel 声明修改为 buffered channel: 1retCh := make(chan string, 1) 此时的输出结果为: === RUN TestService working on something else return result service exited task is done Done --- PASS: TestService (1.10s) 此时可以看到 service exited 立即被执行了, 说明 buffered channel 此时不会被阻塞. 1.4 多路选择和超时控制多路选择是一种常见的场景, 通过 select 关键字, 每次从多个 case 中找到最先返回的 channel 并执行预设的逻辑, 只要任何一个 channel 处于非阻塞状态, 并且挑选的 case 顺序与代码顺序无关, 这种方案也常被用来完成超时的控制. 我们对上一节的测试代码做如下修改 123456789101112func TestService(t *testing.T) &#123; retCh := asyncService() otherTask() select &#123; case ret := &lt;-retCh: t.Logf("result=[%s]", ret) case &lt;-time.After(time.Second): // 如果等待时间超过 1s t.Error("time out") &#125; time.Sleep(time.Second)&#125; 1.5 channel 的关闭和广播 向关闭的 channel 发送数据, 会导致 panic; v, ok &lt;- ch; ok 为 bool 值, true 表示正常接收数据, false接收到通道关闭的信号, 此时 v 的值为 channel 类型的 零值, 如 chan string 会返回空字符串, chan int 会返回 0; 所有的 channel 接受者都会在 channel 被关闭时, 立即从阻塞等待中返回且 ok 的值均为 false. 这个广播的机制经常被利用, 进行向多个订阅者同时发送信号. 在大部分场景中, 我们并不清楚 channel 中会传递多少个消息, 在没有 close 机制的情况下, 可以约定一个特殊的值, 如-1, 消费方接收到 -1 就认为结束了. 但这样的方式存在一个明显的问题, 那就是如果一个 channel 对应多个消费方, -1 只会被其中一个消费方接收到. 因此 go 提供了 close 方法来专门用于关闭操作, 并且会向所有的消费方广播这一事件. 123456789101112131415161718192021222324252627282930313233343536func dataProducer(ch chan int, wg *sync.WaitGroup) &#123; go func() &#123; for i := 0; i &lt; 10; i ++ &#123; ch &lt;- i &#125; // 发送完毕数据后显式将 channel 关闭 close(ch) wg.Done() &#125;()&#125;func dataReceiver(ch chan int, wg *sync.WaitGroup) &#123; go func() &#123; for i := 0; i &lt; 20; i++ &#123; if data, ok := &lt;- ch; ok &#123; // 如果通道未被关闭并成功取出数据 fmt.Printf("data: [%d]\n", data) &#125; else &#123; // 如果通道已被关闭 fmt.Println("close") break &#125; &#125; &#125;() wg.Done()&#125;func TestCloseChannel(t *testing.T) &#123; var wg sync.WaitGroup ch := make(chan int) wg.Add(1) dataProducer(ch, &amp;wg) wg.Add(1) dataReceiver(ch, &amp;wg) wg.Wait()&#125; 输出结果: data: [0] data: [1] data: [2] data: [3] data: [4] data: [5] data: [6] data: [7] data: [8] data: [9] close 1.6 Context 与任务取消有时候我们在取消某个任务的时候, 还需要取消与其关联的子任务, 这种情况下 go 提供了 Context 包来完成父协程与子协程间的通信. 根 Context: 通过 context.Background() 创建 子 Context: context.WithCancel(parentContext) 创建 ctx, cancel := context.WitchCancel(context.Background()) 当前 Context 被取消时, 基于它的子 context 都会被取消 接收取消通知: &lt;- ctx.Done() 1234567891011121314151617181920212223242526func isCancelled(ctx context.Context) bool &#123; select &#123; case &lt;-ctx.Done(): return true default: return false &#125;&#125;func TestCancel(t *testing.T) &#123; ctx, cancel := context.WithCancel(context.Background()) for i := 0; i &lt; 5; i++ &#123; go func(i int, ctx context.Context) &#123; for &#123; if isCancelled(ctx) &#123; break &#125; time.Sleep(5 * time.Millisecond) &#125; fmt.Println(i, "cancelled") &#125;(i, ctx) &#125; // 调用根 context 的取消方法, 会向所有子 context 发送通知 cancel() time.Sleep(1 * time.Second)&#125; 此时 5 个子协程会全部被取消. 2. 并发任务2.1 仅执行一次在多线程环境中保证某段代码只执行一次, 典型场景: 单例模式 123456789101112131415161718192021222324252627type Singleton struct &#123;&#125;var singleInstance *Singletonvar once sync.Oncefunc GetSingletonInst() *Singleton &#123; once.Do(func() &#123; fmt.Println("create singleton") singleInstance = &amp;Singleton&#123;&#125; &#125;) return singleInstance&#125;func TestSingleton(t *testing.T) &#123; var wg sync.WaitGroup for i := 0; i &lt; 10; i++ &#123; wg.Add(1) go func() &#123; s := GetSingletonInst() fmt.Printf("%p\n", s) wg.Done() &#125;() &#125; wg.Wait()&#125; 在测试方法中还打印了地址, 可以看到十个协程返回的地址值都是相同的: create singleton 0x120aac0 0x120aac0 0x120aac0 0x120aac0 0x120aac0 0x120aac0 0x120aac0 0x120aac0 0x120aac0 0x120aac0 2.2 仅需任意任务完成 并行执行多个任务, 当其中任意一个任务返回就可以返回给用户 1234567891011121314151617181920212223242526func runTask(id int) string &#123; time.Sleep(10 * time.Millisecond) return fmt.Sprintf("the result is from %d", id)&#125;func firstResponse() string &#123; numOfRunner := 10 // 声明一个 buffered channel, 此时生产者发送消息不需要阻塞 ch := make(chan string, numOfRunner) for i := 0; i &lt; numOfRunner; i++ &#123; go func(i int) &#123; ret := runTask(i) ch &lt;- ret &#125;(i) &#125; // 尝试从 channel 中获取数据, 一旦有数据函数立刻结束 return &lt;-ch&#125;func TestFirstResp(t *testing.T) &#123; // 同时查看执行前后是否有协程泄漏 t.Log("before", runtime.NumGoroutine()) t.Log(firstResponse()) time.Sleep(time.Second) t.Log("after", runtime.NumGoroutine())&#125; 由于使用了 buffered channel, 生产方可以随时把消息发送进 channel 不会被阻塞, 因此不会出现阻塞导致协程泄漏的场景. 2.3 对象池在使用创建代价比较高的对象(如网络连接等)时, 我们通常会考虑池化, go 语言中我们可以使用 buffered channel 实现一个对象池: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 可复用的对象type ReusableObj struct &#123;&#125;// 对象池type ObjPool struct &#123; bufChan chan *ReusableObj&#125;// 初始化对象池func (objPool *ObjPool) initObjPool(size int) &#123; objPool.bufChan = make(chan *ReusableObj, size) for i := 0; i &lt; size; i++ &#123; objPool.bufChan &lt;- &amp;ReusableObj&#123;&#125; &#125; return&#125;func (objPool *ObjPool) Get(timeout time.Duration) (obj *ReusableObj, err error) &#123; select &#123; case obj = &lt;-objPool.bufChan: return obj, nil case &lt;-time.After(timeout): // 超时控制 err = fmt.Errorf("time out for: [%d] nanoseconds", timeout.Nanoseconds()) return obj, err &#125;&#125;func (objPool *ObjPool) Release(obj *ReusableObj) (err error) &#123; select &#123; case objPool.bufChan &lt;- obj: default: err = fmt.Errorf("overflow: [%t]", obj) &#125; return&#125;func TestObjectPool(t *testing.T) &#123; pool := &amp;ObjPool&#123;&#125; pool.initObjPool(10) for i := 0; i &lt; 11; i++ &#123; if v, err := pool.Get(time.Second); err != nil &#123; t.Error(err) &#125; else &#123; fmt.Printf("%T\n", v) if err := pool.Release(v); err != nil &#123; t.Error(err) &#125; &#125; &#125; fmt.Println("done")&#125; 2.4 Sync.Pool 尝试从私有对象获取 私有对象不存在, 尝试从当前 Processor 的共享池获取 如果当前 Processor 共享池也是空的. 那么就尝试去其他 Processor 的共享池获取 如果所有子池都是空的, 最后就用用户指定的 New 函数产生一个新的对象. 实现方式类似于 Java 中的弱引用一样, 缓存的有效期只能维持到下一次 GC 之前. 总结: 适合于通过复用, 降低复杂对象的创建和 GC 代价 协程安全, 会有锁的开销 生命周期受 GC 影响, 不适合于做连接池等, 需自己管理生命周期的资源池化. 3. 测试相关3.1 Benchmark用于测试代码片段的性能 12 3.2 BDDBDD(Behavior Driven Development) 主要用来解决软件开发中的需求通过问题 安装: 1go get -u github.com/smartystreets/goconvey/convey 启动 WEB UI 1$GOPATH/bin/goconvey 3. 反射3.1 类型判断 reflect.TypeOf 返回类型(reflect.Type) reflect.ValueOf 返回值(reflect.Value) 可以从 reflect.Value 获得类型 通过 kind 来判断类型 1234567891011func CheckType(v interface&#123;&#125;) &#123; t := reflect.TypeOf(v) switch t.Kind() &#123; case reflect.Float32, reflect.Float64: fmt.Println("float") case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: fmt.Println("int") default: fmt.Println("unknown type: ", t) &#125;&#125; 3.2 编写灵活代码按名字访问结构的成员: 1reflect.Value(*e).FieldByName("Name") 按名字访问结构的方法 1reflect.ValueOf(e).MethodByName("UpdateAge")Call([]reflect.Value&#123;reflect.ValueOf(1)&#125;)) 反射获取并操作对象属性方法的简单实例: 12345678910111213141516171819202122232425type Employee struct &#123; EmployeeId string Name string `format:"normal"` Age int&#125;func (e *Employee) UpdateAge(newAge int) &#123; e.Age = newAge&#125;func TestInvokeByName(t *testing.T) &#123; e := &amp;Employee&#123; EmployeeId: "1", Name: "Mike", Age: 30, &#125; t.Logf("name: value(%[1]v), type(%[1]T)", reflect.ValueOf(*e).FieldByName("Age"), reflect.ValueOf(*e).FieldByName("Age")) if nameField, ok := reflect.TypeOf(*e).FieldByName("Name"); !ok &#123; t.Error("failed to get field: Name") &#125; else &#123; t.Log("tag: format", nameField.Tag.Get("format")) &#125; reflect.ValueOf(e).MethodByName("UpdateAge").Call([]reflect.Value&#123;reflect.ValueOf(1)&#125;) t.Logf("updated employee: [%+v]", e)&#125; 4. easyjsongo 内置的 json 解析由于使用反射机制实现, 因此效率并不高, 在对性能要求较高的场景中并不适用, 市面上有多种替代方案, 以 easyjson 来举例 安装: 1go get -u github.com/mailru/easyjson/... 使用: 1easyjson -all &lt;file&gt;.go 首先需要定义 json 实体 12345678910111213type BasicInfo struct &#123; Name string `json:"name"` Age int `json:"age"`&#125;type JobInfo struct &#123; Skills []string `json:"skills"`&#125;type Employee struct &#123; BasicInfo *BasicInfo `json:"basic_info"` JobInfo *JobInfo `json:"job_info"`&#125; 然后在文件路径下执行 easyjson -all &lt;file&gt;.go, 生成一个新的文件, 用于完成对该元素和 json 的相互转换. 然后编写测试 benchmark 测试代码, 我们比较默认序列化方式和 easyjson 的性能差异: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465var jsonStr = `&#123; "basic_info":&#123; "name":"Mike", "age":30 &#125;, "job_info":&#123; "skills":["Java","Go","C"] &#125;&#125;`func TestSerialize(t *testing.T) &#123; e := &amp;Employee&#123; BasicInfo: &amp;BasicInfo&#123; Name: "Mike", Age: 30, &#125;, JobInfo: &amp;JobInfo&#123; Skills: []string&#123;"Java", "Go", "C"&#125;, &#125;, &#125; bytes, err := json.Marshal(e) assert.Nil(t, err) fmt.Println(string(bytes))&#125;func TestEasyJson(t *testing.T) &#123; e := Employee&#123;&#125; err := e.UnmarshalJSON([]byte(jsonStr)) assert.Nil(t, err) fmt.Println(err) fmt.Println(e) if v, err := e.MarshalJSON(); err != nil &#123; t.Error(err) &#125; else &#123; fmt.Println(string(v)) &#125;&#125;func BenchmarkEmbeddedJson(b *testing.B) &#123; b.ResetTimer() e := new(Employee) for i := 0; i &lt; b.N; i ++ &#123; if err := json.Unmarshal([]byte(jsonStr), e); err != nil &#123; b.Error(err) &#125; if _, err := json.Marshal(e); err != nil &#123; b.Error(err) &#125; &#125;&#125;func BenchmarkEasyJson(b *testing.B) &#123; b.ResetTimer() e := Employee&#123;&#125; for i := 0; i &lt; b.N; i ++ &#123; if err := e.UnmarshalJSON([]byte(jsonStr)); err != nil &#123; b.Error(err) &#125; if _, err := json.Marshal(e); err != nil &#123; b.Error(err) &#125; &#125;&#125; 通过 benchmark, 可以从平均执行时间, 占用内存大小, 分配内存次数看到两种方式的差异 5. 性能分析工具准备工作: 安装 graphviz 1brew install graphviz 将 $GOPATH/bin 加入 $PATH 安装 go-torch go get github.com/uber/go-torch 下载并复制flamegraph.pl(https://github.com/brendangregg/FlameGraph) 至 $GOPATH/bin 路径下 将 $GOPATH/bin 加入 $PATH 5.1 通过文件方式输出 Profile 灵活性高, 适用于特定代码片段 通过手动调用 runtime/pprof 的 API go tool pprof [binary] [binary.prof] https://studygoloang.com/static/pkgdoc/pkg/runtime_pprof.htm 假设我们使用 pprof 工具分析如下代码的性能: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465const ( row = 10000 col = 10000)func fillMatrix(arr *[row][col]int) &#123; s := rand.New(rand.NewSource(time.Now().UnixNano())) for i := 0; i &lt; row; i++ &#123; for j := 0; j &lt; col; j++ &#123; arr[i][j] = s.Intn(100000) &#125; &#125;&#125;func calculate(arr *[row][col]int) &#123; for i := 0; i &lt; row; i++ &#123; tmp := 0 for j := 0; j &lt; col; j++ &#123; tmp += arr[i][j] &#125; &#125;&#125;func main() &#123; // 创建输出文件 f, err := os.Create("cpu.prof") if err != nil &#123; log.Fatal("could not create CPU profile: ", err) &#125; // 获取系统信息 if err := pprof.StartCPUProfile(f); err != nil &#123; log.Fatal("could not start cpu profile: ", err) &#125; defer pprof.StopCPUProfile() // 代码逻辑 x := [row][col]int&#123;&#125; fillMatrix(&amp;x) calculate(&amp;x) // f1, err := os.Create("mem.prof") if err != nil &#123; log.Fatal("could not create mem profile: ", err) &#125; runtime.GC() if err := pprof.WriteHeapProfile(f1); err != nil &#123; log.Fatal("could not write mem profile: ", err) &#125; f1.Close() f2, err := os.Create("goroutine.prof") if err != nil &#123; log.Fatal("could not create goroutine profile: ", err) &#125; // https://golang.org/src/runtime/pprof/pprof.go if gProf := pprof.Lookup("goroutine"); gProf == nil &#123; log.Fatal("could not write goroutine profile: ", err) &#125; else &#123; gProf.WriteTo(f2, 0) &#125; f2.Close()&#125; 简单解释一下上图命令行的功能: go build prof.go ./prof 执行测试代码 上述代码执行后在当前路径生成 cpu.porf, mem.prof 和 goroutine.prof 文件 go tool pprof prof cpu.prof 对照二进制文件 prof 打开 cpu.prof 通过 top 查看 CPU 耗时最长的几个方法, flat 列代表实际耗时, flat% 代表实际占比 发现 fillMatrix 耗时较长, 可以通过 list fillMatrix 分析方法中耗时较长的代码 通过 svg 生成图片 此外我们还可以通过 go-torch 来获取火炬图: 火炬图能够比较形象的展示方法调用树的 CPU 耗时关系 5.2 通过 HTTP 方式输出 profile 简单, 适合于持续性运行的应用 在应用程序导入 import _ &quot;net/http/pprof&quot;, 并启动 HTTP server 即可 http://$HOST:$PORT/debug/pprof/ go tool pprof http://$HOST:$PORT/debug/pprof/profile?seconds=10(默认为 30) go-torch -seconds 10 http://$HOST:$PORT/debug/pprof/profile 测试代码: 12345678910111213141516171819202122232425262728293031323334import ( "fmt" "log" "net/http" _ "net/http/pprof")func GetFibonacciSerie(n int) (fb []int) &#123; fb = make([]int, 2, n) fb[0] = 1 fb[1] = 1 for i := 2; i &lt; n; i ++ &#123; fb = append(fb, fb[i-2]+fb[i-1]) &#125; return fb&#125;func index(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte("welcome!"))&#125;func createFBS(w http.ResponseWriter, r *http.Request) &#123; var fbs []int for i := 0; i &lt; 1000000; i++ &#123; fbs = GetFibonacciSerie(50) &#125; w.Write([]byte(fmt.Sprintf("%v", fbs)))&#125;func main() &#123; http.HandleFunc("/", index) http.HandleFunc("/fb", createFBS) log.Fatal(http.ListenAndServe(":8081", nil))&#125; 在上面的终端中我们开启了 HTTP 服务, 在 30 秒的采样期内, 请求生成 fibonacci 接口, 然后通过命令行可以看到采样结果 使用 go-torch 1go-torch http://localhost:8081/debug/pprof/profile 执行命令后, 在 30 秒的采样期发起多次请求, 即可看到生成的火炬图: 通过火炬图可以看到每个方法的执行详情.]]></content>
  </entry>
  <entry>
    <title><![CDATA[深入理解 MySQL 原理]]></title>
    <url>%2Fblog%2F2019%2F08%2F13%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-MySQL-%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. MySQL 体系架构MySQL 的架构整体上可以分为服务层和引擎层: Server 层涵盖了 MySQL 大多数核心服务, 包括请求的接收, 以及绝大多数内置函数(如 DATE()等) Engine 层负责数据的读写 1.1 连接器负责建立与客户端建立连接, 获取权限, 维持和管理连接 通过 TCP 连接, 验证用户身份, 当连接到达时获取用户当前所有权限, 而权限的获取是一次性的, 也就是说即使登录后对该用户的权限做了修改, 也无法立即生效, 需要等到用户下一次登录 MySQL 才能体现. 常用的登录命令: 12~$ mysql -h$IP -P$PORT -u$USER -pEnter password: # 此时再输入密码 然后再输入密码, 虽然 -p 后可以直接跟密码, 但此时界面不会对密码进行隐藏, 为了安全起见还是建议使用前者 在登录之后, 可以通过 show processlist 命令查询当前所有生效的连接, 下图是我通过两个终端分别登录本机的 MySQL, 并使用第二个连接执行该命令的结果 登录成功后, 如果没有后续的操作, 连接会处于 Sleep 状态, 如上图中 Id 为 3 的连接, 表示系统中存在的一个空闲连接. 而 Id 为 4 的连接此时由于正在执行 show processlist 命令, 因此 Command 列值为 Query MySQL 连接默认的超时时间为 8 小时, 意味着该连接如果 8 小时内没有进行任何的操作, 就会被系统逐出. 超时失效后的连接如果试图再执行任何操作, 都会被告知 Lost connection to MySQL server during query 1.2 查询缓存MySQL 所有的查询请求都会先从查询缓存中查找, 其内容可以看做一个一个典型的映射关系 1Map&lt;SQL 语句, 结果集&gt; 如果查询语句命中缓存就不会执行后面的操作 虽然看起来很美好, 但 MySQL 为此做了相对复杂的缓存一致性的维护, 对表的任何写操作都会导致使用该表所对应的缓存全部失效. 为什么需要全部失效呢? 因为 MySQL 对于范围查询的侦测基本上无能为力, 假设我们有如下语句: 1SELECT name, score FROM student WHERE score &gt; 90; 这样一个典型的区间查询, 假设有如下操作: 插入一条 score 为 92 的字段; 假设有一个 name 为 Bob 的记录, score 为 80, 现在将其修改为 91; 执行这样的操作时, MySQL 难以实现也没有必要去完成对缓存细粒度的更新, 因此任何写操作都会导致该表的全部缓存失效. 这样的机制就带来了一个问题: 对于写操作比较频繁的表, 对应缓存失效非常频繁, 导致白白浪费内存和 CPU. 因此可以在配置中禁用缓存模块, 甚至在 MySQL8.0 之后, 官方已经彻底将缓存模块删除. 1.3 分析器分析器是执行 SQL 的第一步 1.3.1 词法分析解析字符串中每个单词的含义, 建立连接后, 客户端都是已一条字符串格式的 SQL 语句与 MySQL 进行交互, 假设客户端传入了如下一条 SQL 语句 1SELECT id, name, gender, score FROM student WHERE grade = 4 ORDER BY score LIMIT 0, 100; 在进行词法分析的时候, 会进行如下操作: 从 SELECT 判断出这是一条查询语句 从 id, name, gender, score 识别为列名 从 student 识别出表名 … 分析的的输出是一棵语法树, 语法树的节点主要分为以下两种类型: 单个元素, 例如关键字, 表名, 运算符等 子语句, 例如子查询, 而每个子语句也有一棵语法树用来表示自身的所有单个元素和子语句 1.3.2 语法分析根据词法分析的结果和语法规则判断输入的 SQL 语句是否满足 MySQL 语法 1.3.3 语义分析1.4 优化器经过分析器, MySQL 已经理解了 SQL 语句要做什么, 现在需要进行优化操作 根据规则(扫描行数/是否排序等)决定使用哪条索引 进行多表关联的时候, 决定表的连接顺序 最终确定执行方案 1.5 执行器先判断用户对表有没有相应的执行权限, 如果有权限, 根据表所属的引擎调用不同接口. 至于为什么在此处才查询是否有权限, 是因为有时候 SQL 语句需要操作的表不只是 SQL 语句中使用的, 例如当有触发器需要执行时, 涉及的表就没有 体现在 SQL 语句中. 查询语句会优先执行 获取满足条件的第一行 接口, 然后再循环调用 查询满足条件的下一行 接口 2. MySQL 日志系统这里主要介绍两种日志, 慢查询日志和二进制日志(BinLog) RedoLog(重做日志) 和 UndoLog(回滚日志)属于 InnoDB 提供的特性, 而非 MySQL 提供, 对二者的介绍会放在事务的实现一章. 2.1 慢查询日志2.2 BinLogBinLog 记录了对 MySQL 数据库执行更改的所有操作, BinLog 功能会将所有事务的操作通过日志的形式追加到磁盘中持久化, 不存在被自动覆盖的情况. BinLog 是 MySQL server 层的概念, 与存储引擎无关, 但大部分支持事务的存储引擎都实现了 BinLog 的整合, 例如 InnoDB 中 BinLog 的持久化是事务中的一个步骤, InnoDB 会等待 MySQL 返回 BinLog 持久化的结果, 再决定自身是提交还是回滚, 因此对 InnoDB 来说, 任何提交的事务必然存在 BinLog. 2.2.1 BinLog 内容BinLog 有两种形式: 形式 描述 STATEMENT BinLog 记录的是执行的 SQL 语句本身, 优点是节省空间, 缺点是有些特定的函数在不同情况下得到的结果不同 ROW BinLog 记录的是记录的修改情况, 假设一条 SQL 语句修改了 100 条语句, 该模式下 BinLog 会记录这 100 条语句的被修改情况, 缺点是浪费空间, 优点是记录的更为准确, 也不会出现 STATEMENT 模式的问题 MIXED 是以上两种模式的混合, 一般的语句修改使用 STATEMENT 保存, 而如果存在某些 STATEMENT 无法完成主从复制的操作, 则采用 ROW 格式保存. 假设有如下表: 12345678CREATE TABLE `t` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`), KEY `idx_a` (`a`), KEY `idx_t_modified`(`t_modified`)) ENGINE=InnoDB; 当我们执行: 1delete from t where a &gt;= 4 and t_modified &lt;= '2019-09-04' limit 1; 如果 BinLog 格式为 statement, BinLog 中记录的就是 SQL 语句的原文, 但这样一条看似没有问题的 BinLog 如果用来复现数据, MySQL 会抛出一条警告, 因为这条 delete 语句带 limit, 贸然执行可能会带来数据不一致的场景: 如果 delete 语句使用的是索引 idx_a, 那么会根据 idx_a 找到第一个满足条件的行 如果 delete 语句使用的索引是 idx_t_midified, 那么会根据 idx_t_midified 删除第一个满足条件的行. 如果 BinLog 格式为 row, 此时的 BinLog 原文中不会存在 SQL 语句原文, 而是替换成了两个 event: Table_map event: 标识后面的操作是基于哪张表; Delete_rows event: 用于定义删除行为. 此时 BinLog 中记录的是真实被删除记录的主键, 当然不会出现主备删除不同行的问题. 此外, statement 模式下对一些函数做了处理, 例如 NOW(), 不会出现在主库从库分别记录当前时间的情况, 原理是在BinLog 生成时, 多记了一条命令: SET TIMESTAMP=1567611268, 通过这条命令, 让 MySQL 显式确保主备数据的一致性. 2.2.2 BinLog 功能总的来说, BinLog 具有以下功能: 恢复数据, 数据库存在误操作的可能, 假设某个时间被删库跑路应该如何防范?比较常见的方式是采用定级备份 + BinLog 恢复. 定时备份可以选择每日或者每周进行一次, BinLog 会一直追加. 假设数据库在 t1 时刻被删库跑路, 而距离 t1 最近的一次全量备份发生在 t0, 那么首先需要将 t0 时刻的副本覆盖, 然后就可以通过全量执行 t0 ~ t1 期间的全量 BinLog 来将数据库恢复到 t1 时刻的状态. 主备复制, 目前数据库集群在主备模式下, 一般都使用 BinLog 来实现主从复制. 每个备库会定时从主库进行 BinLog 的同步去执行. 每个备库都维护了自身的同步进度, 同步时会根据自己当前额进度去获取其后的 BinLog. 业务需求, 业务系统间有时会通过监听 BinLog 的方式去实现通信. 如某个系统本身逻辑比较复杂, 但只需要关心其写入 DB 的数据情况, 此时就可以通过监听该系统所用数据库的 BinLog 即可. 常见的工具有 Cannal, Maxwell 等. BinLog 的日志文件格式为二进制, 其产生的二进制文件不能通过 vim, cat, tail 等命令直接查看, 需要使用 MySQL 提供的专用查看工具 mysqlbinlog 进行查看. BinLog 的写入机制 事务执行过程中, 先把日志写到 BinLog Cache, 事务提交的时候再把 BinLog Cache 写入到 BinLog 文件中. 一个事务的 BinLog 不能被拆开, 再大的事务也要确保一次性写入. MySQL 给每个线程分配了一块 BinLog Cache 的内存, 如果超过了这个大小就需要暂存到磁盘, 事务提交的时候执行器把 BinLog Cache 里完整事务写入到 BinLog 中, 并清空 BinLog Cache. 每个线程都有自己的 BinLog Cache, 但是共用一份 BinLog 文件. write 操作指的是将日志写入文件系统的 Page cache, 并没有落盘, 速度较快; fsync 会落盘 wirte 和 fsync 的时机由 sync_binlog 控制: sync_binlog = 0, 每次提交只 write, 不 fsync sync_binlog = 1, 每次提交既 write, 又 fsync sync_binlog = N(N &gt; 1), 每次提交都 write, 累计 N 个后再 fsync 实际业务场景中, 考虑到丢失日志量的可控性, 通常会设置为 100~1000 之间, 但这样的话如果 MySQL 宕机重启, 会丢失最新一部分事务的 BinLog 日志. 3. MySQL 索引3.1 索引概述常见的索引有如下几种: 哈希表 搜索树 哈希表示一种 以 k-v 形式存储数据的结构, 其典型的实现有 Java 中的 HashMap 等, 只要输入查询的 key, 就可以找到其对应的 value. 哈希表的实现方式比较简单, 根据 key 计算出一个哈希值, 然后放在数组的某个特定位置, 常见的 数组+链表挂链 的形式就是对哈希表的实现. 哈希表的插入和查询性能十分优秀, 通常可以认为其 get/set 方法的时间复杂度是 O(1). 对于等值查询通常是首选, 在 Redis, Memcache 中均有广泛应用. 但由于其 key 的排布无序, 虽然在 put 新元素时由于不需要考虑顺序因此非常快, 但却无法处理区间查询(大于和小于) 最典型的搜索树结构就是二叉查找树, 二叉树的特点是左子树的值小于等于双亲结点, 右子树的值大于双亲结点, 在查询的时候应用二分查找的原理能够做到理想情况下 O(log(N)) 级别的插入和查询, 并且由于其本身就是有序的, 因此天然支持区间查询. 如果能够加上自平衡的功能, 例如红黑树, 确实作为索引的性能已经比较理想, 但是这样的结论仅限于内存中的数据结构. 由于数据库系统的数据和索引需要存储在磁盘上, 而对于正常的机械磁盘来说, 一次随机读平均耗时 10ms, 其实时间主要消耗在寻到和旋转磁头的延迟上了. 而顺序读一条数据的消耗大概不到前者的 1%, 因此如果想作为一个对磁盘友好的索引结构, 不能只考虑内存中的性能, 还需要尽可能的降低随机读的频率. 那么应该如何去降低随机读的频率呢? 以红黑树为例, 假设有一千万条数据, 红黑树最少需要 24 层能够容纳得下, 那就意味着如果想根据磁盘中的红黑树找到磁盘中的数据, 就需要随机读 24 次磁盘, 这显然是不能接受的, 因此想降低随机读的频率, 首先就需要尽可能降低查询次数, 也就是降低树的深度. 在数据总量保持不变的前提下, 如果想降低树的深度, 最可行的办法就是将二叉树变为多叉树. 每个节点变成多叉树之后, 其双亲结点内部相应的需要维护一个小索引(假设是 10 叉树, 则双亲节点内部需要维护其负责的 10 个区间对应的指针), 但其实这个成本是可以忽略不计的, 因为我们一次将其从磁盘中取出, 每个节点内部的索引操作都是在内存中完成. 这样就能避免在一次查询中过多操作磁盘. 因此引出了 InnoDB 索引的实现: B+树, B+树就是为了充分利用磁盘预读功能而设计的一种数据结构: 磁盘预读与局部性原理:由于存储介质的特性, 磁盘的IO 速度远远低于主存, 因此为了提高效率, 要尽量减少磁盘 IO, 因此磁盘往往不是严格按需读取, 而是每次会预读一块数据, 即使只读一个字节, 磁盘也会从这个位置开始, 顺序向后读取一定长度(默认 4k)的数据放入内存, 这样做的理论依据是注明的局部性原理:当一个数据被用到时, 其附近的数据也通常马上会被使用. B+ 数每个节点可以存储多个关键字, 它将节点大小设置为磁盘页的大小, 充分利用了磁盘预读的功能, 每次读取磁盘页的时候就会读取整个节点, 也正因为每个节点存储着非常多的关键字(InnoDB 每个双亲结点大概可以存储 1200 个子节点), 会使得树深度很小, 进而要执行的磁盘读取操作次数就会非常少, 更多的是在内存中对读取的数据进行查询操作, 而这部分操作的消耗往往可以忽略不计. 3.2 InnoDB 索引模型InnoDB 支持以下几种索引: B+ 树索引 全文索引 自适应性哈希索引 B+ 树索引就是传统意义上的索引, 是目前关系型数据系统中查找数据最为常用和有效的索引. 结构类似于一棵多叉树, 根据键快速找到数据. 自适应性哈希索引, 顾名思义是由 InnoDB 根据实时的查询情况自动为表生成的索引, 不能人为干预. B+ 数索引的本质就是 B+ 树在数据库中的实现. 在 InnoDB 中, 每个 B+ 数的双亲节点大致可以保存 1200 个子节点, 可以近似理解为 1200 叉树, 那么即使在面对亿级数据量时, 也能够做到不超过 4 层, 并且 B+ 数的第二层基本会常驻内存, 因此平均场景下, InnoDB 通过索引查询一条记录最多只需要 2~4 次磁盘 IO, 意味着查询时间大致需要 20~40ms. 在 InnoDB 中, 表都是根据主键顺序以索引的形式存放的, 这种存储方式称之为索引组织表. 所有的数据都存储在主键的 B+ 树中. 除了主键以外的其他索引被称为辅助索引, 叶子节点存储着索引字段和主键的映射, 在通过辅助索引查询时, 需要先从辅助索引中找到记录的主键, 再回到主索引查询对应记录. 下面通过一个例子来解释一下 InnoDB 是如何通过索引快速定位数据的. 假设有以下表: 123456789101112CREATE TABLE t ( id INT PRIMARY KEY, k int not null, name varchar(16), index(k)) engine=InnoDBINSERT INTO t VALUES(10, 1, 'Alice');INSERT INTO t VALUES(20, 2, 'Bob');INSERT INTO t VALUES(30, 3, 'Carl');INSERT INTO t VALUES(50, 5, 'David');INSERT INTO t VALUES(60, 6, 'Eartha'); 此时表中记录为 id k name 10 1 Alice 20 2 Bob 30 3 Carl 10 1 David 10 1 Eartha 10 1 Frank 如果查询语句是 SELECT * FROM t WHERE id = 10;, 及主键查询, 则只需所搜主索引; 如果查询语句是 SELECT * FROM t where k = 5;, 即普通索引查询, 则需要先搜索 k 索引树, 得到 id 值为 50, 再去主索引中搜索一次, 这个过程被称为回表. 3.3 索引维护B+ 树是一种相对较为复杂的数据结构, 为了能够最大程度优化磁盘的读写, 引入了很多较为复杂的特性, 这里简单介绍一下 B+ 树节点的分裂与合并 B+ 树在插入和删除元素的时候, 都需要维护其有序性: 以上图为例, 加入插入的新行 id 为 70, 则只需要在 R5 后追加一条记录. 如果插入的 id 值为 40, 就相对麻烦一些, 需要将 R4 后的数据在逻辑上向后挪, 并将 id 为 40 的记录插入到 R3 之后, 更糟的情况是, 如果该叶子节点已满, 就需要申请一个新的数据页, 然后挪动一部分数据过去, 这个过程称为页的分裂, 频繁的分裂会对性能造成影响 叶子节点满 双亲节点满 操作 NO NO 直接将记录插入到叶子节点 YES NO 1. 拆分叶子节点2. 将中间的节点放入双亲结点3. 小于中间节点的记录放左边4. 大于或等于中间节点的记录放右边 YES YES 1. 拆分叶子节点 2. 小于中间节点的记录放在左边 3. 大于中间节点的记录放在右边 4. 拆分双亲结点 5. 小于中间节点的记录放左边 6. 大于中间节点的记录放右边 7. 中间节点放入上一层双亲结点 为什么 InnoDB 的表推荐使用自增主键从上图的插入过程可以发现, 对 B+ 树来说, 效率最高的插入方式就是插入 id 最大的元素(未必需要递增, 只需要保证每次插入最大即可), 这样的插入永远是在最后一个叶子节点中向后最佳元素. 而其他情况下的插入则需考虑节点分裂. 对数据库来说, 实现 永远插入最大值 最简单的方式就是自增 3.4 联合索引联合索引指的是对表上的多个列进行索引, 联合索引的创建方法也和单个索引相同, 唯一的不同之处在于有多个索引列. 底层结构也与普通索引基本相同, 不同之处在于联合索引的叶子节点中, key 是由多个值组成的, 并且 key 之间时按照多个列从左到右的顺序排序 联合索引能够解决相对复杂的查询逻辑, 同时对多个字段进行查询, 但其使用时必须遵循最左匹配原则. 上图是对两个 int 列进行联合索引的示意图, 可以看到, 联合索引中 key 的顺序先按照列 a 排序, 列 a 相同再按照列 b 排序, 这样类似字典序的排序方式. 由于这种特性, 如果想使用某条联合索引, 筛选条件中列的顺序必须严格符合联合索引的最左匹配, 因为如果跳过了某一列, 索引就不再有序, 假设把上图中的列 a 去掉, 列 b 的索引就变成了 [10, 15, 3, 5, 5] 显然无法发挥索引的功能. 假设现在有一条 a, b, c, d 列组成的联合索引, 那么能匹配该索引的查询语句为:a -&gt; b -&gt; c -&gt; da -&gt; b -&gt; ca -&gt; ba 3.5 覆盖索引如果一条查询语句能够从辅助索引中获得全部需要的信息, 那么就不再需要回表, 我们就将这样的索引成为覆盖索引. 对于 InnoDB 的辅助索引而言, 叶子节点的 key 为参与索引的所有字段, value 为主键信息, 假设该索引的字段为k1, k2, 那么如下查询语句都可以使用覆盖所以, 免去回表操作. 12SELECT k1 FROM t WHERE k2 = ?;SELECT id, k1 FROM t WHERE k2 = ?; 3.6 索引的选择由于一张表中可以存在多个索引(建议索引的数量不要超过 16 条), 但目前一条 SQL 语句只会选择一条索引去执行, 当 SQL 语句中没有明确规定走哪一条索引时, 就会由查询优化器来选择一条. 下面我们来聊一聊优化器是如何选择索引的. 查询优化器选择索引的目的, 是为了找到一个最优的方案, 最终以最小的代价去执行语句. 在绝大部分情况下, 查询优化器的行为都是符合预期的, 但既然查询优化器的行为也是由代码逻辑控制, 就可能在特定的情况下与预期不符. 先说说优化器选择的几个主要标准: 扫描行数: 这是最直接的指标, 扫描行数越多就意味着访问磁盘的次数越多, 消耗的 CPU 越多; 是否需要回表 是否使用临时表; 是否排序; 3.6.1 扫描行数首先需要明确一个概念, MySQL 在真正开始执行语句前, 无法准确知道满足条件的记录有多少条, 只能根据 统计信息 来估算记录数. 统计信息就是索引的区分度, 我们在建立索引时普遍会选择区分度更高, 也就是值的离散程度更高的列作为索引. 而一个索引上不同值的个数, 我们称之为 基数, 基数越大, 索引的区分度越高. 在 MySQL 中, 可以使用 show index 方法查看一个索引的基数. 而 MySQL 获取索引基数的方式是通过采样统计, 也就是说这里的 cardinality 列只是一个估算的值. 真正执行一遍 SQL 语句再统计虽然可以得到较为准确的值, 但是一旦表中数据过大, 这项统计工作就会变得异常耗时. 在进行统计工作的时候, MySQL 会默认选择 N 个数据页, 统计这些页上不同的值, 得到这些页上的基数后, 得到一个平均值, 再乘以这个索引的数据页数, 就得到整条索引的基数. 而表的数据是会持续更新的, 因此索引的统计信息也不是一成不变的. 从上一次统计开始, 当整条索引上的数据行变更超过 1/M 的时候, 会自动触发重新进行一次索引统计.MySQL 可以使用 innodb_stats_persistent 参数控制索引统计的行为 当设置为 on 的时候, 表示会将统计信息持久化存储, 此时默认 N 为 20, M 为 10. 当设置为 off 的时候, 表示统计信息只存储在内存中, 此时默认的 N 为 8, M 为 16. 我们可以看到当设置为 off 的时候, 统计采样的页数更少, 并且更新的更不活跃, 一般情况下设置为 on 会获得更好的统计效果. 但不论哪种采样方式, 与实际情况依然会存在一定偏差. 对 MySQL 的查询优化器来说, 大部分查询操作如果能通过主索引完成, 哪怕预计的扫描行数会更多, 也会优先选择主索引, 因为回表也是一种比较耗时的操作, 从辅助索引取出的没一行记录都需要再从主索引中找到整行记录在大部分情况下都会比直接走主索引更加耗时. 这一点, 在统计行数基本无误的情况下, 是没有问题的, 但假如统计行数出现了问题, 就可能会出现通过某一条辅助索引能很快定位, 优化器却选择了另一条扫描行数更多的索引. 而什么情况会导致 MySQL 对索引的采样统计出现偏差呢? 最容易想到的就是索引记录进行了大量的修改, 却没有到达触发下次采样统计的行为时 在数据库短时间进行了大量的删除和插入语句时, 由于 MySQL 是使用标记删除来删除记录的,并不从索引和数据文件中真正的删除, 如果 delete 和 insert 中间的间隔相对较小,purge线程还没有来得及清理该记录. 如果主键相同的情况下, 新插入的insert会沿用之前删除的delete的记录的空间. 由于相同的近似的以及表大小,所以导致了统计信息没有变化 遇到由于索引基数采样统计不准确而导致的索引选择问题, 可以通过重新统计索引信息的命令来处理: 1ANALYZE TABLE t 3.6.2 是否会回表回表也是一个相对耗时的操作, 对于一个满足覆盖索引的查询语句来说, 执行步骤通常是这样的: 从辅助索引中找到第一条符合条件的记录, 并将其需要的字段放入结果集中 从辅助索引中找到下一条符合条件的记录, 并将其需要的字段放入结果集中 重复第 2 步, 直到辅助索引中下一条记录不再符合条件 向客户端返回 而对于需要回表的查询语句, 执行步骤会变成: 从辅助索引中找到第一条符合条件的记录 拿到其主键, 通过主索引找到整行记录, 并将其需要的字段防入结果集中 从辅助索引中找到吓一跳符合条件的记录 拿到其主键, 通过主索引找到整行记录, 并将其需要的字段放入结果集中 重复 3/4 步骤, 直到辅助索引中下一条记录不再符合条件 不难看出, 一旦脱离覆盖索引, 最坏情况下辅助索引筛选出的每条记录都需要进行一次磁盘 IO, 这个代价是比较大的, 因此会出现如果一条查询语句同时通过主键和辅助索引筛选, 即便辅助索引扫描行数小于主键, 优化器也会选择使用主键 3.6.3 是否需要排序排序的情况也和回表类似, 排序也是一个相对耗时的操作, 尤其是大数据量的排序, 如果无法直接在内存中完成, MySQL 会借助临时文件进行基于归并思想的外部排序. 在查询优化器的决策思路中, 也会尽量选择排序使用的索引而非前面筛选使用的索引. 假设我们的表 t 中有 a, b 两个字段, a 是主键, b 使用辅助索引, 我们向该表插入 100000 条记录, a, b 两列均从 1 开始递增, 现在执行查询语句:1SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b limit 1; 正常情况下, 查询优化器会得出索引 a 的扫描行数 ≈ 1000, 索引 b 的扫描行数 ≈ 50000 的结论, 但最终会选择 b 索引, 原因就在于 ORDER BY 语句, 会使得查询优化器更倾向于选择能够直接排序的索引, 选择 b 的好处是从该索引上获取的数据天然有序, 不必再去进行额外的排序操作. 我们来简单解释一下 MySQL 是如何执行 ORDER BY 语句的 当我们对一条 SQL 语句执行 Explain 时, 如果 Extra 字段值为 Using filesort 就表示需要排序, MySQL 会给每个线程分配一块内存(sort_buffer)用于排序.正常的排序语句执行过程: 初始化 sort_buffer, 并确定需要参与的字段(MySQL 的原则是内存足够的情况下尽量将 select 的全部字段放入, 否则排序完还需要回表) 从主索引(可能需要回表)取出整行, 再去 select 的字段存入 sort_buffer 中 从主索引再取一行记录进行相同操作, 直到不满足查询条件为止. 在 sort_buffer 中对 ORDER BY 字段进行快速排序 按照结果返回给客户端 这是一条 ORDER BY 语句最理想的执行情况, sort_buffer 大小大于需要排序的总数据量, 一旦 MySQL 发现内存放不下, 就需要借助磁盘临时文件辅助排序, MySQL 需要将总数据量分为 N 份, 每一份单独排序后存在这些临时文件中, 然后把这 N 有序文件再合并成一个有序的大文件. 这个 N 与排序的总数据量和 sort_buffer 大小有关. 此外, 如果 MySQL 认为单行数据量太大, 超过 max_length_for_sort_data 的值, 就会换成另外一种算法, 只在 sort_buffer 中对 ORDER BY 字段 + id 进行排序, 得到结果后再进行回表. 因此在出现可能的排序场景时, 有如下优化措施: 我们大部分情况下尽量让走排序字段的索引, 这样数据就天然有序, 不需要再额外进行排序操作. 也可以利用覆盖索引的特性, 尽可能不进行额外的回表操作 只 SELECT 必要的字段, 过多的字段可能会触发 MySQL 只对 ORDER BY 字段排序, 再利用 ID 回表. 3.6.4 如何选择正确的索引在前面我们分析了查询优化器选择索引的原理, 也分析了几个查询优化器误选索引的场景, 现在来解决不同情况下误选索引的问题 由于 MySQL 索引基数采样不准确引起的, 这类问题可以通过 SHOW INDEX FROM t 语句确定, 再通过 ANALYZE TABLE t 重新触发采样解决 由于回表/排序问题导致的误选索引, 在确定该语句绝大部分情况下都会误选的前提下(因为范围查询未必总会出现上述情况), 可以通过 FORCE INDEX(idx_name) 来强制使用某条索引. 此外对于排序问题, 还可以将其他的索引字段也加入 ORDER BY 子句中, 通过这样的方式让查询优化器明白, 无论选择哪条索引都无法避免排序, 从而强迫它放弃这一筛选条件, 如上述的 SQL 语句改成 SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b, a limit 1; 后, 查询优化器就会根据索引的扫描行数去决定. 3.7 索引没有生效的场景上一节我们讨论了 MySQL 查询优化器选错索引的原因, 这节继续讨论设置了索引但是却意外的没有生效的场景 3.7.1 条件字段做函数计算假设表 t 中包含一个类型为 datetime 类型的字段 create_time, 并为该字段建立索引 idx_create_time, 如果查询语句为: 1select * from t where create_time = '2019-8-24' 此时可以正常通过 idx_create_time 查询, 但是如果使用如下语句查询 create_time 字段月数为 8 的全部记录: 1select * from t where MONTH(create_time) = 8 此时 MySQL 会直接执行全表扫描. 这样的执行方式并不符合我们的预期结果, 因为月份和日期一样, 都是有序的, 但此时为什么不能通过 idx_create_time 进行快速查找呢, 这需要从 InnoDB 索引查询记录的方式说起: 之前我们提到过, B+ 树的本质是一棵多叉树, 通过在一个节点上尽可能多放节点来降低树的深度, 且 B+树一个节点内的数据是有序的, 查找的方式是从根节点开始, 找到目标记录出现的下层指针, 直到查询到叶子节点, 这样的查询必须依赖与每层跨界点有序, 不然在遍历当前层级的时候, 记录旧可能出现在多个叶子节点, 这样 B+树的查询就会失去意义. 在上图叶子节点的绿色数据中, 我列出了每个 k 的 MONTH() 函数值, 显然并不满足同一层级跨节点有序. 因此 InnoDB 无法通过这样的一条索引去完成 MONTH() 查询. 但是优化器并不是完全放弃使用这个索引, 优化器可以选择遍历主键索引, 也可以选择遍历 idx_create_time, 这需要优化器按照查询计划分别计算出两种方式预计的耗时. 对于会改变有序性的函数, 优化器的决定毋庸置疑, 但对于本身就不会改变有序性的函数来说, 优化器由于场景比较复杂, 依然直接采用放弃索引的方式规避麻烦. 3.7.2 隐式类型转换假设表 t 有字段 uid, 类型为 varchar(64), 当执行如下 SQL 语句时, 会直接走全表扫描: 1select * from t where uid = 1234; 原因是查询语句发生了隐式的类型转换, MySQL 的类型转换规则是如果字符型和数字做比较的话, 会将字符型转换成数字. 因此上面的 SQL 语句实际被优化器转换为: 1select * from t where CAST(uid AS signed int) = 1234; 隐式类型转换的问题本质上还是由于 对索引字段做函数操作, 优化器会放弃走索引树的搜索功能, 触发主索引或辅助索引的全表扫描 4. MySQL 锁锁是一个用于管理对共享资源并发访问的数据结构. 对于写操作, InnoDB 会在行记录上加锁, 使用 lock 功能的对象是事务, 锁定的对象是数据库存储中的对象, 包括表, 页, 行. 并且一般锁会在事务 commit 或 rollback 后释放. InnoDB 实现了两种标准的锁: 共享锁(S 锁), 允许事务读一行数据, 与其他 S 锁兼容, 与 X 锁不兼容 排他锁(X 锁), 允许事务删除或更新一行数据, 与其他 S 锁或 X 锁均不兼容 4.1 锁的分类根据加锁的范围, MySQL 中的锁大致可以分为全局锁, 表级锁和行级锁. 4.1.1 全局锁全局锁会对整个数据库实例加锁. Flush Tables With Read Lock (FTWRL), 可以让整个数据库全局加读锁, 处于只读状态, 所有更新 DDL, DML 和写事务的提交均会被阻塞. 一般用来做全库逻辑备份, 备份过程中整个库处于只读状态. 如果不加锁备份得到的库不是同一个逻辑时间点. MySQL 自带的备份工具 mysqldump, 当使用 -single-transaction 时, 执行 dump 前会启动一个事务来获取一致性视图, MVCC 可以保证其他写操作正常. 4.1.2 表级锁 表锁 lock tables t read/write, 限制接下来所有线程的读/写 元数据锁(metadata lock), 访问时会被自动加上, 保证读写操作的正确性. 防止事务 A 读期间事务 B 对表结构做修改. 普通的增删改查 DML 会对元数据加 S 锁, DDL 操作会对元数据加 X 锁. 如果安全的执行 ALTER TABLE: 解决长事务, 可以通过 information_schema 库的 innodb_trx 表查看执行中的事务. 读写频繁, 由于对元数据的修改会阻塞其后的所有事务, 可以给 ALTER TABLE 设定超时时间, 超时后扔拿不到锁就会直接放弃. 4.1.3 InnoDB 行锁的实现InnoDB 实现了 3 种行锁的算法, 分别是: 记录锁: 单个记录上的锁, 总是会去锁住索引记录. 间隙锁: 锁定一个范围, 但不包含记录本身 临键锁: 实现的方式是记录锁+间隙锁, 锁定一个范围, 并且锁定记录本身. 在 InnoDB 事务中, 行锁是在需要的时候才加上的, 但并不是不需要就立即释放, 需要等事务结束后再统一释放. 行锁在 InnoDB 中是基于索引实现的, 因此一旦某个加锁操作没有使用索引, 那么该锁就会退化为表锁. 4.1.3.1 记录锁(Record Locks)为某行记录加锁, 会封锁该行 的索引记录: 123-- id 列必须为主键或唯一索引SELECT * FROM t WHERE id = 1 FOR UPDATE;UPDATE t SET grade = 100 WHERE id = 1; 在使用 SELECT FOR UPDATE 和 UPDATE 时, id 为 1 的记录行会被锁住, 但锁住的索引必须是主索引或者唯一索引, 否则加的锁就是临键锁, 同时, 查询语句必须为精确匹配, 不能为 &lt;, &gt; 或 LIKE, BETWEEN 等, 否则也只会加临键锁 4.1.3.2 间隙锁(Gap Locks)间隙锁作用域普通索引(非主索引或唯一索引), 间隙锁锁住的是一个区间, 而不仅仅是这个区间中的每一条记录. 1UPDATE t SET grade = grade + 10 WHERE id BETWEEN 10 AND 15; 即所有在(10, 20)区间范围内的行记录都会被锁住, 即 id 为 11, 12, 13, 14 的记录. 但 10 和 15 两条记录不会被锁住. 4.1.3.3 临键锁可以理解为特殊的间隙锁. 每个数据行上的普通索引列都会存在一把临键锁, 当某个事务持有该行的临键锁时, 会锁住一段 左开右闭区间 的数据, InnoDB 中的行锁是基于索引实现, 临键锁只与普通索引有关, 在主索引和唯一键索引上不存在临键锁. 假设有如下数据表: 123456create table t ( id bigint primary key, age int, name varchar(64), index(age),) 内容如下: id age name 1 10 Lee 3 24 soraka 5 32 Zed 7 45 Talon 此时, age 索引上潜在的临键锁有: (-∞, 10] (10, 24] (24, 32] (32, 45] (45, +∞) 此时进行如下操作: 时刻 事务 A 事务 B 情况 t1 SELECT * FROM t WHERE id BETWEEN 10 AND 24 FOR UPDATE 无 获得间隙锁 t2 无 INSERT INTO t(age, name) VALUES(15, &#39;Tom&#39;) 插入操作被阻塞 使用这样的方式保证事务执行期间不会出现幻读. 4.1.4 解决幻读大部分数据库都是通过最高事务隔离级别 SERIALIZABLE 去解决幻读问题, 但 InnoDB 不同, 它是通过 MVCC 和临键锁, 在 REPEATABLE READ 隔离级别下避免幻读. 我们下面就来解释一下原因 幻读: 在同一事务下, 连续执行两次 SQL 语句可能导致不同的结果, 第二次 SQL 语句可能会返回之前不存在的行或者没有返回之前存在的行, 即无法感知当前事务执行期间其他事务的 INSERT 或 DELETE 操作. 假设有如下表记录: 123456789CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5), (10,10,10),(15,15,15),(20,20,20),(25,25,25); 当我们执行如下查询语句时: 123begin;select * from t where d=5 for update;commit; InnoDB 的加锁顺序是这样的: 字段 d 没有索引, 只能通过主索引全表扫描, 将主索引上全部记录加行锁 将主索引上全部 间隙 加锁 时刻 tx-a tx-b tx-c t1 select * from t where d=5 for update; t2 update t set d=5 where id=0; t3 select * from t where d=5 for update t4 update t set d=5 where id=0; t5 select * from t where d=5 for update 如果只对 id=5 这一行加锁, 而其他行不加锁的话, 那么在事务 a 中, 三次 select 语句执行的结果均不相同. 这种情况就被成为幻读, 一个事务在前后两次查询同一个范围时, 第二次查询到了前一次没有看到的行. 幻读带来的问题: 破坏语义: T1 时刻事务 a 想做的事情是 把所有 d=5 的行锁住, 不准别的事务进行读写操作, 但幻读显然破坏了这样的语义 数据一致: 假设在事务 a 执行范围修改后, 提交前其他事务插入了符合 a 修改条件的记录, 并直接提交, 那么事务 a 提交后的 BinLog(STATEMENT 模式) 中涉及的修改就会包含其他事务添加的行. 幻读问题的根源在于即使把所有记录都加锁, 依然无法阻止新纪录的插入, 因此为了解决幻读, InnoDB 引入了间隙锁, 用于锁住两个值之前的空隙. 例如初始化后的表 t 有 6 条记录, 就会产生 7 个间隙: (-∞, 0) (0, 5) (5, 10) (10, 15) (15, 20) (25, +∞) 当执行 SELECT * FROM t WHERE d=5 FOR UPDATE; 时, 由于 d 字段没有索引, 不止会给已有的 6 条记录加上行锁, 还同时给 7 个间隙全部加上间隙锁, 这样就保证无法再插入新的数据. 在 InnoDB 中, 数据行是可以加锁的实体, 数据行之间的间隙也是. 但间隙锁不像行锁会分为读锁和写锁, 与间隙锁存在冲突的是 向这个间隙中插入记录 这个操作, 不同间隙锁之间不存在冲突关系. 5. 事务事务是数据库系统区别于文件系统的重要特性之一, 在文件系统中, 如果在写文件的时候进程退出, 这个文件就很有可能被损坏. 还有在顺序写入多个文件的场景, 如果执行到中间某个状态时进程退出, 就会产生复杂的中间状态. 数据库引入了事务, 就是希望能够安全的将数据库从一种一致状态转换到另一种一致的状态上来, 当数据库提交工作时, 可以确保要么所有的修改都已经成功保存, 要么所有的修改都被废弃. 而保证这些功能的关键就在于满足 ACID 特性. 概念 描述 A(Atomicity) 原子性 原子性需要保证一系列的更新操作要么全部执行成功, 要么全部被废弃 C(Consisteny) 一致性 事务将数据库从一种抑制状态转变为下一种一致的状态, 在事务的开始和结束前后, 数据库的完整性约束没有被破坏 I(Isolation) 隔离性 隔离性保证每个读写事务的对象对其他事务的操作独享能相互分离, 即该事务提交前对其他事务都不可见 D(Durability) 持久性 事务一旦提交, 其结果就是持久性的, 即使发生宕机等事故, 数据库也能将数据恢复. 5.1 隔离级别当数据库上有多个事务同时执行的时候, 可能出现脏读, 不可重复读, 幻读等问题, 为了解决这些问题, 就有了隔离级别的概念. 在理解隔离级别的时候, 我们可以先想象机场的安检级别, 在机场中, 由于客流量较大, 并且安全问题非常重要, 因此通常会使用不同安检预案来应对不同的情况. 在常规情况下, 安检级别可能不高, 此时安检项目不多, 吞吐量较高; 但如果有国家政要等情况, 安检级别就会相对升高, 甚至当机场受到了恐怖威胁可能安检级别会更高.总之安检级别越高, 相对吞吐量就会降低, 但可以保证更高的安全性. 隔离级别也是同理, 是由 SQL92 标准定义的一套预案, 各个数据库自己来实现, 实际使用场景中, 需要由开发人员根据实际业务特点来灵活选择. 目前提供的标准事务隔离级别主要包括: 隔离级别 描述 读未提交 一个事务还没有提交时, 它做的变更就能被别的事务看到 读已提交 一个事务提交后, 它的变更才能被其他事物看到 可重复读 一个事务执行过程中看到的数据, 总是跟这个事务在启动过程中看到的数据是一致的. 可串行化 对于同一行记录, 写加 X 锁, 读加 S 锁, 当读写冲突的时候, 后访问的事务必须等前一个事务执行完成才能继续执行. 读未提交的实现方式比较简单, 写操作在完成之前就能被看到说明读写可以同时对一个事务加锁, 目前绝大部分数据库的默认隔离级别都不会是读未提交, 并且在绝大多数场景中都不能使用读未提交. 目前 InnoDB 的默认隔离级别是可重复读, Oracle 的默认隔离级别是读已提交. 5.1.2 事务隔离级别的实现在 InnoDB 中, 每条记录在更新的时候都会同时记录一条回滚操作. 记录上的最新值通过回滚操作介意得到前一个状态的值. 假设一个值从 1 被依次改为 2, 3, 4, 在回滚段中会有类似记录: 当前的值为 4, 但是在查询这条记录时, 不同时刻启动的事务会有不同的 ReadView(视图), 同一条记录可以存在多个版本, 这就是数据库的多版本并发控制(Multi-Version-Concurrency-Control, MVCC), 对于在该条记录为值为 1 时启动的事务, 会使用 ReadView-A 去查询该记录, 查询的原理是通过从最新值开始, 依次向前比较直到找到提交时间早于该事物启动时间的第一条记录, 然后返回. 回滚段的删除比较特殊, 需要等到整个系统中没有比这个回滚段更早的 ReadView 时, 才可以删除, 因为 InnoDB 不能确定哪些 ReadView 会访问这条数据, 只有等真正执行的时候才知道. 在可重复读隔离级别下, 事务启动时会同时启动一份快照, 这个快照是基于整个数据库的. 但它不是真的对整个数据库做一次备份. InnoDB 中每个事务都有一个唯一的事务 ID, 叫做 txId, 当事务启动时统一分配并且严格递增. 每条记录也有多个版本, 每次更新都会创建一个新的版本, 并且记录修改的 txId 作为 row rx-id. 同时旧的数据版本就放在回滚段中.但是记录的多个版本只是逻辑上的概念, InnoDB 并不是真的存储数据, 存储的是能够将数据恢复到上一个版本的 undo log.对于可重复读, 一个事务启动的时候, 能够看到所以已经提交的事务结果, 也就是该事物只能看到每条记录所有已提交的 row tx_id 小于自己 tx_id 的版本. InnoDB 为每个事务构造了一个数组, 用来保存这个事务启动时未提交的事务 id. 对于该事物, 通过 未提交事务列表中最小值 和 当前数据库最大事务 id + 1 两个值将当前时刻的全部事务分为三部分: 已创建, 并且确定提交的事务 已创建, 但需要进一步确认是否提交的事务 还未创建的事务 此时, 对数据库中全部记录的 row tx_id 来说, 分为四种类型: 蓝色部分: 由已创建且已提交的事务生成, 可见 绿色部分: 在当前事务 未提交事务列表 中, 代表由已创建但未提交的事务生成, 不可见 不在当前事务 未提交事务列表 中, 代表由已创建且已提交的事务生成, 可见 黄色部分: 由未来启动的事务生成的, 不可见 InnoDB 利用 redo log 实现了 MVCC, 再利用 MVCC 实现秒级创建快照的能力. 而读已提交和可重复读的实现都利用了快照, 不同之处在于: 读已提交级别下, 每一条语句执行前都会重新计算出一个快照 可重复读级别下, 只在事务创建时计算一次快照, 之后事务里的其他查询都共用这一个视图. 可序列化隔离级别, 不需要视图以及其他额外的特性, 每条记录都按照 S 锁和 X 锁的定义依次执行即可. 5.2 事务的实现事务的隔离性由锁来实现, 原子性和持久性由 redo log 实现, 一致性由 undo log 实现. redo log 用来恢复提交事务修改的页操作, undo log 用来将行记录回滚到某个特定版本. 5.2.1 Redo log我们先想象一个最直接的 UPDATE 语句执行方式: 根据索引从磁盘中读出记录所在的数据页 在内存中修改数据页对应的值 将数据页刷新回磁盘 在不考虑性能的前提下, 这是完成一条更新操作最直观的方式. 但往往越直观的方式, 性能越差. UPDATE 操作是一个典型的随机写, 对于机械硬盘来说, 一次随机写平均花费 10ms, 并且一个事务中可能存在多条写操作, 在保证其能执行成功的同时还要保证原子性, 由此可见这并不是一个理想的方案. InnoDB 引入了 WAL 思想, 其关键在于先写日志, 再写磁盘, 当有一条记录需要更新的时候, InnoDB 就会先把记录写到 RedoLog 中, 并更新内存, 此时更新操作就完成了. InnoDB 会在 适当 的时候, 将这个操作记录更新到磁盘中, 这样的更新都是在系统相对比较空闲的时候. 这里借用极客时间的图来说明 RedoLog 的实现方式, 磁盘中的 RedoLog 是固定大小的(并不像 BinLog 可以在磁盘空间未满的情况下无限追加), 写入的方式类似环形队列, write pos 是当前记录的位置, 一边写一边后移, checkpoint 是当前需要擦除的位置, 也是往后推移并且循环, 擦除记录前要把记录更新到数据文件. 假设我们为 RedoLog 文件定义两个操作: push: 向 RedoLog 文件写入数据, 并增加 write pos, 当事务执行写操作触发 pop: 从 RedoLog 中删除数据, 并增加 check point, 当该事务的更新操作落盘时触发, 代表该条 RedoLog 不再需要. RedoLog 的写入机制: 事务在执行的时候, 生成的 RedoLog 会先写入 RedoLog Buffer, 当事务提交时再统一持久化到磁盘. 我们先从一条更新 SQL 语句的执行过程来体会 RedoLog 的功能. 1UPDATE t SET grade = grade + 1 WHERE id = 2; 执行过程如下: 需要着重解释的几个点: 5.2.1.1 BinLog 和 RedoLog 能否相互替代答案是不能, 首先 BinLog 是 MySQL Server 层提供的功能, 旨在提供数据恢复, 集群同步等功能; RedoLog 是 InnoDB 独有的概念, 用来实现事务的原子性和持久性. 简单来说二者的设计方向不同, BinLog 在磁盘空间足够的前提下可以无限增加, 用来复现某个时间点之后的全部写操作. RedoLog 文件在磁盘中大小固定, 循环队列的结构会使得较早的日志被清理掉. BinLog 功能: 保证数据库能够从某个时间点正确恢复以及主从一直. RedoLog 功能: 保证事务原子性和持久性, RedoLog 落盘后数据库即使宕机重启更新依然不丢. 5.2.1.2 为什么 RedoLog 需要先 Prepare答案是为了保证 RedoLog 和 BinLog 的一致性. 我们可以做一个假设, 如果不使用两阶段提交, 分别提交 BinLog 和 RedoLog 看看会出现什么情况. 场景 问题 先提交 BinLog, 提交 RedoLog 前数据库宕机 此时 BinLog 落盘成功, 从库可以拉取到该 BinLog, 会将该更新在自己身上提交, 主库恢复后无法复现该事务, 此时主从不一致. 此外, 主库如果从某个时刻想通过 BinLog 恢复到当前状态, 恢复出来的时候就会多出一个事务, 该记录的值与原库值不同. 先提交 RedoLog, 提交 BinLog 时数据库宕机 此时 RedoLog 落盘成功, 即使数据库宕机, 主库恢复后依然可以复现. 但由于 BinLog 没有写入成功, 此时如果用这个 BinLog 来恢复临时库或者主从同步, 恢复出来的行记录就会少一条事务, 依然与原库值不同 因此我们可以看到, RedoLog 影响宕机重启后的事务重新执行, BinLog 影响可能需要的恢复和主从同步, 要想一致就必须使用两阶段提交. 5.2.1.3 两阶段提交如何保证 RedoLog 与 BinLog 一致RedoLog 的两阶段提交一共分为三步: 写入 RedoLog, 处于 Prepare 状态 写入 BinLog 提交事务, 处于 commit 状态 问题可能出现在步骤 1 后和步骤 2 后, 我们分情况来讨论下: 写入 Prepare 状态的 RedoLog 后 MySQL 宕机: 此时 BinLog 没有写入, RedoLog 也没有提交, 此时可以当做事务提交失败. 写入 BinLog 后 MySQL 宕机: 崩溃恢复的规则如下: 如果 RedoLog 中事务是完整的, 也就是有了 commit 标识, 则可以直接提交; 如果 RedoLog 中事务只有完整的 Prepare, 则判断对应事务的 BinLog 是否完整, BinLog 如果完整就可以提交事务, 否则回滚. 对于 MySQL 来说, 每个事务的 BinLog 都有完整的格式, 通过识别该格式就可以判断事务额 BinLog 是否完整. 此外, BinLog 和 RedoLog 都有一个共同的字段 XID, 在崩溃恢复的时候会按顺序扫描 RedoLog: 如果碰到既有 Prepare 又有 commit 的 RedoLog, 就直接提交; 如果碰到只有 Prepare 但没有 commit 的 RedoLog, 就需要通过 TXID 去 BinLog 中查询, 再通过 BinLog 是否完整决定提交或回滚. 5.2.2 回滚日志 UndoLogRedoLog 记录了事务的行为, 可以通过其对数据页进行重做. 但事务如果需要进行回滚, 就需要 UndoLog. 当事务执行失败或者显式执行 ROLLBACK 的时候, 就可以利用 UndoLog 将数据回滚到某个特定的版本. UndoLog 存放在数据库内部的回滚段中, UndoLog 本身不是快照, 只是逻辑地将数据库恢复到原来的样子, 比如某个字段自增, UndoLog 中就会记录将该字段 -1 可以得到上一个版本 5.2.3 组提交我们通常给 sync_binlog 和 innodb_flush_log_at_trx_commit 都会设置为 1, 也就是说一个完整的事务提交前, 需要进行两次 fsync 操作, 依次是 RedoLog(prepare), 另一次是 BinLog. 然而磁盘的 fsync 性能是有限的, 甚至磁盘 fsync 的速度很大程度上限制了数据库的 TPS 上限, 为了提高磁盘 fsync 的效率, MySQL 提供了 group commit 的功能, 即一次 fsync 可以刷新确保多个事务日志被写入文件. 事务提交时, 会进行两个阶段的操作: 修改内存中事务对应的信息, 并且将日志写入 RedoLog Buffer 调用 fsync 将确保日志都从 RedoLog Buffer 写入磁盘 步骤 2 的耗时远大于步骤 1, 此时我们就可以当某个事务进行步骤 2 的时候, 让其他事务先执行步骤 1, 这样就可以将多个事务的重做日志通过一次 fsync 刷新到磁盘, 这样可以减轻磁盘的压力. MySQL 甚至提供了把 RedoLog 做 fsync 时间拖到步骤 1 之后的功能: binlog_group_commit_sync_delay 参数, 表示延迟多少微秒后才调用 fsync; binlog_group_commit_sync_no_delay_count 参数, 表示累计多少次以后才调用 fsync 因此 WAL 机制主要能带来两方面提升: RedoLog 和 BinLog 都是顺序写, 速率远大于随机写. 组提交机制, 大幅降低磁盘的 IOPS 消耗. 6. 集群与高可用6.1 通过 BinLog 保证主备一致在 MySQL 的高可用场景中, 最简单和常用的就是主备复制, 客户端的读写都直接访问主库, 而备库只负责将主库的更新同步到本地执行, 当主库出现问题的时候, 可以将主库下线, 并将备库立即提升为主库. MySQL 是通过 BinLog 的同步完成主备的数据同步功能的. 在主备同步时, 备库与主库维持了一个长连接, 主库有一个单独的线程用于处理备库的长连接, 日志的同步过程如下: 备库通过 change master 命令指定主库的 ip, 端口, 用户名, 密码以及请求 BinLog 的文件名和日志偏移量; 备库通过 start slave 命令启动两个线程: 负责与主库建立连接的 io_thread 和 负责复现数据的 sql_thread; 主库建立连接后, 会按照备库传来的位置从本地读取 BinLog 发给备库; 备库拿到 BinLog 后, 写入到本地文件, 成为中转日志(relay log); sql_thread 读取中转日志, 解析出日志中的命令并执行.]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka简介]]></title>
    <url>%2Fblog%2F2019%2F07%2F27%2FKafka%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1. 概述Kafka 是一种分布式, 基于发布/订阅的消息系统, 具备高性能, 高可用, 可扩展, 可持久化的特点. 在设计上具有以下特点 面对海量消息时也能高效读写, 以顺序的方式读写磁盘, 从而避免随机读写的性能瓶颈, 与此同时还支持批量读写和批量压缩 支持消息分区, 在每个分区内保证顺序, 不同分区间可以并发操作 每个分区可以创建多个副本, 只有 Leader 副本负责读写, 其他副本只负责同步 Kafka 典型应用场景: 传统消息中间件 系统数据总线 日志收集中心 接入 Kafka 能够带来的优势: 解耦, 以前彼此依赖的系统只需要和 Kafka 通信 数据持久化, Kafka 把数据以消息的形式持久化到磁盘, 并能按照一定的机制清理和压缩. 扩展, Kafka 的每个 Topic 多可以分为多个 Partition, 每个 Partition 都存在多个副本以实现冗余备份. 每个 Partition 中的消息不同, 类似 DB 的水平切分 容灾, 每个 Partition 中的不同 Replica 保存的是相同的副本, 一主多从, 从副本正常情况下只与主副本同步消息, 当主副本出现故障, 则在从副本中重新选举一个主副本对外提供服务. 灵活的 Consumer, Consumer 使用从服务端 Pull 的方式拉取消息, 并且保存消费的具体位置, 当消费者宕机恢复后, 根据 Consumer 的状态重新获取需要的消息. 顺序保证, Kafka 保证一个 Partition 内消息的有序性, 但是并不保证多个 Partition 之间数据有顺序. 1.2 Kafka 核心概念1.2.1 Topic &amp; Partition &amp; LogTopic 是用于存储消息的逻辑概念, 可以看做消息的集合 每个 Topic 可以划分成一个或多个 Partition, 同一 Topic 下的不同 Partition 包含的信息是不同的, 每个消息在被添加到 Partition 时都会被分配一个 offset, 这是在此 Partition 中的唯一编号, Kafka 通过 offset 保证消息在 Partition 内的顺序 Partition 在逻辑上对应着一个 Log, 当 Producer 将消息写入 Partition 时, 实际上写入到了 Partition 对应的 Log 中. Log 是一个逻辑概念, 可以对应到磁盘的文件夹, Log 由多个 Segment 组成, 每个 Segment 对应一个日志文件和索引. 在面对海量数据时, 为避免出现超大文件, 每个日志文件的大小是由限制的, 当超出是会创建新的 Segment 继续对外服务. Kafka 采用顺序 I/O, 因此只会向最新的 Segment 追加数据. 索引采用稀疏索引的方式, 在运行时会映射到内存以提高速度. 1.2.2 保留策略 &amp; 日志压缩不论消息是否已被消费, Kafka 都会将其保存, 与此同时提供了保留策略以进行周期性的清理. 根据消息保留时间, 超过 TTL 的消息就可以被删除 根据 Topic 存储数据的大小, 当 Topic 所占的日志文件大于某个阈值, 就从最旧的消息开始删除. Kafka 还提供了日志压缩的功能, 原理上和 Redis 的 AOF 日志压缩相同, Kafka 会通过后台线程定期将相同 key 的消息进行合并, 只保留最新的值 1.2.3 Broker一个单独的 Kafka server 就是一个 Broker. Broker 的主要工作就是接收生产者发送的消息, 分配 offset, 保存在日志中. 同时接收消费者, 其他 Broker 的请求, 根据请求类型就行不同的处理和响应, 一般一个 Broker 独占一个节点. 1.2.4 副本Kafka 对消息进行冗余备份, 每个 Partition 可以有多个副本, 每个副本中包含的消息是一样的. 每个 Partition 至少有一个副本(Leader), 多的副本为 Follower. Leader: 提供读写服务 Follower: 只从 Leader 副本处把数据同步到本地并更新自己的 Log 一般情况下, 每个 Partition 的多个副本会被分配到不同的 Broker 上. 1.2.5 ISR 集合ISR(In-Sync Replica) 表示目前可用, 并且消息量与 Leader 相差不多的副本集合, 是整个副本集合的一个子集, 条件: 副本所在节点必须维持与 zk 的连接 副本最后一条消息的 offset 与 leader 副本的最后一条消息的 offset 之间差值不能超过指定阈值 每个 Partition 的 leader 副本都会维护当前 Partition 的 ISR 集合, 并且在不断处理请求的过程中, 这个集合是在不断变化的, 有的 Follower 会因为跟不上掉队, 有的 Follower 会重新回到 ISR 集合中. 1.2.6 HW &amp; LEOHW(HighWatermark) 和 LEO 与上面的 ISR 集合紧密相关, HW 标记了一个特殊的 offset, 当消费者处理消息的时候, 只能拉取到 HW 之前的消息, HW 之后消息对 Consumer 来说是不可见的. HW 由 Leader 维护, 当 ISR 集合中全部的 Follower 都拉取 HW 指定消息进行同步后, Leader 会递增 HW 的值, Kafka 将 HW 之前消息的状态定义为 commit, 代表已 commit 的消息即使 leader 宕机也不会丢失 LEO(Log End Offset) 是所有副本都会维护的 offset 标记, 它指向追加到当前副本的最后一个消息的 offset. 当 Producer 向 Leader 副本追加消息的时候 Leader 副本的 LEO 会递增 当 Follower 从 Leader 副本拉取消息成功时, Follower 副本的 LEO 就递增 以一个例子总结下 HW 和 LEO 的关系 Producer 向 Partition 推送消息 Leader 将消息成功追加到 Log 中, 并递增其 LEO Follower 成功从 Leader 同步该消息 Follower 将该消息追加到本地 Log 中, 并递增其 LEO 当 ISR 集合中所有的副本都完成了对该消息的同步, Leader 会递增 HW, 此时该消息对消费者可见 Kafka 这样设计的目的是为了权衡同步和异步复制, 如果 Follower 延迟过高, 会被踢出 ISR 集合以保证性能; 当 Leader 宕机, 会优先将 ISR 中的 Follower 副本选举为新 Leader, 新 Leader 同样包含了 HW 之前的全部消息 1.2.7 Cluster &amp; Controller多个 Broker 可以组成一个 Cluster 对外提供服务, 每个 Cluster 会选举出一个 Broker 来担任 Controller 作为集群的指挥中心, 而其他的 Broker 则听从 Controller 指挥实现相应功能. Controller 负责管理分区的状态, 管理每个分区的副本状态, 监听 zk 中数据变化等. Controller 宕机会从剩下的 Broker 中进行重新选举. 1.2.8 Produce &amp; Consumer 生产者主要负责生产消息, 并将消息按照一定的规则推送到 Topic 的分区中, 其中规则可以是根据消息 key 的 hash 值选择, 或者轮询 消费者主要负责拉取消息, 并对消息进行消费, 每个消费者消费到 Partition 哪个 offset 的相关信息是由自己来维护的, 不同消费者管理各自的消费位置. 1.2.9 Consumer Group在 Kafka 中, 多个 Consumer 可以组成一个 Group, 一个 Consumer 只能属于一个 Group. Consumer Group 保证其订阅的 Topic 的每个 Partition 只能被分配给一个 Consumer. 一个 Topic 如果同时被多个 Consumer Group 订阅, 不同 Consumer Group 之间不会干扰. 如果想要实现一个消息被多个消费者同时消费的效果, 则每个消费者需要放入单独的 Consumer Group; 如果要实现一个消息只能被一个消费者独占, 则将所有的 Consumer 放入一个 Group 中. 简单来讲, 对于同一个 Consumer Group 中, 尽管有多个消费者, 但每个消息只会被消费一次. 此外, Consumer Group 还具有水平扩展和故障转移的功能. 当我们向一个 Consumer Group 添加新的 Consumer 时, 会触发 Rebalance 重新分配分区与消费者的对应关系. 而如果有 Consumer 故障, 也会触发 Rebalance 进行重新分区. 生产者根据业务逻辑产生消息 生产者根据路由规则将消息发送到指定 Partition 的 Leader 副本所在的 Broker 上 Leader 将日志追加成功后, 递增 LEO Follower 副本从 Leader 同步到消息, 追加成功后, 递增 LEO Leader 递增 HW, 使该消息对消费者可见 消费者加入 Consumer Group 后, 会触发 Rebalance, 将 Partition 分配给不同的消费者消费 消费者恢复其消费位置, 并向 Kafka 服务端发送拉取消息的请求 Leader 副本会验证请求的 offset 以及其他相关的信息, 最后返回消息 1.2 Kafka 配置文件config/server.properties 是 Kafka 的主要配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879############################# Server Basics ############################## 每个 Broker 在集群中的唯一标识, 即使 Broker 的 IP 地址发生了变化, broker.id 只要没变则不会影响 consumers 的消息情况broker.id=0############################# Socket Server Settings ############################## Kafka Server 使用的协议, 主机名及网络端口格式如下:# listeners = security_protocol://host_name:port# 参考实例:# listeners = PLAINTEXT://your.host.name:9092#listeners=PLAINTEXT://:9092 这是默认配置, 使用 PLAINTEXT, 端口是 9092# 接收请求的线程数num.network.threads=3# 执行请求的线程数num.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ############################## 用于存储 log 文件的目录, 可以将多个目录通过逗号分隔, 形成一个目录列表log.dirs=/tmp/kafka-logs# 每个 Topic 默认的 Partition 数num.partitions=1# 用来恢复 log 文件以及关闭是将 log 数刷新到磁盘的线程数量, 每个目录都对应该配置num.recovery.threads.per.data.dir=1############################# Log Flush Policy ############################## 每隔多少个消息触发一次 flush 操作, 将内存中的信息刷新到硬盘上#log.flush.interval.messages=10000# 每隔多少毫秒触发一次 flush 操作, 将内存中的信息刷新到硬盘上#log.flush.interval.ms=1000############################# Log Retention Policy ############################## The following configurations control the disposal of log segments. The policy can# be set to delete segments after a period of time, or after a given size has accumulated.# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens# from the end of the log.# The minimum age of a log file to be eligible for deletionlog.retention.hours=168# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining# segments don&apos;t drop below log.retention.bytes.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=localhost:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何高效使用Vim]]></title>
    <url>%2Fblog%2F2019%2F06%2F19%2F%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8Vim%2F</url>
    <content type="text"><![CDATA[1. 简介2. 基本使用方式2.1 vim 的模式当我们使用 vim, 或在后面加文件名的时候, 就可以进入 vim 的界面 12$ cd ~/Desktop$ vim demo.txt 该命令就会在 ~/Desktop 路径下打开(如果有)或编辑(如果没有) demo.txt 文件 最初进入 vim 时是普通模式, vim 的特点之一就是可以通过不同的操作快速进入多种模式: 普通模式: 进入 vim 默认的模式, 该模式有非常多的快捷键组合, 无法进行输入, 如果想编辑, 需要进入写入模式. 写入模式: 由命令模式进入, 最简单的方式通过在普通模式下输入小写 i 来完成(后面会介绍更多的方式), 进入写入模式后, 终端的左下角会出现 -- INSERT -- 标志, 该模式下字母, 数字, 字符键都可以正常完成输入功能, 写入模式可以通过 esc 退出并回到普通模式. 命令模式: 所有的 vim 指令都需要进入由普通模式输入 : 进入命令模式完成, 常见的指令包括保存(w), 退出(q)等 此外, 普通模式进入写入模式除了 i 之外, 还有其他几种方式, 不同方式之间的区别在于进入插入模式时光标的位置: 输入 全称 光标的位置 i insert 与普通模式相同 I a append 普通模式光标的下一个字符 A 普通模式光标所在行的结尾 o 普通模式光标所在行的下一行开出一个新行, 并把光标移动到新行的行首 O 普通模式光标所在行的上一行开出一个新行, 并把光标移动到新行的行首 2.2 vim 光标移动 按键 操作 h 光标向左 j 光标向下 k 光标向上 l 光标向右 3. vim 配置文件vim 配置文件可以修改 vim 界面的外观, 组合按键等 123456$ cd ~# 新建一个 .vim 文件夹$ mkdir .vim$ cd .vim# 新建一个 vimrc 文件$ vim vimrc 开始进行配置: noremap 是一个更改键位的命令 e.g. noremap a b 当该配置生效后, 如果用户按下 a 键之后, vim 就会认为按的是 b 我们需要替换的键位1234map s &lt;nop&gt; # 禁用 s 键map S :w&lt;CR&gt; # 用 S 替换 vim 中的 `:+w+回车` 的保存功能map Q :q&lt;CR&gt; # 用 Q 替换 vim 中的 `:+q+回车` 的退出功能map R :source $MYVIMRC&lt;CR&gt; # 用 R 键替换 source 当前 vimrc 文件 3.1 配置 vim 的编辑器12syntax on # 开启语法高亮set nu # 开启行号 3.1.1 set relativenumber 开启真实行号该配置生效之后, 行号会分两列展示, 第一列用于展示真正的行号, 第二列用于展示其他行相对当前行的距离 3.1.2 set cursorline 开启当前行高亮线 3.1.3 set wrap 开启自动换行3.1.4 set showcmd 右下角显示执行的命令3.1.5 set wildmenu 命令模式下的提示使用 : 进入命令模式, 输入 so 时, 敲 tab 会给出提示: sort 和 source 3.2 vim 的编辑操作vim 下的编辑操作通常由 操作 和 动作 组成 3.2.1 常见操作3.2.1.1 删除假设有如下内容, 我们需要删除中间的空格, 有如下几种方式 &lt;optration&gt; &lt;motion&gt; 总的来说, 编辑指令的语法类似于动宾短语, 操作一般是动词, 如复制, 删除等, 动作一般为宾语, 代表执行操作的字符. 下面来分别介绍一下常见的操作和动作 在普通模式下将光标移动到空格后的 &lt; 然后输入 x 将光标的前一个字符删除. 在普通模式下输入 d, d 代表 delete, 提供了多种选项: d + ←(方向键左), 代表向左删除一个字符 d + 3 + →(方向键右), 代表向右删除三个字符 d + d, 代表对整行执行删除操作(实际上大多数操作都遵循双击代表针对行的规律) 3.2.1.2 粘贴p, 代表 paste, 可以用来粘贴被复制或剪切的字符 3.2.1.4 复制y, 代表 copy, 可以用来复制选中的字符 y + →, 代表向右复制一个字符 y + 3 + →, 代表向右复制三个字符 3.2.1.5 改变(c)c, 代表 change, 与 d 操作相似, 不同的是完成了删除操作之后, 会自动进入编辑模式 c + → + 6, 代表删除光标右边的 6 个字符, 并进入编辑模式 3.2.2 常见动作最常见的动作就是上下左右, 除此之外还有一些快捷动作. 3.2.2.1 移动到下个单词(w)假设有如下字符 I am Happy Today. ^ 此时光标在 I 上, 如果在普通模式下按 w, 光标会移动到 am 的首字母 a, 以此类推, 每次都会让光标移动到下一个单词的首字母 假设我们想将上例中的 Happy 修改为 excited, 可以进行如下操作: 将光标移动到 Happy 的首字母 h, 然后使用 c + w, 就可以将该词删除, 并且进入编辑模式, 然后输入 excited 即可. 3.2.2.2 移动到当前单词的首字母(b)b, 代表 back, 可以将光标移动到当前单词的首字母位置 同样, 通过该动作就可以在 happy 的任意一个字符快速移动到首字母, 并完成删除操作 3.2.2.3 范围(i)i, 代表 in, 表示选中在某个范围内的全部字符 c + i + w 表示将当前光标所在单词范围内的全部字符替换 y + i + w 表示将当前光标所在单词范围内的全部字符复制 c + i + &quot; 表示将当前光标所在引号范围的全部字符替换 3.2.2.4 查找 (f)f, 代表 find, 会将光标移动到第一个相同的字符 f + v, 代表将光标向后移动到第一个 v 所在的位置s d + f + :, 代表 删除+寻找+: 从光标所在字符开始, 一直删除到其后的第一个 : 4 搜索4.1 搜索方式vim 下的搜索主要分为两种方式: 从上向下搜索(快捷键 /) 从下向上搜索(快捷键 ?) 两种操作的相同之处都是会以光标作为查询的起点, 向上/向下进行搜索 将搜索内容高亮的设置: 123456set hlsearch # 将搜索结果高亮set incsearch # 将搜索内容即时高亮set ignorecase # 忽略大小写set smartcase # 开启智能拼写exec "nohlsearch" # 搜索结果的高亮会在下次进入 vim 是继续保留, 因此可以先执行该命令清除noremap &lt;LEADER&gt;&lt;CR&gt; :nohlsearch&lt;CR&gt; # 执行完搜索之后, 高亮会一直保留, 比较影响视线, 因此使用 `LEADER`(默认为 \ 键) + 回车执行 nohlsearch 命令, 取消高亮 在 vim 的搜索模式下, 模式使用 n 进行下一项的搜索, N 进行上一项的搜索, 可以配合 zz (将光标所在行移动到屏幕中间) 12noremap n nzznoremap N Nzz 5 美化 vim 界面5.1 使用自带美化方案方式是在命令模式下输入 color + 空格 + tab 键, 接下来就会提示可以用的美化方案 5.2 自定义美化方案但如果系统自带的美化方案不能满足需求, 就可以下载其他美化方案 vim 插件管理 5.2.1 下载使用下面的命令进行下载12curl -fLo ~/.vim/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 5.2.2 安装插件在 ~/.vimrc 中, 以下文开头 1call plug#begin('~/.vim/plugged') 然后安装的语法格式为: 1Plug '' # 引号内为想装的插件 最后使用下文结束安装 1call plug#end() 将 ~/.vimrc source 之后, : 进入命令模式, 输入 PlugInstall 命令开始安装指定插件 5.2.3 推荐的插件5.2.3.1 vim-airline会在 vim 底部展示状态栏 包括文件路径, 编码格式以及进度条等. 5.2.3.2 connorholyday/vim-snazzy加入 connorholyday/vim-snazzy 并 PlugInstall 之后, 在配置文件之后再添加如下配置 1colorscheme snazzy 最后 source 即可生效, 效果如图]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hadoop基础]]></title>
    <url>%2Fblog%2F2019%2F04%2F21%2FHadoop%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[1. 简介2. Hadoop 安装2.1 JDK 安装配置可以在 Oracle 官网或者直接使用 wget 命令下载 1wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64.tar.gz 使用 tar -zxvf 完成解压 再将路径 (/usr/soft/jdk1.8.0_65) 配置到 etc/enviroment 路径下 12345# 给 path 新增 JDK 的 bin 路径PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/soft/jdk1.8.0_65/bin&quot;# jdk 路径JAVA_HOME=/usr/soft/jdk1.8.0_65 经此验证, 已经成功安装并配置 JDK 2.2 Hadoop 安装配置在 Apache 官网下载压缩包并解压: 在 /etc/enviroment 文件中配置环境变量 PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/soft/jdk1.8.0_65/bin:/usr/soft/hadoop-2.7.7/bin:/usr/soft/hadoop-2.7.7/sbin&quot; JAVA_HOME=/usr/soft/jdk1.8.0_65 HADOOP_INSTALL=/usr/soft/hadoop-2.7.7 在输入 hadoop version 即可看到输出: destiny@destiny-Parallels-Virtual-Platform:/etc$ hadoop version Hadoop 2.7.7 Subversion Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac Compiled by stevel on 2018-07-18T22:47Z Compiled with protoc 2.5.0 From source with checksum 792e15d20b12c74bd6f19a1fb886490 This command was run using /usr/soft/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar destiny@destiny-Parallels-Virtual-Platform:/etc$ 3. Hadoop 配置Hadoop 的配置都是 XML 文件的方式完成, 通用配置都在 core-site.xml 中, HDFS, MapReduce 和 YARN 都有对应的 hdfs-site.xml, mapred-site.xml 以及 yarn-site.xml. Hadoop 的设计的目的在于处理海量数据, 其主要内容包括数据的存储以及运算, 存储使用 HDFS 实现, 运算使用 MapReduce 编程模型实现. Hadoop 有三种配置方式: 独立模式: 没有守护程序, 所有程序都运行在一个单独的 JVM 之上, 独立模式适合在开发期间运行 MapReduce 程序, 方便调试和测试. 伪分布式: Hadoop 守护程序运行在本地机器上, 会模拟一个小规模的集群. 完全分布式: 运行在集群的不同机器上. 当需要运行某个模式的 Hadoop 时, 需要设置适当的配置, 以及启动守护进程(独立模式除外), 不同模式见的配置如下: 配置文件 属性 独立模式值 伪分布式值 完全分布式值 core fs.defaultFS file:///(默认值) hdfs://localhost/ hdfs://namenode HDFS dfs.replication N/A 1 3(默认值) MapReduce mapreduce.framework.name local(默认值) yarn yarn yarn yarn.resourcemanager.hostnameyarn.nodemanager.aux-services N/AN/A localhost mapreduce_shuffle resourcemanager mapreduce_shuffle 此外, Hadoop 的不同配置模式见可以共存, 只需用不同的目录存放配置文件即可, 启动的时候可以通过如下两种方式来指定配置文件: 设置 HADOOP_CONF_DIR 环境变量 通过 --config 选项来指定 3.1 独立模式在独立模式下不需要进行额外的配置, 所有默认的属性都是针对独立模式的, 也没有守护程序运行, 独立模式下使用的文件系统是 Local File System 和 Local MR job runner. 可以看到, 独立模式下使用 hadoop fs -ls 显示的就是本机的根路径文件 3.2 伪分布式3.2.1 配置文件在伪分布式环境下, 需要配置如下文件: core-site.xml(核心站点) 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost/&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml 1234567&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;!-- yarn 是一个 MapReduce 框架, 2.0 版本以上开始引入 --&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;localhost&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 初始状态下, 这些配置文件中都是空值, 需要根据使用者的自身情况去配置以完成不同环境的搭建. 我们将 $HADOOP_INSTALL/etc/hadoop 文件夹拷贝一份, 用作伪分布式的配置 然后依次将上文提到的四个配置文件修改成指定的配置方式 3.2.2 配置 SSH在伪分布式下, 必须要启动守护进程, 启动守护进程就需要使用提供的启动脚本, Hadoop 并不严格区分伪分布式和完全分布式, 只是在目标主机上启动守护进程, 通过 SSH 命令让主机之间相互通信, 而且要启动守护进程. 伪分布式只是完全分布式的一个特例, 是一个在单个主机上运行 Hadoop 完全分布式的场景, 因此我们需要确保能够通过 SSH 命令登录本机, 而不需要通过输入密码. 在 ubuntu 上可以通过 sudo apt-get install ssh 123456$ sudo apt-get install ssh # 安装 ssh$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa # 生成公钥和私钥, -P '' 代表指定密码为空$ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys # 将公钥配置给 authorized_keys, 用来实现免密登陆$ ssh localhost # 第一次yes$ yes$ ssh localhost # 第二次不需要口令 3.2.3 使用 HDFS首先需要对文件系统进行格式化 hdfs namenode -format 然后就可以启动守护进程 3.2.3.1 启动12# start-dfs.sh --config $HADOOP_INSTALL/etc/hadoop_pseudo 3.2.3.2 启动 yarn12# start-yarn.sh --config $HADOOP_INSTALL/etc/hadoop_pseudo 此时可以通过 jps 查看: 其中 ResourceManager 和 NodeManager 由 Yarn 提供 NameNode, DataNode, SecondaryNameNode 由 HDFS 提供 可以使用如下命令停止 Hadoop12stop-yarn.shstop-dfs.sh 通过设置环境变量, 可以不再需要借助 –config 1export HADOOP_CONF_DIR=/usr/soft/hadoop-2.7.7/etc/hadoop_pseudo 此时再使用 hadoop fs -ls / 就已经没有结果显示 我们可以像使用 Linux 系统类似的命令去操作 HDFS, 下图展示一个创建文件夹的操作 3.3 完全分布式3.3.1 准备工作 在 /etc/passwd 修改登录提示消息 在 /etc/hostname 中修改主机名 可以通过软连接的方式指定 Hadoop 配置文件 将现在的 ubuntu 虚拟机克隆出三份, 具体配置如下: 左边标出本人当前的四台节点 ip 将 ip 和编号分别写在当前节点(s1) 的 /etc/hosts 文件中: 123410.211.55.33 s010.211.55.34 s110.211.55.35 s210.211.55.36 s3 此时测试, s0, s1, s2, s3 均可以被 ping 通 现在需要将 hosts 分别同步(覆盖)给到 s1, s2, s3 节点 Hadoop 集群架构分析 3.3.2 集群模式配置预期部署的网络拓扑图: 节点名 功能 s0 名称节点 s1 数据节点 s2 数据节点 s3 辅助名称节点 下面我们从 s0 开始进行配置, 在完成 s0 的配置后, Hadoop 运行时需要所有节点的配置相同, 因此类似于 hosts 文件, 我们需要将配置好的文件覆盖到其他节点. 3.3.2.1 core-site.xmlcore-site.xml 用来配置 NameNode 所运行的节点 ip 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://s0/&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 3.3.2.2 hdfs-site.xmlhdfs-site.xml 用来配置 HDFS 的副本数量 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 3.3.2.4 yarn-site.xmlyarn-site.xml 用来配置 yarn 的资源管理节点 123456789101112&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;s0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 3.3.2.5 slaves通过该文件配置从节点(DataNode) 的 ip 12s1s2 最后再将整个 hadoop_cluster 文件夹覆盖到其他节点 123sudo scp -r hadoop_cluster root@s1:/usr/soft/hadoop-2.7.7/etc/sudo scp -r hadoop_cluster root@s2:/usr/soft/hadoop-2.7.7/etc/sudo scp -r hadoop_cluster root@s3:/usr/soft/hadoop-2.7.7/etc/ 使用 start-all.sh 完成 hdfs 和 yarn 的启动: 我们可以对启动日志做一个简单的解读: 在 s0 节点上启动名称节点 分别在 s1 和 s2 启动数据节点 启动辅助名称节点 启动 yarn 守护进程 分别在 s1 和 s2 启动节点管理器 可以看一下此时集群上所有节点的 Java 进程状态 此时我们已经完成了 Hadoop 完全分布式配置. 4. 分布式文件系统HDFS4.1 概念 Hadoop 实现的分布式文件系统(Hadoop Distributed File System), 简称 HDFS 源自于 Google 的 GFS 论文 发表与 2003 年, HDFS 是 GFS 的克隆版 4.2 设计目标 非常巨大的分布式文件系统 运行在普通的廉价硬件之上 易扩展, 为用户提供性能较高的文件存储服务 4.3 HDFS 架构 一个 Master(NameNode/NN), 以及多个 Slave(DataNode/DN), DataNode 用于管理数据的读写, 一个文件会被拆分成多个 block, 默认为 128M, 被存储在一系列的 DataNode(不是一个 DataNode). NameNode 职责: 负责客户端请求的响应 负责元数据(文件名称, 副本系数, block 存放的 DN)的管理 DataNode 职责: 存储用户文件对应的数据块 要定期向 NameNode 发送心跳信息, 汇报本身及其所有的 block 信息, 健康状况 4.4 HDFS 副本机制 心跳包中包含的信息: 文件名称, 副本系数, block id e.g. 文件名 part-0, 副本系数 2, block id 为 {1, 3} e.g. 文件名 part-1, 副本系数 3, block id 为 {2, 4, 5} HDFS 副本存放策略: 第一个副本存放在客户端所在的节点, 另外两个副本优先存放在不同的机架上, 假设集群只有一个机架, 所有副本都会存放在同一个机架, 如果集群存在多个机架, 就随机挑选一个. 4.5 Hadoop Shell基本的命令格式: 12hdfs dfs/hadoop fs [generic options]比如 ls 命令可以写成: hdfs dfs -ls / 或 hadoop fs -ls / 命令 功能 ls 展示文件/文件夹列表 mkdir 创建文件夹 put 上传文件 get 获取文件 rm 删除文件/文件夹 4.6 通过代码操作 API4.6.1 测试文件的通用代码12345678910111213141516171819202122232425public class HDFSApp &#123; public static final String HDFS_PATH = "hdfs://10.211.55.33:8020"; /** * 对于文件系统, 所有操作的统一入库 */ FileSystem fileSystem = null; Configuration configuration = null; @Before public void setUp() throws URISyntaxException, IOException &#123; System.out.println("HDFSApp.setUp"); configuration = new Configuration(); fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration); &#125; @After public void tearDown() &#123; configuration = null; fileSystem = null; System.out.println("HDFSApp.tearDown"); &#125;&#125; 4.6.2 创建路径1234567/** * 创建 HDFS 目录 */@Testpublic void mkdir() throws IOException &#123; fileSystem.mkdirs(new Path("/hdfsapi/test"));&#125; 执行后的结果: 4.6.3 创建文件12345678910/** * 创建文件 */@Testpublic void create() throws IOException &#123; FSDataOutputStream fsDataOutputStream = fileSystem.create(new Path("/hdfsapi/test/a.txt")); fsDataOutputStream.write("hello hadoop".getBytes()); fsDataOutputStream.flush(); fsDataOutputStream.close();&#125; 执行后的结果: 4.6.4 查看文件内容123456789/** * 查看 HDFS 文件的内容 */@Testpublic void cat() throws IOException &#123; FSDataInputStream fsDataInputStream = fileSystem.open(new Path("/hdfsapi/test/a.txt")); IOUtils.copyBytes(fsDataInputStream, System.out, 1024); fsDataInputStream.close();&#125; 4.6.5 重命名123456789/** * 重命名 * @throws IOException */@Testpublic void rename() throws IOException &#123; boolean rename = fileSystem.rename(new Path("/hdfsapi/test/a.txt"), new Path("/hdfsapi/test/b.txt")); System.out.println("rename = " + rename);&#125; 执行结果: 4.6.6 将本地文件 copy 到 HDFS12345678910/** * 将文件从本地 copy 到 HDFS * @throws IOException */@Testpublic void copyFromLocalFile() throws IOException &#123; Path localPath = new Path("/Users/destiny/dev/apache-tomcat-8.5.29-src.tar.gz"); Path hdfsPath = new Path("/hdfsapi/test/"); fileSystem.copyFromLocalFile(localPath, hdfsPath);&#125; 执行结果: 4.6.7 带进度条的上传12345678910111213141516/** * 将文件从本地 copy 到 HDFS * @throws IOException */@Testpublic void copyFromLocalFileWithProgress() throws IOException &#123; InputStream inputStream = new BufferedInputStream(new FileInputStream(new File("/Users/destiny/dev/hadoop-2.7.7.tar.gz"))); FSDataOutputStream fsDataOutputStream = fileSystem.create(new Path("/hdfsapi/test/hadoop-2.7.7.tar.gz"), new Progressable() &#123; @Override public void progress() &#123; // 带进度条提醒信息 System.out.print("#"); &#125; &#125;); IOUtils.copyBytes(inputStream, fsDataOutputStream, 4096);&#125; 执行结果: 4.6.8 下载 HDFS 文件12345678910/** * 下载 HDFS 文件到本地 * @throws IOException */@Testpublic void copyToLocalFile() throws IOException &#123; Path localPath = new Path("/Users/destiny/dev/"); Path hdfsPath = new Path("/hdfsapi/test/b.txt"); fileSystem.copyToLocalFile(hdfsPath, localPath);&#125; 4.6.9 查看指定路径下的所有文件12345678910111213141516171819/** * 查看指定路径的所有文件 * @throws IOException */@Testpublic void listFiles() throws IOException &#123; FileStatus[] fileStatuses = fileSystem.listStatus(new Path("/hdfsapi/test/")); for (FileStatus fileStatus : fileStatuses) &#123; boolean directory = fileStatus.isDirectory(); System.out.println("directory = " + directory); short replication = fileStatus.getReplication(); System.out.println("replication = " + replication); long len = fileStatus.getLen(); System.out.println("len = " + len); String path = fileStatus.getPath().toString(); System.out.println("path = " + path); System.out.println("==============================="); &#125;&#125; 执行结果: 这里有一个小问题: 在前面的分布式配置中, hdfs-site.xml 中设置的副本系数为 2, 但这里查询到的结果却为 3如果是通过 HDFS shell 的方式 put 上去, 那么会采用设置的副本系数 2而如果是通过 java API 上传, 那么由于本地没有设置副本系数, 因此采用的是 Hadoop 自带的副本系数 4.6.10 删除文件12345678/** * 删除文件(默认递归) * @throws IOException */@Testpublic void delete() throws IOException &#123; fileSystem.delete(new Path("/hdfsapi/test/"), true);&#125; 4.7 HDFS 文件写入流程4.8 HDFS 文件读取刘晨5. 资源调度框架 YARN5.1 背景5.1.1 MapReduce 1.X 存在的问题 集群由一个 JobTracker 与多个 TaskTracker 构成, 客户端提交任务的时候, 直接将作业提交给 JobTracker, 由 JobTracker 负责资源的管理与作业的调度; TaskTracker 定期通过心跳机制与 JobTracker 进行通信, 汇报健康状况, 资源使用情况以及任务的执行进度, 并且接收来自 JobTracker 的命令来进行任务的启动和结束 存在问题: JobTracker 存在单点故障 JobTracker 负载较大, 需要接收 TaskTracker 的心跳信息, 制约 Hadoop 集群的扩展 JobTracker 承载职责较多, 包括资源管理, 资源调度, 任务分配 仅仅支持 MapReduce 作业, Spark 以及 Storm 作业无法支持 5.1.2 资源利用&amp;运维成本 由于 Hadoop 集群不支持其他形式的作业, 因此生产环境需要部署多套集群, 而不同集群在造成更多资源占用的同时, 往往存在运行时间不同, 如果能够将多个集群整合在一起, 就可以节约计算资源. 如果存在一种 共享集群, 能够处理不同类型的作业, 并且能够自行实现资源的合理分配, 就可以解决不同作业任务需要多套集群环境的问题. 在 Hadoop2.0 的架构中, Hadoop 之上运行 YARN, YARN 负责集群的资源管理, 而 YARN 可以接收来自 MapReduce, HBase, Storm, Spark 等多种应用的输入. YARN 做了统一的抽象, 类似操作系统级别的通用资源调度框架, 可以让更多的计算框架运行在同一个集群中, 不同的计算框架可以共享同一个 HDFS 上的数据, 享受整体的资源调度. 5.2 架构 Yarn(Yet Another Resource Negotiator, 另一个资源协调者的简称) 是一个通用的资源管理系统 为上层应用提供统一的资源管理和调度 Yarn 架构的核心组件: 角色 描述 功能 ResourceManager 整个集群同一时间提供服务的 Resource Manager 只有一个, 负责集群资源的统一管理和调度 1. 提交作业2. 杀死作业3. 监控 NodeManager, 一旦某个 NodeManager 挂了, 该 NameNode 上运行的任务要告诉 Application Master NodeManager 整个集群中有多个 NodeManager, 负责当前节点资源管理和使用 1. 定时向 ResourceManager 汇报当前节点的资源使用情况2. 接受并处理 ResourceManager 的各种命令3. 处理来自 Application Master 的命令4. 单个节点的资源管理 Application Master 每个应用程序对应一个 Application Master, 负责应用程序的管理 1. 为应用程序向 ResourceManager 申请资源(core, mem)2. 分配给内部的 Task 处理 3. 需要与 NodeManager 通信, 启动/停止 task Container 封装了 CPU, MEM 等资源的容器, 是一个任务运行环境的抽象 Client 用于封装用户的操作 1. 提交作业 2. 查询作业运行进度 3. 杀死作业 5.3 执行流程 用户向 YARN 提交作业 ResourceManager 为作业分配第一个 Container, 与对应的 NodeManager 通信, 要求在其上启动 Container, 用来启动应用程序 NodeManager 按照要求, 启动 Application Master Application Master 启动后, 会首先在 ResourceManager 进行注册, 此时就可以通过 ResourceManager 查询作业的运行情况. 然后 ApplicationMaster 会将所需要的资源到 ResourceManager 上去申请 ApplicationMaster 申请到资源之后在对应的 NodeManager 上开始启动任务, 所有的任务都是以 Container 的方式运行的 NodeManager 启动对应的 Container 去执行任务. 5.5 提交作业到 YARN 上执行5.5.1 提交 Hadoop 包的 Example在 Hadoop 安装路径下的 share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar 文件 使用如下命令将 MapReduce 作业提交到 YARN 上去运行: 1hadoop jar hadoop-mapreduce-examples-2.7.7.jar pi 2 3 6. 启动脚本分析Hadoop 启动脚本位于 ${HADOOP_HOME}/bin, ${HADOOP_HOME}/sbin 和 ${HADOOP_HOME}/libexec 路径下, 其中包含 *nux 的 Shell 脚本和 win 的批处理文件. 6.1 start-all.sh 启动分析1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env bash# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the "License"); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# Start all hadoop daemons. Run this on master node.echo "This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh"bin=`dirname "$&#123;BASH_SOURCE-$0&#125;"`bin=`cd "$bin"; pwd`DEFAULT_LIBEXEC_DIR="$bin"/../libexecHADOOP_LIBEXEC_DIR=$&#123;HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR&#125;. $HADOOP_LIBEXEC_DIR/hadoop-config.sh# start hdfs daemons if hdfs is presentif [ -f "$&#123;HADOOP_HDFS_HOME&#125;"/sbin/start-dfs.sh ]; then "$&#123;HADOOP_HDFS_HOME&#125;"/sbin/start-dfs.sh --config $HADOOP_CONF_DIRfi# start yarn daemons if yarn is presentif [ -f "$&#123;HADOOP_YARN_HOME&#125;"/sbin/start-yarn.sh ]; then "$&#123;HADOOP_YARN_HOME&#125;"/sbin/start-yarn.sh --config $HADOOP_CONF_DIRfi 首先会通过 echo 输出一句话, 大意是该脚本已被废弃, 推荐使用 start-dfs.sh 和 start-yarn.sh bin=`dirname &quot;${BASH_SOURCE-$0}&quot;` 提取 start-all.sh 所在的绝对路径 bin=`cd &quot;$bin&quot;; pwd` 切换到 start-all.sh 所在的绝对路径 DEFAULT_LIBEXEC_DIR=&quot;$bin&quot;/../libexec 获取 ${HADOOP_HOME}/libexec/hadoop-config.sh 路径 HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR} 为 HADOOP_LIBEXEC_DIR 变量三元赋值: 如果 HADOOP_LIBEXEC_DIR 为空或者环境变量没有配置, 复制默认的绝对路径 . $HADOOP_LIBEXEC_DIR/hadoop-config.sh 执行 ${HADOOP_HOME}/libexec/hadoop-config.sh 脚本, 为后面执行启动各节点和启动 yarn 做预处理 &quot;${HADOOP_HDFS_HOME}&quot;/sbin/start-dfs.sh --config $HADOOP_CONF_DIR 如果 ${HADOOP_HDFS_HOME}&quot;/sbin/start-dfs.sh 是文件, 就通过 –config 参数启动 start-dfs.sh 脚本 &quot;${HADOOP_YARN_HOME}&quot;/sbin/start-yarn.sh --config $HADOOP_CONF_DIR: 如果 ${HADOOP_YARN_HOME}&quot;/sbin/start-yarn.sh 是文件, 就通过 –config 参数启动 start-yarn.sh 脚本 6.2 hadoop-config.sh该脚本位于 7. MapReduceMapReduce 是一种并行计算编程模型, 源自于 Google 的 MapReduce 论文, 包含 Map 过程和 Reduce 过程, Map 过程对应创建 Mapper 实现类, Reduce 过程对应创建 Reducer 实现类. 7.2 Map 和 Reduce 阶段将作业拆分成 Map 阶段和 Reduce 阶段 准备 Map 处理的输入数据 Mapper 处理 Shuffle: 将相同的 key 分配到同一个 Reduce 节点 Reduce 处理 输出结果 假设现在有两个节点 使用 InputFormat 读取文件系统(本地, HDFS), 并拆分成多个 Split 每个 Split 由一个 RecordReader 负责读取, 每读一行交由一个 mapper 处理 map 产生的结果交由 Partitioner, 将所有的 key 按一定规则分配给同一个节点并完成排序 相同的 key 交给 Reduce 负责处理 处理的结果交给 OutputFormat 写回文件系统 7.3 MapReduce 编程模型 7.3.1 Split被 InputFormat 从文件系统中读取并分片, 并交由 MapReduce 作业来处理的数据块 HDFS 中的 blocksize 是 HDFS 中最小的存储单元, 默认 128MSplit 是 MapReduce 中最小的计算单元默认情况下二者是一一对应的, 也可以手工设置二者之间的关系. 7.3.2 Combiner7.3.3 Partitioner7.4 MapReduce 1.x 架构 JobTracker(JT) 作业的管理者 将作业分解成多个任务(MapTask &amp; ReduceTask) 将任务分派给 TaskTracker 运行 作业监控, 容错处理 在一定时间内 JobTacker 没有收到 TaskTracker 的心跳, 会重新指派到其他的 TaskTracker 去执行 TaskTracker(TT) 任务的执行者, 执行任务(MapTask &amp; ReduceTask) 与 JobTracker 交互: 执行/启动/停止, 发送心跳信息给 JobTracker MapTask 开发的 map 任务交由 MapTask 完成 解析每条记录的数据交给自己的 Map 方法处理 将 Map 的输出结果写到本地磁盘 ReduceTask 将 MapTask 输出的数据进行读取 按照数据进行分组传给 Reduce 方法处理 输出结果, 写入到 HDFS 7.5 MapReduce 2.x 架构7.6 Combiner 在 Mapper Task本地的 Reduce 减少 Map Task 输出的数据量及数据网络传输量 大部分情况下逻辑和 Reduce 基本相同 7.7 Partitioner 决定 MapTask 输出的数据交由哪个 Reducer 处理 默认实现: 分发的 key 的 hash 值对 Reduce Task 个数取模]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(9)-XML解析]]></title>
    <url>%2Fblog%2F2019%2F04%2F08%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-9-XML%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. XML 解析1.1. DOM 模型 优点: 文档解析的时候允许客户端编辑和更新 XML 文档的内容, 并可以随机访问文档中定义的元素数据. 缺点: 文档解析的时候需要将 XML 一次性加载到内存, 进而映射成 Document 对象中的树形结构, 在解析大文件的时候内存占用大, 元素遍历查找慢, 性能容易成为瓶颈. 1.2. SAX 模型 优点: 该方式解析文档的时候, 每一次操作只会将解析的节点放置到内存中, 从头部开始, 读取一段处理一段, 内存占用小. 缺点: 解析文档的时候文档是只读的, 不能编辑, 并且文件流只能前进不能后退 在 Activiti 中, 由于 XML 完全由用户的输入决定, 无法控制器大小, 因此选用 SAX 模型 2. 文档转换器文档转换器可以将文档转换为 BpmnModel, 也可以将 BpmnModel 转换为文档 文档解析器: BpmnXMLConverter 解析器内部持有所有 元素解析器 元素解析器与元素之间一一对应 任务节点的元素名称是 UserTask, 因此对应的解析器为 UserTaskXMLConverter 连线的元素名称是 SequenceFlow, 对应的解析器为 SequenceFlowXMLConverter]]></content>
      <categories>
        <category>Activiti</category>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(7)-ID生成器]]></title>
    <url>%2Fblog%2F2019%2F03%2F26%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-7-ID%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1. DbIdGenerator Activiti 默认采用数据库来实现强一致的发号器 DbIdGenerator 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DbIdGenerator implements IdGenerator &#123; protected int idBlockSize; protected long nextId; protected long lastId = -1; protected CommandExecutor commandExecutor; protected CommandConfig commandConfig; public synchronized String getNextId() &#123; if (lastId &lt; nextId) &#123; getNewBlock(); &#125; long _nextId = nextId++; return Long.toString(_nextId); &#125; protected synchronized void getNewBlock() &#123; IdBlock idBlock = commandExecutor.execute(commandConfig, new GetNextIdBlockCmd(idBlockSize)); this.nextId = idBlock.getNextId(); this.lastId = idBlock.getLastId(); &#125; public int getIdBlockSize() &#123; return idBlockSize; &#125; public void setIdBlockSize(int idBlockSize) &#123; this.idBlockSize = idBlockSize; &#125; public CommandExecutor getCommandExecutor() &#123; return commandExecutor; &#125; public void setCommandExecutor(CommandExecutor commandExecutor) &#123; this.commandExecutor = commandExecutor; &#125; public CommandConfig getCommandConfig() &#123; return commandConfig; &#125; public void setCommandConfig(CommandConfig commandConfig) &#123; this.commandConfig = commandConfig; &#125;&#125; DbIdGenerator 实现了 getNextId 方法, 用于对应用范围内所有的实体对象分配 id, 我们就以这个方法为起点, 分析默认的发号器逻辑. 1.1. DbIdGenerator#getNextId()1234567public synchronized String getNextId() &#123; if (lastId &lt; nextId) &#123; getNewBlock(); &#125; long _nextId = nextId++; return Long.toString(_nextId);&#125; 比较内部持有的两个布局变量 lastId 和 nextId 如果 lastId 已经小于 nextId 获取一个新的 Block 获得当前的 _nextId, 并转换成字符串, 同时持有的局部变量 nextId 自增 1.2. DbIdGenerator#getNewBlock()12345protected synchronized void getNewBlock() &#123; IdBlock idBlock = commandExecutor.execute(commandConfig, new GetNextIdBlockCmd(idBlockSize)); this.nextId = idBlock.getNextId(); this.lastId = idBlock.getLastId();&#125; 获取一个新的 IdBlock 对象 分别将该对象的 nextId 和 lastId 赋值给自身持有的同名字段 1.3. GetNextIdBlockCmd#execute(CommandContext commandContext)1234567public IdBlock execute(CommandContext commandContext) &#123; PropertyEntity property = (PropertyEntity) commandContext.getPropertyEntityManager().findById("next.dbid"); long oldValue = Long.parseLong(property.getValue()); long newValue = oldValue + idBlockSize; property.setValue(Long.toString(newValue)); return new IdBlock(oldValue, newValue - 1);&#125; 调用 PropertyEntityManager, 从 ACT_GE_PROPERTY 表中获取 next.dbid 字段的值 将旧值转换成 long 类型并增加 idBlockSize 长度得到新值, 其中 idBlockSize 通过调用链追踪到在 ProcessEngineConfiguration 将其设置为 2500, 并调用命令类的初始化 将新值设置进查询到的 property 对象 返回新的 IdBlock 对象]]></content>
      <categories>
        <category>Activiti</category>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(8)-发起流程实例]]></title>
    <url>%2Fblog%2F2019%2F03%2F09%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-8-%E5%8F%91%E8%B5%B7%E6%B5%81%E7%A8%8B%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[1. 概念1.1. 启动流程 操作数据库的 ACT_RU_EXECUTION 表, 如果是用户任务节点, 同时也会在 ACT_RU_TASK 表添加一条记录; 1.2. 流程实例 代表流程定义的执行实例 一个流程实例包括了所有的运行节点 流程实例表示一个流程从开始到结束的最大流程分支 流程实例也被称为执行实例根节点 在 Activiti 对应的接口为: 123public interface ProcessInstance extends Execution &#123; // ...&#125; 可以看出 ProcessInstance 就是 Execution 1.3. 执行实例 启动流程的时候会首先创建流程实例, 然后创建执行实例 流程运转的过程中永远执行的是自己对应的执行实例 当所有的执行实例按照规则完毕之后, 对应的流程随之结束 Activiti 使用 Execution 对象去描述流程执行的每一个节点 流程按照流程定义的规则执行一次的过程, 就可以表示执行对象 Execution 一个流程中, 执行对象可以存在多个, 但流程实例只能有一个 执行实例的父级 / 父级的父级为流程实例 1.4. 概念演示1.4.1. 简单流程实例 发起流程的时候, 会先创建一个流程实例, 然后创建执行实例; 随着流程的运转, 执行实例会不断更新; 直到流程执行完毕(走到结束节点), 对应执行实例会结束, 此时流程实例也结束. 1.4.2. 有分支的流程实例 当流程进入并行网关之后, 会创建两个执行实例 当两个执行实例都结束之后, 再创建第三个执行实例 2. RuntimeServiceImpl#startProcessInstanceByKey(String processDefinitionKey)123public ProcessInstance startProcessInstanceByKey(String processDefinitionKey) &#123; return commandExecutor.execute(new StartProcessInstanceCmd&lt;ProcessInstance&gt;(processDefinitionKey, null, null, null));&#125; 2.1. StartProcessInstanceCmd#execution(CommandContext commandContext)1234567891011121314151617181920212223242526272829303132333435public ProcessInstance execute(CommandContext commandContext) &#123; DeploymentManager deploymentCache = commandContext.getProcessEngineConfiguration().getDeploymentManager(); // Find the process definition ProcessDefinition processDefinition = null; if (processDefinitionId != null) &#123; processDefinition = deploymentCache.findDeployedProcessDefinitionById(processDefinitionId); if (processDefinition == null) &#123; throw new ActivitiObjectNotFoundException("No process definition found for id = '" + processDefinitionId + "'", ProcessDefinition.class); &#125; &#125; else if (processDefinitionKey != null &amp;&amp; (tenantId == null || ProcessEngineConfiguration.NO_TENANT_ID.equals(tenantId))) &#123; processDefinition = deploymentCache.findDeployedLatestProcessDefinitionByKey(processDefinitionKey); if (processDefinition == null) &#123; throw new ActivitiObjectNotFoundException("No process definition found for key '" + processDefinitionKey + "'", ProcessDefinition.class); &#125; &#125; else if (processDefinitionKey != null &amp;&amp; tenantId != null &amp;&amp; !ProcessEngineConfiguration.NO_TENANT_ID.equals(tenantId)) &#123; processDefinition = deploymentCache.findDeployedLatestProcessDefinitionByKeyAndTenantId(processDefinitionKey, tenantId); if (processDefinition == null) &#123; throw new ActivitiObjectNotFoundException("No process definition found for key '" + processDefinitionKey + "' for tenant identifier " + tenantId, ProcessDefinition.class); &#125; &#125; else &#123; throw new ActivitiIllegalArgumentException("processDefinitionKey and processDefinitionId are null"); &#125; processInstanceHelper = commandContext.getProcessEngineConfiguration().getProcessInstanceHelper(); ProcessInstance processInstance = createAndStartProcessInstance(processDefinition, businessKey, processInstanceName, variables, transientVariables); return processInstance;&#125; 初始化 processDefinition 对象, 由于 startProcessInstanceByXX 系列方法有多种参数, 因此一下三种条件都可以实现: 如果 processDefinitionId 不为空, 通过该 id 查询流程定义; 如果 processDefinitionKey 不为空, 并且 tenantId 为空, 就通过 processDefinitionKey 查询最新的流程定义; 如果 processDefinitionKey 不为空, 并且 tenantId 也不为空, 就通过这两个参数一起查询最新的流程定义; 获取 processInstanceHelper 对象 执行创建流程逻辑并返回 2.2. StartProcessInstanceCmd#createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String,Object&gt; variables, Map&lt;String, Object&gt; transientVariables)参数较多, 先解释下参数: processDefinition: 流程定义对象 businessKey: 业务标识 processInstanceName: 需要设置的流程名称 variables: 表单数据(会持久化到变量表中) transientVariables: 不需要持久化的变量表 1234protected ProcessInstance createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String,Object&gt; variables, Map&lt;String, Object&gt; transientVariables) &#123; return processInstanceHelper.createAndStartProcessInstance(processDefinition, businessKey, processInstanceName, variables, transientVariables);&#125; 2.3. ProcessInstanceHelper#createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance)123456789101112131415161718192021222324252627282930protected ProcessInstance createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance) &#123; CommandContext commandContext = Context.getCommandContext(); // Todo: ideally, context should be passed here if (Activiti5Util.isActiviti5ProcessDefinition(commandContext, processDefinition)) &#123; Activiti5CompatibilityHandler activiti5CompatibilityHandler = Activiti5Util.getActiviti5CompatibilityHandler(); return activiti5CompatibilityHandler.startProcessInstance(processDefinition.getKey(), processDefinition.getId(), variables, businessKey, processDefinition.getTenantId(), processInstanceName); &#125; // Do not start process a process instance if the process definition is suspended if (ProcessDefinitionUtil.isProcessDefinitionSuspended(processDefinition.getId())) &#123; throw new ActivitiException("Cannot start process instance. Process definition " + processDefinition.getName() + " (id = " + processDefinition.getId() + ") is suspended"); &#125; // Get model from cache Process process = ProcessDefinitionUtil.getProcess(processDefinition.getId()); if (process == null) &#123; throw new ActivitiException("Cannot start process instance. Process model " + processDefinition.getName() + " (id = " + processDefinition.getId() + ") could not be found"); &#125; FlowElement initialFlowElement = process.getInitialFlowElement(); if (initialFlowElement == null) &#123; throw new ActivitiException("No start element found for process definition " + processDefinition.getId()); &#125; return createAndStartProcessInstanceWithInitialFlowElement(processDefinition, businessKey, processInstanceName, initialFlowElement, process, variables, transientVariables, startProcessInstance); &#125; 如果流程定义是 Activiti5 风格的, 执行 Activiti5 相关的兼容代码 如果流程定义已经被挂起, 那么抛出异常 根据 processDefinitionId 获取 Process 对象, 如果失败抛出异常 获取 Process 对象的 initialFlowElement 创建并开启流程实例, 并返回结果 2.3.1. ProcessDefinitionUtil#getProcess(String processDefinitionId)123456789101112public static Process getProcess(String processDefinitionId) &#123; if (Context.getProcessEngineConfiguration() == null) &#123; return Activiti5Util.getActiviti5CompatibilityHandler().getProcessDefinitionProcessObject(processDefinitionId); &#125; else &#123; DeploymentManager deploymentManager = Context.getProcessEngineConfiguration().getDeploymentManager(); // This will check the cache in the findDeployedProcessDefinitionById and resolveProcessDefinition method ProcessDefinition processDefinitionEntity = deploymentManager.findDeployedProcessDefinitionById(processDefinitionId); return deploymentManager.resolveProcessDefinition(processDefinitionEntity).getProcess(); &#125;&#125; 2.3.2. DeploymentManager#findDeployedProcessDefinitionById(String processDefinitionId)123456789101112131415161718public ProcessDefinition findDeployedProcessDefinitionById(String processDefinitionId) &#123; if (processDefinitionId == null) &#123; throw new ActivitiIllegalArgumentException("Invalid process definition id : null"); &#125; // first try the cache ProcessDefinitionCacheEntry cacheEntry = processDefinitionCache.get(processDefinitionId); ProcessDefinition processDefinition = cacheEntry != null ? cacheEntry.getProcessDefinition() : null; if (processDefinition == null) &#123; processDefinition = processDefinitionEntityManager.findById(processDefinitionId); if (processDefinition == null) &#123; throw new ActivitiObjectNotFoundException("no deployed process definition found with id '" + processDefinitionId + "'", ProcessDefinition.class); &#125; processDefinition = resolveProcessDefinition(processDefinition).getProcessDefinition(); &#125; return processDefinition;&#125; 首先从缓存中查找 如果缓存没有, 继续从 DB 中查找 将 ProcessDefinition 转换为 Process 并返回 2.3.3. DeploymentManager#resolveProcessDefinition(ProcessDefinition processDefinition)12345678910111213141516171819202122232425public ProcessDefinitionCacheEntry resolveProcessDefinition(ProcessDefinition processDefinition) &#123; String processDefinitionId = processDefinition.getId(); String deploymentId = processDefinition.getDeploymentId(); ProcessDefinitionCacheEntry cachedProcessDefinition = processDefinitionCache.get(processDefinitionId); if (cachedProcessDefinition == null) &#123; CommandContext commandContext = Context.getCommandContext(); if (commandContext.getProcessEngineConfiguration().isActiviti5CompatibilityEnabled() &amp;&amp; Activiti5Util.isActiviti5ProcessDefinition(Context.getCommandContext(), processDefinition)) &#123; return Activiti5Util.getActiviti5CompatibilityHandler().resolveProcessDefinition(processDefinition); &#125; DeploymentEntity deployment = deploymentEntityManager.findById(deploymentId); deployment.setNew(false); deploy(deployment, null); cachedProcessDefinition = processDefinitionCache.get(processDefinitionId); if (cachedProcessDefinition == null) &#123; throw new ActivitiException("deployment '" + deploymentId + "' didn't put process definition '" + processDefinitionId + "' in the cache"); &#125; &#125; return cachedProcessDefinition;&#125; 首先尝试从缓存中获取流程定义 如果为空 如果是 Activiti5 风格的配置 通过 Activiti5 的方式获取并返回 尝试从 DB 中获取, 补充到缓存中 再从缓存中获取 返回 2.4. ProcessInstanceHelper#createAndStartProcessInstanceWithInitialFlowElement(ProcessDefinition processDefinition, String businessKey, String processInstanceName, FlowElement initialFlowElement, Process process, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public ProcessInstance createAndStartProcessInstanceWithInitialFlowElement(ProcessDefinition processDefinition, String businessKey, String processInstanceName, FlowElement initialFlowElement, Process process, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance) &#123; CommandContext commandContext = Context.getCommandContext(); // Create the process instance String initiatorVariableName = null; if (initialFlowElement instanceof StartEvent) &#123; initiatorVariableName = ((StartEvent) initialFlowElement).getInitiator(); &#125; ExecutionEntity processInstance = commandContext.getExecutionEntityManager() .createProcessInstanceExecution(processDefinition, businessKey, processDefinition.getTenantId(), initiatorVariableName); commandContext.getHistoryManager().recordProcessInstanceStart(processInstance, initialFlowElement); processInstance.setVariables(processDataObjects(process.getDataObjects())); // Set the variables passed into the start command if (variables != null) &#123; for (String varName : variables.keySet()) &#123; processInstance.setVariable(varName, variables.get(varName)); &#125; &#125; if (transientVariables != null) &#123; for (String varName : transientVariables.keySet()) &#123; processInstance.setTransientVariable(varName, transientVariables.get(varName)); &#125; &#125; // Set processInstance name if (processInstanceName != null) &#123; processInstance.setName(processInstanceName); commandContext.getHistoryManager().recordProcessInstanceNameChange(processInstance.getId(), processInstanceName); &#125; // Fire events if (Context.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123; Context.getProcessEngineConfiguration().getEventDispatcher() .dispatchEvent(ActivitiEventBuilder.createEntityWithVariablesEvent(ActivitiEventType.ENTITY_INITIALIZED, processInstance, variables, false)); &#125; // Create the first execution that will visit all the process definition elements ExecutionEntity execution = commandContext.getExecutionEntityManager().createChildExecution(processInstance); execution.setCurrentFlowElement(initialFlowElement); if (startProcessInstance) &#123; startProcessInstance(processInstance, commandContext, variables); &#125; return processInstance;&#125; 创建流程实例(父级 Execution) 在历史流程表中将流程实例标记为开始 将所有 DataObject 转换为 Map&lt;String, Object&gt;, 并设置为流程实例的变量 将创建流程时填入的表单信息设置为变量 为流程变量设置名称 触发事件 创建第一个将访问所有流程定义元素的 Execution 并将该 Execution 对象的当前元素设置为传入的初始化元素 如果需要立即开启 调用开启流程实例方法 返回该流程实例 2.4.1. ExecutionEntityManagerImpl#createProcessInstanceExecution(ProcessDefinition processDefinition, String businessKey, String tenantId, String initiatorVariableName)123456789101112131415161718192021222324252627282930313233343536373839404142434445public ExecutionEntity createProcessInstanceExecution(ProcessDefinition processDefinition, String businessKey, String tenantId, String initiatorVariableName) &#123; ExecutionEntity processInstanceExecution = executionDataManager.create(); if (isExecutionRelatedEntityCountEnabledGlobally()) &#123; ((CountingExecutionEntity) processInstanceExecution).setCountEnabled(true); &#125; processInstanceExecution.setProcessDefinitionId(processDefinition.getId()); processInstanceExecution.setProcessDefinitionKey(processDefinition.getKey()); processInstanceExecution.setProcessDefinitionName(processDefinition.getName()); processInstanceExecution.setProcessDefinitionVersion(processDefinition.getVersion()); processInstanceExecution.setBusinessKey(businessKey); processInstanceExecution.setScope(true); // process instance is always a scope for all child executions // Inherit tenant id (if any) if (tenantId != null) &#123; processInstanceExecution.setTenantId(tenantId); &#125; String authenticatedUserId = Authentication.getAuthenticatedUserId(); processInstanceExecution.setStartTime(Context.getProcessEngineConfiguration().getClock().getCurrentTime()); processInstanceExecution.setStartUserId(authenticatedUserId); // Store in database insert(processInstanceExecution, false); if (initiatorVariableName != null) &#123; processInstanceExecution.setVariable(initiatorVariableName, authenticatedUserId); &#125; // Need to be after insert, cause we need the id processInstanceExecution.setProcessInstanceId(processInstanceExecution.getId()); processInstanceExecution.setRootProcessInstanceId(processInstanceExecution.getId()); if (authenticatedUserId != null) &#123; getIdentityLinkEntityManager().addIdentityLink(processInstanceExecution, authenticatedUserId, null, IdentityLinkType.STARTER); &#125; // Fire events if (getEventDispatcher().isEnabled()) &#123; getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, processInstanceExecution)); &#125; return processInstanceExecution;&#125; 创建一个新的 ExecutionEntity 对象并初始化 获取创建人 ID 和开始时间 插入该 ExecutionEntity 触发事件 2.4.2. DefaultHistoryManager#recordProcessInstanceStart(ExecutionEntity processInstance, FlowElement startElement)12345678910111213141516public void recordProcessInstanceStart(ExecutionEntity processInstance, FlowElement startElement) &#123; if (isHistoryLevelAtLeast(HistoryLevel.ACTIVITY)) &#123; HistoricProcessInstanceEntity historicProcessInstance = getHistoricProcessInstanceEntityManager().create(processInstance); historicProcessInstance.setStartActivityId(startElement.getId()); // Insert historic process-instance getHistoricProcessInstanceEntityManager().insert(historicProcessInstance, false); // Fire event ActivitiEventDispatcher activitiEventDispatcher = getEventDispatcher(); if (activitiEventDispatcher != null &amp;&amp; activitiEventDispatcher.isEnabled()) &#123; activitiEventDispatcher.dispatchEvent( ActivitiEventBuilder.createEntityEvent(ActivitiEventType.HISTORIC_PROCESS_INSTANCE_CREATED, historicProcessInstance)); &#125; &#125;&#125; 根据传入的 processInstance 构造 HistoricProcessInstanceEntity 对象 向历史表插入该对象 将给定的事件分派给任何已注册的侦听器 2.4.3. ExecutionEntityManagerImpl#createChildExecution(ExecutionEntity parentExecutionEntity)创建第一个将访问所有流程定义元素的执行对象 123456789101112131415161718192021222324252627public ExecutionEntity createChildExecution(ExecutionEntity parentExecutionEntity) &#123; ExecutionEntity childExecution = executionDataManager.create(); inheritCommonProperties(parentExecutionEntity, childExecution); childExecution.setParent(parentExecutionEntity); childExecution.setProcessDefinitionId(parentExecutionEntity.getProcessDefinitionId()); childExecution.setProcessDefinitionKey(parentExecutionEntity.getProcessDefinitionKey()); childExecution.setProcessInstanceId(parentExecutionEntity.getProcessInstanceId() != null ? parentExecutionEntity.getProcessInstanceId() : parentExecutionEntity.getId()); childExecution.setScope(false); // manage the bidirectional parent-child relation parentExecutionEntity.addChildExecution(childExecution); // Insert the child execution insert(childExecution, false); if (logger.isDebugEnabled()) &#123; logger.debug("Child execution &#123;&#125; created with parent &#123;&#125;", childExecution, parentExecutionEntity.getId()); &#125; if (getEventDispatcher().isEnabled()) &#123; getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, childExecution)); getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_INITIALIZED, childExecution)); &#125; return childExecution; &#125; 创建一个新的 ExecutionEntity 对象, 并继承父 ExecutionEntity 的公共配置 设置父子关系 插入子 ExecutionEntity 将指定事件分派给已注册的监听器 2.4.4. ExecutionEntityManagerImpl#startProcessInstance(ExecutionEntity processInstance, CommandContext commandContext, Map&lt;String, Object&gt; variables)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public void startProcessInstance(ExecutionEntity processInstance, CommandContext commandContext, Map&lt;String, Object&gt; variables) &#123; Process process = ProcessDefinitionUtil.getProcess(processInstance.getProcessDefinitionId()); // Event sub process handling List&lt;MessageEventSubscriptionEntity&gt; messageEventSubscriptions = new LinkedList&lt;&gt;(); for (FlowElement flowElement : process.getFlowElements()) &#123; if (flowElement instanceof EventSubProcess) &#123; EventSubProcess eventSubProcess = (EventSubProcess) flowElement; for (FlowElement subElement : eventSubProcess.getFlowElements()) &#123; if (subElement instanceof StartEvent) &#123; StartEvent startEvent = (StartEvent) subElement; if (CollectionUtil.isNotEmpty(startEvent.getEventDefinitions())) &#123; EventDefinition eventDefinition = startEvent.getEventDefinitions().get(0); if (eventDefinition instanceof MessageEventDefinition) &#123; MessageEventDefinition messageEventDefinition = (MessageEventDefinition) eventDefinition; BpmnModel bpmnModel = ProcessDefinitionUtil.getBpmnModel(processInstance.getProcessDefinitionId()); if (bpmnModel.containsMessageId(messageEventDefinition.getMessageRef())) &#123; messageEventDefinition.setMessageRef(bpmnModel.getMessage(messageEventDefinition.getMessageRef()).getName()); &#125; ExecutionEntity messageExecution = commandContext.getExecutionEntityManager().createChildExecution(processInstance); messageExecution.setCurrentFlowElement(startEvent); messageExecution.setEventScope(true); messageEventSubscriptions .add(commandContext.getEventSubscriptionEntityManager().insertMessageEvent(messageEventDefinition.getMessageRef(), messageExecution)); &#125; &#125; &#125; &#125; &#125; &#125; ExecutionEntity execution = processInstance.getExecutions().get(0); // There will always be one child execution created commandContext.getAgenda().planContinueProcessOperation(execution); if (Context.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123; ActivitiEventDispatcher eventDispatcher = Context.getProcessEngineConfiguration().getEventDispatcher(); eventDispatcher.dispatchEvent(ActivitiEventBuilder.createProcessStartedEvent(execution, variables, false)); for (MessageEventSubscriptionEntity messageEventSubscription : messageEventSubscriptions) &#123; commandContext.getProcessEngineConfiguration().getEventDispatcher() .dispatchEvent(ActivitiEventBuilder.createMessageEvent(ActivitiEventType.ACTIVITY_MESSAGE_WAITING, messageEventSubscription.getActivityId(), messageEventSubscription.getEventName(), null, messageEventSubscription.getExecution().getId(), messageEventSubscription.getProcessInstanceId(), messageEventSubscription.getProcessDefinitionId())); &#125; &#125;&#125; 获取流程对象 找到所有的子流程的开始事件, 并查找开始事件的事件定义来收集所有的消息事件 获取当前 ExecutionEntity 的第一个子对象, 并由该子对象开始执行 开始流程后, 继续进行将给定的事件分派给任何已注册的侦听器的操作]]></content>
      <categories>
        <category>Activiti</category>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(6)--RepositoryService(仓库服务类)模型校验]]></title>
    <url>%2Fblog%2F2019%2F03%2F09%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-6-RepositoryService-%E4%BB%93%E5%BA%93%E6%9C%8D%E5%8A%A1%E7%B1%BB-%E6%A8%A1%E5%9E%8B%E6%A0%A1%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445 @Test public void testBpmnModel() throws UnsupportedEncodingException &#123; BpmnModel bpmnModel = new BpmnModel(); Process process = new Process(); process.setId("my-process"); StartEvent startEvent = new StartEvent(); startEvent.setId("startEvent"); UserTask someTask = new UserTask(); someTask.setId("someTask"); someTask.setName("Activiti is awesome!"); someTask.setAssignee("$&#123;user&#125;"); MultiInstanceLoopCharacteristics multiInstanceLoopCharacteristics = new MultiInstanceLoopCharacteristics(); multiInstanceLoopCharacteristics.setSequential(false); multiInstanceLoopCharacteristics.setInputDataItem("$&#123;usersBean.getUsers(name)&#125;"); multiInstanceLoopCharacteristics.setElementVariable("user"); multiInstanceLoopCharacteristics.setCompletionCondition("$&#123;nrOfCompletedInstances &gt; 0&#125;"); someTask.setLoopCharacteristics(multiInstanceLoopCharacteristics); EndEvent endEvent = new EndEvent(); endEvent.setId("endEvent"); SequenceFlow flow1 = createSequence("startEvent", "someTask", "flow1", "flow1", null); SequenceFlow flow2 = createSequence("someTask", "endEvent", "flow2", "flow2", null); process.addFlowElement(startEvent); process.addFlowElement(someTask); process.addFlowElement(endEvent); process.addFlowElement(flow1); process.addFlowElement(flow2); bpmnModel.addProcess(process); byte[] bytes = new BpmnXMLConverter().convertToXML(bpmnModel); String s = new String(bytes, "utf-8"); log.info(s); ProcessValidatorFactory processValidatorFactory = new ProcessValidatorFactory(); ProcessValidator defaultProcessValidator = processValidatorFactory.createDefaultProcessValidator(); List&lt;ValidationError&gt; validate = defaultProcessValidator.validate(bpmnModel); log.info("validate: &#123;&#125;", validate); &#125;&#125; 生成的 XMl 文件:1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process" isExecutable="true"&gt; &lt;startEvent id="startEvent"&gt;&lt;/startEvent&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:assignee="$&#123;user&#125;"&gt; &lt;multiInstanceLoopCharacteristics isSequential="false" activiti:collection="$&#123;usersBean.getUsers(name)&#125;" activiti:elementVariable="user"&gt; &lt;completionCondition&gt;$&#123;nrOfCompletedInstances &amp;gt; 0&#125;&lt;/completionCondition&gt; &lt;/multiInstanceLoopCharacteristics&gt; &lt;/userTask&gt; &lt;endEvent id="endEvent"&gt;&lt;/endEvent&gt; &lt;sequenceFlow id="flow1" name="flow1" sourceRef="startEvent" targetRef="someTask"&gt;&lt;/sequenceFlow&gt; &lt;sequenceFlow id="flow2" name="flow2" sourceRef="someTask" targetRef="endEvent"&gt;&lt;/sequenceFlow&gt; &lt;/process&gt; &lt;bpmndi:BPMNDiagram id="BPMNDiagram_my-process"&gt; &lt;bpmndi:BPMNPlane bpmnElement="my-process" id="BPMNPlane_my-process"&gt;&lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt; validate 的结果validate: [] 代表当前流程正常, 没有错误 1. ProcessValidatorFactory#createDefaultProcessValidator()12345public ProcessValidator createDefaultProcessValidator() &#123; ProcessValidatorImpl processValidator = new ProcessValidatorImpl(); processValidator.addValidatorSet(new ValidatorSetFactory().createActivitiExecutableProcessValidatorSet()); return processValidator;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(5)--RepositoryService(仓库服务类)classpath资源部署]]></title>
    <url>%2Fblog%2F2019%2F03%2F09%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-5-RepositoryService-%E4%BB%93%E5%BA%93%E6%9C%8D%E5%8A%A1%E7%B1%BB-classpath%E8%B5%84%E6%BA%90%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[RepositoryService 是 Activiti 的仓库服务类, 仓库指的是流程定义文档的两个文件: BPMN 文件和流程图片 获得方式: 1RepositoryService repositoryService = processEngine.getRepositoryService(); 其实现类为: RepositoryServiceImpl 可以产生 DeploymentBuilder, 用来产生定义流程部署的相关参数 1Deployment deployment = repositoryService.createDeployment(); 1. classpath 部署方式说明 先获取流程引擎对象, 在创建时会自动加载 classpath 下的 activiti.cfg.xml 首先获得默认的流程引擎, 通过流程引擎获取一个 RepositoryService 对象 由仓库的服务对象产生一个部署对象配置对象, 用来封装部署操作的相关配置 链式编程, 在部署的配置对象中设置显示名, 上传流程定义规则文件 向数据库中存放流程定义的规则信息 测试代码 1234567891011@Testpublic void test() &#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); Deployment deployment = processEngine.getRepositoryService() .createDeployment() .name("my-process") .addClasspathResource("process/my-process.bpmn20.xml") .deploy(); log.info("deployment: &#123;&#125;", deployment);&#125; 1.1. DeploymentBuilderImpl#addClasspathResource(String resource)1234567public DeploymentBuilder addClasspathResource(String resource) &#123; InputStream inputStream = ReflectUtil.getResourceAsStream(resource); if (inputStream == null) &#123; throw new ActivitiIllegalArgumentException("resource '" + resource + "' not found"); &#125; return addInputStream(resource, inputStream);&#125; 通过资源路径获取输入流 添加输入流并返回 1.1.1. ReflectUtil.getResourceAsStream(String name)12345678910111213141516171819public static InputStream getResourceAsStream(String name) &#123; InputStream resourceStream = null; ClassLoader classLoader = getCustomClassLoader(); if (classLoader != null) &#123; resourceStream = classLoader.getResourceAsStream(name); &#125; if (resourceStream == null) &#123; // Try the current Thread context classloader classLoader = Thread.currentThread().getContextClassLoader(); resourceStream = classLoader.getResourceAsStream(name); if (resourceStream == null) &#123; // Finally, try the classloader for this class classLoader = ReflectUtil.class.getClassLoader(); resourceStream = classLoader.getResourceAsStream(name); &#125; &#125; return resourceStream;&#125; 获取自定义类加载器 如果类加载器不为空, 获取 classpath 路径下的资源 如果资源为空, 重新获取当前线程的类加载器, 再次尝试获取 classpath 下的资源 如果资源依然为空, 再获取当前类的类加载器再次尝试获取 classpath 下的资源 返回 1.2. DeploymentBuilderImpl#addInputStream(String resourceName, InputStream inputStream)1234567891011public DeploymentBuilder addInputStream(String resourceName, InputStream inputStream) &#123; if (inputStream == null) &#123; throw new ActivitiIllegalArgumentException("inputStream for resource '" + resourceName + "' is null"); &#125; byte[] bytes = IoUtil.readInputStream(inputStream, resourceName); ResourceEntity resource = resourceEntityManager.create(); resource.setName(resourceName); resource.setBytes(bytes); deployment.addResource(resource); return this;&#125; 将输入流转化为字节数组 创建一个 ResourceEntity 实例对象, 并设置名称和字节数组 为 deployment 对象添加资源, 其内部包含一个 Map&lt;String, ResourceEntity&gt; 的属性 返回当前对象(DeploymentBuilder) 1.2.1. IoUtil#readInputStream(InputStream inputStream, String inputStreamName)1234567891011121314public static byte[] readInputStream(InputStream inputStream, String inputStreamName) &#123; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); byte[] buffer = new byte[16 * 1024]; try &#123; int bytesRead = inputStream.read(buffer); while (bytesRead != -1) &#123; outputStream.write(buffer, 0, bytesRead); bytesRead = inputStream.read(buffer); &#125; &#125; catch (Exception e) &#123; throw new ActivitiException("couldn't read input stream " + inputStreamName, e); &#125; return outputStream.toByteArray();&#125; 1.3. DeploymentEntityImpl#addResource(ResourceEntity resource)123456public void addResource(ResourceEntity resource) &#123; if (resources == null) &#123; resources = new HashMap&lt;String, ResourceEntity&gt;(); &#125; resources.put(resource.getName(), resource);&#125; 1.4. RepositoryServiceImpl#deploy()123public Deployment deploy(DeploymentBuilderImpl deploymentBuilder) &#123; return commandExecutor.execute(new DeployCmd&lt;Deployment&gt;(deploymentBuilder));&#125; 1.5. DeployCmd#execute(CommandContext commandContext)12345678910111213public Deployment execute(CommandContext commandContext) &#123; // Backwards compatibility with Activiti v5 if (commandContext.getProcessEngineConfiguration().isActiviti5CompatibilityEnabled() &amp;&amp; deploymentBuilder.getDeploymentProperties() != null &amp;&amp; deploymentBuilder.getDeploymentProperties().containsKey(DeploymentProperties.DEPLOY_AS_ACTIVITI5_PROCESS_DEFINITION) &amp;&amp; deploymentBuilder.getDeploymentProperties().get(DeploymentProperties.DEPLOY_AS_ACTIVITI5_PROCESS_DEFINITION).equals(Boolean.TRUE)) &#123; return deployAsActiviti5ProcessDefinition(commandContext); &#125; return executeDeploy(commandContext);&#125; 1.6. DeployCmd#executeDeploy(CommandContext commandContext)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859protected Deployment executeDeploy(CommandContext commandContext) &#123; DeploymentEntity deployment = deploymentBuilder.getDeployment(); deployment.setDeploymentTime(commandContext.getProcessEngineConfiguration().getClock().getCurrentTime()); if (deploymentBuilder.isDuplicateFilterEnabled()) &#123; List&lt;Deployment&gt; existingDeployments = new ArrayList&lt;Deployment&gt;(); if (deployment.getTenantId() == null || ProcessEngineConfiguration.NO_TENANT_ID.equals(deployment.getTenantId())) &#123; DeploymentEntity existingDeployment = commandContext.getDeploymentEntityManager().findLatestDeploymentByName(deployment.getName()); if (existingDeployment != null) &#123; existingDeployments.add(existingDeployment); &#125; &#125; else &#123; List&lt;Deployment&gt; deploymentList = commandContext.getProcessEngineConfiguration().getRepositoryService().createDeploymentQuery().deploymentName(deployment.getName()) .deploymentTenantId(deployment.getTenantId()).orderByDeploymentId().desc().list(); if (!deploymentList.isEmpty()) &#123; existingDeployments.addAll(deploymentList); &#125; &#125; DeploymentEntity existingDeployment = null; if (!existingDeployments.isEmpty()) &#123; existingDeployment = (DeploymentEntity) existingDeployments.get(0); &#125; if ((existingDeployment != null) &amp;&amp; !deploymentsDiffer(deployment, existingDeployment)) &#123; return existingDeployment; &#125; &#125; deployment.setNew(true); // Save the data commandContext.getDeploymentEntityManager().insert(deployment); if (commandContext.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123; commandContext.getProcessEngineConfiguration().getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, deployment)); &#125; // Deployment settings Map&lt;String, Object&gt; deploymentSettings = new HashMap&lt;String, Object&gt;(); deploymentSettings.put(DeploymentSettings.IS_BPMN20_XSD_VALIDATION_ENABLED, deploymentBuilder.isBpmn20XsdValidationEnabled()); deploymentSettings.put(DeploymentSettings.IS_PROCESS_VALIDATION_ENABLED, deploymentBuilder.isProcessValidationEnabled()); // Actually deploy commandContext.getProcessEngineConfiguration().getDeploymentManager().deploy(deployment, deploymentSettings); if (deploymentBuilder.getProcessDefinitionsActivationDate() != null) &#123; scheduleProcessDefinitionActivation(commandContext, deployment); &#125; if (commandContext.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123; commandContext.getProcessEngineConfiguration().getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_INITIALIZED, deployment)); &#125; return deployment;&#125; 设置部署时间 2. 资源部署涉及到的表 ACT_RE_DEPLOYMENT: 存放流程定义的显示名称和部署时间, 每部署一次增加一条记录; ACT_RE_PROCDEF: 流程定义表, 存放流程定义的属性信息, 部署每个新的流程定义都会在这张表中增加一条记录, 当流程定义的 key 相同的时候, 使用的是版本升级 ACT_GE_BYTEARRAY: 资源文件表, 存储流程定义相关的二进制文件, 包括 XML 和图片.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(4)--CommandExecutor(命令执行器)]]></title>
    <url>%2Fblog%2F2019%2F02%2F21%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4-CommandExecutor-%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1. commandExecutor 对象的构造1.1. ProcessEngineConfigurationImpl#ProcessEngineConfigurationImpl()1234567public void initCommandExecutors() &#123; initDefaultCommandConfig(); initSchemaCommandConfig(); initCommandInvoker(); initCommandInterceptors(); initCommandExecutor();&#125; 该方法由 ProcessEngineConfigurationImpl#init() 调用, init 在创建 ProcessEngineConfigurationImpl 对象的时候已经分析过 第 5 行, 初始化命令拦截器 第 6 行, 初始化命令执行器 1.1.1. initCommandInterceptors() 方法Activiti 提供了命令拦截器的功能, 通过 API 对 Activiti 流程各个实例的操作本质上都是对 DB 的操作. 因此 Activiti 将每一个 CRUD 操作都封装为一个 Command, 然后交由命令执行器 CommandExecutor 去执行. 为了能让使用者可以对命令进行拦截, Activiti 还是用了 责任链模式, 使用者可以在其中添加相应的拦截器. 职责链让多个对象都有机会处理请求, 从而避免了请求发送者和接受者之间的耦合, 这些请求接受者将组成一条链, 并沿着这条链传递下去, 直到有一个对象处理了这个请求为止. 12345678910111213public void initCommandInterceptors() &#123; if (commandInterceptors == null) &#123; commandInterceptors = new ArrayList&lt;CommandInterceptor&gt;(); if (customPreCommandInterceptors != null) &#123; commandInterceptors.addAll(customPreCommandInterceptors); &#125; commandInterceptors.addAll(getDefaultCommandInterceptors()); if (customPostCommandInterceptors != null) &#123; commandInterceptors.addAll(customPostCommandInterceptors); &#125; commandInterceptors.add(commandInvoker); &#125;&#125; 该方法完成对所有拦截器的初始化 自定义前置拦截器: 需要开发者实现 CommandInterceptor 接口, 并配置到 Activiti 配置文件(activiti.cfg.xml)中 默认的拦截器: LogInterceptor: 日志拦截器, 用于打印执行的日志 TransactionInterceptor: 事务拦截器 CommandContextInterceptor: 命令上下文拦截器 自定义后置拦截器: 需要开发者实现 CommandInterceptor 接口, 并配置到 Activiti 配置文件中. 1.1.2. getDefaultCommandInterceptors()12345678910111213141516171819public Collection&lt;? extends CommandInterceptor&gt; getDefaultCommandInterceptors() &#123; List&lt;CommandInterceptor&gt; interceptors = new ArrayList&lt;CommandInterceptor&gt;(); interceptors.add(new LogInterceptor()); CommandInterceptor transactionInterceptor = createTransactionInterceptor(); if (transactionInterceptor != null) &#123; interceptors.add(transactionInterceptor); &#125; if (commandContextFactory != null) &#123; interceptors.add(new CommandContextInterceptor(commandContextFactory, this)); &#125; if (transactionContextFactory != null) &#123; interceptors.add(new TransactionContextInterceptor(transactionContextFactory)); &#125; return interceptors;&#125; 1.2. ProcessEngineConfigurationImpl#initCommandExecutor()123456public void initCommandExecutor() &#123; if (commandExecutor == null) &#123; CommandInterceptor first = initInterceptorChain(commandInterceptors); commandExecutor = new CommandExecutorImpl(getDefaultCommandConfig(), first); &#125;&#125; 将命令拦截器列表初始化为职责链 色织第一个拦截器 1.2.1 ProcessEngineConfigurationImpl#initInterceptorChain(List chain)123456789public CommandInterceptor initInterceptorChain(List&lt;CommandInterceptor&gt; chain) &#123; if (chain == null || chain.isEmpty()) &#123; throw new ActivitiException("invalid command interceptor chain configuration: " + chain); &#125; for (int i = 0; i &lt; chain.size() - 1; i++) &#123; chain.get(i).setNext(chain.get(i + 1)); &#125; return chain.get(0);&#125; 初始化命令拦截器链, 并返回其中的第一个拦截器 2. ProcessEngineConfigurationImpl#initService(Object service)在各个服务对象(如 RuntimeService, RepositoryService等)中, 都可以直接使用 CommandExecutor 来执行命令commandExecutor 对象由 RepositoryServiceImpl 的基类 ServiceImpl 声明 在 ProcessEngineConfigurationImpl 类的 initService(Object service) 方法中完成各个服务类的属性注入 12345public void initService(Object service) &#123; if (service instanceof ServiceImpl) &#123; ((ServiceImpl) service).setCommandExecutor(commandExecutor); &#125;&#125;]]></content>
      <categories>
        <category>activiti</category>
        <category>源码</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(3)--Spring配置风格源码分析1]]></title>
    <url>%2Fblog%2F2019%2F02%2F20%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3-Spring%E9%85%8D%E7%BD%AE%E9%A3%8E%E6%A0%BC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901%2F</url>
    <content type="text"><![CDATA[在分析源码之前, 先贴出一个典型的 Activiti 与 Spring 整合的配置文件: 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.spring.SpringProcessEngineConfiguration"&gt; &lt;!-- Spring 需要单独配置 DataSource --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="transactionManager" ref="transactionManager"/&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;/bean&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="driverClassName" value="org.h2.Driver"/&gt; &lt;property name="url" value="jdbc:h2:mem:activiti"/&gt; &lt;property name="username" value="sa"/&gt; &lt;property name="password" value=""/&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 流程引擎对象 --&gt; &lt;bean id="processEngine" class="org.activiti.spring.ProcessEngineFactoryBean"&gt; &lt;property name="processEngineConfiguration" ref="processEngineConfiguration"/&gt; &lt;/bean&gt; &lt;!-- 将服务暴露给 Spring --&gt; &lt;bean id="runtimeService" factory-bean="processEngine" factory-method="getRuntimeService"/&gt; &lt;bean id="repositoryService" factory-bean="processEngine" factory-method="getRepositoryService"/&gt; &lt;bean id="formService" factory-bean="processEngine" factory-method="getFormService"/&gt; &lt;bean id="taskService" factory-bean="processEngine" factory-method="getTaskService"/&gt; &lt;bean id="historyService" factory-bean="processEngine" factory-method="getHistoryService"/&gt; &lt;!-- 配置 activitiRule 用于测试 --&gt; &lt;bean id="activitiRule" class="org.activiti.engine.test.ActivitiRule"&gt; &lt;property name="processEngine" ref="processEngine"/&gt; &lt;/bean&gt;&lt;/beans&gt; 1. ProcessEngines 类1.1. init() 方法12345678910try &#123; resources = classLoader.getResources("activiti-context.xml");&#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("problem retrieving activiti-context.xml resources on the classpath: " + System.getProperty("java.class.path"), e);&#125;while (resources.hasMoreElements()) &#123; URL resource = resources.nextElement(); log.info("Initializing process engine using Spring configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromSpringResource(resource);&#125; 在前两篇文章中, 我们主要对常规模式(即不与 Spring 整合的初始化模式)做了简单介绍, 这篇文章我们对于 Spring 整合方式下的 ProcessEngine 初始化做一个简单分析. 读取 classpath 下的 activiti-context.xml 文件 将资源列表依次交由 initProcessEngineFromSpringResource(resource) 方法完成初始化 1.2. initProcessEngineFromSpringResource(URL resource) 方法123456789101112131415protected static void initProcessEngineFromSpringResource(URL resource) &#123; try &#123; Class&lt;?&gt; springConfigurationHelperClass = ReflectUtil.loadClass("org.activiti.spring.SpringConfigurationHelper"); Method method = springConfigurationHelperClass.getDeclaredMethod("buildProcessEngine", new Class&lt;?&gt;[] &#123; URL.class &#125;); ProcessEngine processEngine = (ProcessEngine) method.invoke(null, new Object[] &#123; resource &#125;); String processEngineName = processEngine.getName(); ProcessEngineInfo processEngineInfo = new ProcessEngineInfoImpl(processEngineName, resource.toString(), null); processEngineInfosByName.put(processEngineName, processEngineInfo); processEngineInfosByResourceUrl.put(resource.toString(), processEngineInfo); &#125; catch (Exception e) &#123; throw new ActivitiException("couldn't initialize process engine from spring configuration resource " + resource.toString() + ": " + e.getMessage(), e); &#125;&#125; 通过反射的方式加载目标类 org.activiti.spring.SpringConfigurationHelper 的 class 对象 通过反射的方式获取该类名为 buildProcessEngine , 参数列表为 URL 的方法对象 反射调用 org.activiti.spring.SpringConfigurationHelper#buildProcessEngine(URL resource) 方法 2. SpringConfigurationHelper 类2.1. buildProcessEngine(URL resource) 方法1234567891011121314public static ProcessEngine buildProcessEngine(URL resource) &#123; log.debug("==== BUILDING SPRING APPLICATION CONTEXT AND PROCESS ENGINE ========================================="); ApplicationContext applicationContext = new GenericXmlApplicationContext(new UrlResource(resource)); Map&lt;String, ProcessEngine&gt; beansOfType = applicationContext.getBeansOfType(ProcessEngine.class); if ((beansOfType == null) || (beansOfType.isEmpty())) &#123; throw new ActivitiException("no " + ProcessEngine.class.getName() + " defined in the application context " + resource.toString()); &#125; ProcessEngine processEngine = beansOfType.values().iterator().next(); log.debug("==== SPRING PROCESS ENGINE CREATED =================================================================="); return processEngine; &#125; 使用传入的 activiti-context.xml 文件创建 ApplicationContext 对象 通过 ApplicationContext 获取类型为 ProcessEngine 的所有对象, 返回值为 Map&lt;beanId, ProcessEngine 对象&gt; 通过遍历获取其中第一个 value 并返回 在执行第 1 步的时候, 就会触发 Spring Application Context 管理的对应对象的初始化. 对应开始时贴出来的配置文件范例, 在初始化 &lt;processEngine, ProcessEngineFactoryBean&gt; 前, 需要先初始化 &lt;processEngineConfiguration, SpringProcessEngineConfiguration&gt; 对象 2.2 SpringProcessEngineConfiguration 对象的默认构造方法123456public SpringProcessEngineConfiguration() &#123; this.transactionsExternallyManaged = true; deploymentStrategies.add(new DefaultAutoDeploymentStrategy()); deploymentStrategies.add(new SingleResourceAutoDeploymentStrategy()); deploymentStrategies.add(new ResourceParentFolderAutoDeploymentStrategy());&#125; 2.3. ProcessEngine 对象的 getObject() 方法1234567891011public ProcessEngine getObject() throws Exception &#123; configureExpressionManager(); configureExternallyManagedTransactions(); if (processEngineConfiguration.getBeans() == null) &#123; processEngineConfiguration.setBeans(new SpringBeanFactoryProxyMap(applicationContext)); &#125; this.processEngine = processEngineConfiguration.buildProcessEngine(); return this.processEngine;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(2)--流程引擎类]]></title>
    <url>%2Fblog%2F2019%2F02%2F18%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-2-%E6%B5%81%E7%A8%8B%E5%BC%95%E6%93%8E%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[在上一篇文章中, 我们跟踪了流程引擎配置类对象的创建过程, 今天紧接着来看 Activiti 在获取到流程引擎配置类之后, 如何完成流程引擎的初始化. 1. ProcessEngineConfiguration 类1.1. buildProcessEngine(URL resource) 方法123456789101112private static ProcessEngine buildProcessEngine(URL resource) &#123; InputStream inputStream = null; try &#123; inputStream = resource.openStream(); ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(inputStream); return processEngineConfiguration.buildProcessEngine(); &#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("couldn't open resource stream: " + e.getMessage(), e); &#125; finally &#123; IoUtil.closeSilently(inputStream); &#125;&#125; 在该方法中, 上一篇文章我们讲了第 5 行代码的源码调用关系, 最终创建了 ProcessEngineConfiguration 对象, 这篇文章中我们来讲第 6 行是如何创建 ProcessEngine 对象的. 1.2. buildProcessEngine() 方法该方法是一个抽象方法, 实现类分别有: MultiSchemaMultiTenantProcessEngineConfiguration ProcessEngineConfigurationImpl SpringProcessEngineConfiguration 在本例中, 最终会调用 ProcessEngineConfigurationImpl 的 buildProcessEngine() 方法, 因为我们在 activiti.cfg.xml 中的配置如下: 12345&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- ... --&gt;&lt;/bean&gt; 使用的是 StandaloneProcessEngineConfiguration, 而打开该类发现该类没有 buildProcessEngine() 方法的实现, 因此实现方法在其父类 ProcessEngineConfigurationImpl 中. 2. ProcessEngineConfigurationImpl 类2.1. buildProcessEngine() 方法1234567891011public ProcessEngine buildProcessEngine() &#123; init(); ProcessEngineImpl processEngine = new ProcessEngineImpl(this); // trigger build of Activiti 5 Engine if (isActiviti5CompatibilityEnabled &amp;&amp; activiti5CompatibilityHandler != null) &#123; Context.setProcessEngineConfiguration(processEngine.getProcessEngineConfiguration()); activiti5CompatibilityHandler.getRawProcessEngine(); &#125; postProcessEngineInitialisation(); return processEngine;&#125; 2.2. init()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void init() &#123; initConfigurators(); configuratorsBeforeInit(); initProcessDiagramGenerator(); initHistoryLevel(); initExpressionManager(); if (usingRelationalDatabase) &#123; initDataSource(); &#125; initAgendaFactory(); initHelpers(); initVariableTypes(); initBeans(); initFormEngines(); initFormTypes(); initScriptingEngines(); initClock(); initBusinessCalendarManager(); initCommandContextFactory(); initTransactionContextFactory(); initCommandExecutors(); initServices(); initIdGenerator(); initBehaviorFactory(); initListenerFactory(); initBpmnParser(); initProcessDefinitionCache(); initProcessDefinitionInfoCache(); initKnowledgeBaseCache(); initJobHandlers(); initJobManager(); initAsyncExecutor(); initTransactionFactory(); if (usingRelationalDatabase) &#123; initSqlSessionFactory(); &#125; initSessionFactories(); initDataManagers(); initEntityManagers(); initHistoryManager(); initJpa(); initDeployers(); initDelegateInterceptor(); initEventHandlers(); initFailedJobCommandFactory(); initEventDispatcher(); initProcessValidator(); initDatabaseEventLogging(); initActiviti5CompatibilityHandler(); configuratorsAfterInit(); &#125; 可以看到 init() 是一个非常大的方法, 其内容主要是各种初始化操作的执行, 其中有些比较重要的需要单独讲解. 如果使用关系型数据库, 其实 usingRelationalDatabase 变量默认为 true, 代表目前只支持关系型数据库, 就会使用 initRelationalDatabase() 方法完成数据库相关的初始化操作. 2.3. initRelationalDatabase()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void initDataSource() &#123; if (dataSource == null) &#123; if (dataSourceJndiName != null) &#123; try &#123; dataSource = (DataSource) new InitialContext().lookup(dataSourceJndiName); &#125; catch (Exception e) &#123; throw new ActivitiException("couldn't lookup datasource from " + dataSourceJndiName + ": " + e.getMessage(), e); &#125; &#125; else if (jdbcUrl != null) &#123; if ((jdbcDriver == null) || (jdbcUsername == null)) &#123; throw new ActivitiException("DataSource or JDBC properties have to be specified in a process engine configuration"); &#125; log.debug("initializing datasource to db: &#123;&#125;", jdbcUrl); PooledDataSource pooledDataSource = new PooledDataSource(ReflectUtil.getClassLoader(), jdbcDriver, jdbcUrl, jdbcUsername, jdbcPassword); if (jdbcMaxActiveConnections &gt; 0) &#123; pooledDataSource.setPoolMaximumActiveConnections(jdbcMaxActiveConnections); &#125; if (jdbcMaxIdleConnections &gt; 0) &#123; pooledDataSource.setPoolMaximumIdleConnections(jdbcMaxIdleConnections); &#125; if (jdbcMaxCheckoutTime &gt; 0) &#123; pooledDataSource.setPoolMaximumCheckoutTime(jdbcMaxCheckoutTime); &#125; if (jdbcMaxWaitTime &gt; 0) &#123; pooledDataSource.setPoolTimeToWait(jdbcMaxWaitTime); &#125; if (jdbcPingEnabled == true) &#123; pooledDataSource.setPoolPingEnabled(true); if (jdbcPingQuery != null) &#123; pooledDataSource.setPoolPingQuery(jdbcPingQuery); &#125; pooledDataSource.setPoolPingConnectionsNotUsedFor(jdbcPingConnectionNotUsedFor); &#125; if (jdbcDefaultTransactionIsolationLevel &gt; 0) &#123; pooledDataSource.setDefaultTransactionIsolationLevel(jdbcDefaultTransactionIsolationLevel); &#125; dataSource = pooledDataSource; &#125; if (dataSource instanceof PooledDataSource) &#123; // ACT-233: connection pool of Ibatis is not properly // initialized if this is not called! ((PooledDataSource) dataSource).forceCloseAll(); &#125; &#125; if (databaseType == null) &#123; initDatabaseType(); &#125;&#125; 如果 dataSource 对象为空, 就初始化一个 PooledDataSource 对象, 根据默认的 jdbcUrl, jdbcDriver, jdbcUsername 等变量创建一个数据库连接, 而上述的默认值则对应 Activiti 内置的内存数据库 H2, 说明如果不设置 dataSource, Activiti 就会使用内置的 H2 数据库完成 dataSource 的初始化. databaseType 用于标识数据库类型, 如果该变量为空, 需要调用 initDatabaseType() 来完成数据库类型的赋值. 2.4. initDatabaseType() 方法12345678910111213141516171819202122232425262728293031public void initDatabaseType() &#123; Connection connection = null; try &#123; connection = dataSource.getConnection(); DatabaseMetaData databaseMetaData = connection.getMetaData(); String databaseProductName = databaseMetaData.getDatabaseProductName(); log.debug("database product name: '&#123;&#125;'", databaseProductName); databaseType = databaseTypeMappings.getProperty(databaseProductName); if (databaseType == null) &#123; throw new ActivitiException("couldn't deduct database type from database product name '" + databaseProductName + "'"); &#125; log.debug("using database type: &#123;&#125;", databaseType); // Special care for MSSQL, as it has a hard limit of 2000 params per statement (incl bulk statement). // Especially with executions, with 100 as default, this limit is passed. if (DATABASE_TYPE_MSSQL.equals(databaseType)) &#123; maxNrOfStatementsInBulkInsert = DEFAULT_MAX_NR_OF_STATEMENTS_BULK_INSERT_SQL_SERVER; &#125; &#125; catch (SQLException e) &#123; log.error("Exception while initializing Database connection", e); &#125; finally &#123; try &#123; if (connection != null) &#123; connection.close(); &#125; &#125; catch (SQLException e) &#123; log.error("Exception while closing the Database connection", e); &#125; &#125;&#125; 获取一个数据库连接 通过该连接获取元数据信息, 得到数据库产品的名称 通过该名称去获取内部实现保存的数据库名称 Properties 集合, 如果为空说明不支持该数据库 通过存在就将 databaseType 完成赋值 2.5. 回到 buildProcessEngine() 方法123456789101112131415@Overridepublic ProcessEngine buildProcessEngine() &#123; init(); ProcessEngineImpl processEngine = new ProcessEngineImpl(this); // trigger build of Activiti 5 Engine if (isActiviti5CompatibilityEnabled &amp;&amp; activiti5CompatibilityHandler != null) &#123; Context.setProcessEngineConfiguration(processEngine.getProcessEngineConfiguration()); activiti5CompatibilityHandler.getRawProcessEngine(); &#125; postProcessEngineInitialisation(); return processEngine; &#125; init() 方法结束后, 已经完成了相关资源的初始化 使用 ProcessEngineConfiguration 对象去创建 ProcessEngineImpl, xxxService 核心服务对象都是通过 ProcessEngineConfiguration 对象中的同类对象完成的初始化. 如果开启 Activiti5 兼容功能, 并且 activiti5CompatibilityHandler(Activiti5兼容处理器对象) 不为空, 执行兼容初始化逻辑, 正常情况下不走该逻辑. 执行 postProcessEngineInitialisation() 2.6. postProcessEngineInitialisation()12345protected void postProcessEngineInitialisation() &#123; if (performanceSettings.isValidateExecutionRelationshipCountConfigOnBoot()) &#123; commandExecutor.execute(new ValidateExecutionRelatedEntityCountCfgCmd()); &#125;&#125; 使用该方法来检查是否使用了流程实例相关数量记录(validateExecutionRelationshipCountConfigOnBoot 配置的默认值为 true, 默认开启) 使用命令执行器执行 ValidateExecutionRelatedEntityCountCfgCmd 3. ValidateExecutionRelatedEntityCountCfgCmd 类实现了 Command 接口, 命令执行器执行的时候会自动调用其 execute(CommandContext commandContext) 方法. 3.1. execute(CommandContext commandContext) 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Overridepublic Void execute(CommandContext commandContext) &#123; /* * If execution related entity counting is on in config | Current property in database : Result * * A) true | not there : write new property with value 'true' * B) true | true : all good * C) true | false : the feature was disabled before, but it is enabled now. Old executions will have a local flag with false. * It is now enabled. This is fine, will be handled in logic. Update the property. * * D) false | not there: write new property with value 'false' * E) false | true : the feature was disabled before and enabled now. To guarantee data consistency, we need to remove the flag from all executions. * Update the property. * F) false | false : all good * * In case A and D (not there), the property needs to be written to the db * Only in case E something needs to be done explicitely, the others are okay. */ PropertyEntityManager propertyEntityManager = commandContext.getPropertyEntityManager(); boolean configProperty = commandContext.getProcessEngineConfiguration().getPerformanceSettings().isEnableExecutionRelationshipCounts(); PropertyEntity propertyEntity = propertyEntityManager.findById(PROPERTY_EXECUTION_RELATED_ENTITY_COUNT); if (propertyEntity == null) &#123; // 'not there' case in the table above: easy, simply insert the value PropertyEntity newPropertyEntity = propertyEntityManager.create(); newPropertyEntity.setName(PROPERTY_EXECUTION_RELATED_ENTITY_COUNT); newPropertyEntity.setValue(Boolean.toString(configProperty)); propertyEntityManager.insert(newPropertyEntity); &#125; else &#123; boolean propertyValue = Boolean.valueOf(propertyEntity.getValue().toString().toLowerCase()); if (!configProperty &amp;&amp; propertyValue) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Configuration change: execution related entity counting feature was enabled before, but now disabled. " + "Updating all execution entities."); &#125; commandContext.getProcessEngineConfiguration().getExecutionDataManager().updateAllExecutionRelatedEntityCountFlags(configProperty); &#125; // Update property if (configProperty != propertyValue) &#123; propertyEntity.setValue(Boolean.toString(configProperty)); propertyEntityManager.update(propertyEntity); &#125; &#125; return null;&#125; 去数据库中的 ACT_GE_PROPERTY 表查询 id 为 cfg.execution-related-entities-count 的记录. 如果没有查到, 则插入一条 cfg.execution-related-entities-count, false 的记录 如果查到, 将该记录中的值转换为小写字符串, 转换为 boolean 值 如果配置的值不等于 DB 中存储的值, 那么将 DB 的值更新为配置的值 最终初始化代码执行完成后, 会在 DB 中存在这样一条记录 执行完毕后, 此时 ProcessEngine 对象已经初始化完成. 调用关系如下:]]></content>
  </entry>
  <entry>
    <title><![CDATA[关系型数据库的瓶颈与优化]]></title>
    <url>%2Fblog%2F2019%2F01%2F19%2F%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%93%B6%E9%A2%88%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[1. 数据库的分类数据库大致可以分为两部分: 传统的关系型数据库, 如: MySQL, Oracle, SQLServer 以及 PostgreSQL; MySQL 是国内使用最广泛的数据库, Oracle 在传统行业应用最为广泛, PostgreSQL 性能和功能都比较完善, 但目前文档和社区还有待成长. 非关系型数据库, 如 HBase(列式数据库), MongoDB(文档型数据库), Redis(高性能 KV 存储), Lucene(搜索引擎) 等等. 2. 关系型数据库的瓶颈与优化2.1 为什么数据库的架构需要调整 互联网的数据增长往往是指数型的; 读写分离, 分布式: 单机性能上存在瓶颈; NoSQL, 搜索引擎: 特殊场景的需求无法满足; 分析系统: 无法满足大数据的分析需求; 部署要求: 同城容灾/异地容灾. 2.2 数据库会遇到什么问题2.2.1 性能 查询性能 写入更新 并发, 数据量等 2.2.2 功能 新功能: LBS/JSON/特殊业务场景 数据安全性: 强一致性/非强一致性 大数据分析 搜索等 3. 不同业务场景的存储选型3.1 一个简单的问题MySQL 已经有 cache 了, 为何还需要加一层 Redis3.2 数据库查询开销 其中比较耗时的步骤有: 建立 TCP 连接 生成执行计划 开表 从磁盘扫描数据 关闭连接 3.2.1 SQL 解析假设有如下三条语句, 均是根据主键的查询. 12345678910# 1 SELECT id, name, price FROM products WHERE id IN (1, 2, 3, 4, ... 30000); # (1-2s)# 2. 将第一条查询转换成 30000 条语句SELECT id, name, price FROM products WHERE id = 1;...SELECT id, name, price FROM products WHERE id = 30000; # (2-3s)# 3. 将第一条转换成 OR 语句SELECT id, name, price FROM products WHERE id = 1 OR id = 2 OR ... OR id = 30000; # (8-10s) 造成第三条语句执行时间如此长的主要原因就是大量的 OR 语句会导致 SQL 解析非常耗时. 3.2.2 以 MySQL 的 InnoDB 存储引擎主键查询为例1SELECT * FROM t WHERE id = ?; 常规配置的服务器基本可以达到 400000 QPS. 3.2.3 如果查询条件不是主键1SELECT * FROM t WHERE name = ?; 对于非主键的查询, MySQL 会根据二级索引查询到主索引对应节点的位置. 按照图中的情况, 会首先通过三次 IO 找到对应主键, 在二级索引的叶子节点会同时保存索引字段的值以及主键的值, 再回到主索引通过主键查询到整条记录. 在 MySQL 中, 主键查询时最为高效的一类查询. DBA 往往希望所有的 SQL 语句都是 KV 查询, 但是往往是不现实的. 主键查询有限, 有些主键没有业务含义; 设计表结构时, 并没有考虑过主键问题. SQL 语句允许开发人员用各种方式从表中获取数据, 但 DBA 却不会希望我们这么做. 3.2.3 数据库的大字段1content varchar(2046) NOT NULL COMMENT '原始消息'; 以 InnoDB 存储引擎为例: TinyText/Text/Mediumtext varchar(256)/varchar(500)/varchar(20000) tinyBlob/blob/mediumBlob text 类型本质上和 varchar 类型没有区别. MySQL 中, 数据是以页的方式来组织的, 每个数据页默认大小 16 KB, 其中包括页头, 页尾, 中间是一行一行的记录. 图中的每条记录包括 ID, NAME, AGE 和 DETAIL. 假设 DETAIL 是一个大字段, 达到超过了单页的大小, 此时 DB 会新开一个数据页, 当前页通过指针指向该页. 如果一页依然不够, MySQL 就会不断新加数据页直到能够存下为止. 一旦存在这样的大字段, 会带来如下问题: 查询开销大; 查询影响大, 严重时会触发热页换出, 引起系统抖动. MySQL 将记录从磁盘读取出来的时候, 可能会有很多数据页, MySQL 自带缓存时非常宝贵的, 会导致真正使用频率高的数据页被替换成大字段的数据页. 此外, 对 MySQL 来说, 即便只查记录中的某几个字段, 数据库依然会把整条记录取出, 读进内存, 再进行指定字段的筛选 对于大字段场景可以尝试的优化方案: 是否适合存储关系型数据库; 是否所有数据都需要存数据库; 是否可以新建一张表存储大字段. 3.2.4 数据库缓存利用率以 InnoDB 存储引擎为例: MySQL 默认数据页为 16KB, 哪怕只读一行记录, 也需要从磁盘中取出 16KB 数据取出; MySQL 是以页为最小的缓存单位; 如果每行数据 1kb, 256kb 内存空间能缓存多少行有效数据, 最好的情况是每条数据整齐排列在一个数据页中, 那么可以缓存256条记录, 最坏的情况下每一页只存在一条数据, 那么就只能缓存16条; 在 256KB 的 Buffer Pool 中, 并不是所有空间都用来做数据页缓存, 有很大的一块在 Write Buffer(MySQL 为了优化写操作, 会将一段时间内的写操作先放在 Write Buffer, 再由后台线程定时异步刷新到磁盘上). 然而剩下的 128KB 中还存在一部分脏页. 缓存为什么如此重要: 互联网产品往往读多写少; 扩展缓存远比扩展 DB 简单; 数据库缓存利用率很低; 互联网应用对 DB 响应时间比较敏感, 缓存系统一般性能比较好 只要符合条件的数据都应该走缓存: 修改不频繁的数据; 非实时的数据, 一致性要求不严的数据; 查询频率较高, 带有明显热点请求的数据; 3.2.5 缓存带来的问题 用了缓存并不一定代表没有问题 缓存命中 缓存穿透 缓存失效 缓存一致 3.2.6 选择正确的索引 降低扫描数据量还是降低排序代价 大多数查询只能使用一个索引, 因此在需要对多个列进行操作的 SQL 语句中, 我们需要准确评估每个索引的开销. key idx_create_time(createTime) key idx_price(price)1SELECT * FROM tb_order WHERE createTime &gt; xxx AND createTime &lt; xxx ORDER BY price DESC; 3.2.7 索引的使用3.2.7.1 索引字段过长, 超过索引支持1234# name varchar(512)# ket idx_name(name(100))SELECT * FROM comment WHERE name &gt;= 'destiny' ORDER BY name ASC LIMIT 100; 上面的例子在实际场景中执行非常慢, 使用 EXPLAIN 打印查询计划: select_type: SIMPLE table: comment type: range possible_keys: id_name key: uk_sess key_len: 403 ref: NULL rows: 462642 Extra:Using where; Using filesort 1 row in set(0.00sec) 其中需要重点关注的是: Extra:Using where; Using filesort Using where: 表用到了索引 Using filesort: MySQL 自带的磁盘排序, 并没有用到索引的排序 问题是为什么使用了索引, 查询效率依然非常慢? 真正的原因是字段太长, 而索引的长度只能覆盖 256 字节, 导致 ORDER BY 无法在内存中完成排序 3.2.7.2查询某个用户 id 的分值总和 123456-- uid varchar(190) NOT NULL DEFAULT '' COMMENT '用户 id',-- score bigint(20) NOT NULL DEFAULT '0' COMMENT '变动分值, 正增, 负减',-- primary key ID-- KEY idx_uid(uid)SELECT SUM(score) FROM name WHERE uid = '5993156' 这条 SQL 的执行顺序: 根据二级索引 uid 找到所有主键 id 再根据主键逐行找到 score 对 score 进行聚合 这个 SQL 的问题在于需要进行大量的回表操作(从二级索引回到一级索引), 然后将全部符合过滤条件的记录放在内存中完成聚合操作. 改进的方法其实很简单, 可以尝试使用 (uid, score) 建立联合索引, 这样只需要查询二级索引就可以获得全部数据. 随机插入 100W 条数据, 现在对比下两条索引的开销. 3.3 数据库写开销 对持久化要求严格, 写操作代价大 日志文件需要 fsync, 硬件存在瓶颈 数据库写操作很难扩展 主从要求一致场景下还要算上网络开销 将 3 所在的数据页读到缓存中; 在内存中将 3 改成 5, 提交事务, 触发 Redo Log 的刷新; 向用户返回操作成功; 3.4 业务场景触发的高并发写入3.4.1 秒杀 高并发写入的极端情况 业务优化(缓存/令牌通/排队/Java 信号量/乐观锁) 热点资源隔离 引入数据库线程池 InnoDB 内核层优化: AliSQL 3.4.2 私信/站内信消息推送 高并发写入 伴随大量的读请求 系统消息/个人消息区分对待 消息内容单独对待 延迟写入, 通过队列/缓存达到限流目的 3.4.3 听歌量 业务原因导致写入量非常大 插入更新比不确定, 更新能力强 数据库需要具备自动扩展的能力 数据非强一致 3.5 死锁和超时 InnoDB 锁超时默认需要 5s 等待 死锁马上就能被发现, 然后被 DB 自动回滚 锁超时一般是索引不对, 或者 SQL 语句执行性能较差 死锁一般是业务实现有问题 锁超时一般影响较为可控 死锁情况比较严重, 会导致全站崩溃 3.6 数据库并发事务, 锁 业务流程中的锁: 减库存, 发优惠券 悲观锁实现:12345BEGIN;SELECT count FROM tb WHERE id = ? FOR UPDATE;-- do sthUPDATE tb SET count = count - ? WHERE id = ?;COMMIT; 乐观锁实现:12345BEGIN;SELECT count FROM tb WHERE id = ?;UPDATE tb SET count = count - ? WHERE id = ? AND count = :count;COMMIT;-- do sth 4. 数据库的模块化拆分4.1 单机服务器的局限 虽然硬件配置越来越高, 但是总有瓶颈(e.g. CPU/内存/网络/IO/容量) 为了后续业务的可扩展性 单机系统崩溃风险较高 优化性能 读写分离 冷热分离, 创建归档库 关键链路和非关键链路隔离 系统层面做好降级 4.2 常见拆分方案4.2.1 读写分离读写分离的原理就是将数据库读写操作分散到不同的节点上 读写分离的基本原理就是: 数据库服务器搭建主从集群; 数据库主机负责写操作, 从机只负责读操作; 数据库主机通过复制将数据同步到从机, 每台数据库服务器都存储了所有业务数据. 业务服务器将写操作发给数据库主机, 将读操作发给数据库从机. 使用读写分离之后, 可能会引入两个问题: 主从复制延迟 分配机制 4.2.1.1 复制延迟主从复制的延迟可能达到秒级, 如果有大量数据短时间需要完成同步, 延迟甚至可能达到分钟. 主从复制所带来的问题: 如果业务服务器将数据写入到主库后进行读取, 此时读操作访问从库, 而主库的数据没有完全复制过来, 从库是无法读取到最新数据的. 解决方案: 写操作后的读操作指定发给主库, 逻辑会和业务强绑定, 对业务侵入较大. 读从库失败后再读一次主库, 如果有大量没有命中从库的读请求, 会给主库带来较大压力. 关键业务读写操作全部走主库, 非关键业务采用读写分离. 4.2.1.2 分配机制将读写操作区分开来, 然后访问不同的数据库服务器, 一般有两种方式: 程序代码封装和中间件封装 1. 程序代码封装在代码中抽象一个数据访问层, 实现读写操作分离和数据库服务器连接的管理. 特点: 实现简单, 可以根据业务定制化; 无法做到多语言通用, 容易重复开发; 故障情况下, 如果主从发生切换, 需要将系统配置手动修改. 2. 中间件封装独立一套系统出来, 实现读写分离和数据库服务器连接的管理, 中间件对业务服务器提供 SQL 兼容的协议, 业务服务器无需自己进行读写分离, 对于业务服务器来说, 访问中间件和访问数据库没有区别 特点: 能够支持多种编程语言, 因为数据库中间件对业务提供的是标准的 SQL 接口. 实现较为复杂, 需要完整支持 SQL 语法和数据库服务器的协议. 性能要求很高, 容易成为瓶颈. 数据库主从切换对业务服务器无感知, 数据库中间件可以探测数据库服务器的主从状态(e.g. 向某个测试库写入一条数据, 成功的是主机, 失败的是从机) 4.2.2 分布式读写分离分散了读写操作的压力, 但没有分散存储的压力, 当数据量达到千万级以上的时候, 单台数据库服务器的存储能力就会成为瓶颈: 数据量太大, 读写的性能会大幅下降. 数据文件备份和恢复都会很困难. 垂直分表: 适合将某些表中不常用且占用大量空间的列拆分出去. 代价是操作表的数量增加. 水平拆分: 适合行数较大的表, 会引入更多的复杂度: 路由, join 操作, count 操作 等]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>关系型数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti源码分析(1)--流程引擎配置类]]></title>
    <url>%2Fblog%2F2018%2F12%2F31%2FActiviti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1-%E5%BC%95%E6%93%8E%E9%85%8D%E7%BD%AE%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[Activiti 配置风格获取引擎源码分析: 流程引擎管理类 ProcessEngines 1234567891011121314151617181920212223242526272829@Testpublic void testProcessEngine() &#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); log.info("processEngine: &#123;&#125;", processEngine); // org.activiti.engine.impl.ProcessEngineImpl@66ea1466 Class&lt;? extends ProcessEngine&gt; processEngineClass = processEngine.getClass(); log.info("class: &#123;&#125;", processEngineClass); // org.activiti.engine.impl.ProcessEngineImpl DynamicBpmnService dynamicBpmnService = processEngine.getDynamicBpmnService(); FormService formEngineFormService = processEngine.getFormEngineFormService(); FormRepositoryService formEngineRepositoryService = processEngine.getFormEngineRepositoryService(); org.activiti.engine.FormService formService = processEngine.getFormService(); HistoryService historyService = processEngine.getHistoryService(); IdentityService identityService = processEngine.getIdentityService(); ManagementService managementService = processEngine.getManagementService(); ProcessEngineConfiguration processEngineConfiguration = processEngine.getProcessEngineConfiguration(); // 流程引擎配置类 RepositoryService repositoryService = processEngine.getRepositoryService(); RuntimeService runtimeService = processEngine.getRuntimeService(); // 运行时 TaskService taskService = processEngine.getTaskService(); // 任务相关 log.info("dynamicBpmnService: &#123;&#125;", dynamicBpmnService); // org.activiti.engine.impl.DynamicBpmnServiceImpl@1601e47 log.info("formEngineFormService: &#123;&#125;", formEngineFormService); // null log.info("formEngineRepositoryService: &#123;&#125;", formEngineRepositoryService); // null log.info("formService: &#123;&#125;", formService); // org.activiti.engine.impl.FormServiceImpl@3bffddff log.info("historyService: &#123;&#125;", historyService); // org.activiti.engine.impl.HistoryServiceImpl@66971f6b log.info("identityService: &#123;&#125;", identityService); // org.activiti.engine.impl.IdentityServiceImpl@50687efb log.info("managementService: &#123;&#125;", managementService); // org.activiti.engine.impl.ManagementServiceImpl@517bd097 log.info("processEngineConfiguration: &#123;&#125;", processEngineConfiguration); // org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration@142eef62 log.info("repositoryService: &#123;&#125;", repositoryService); // org.activiti.engine.impl.RepositoryServiceImpl@4a9cc6cb log.info("runtimeService: &#123;&#125;", runtimeService); // org.activiti.engine.impl.RuntimeServiceImpl@5990e6c5 log.info("taskService: &#123;&#125;", taskService); // org.activiti.engine.impl.TaskServiceImpl@56e07a08&#125; 总的来说流程引擎配置类(ProcessEngineConfiguration) 的获取比较简单, 通过默认配置找到 classpath 下的 activiti.cfg.xml 配置文件, 再将该配置文件使用 Spring 的组件完成读取, 将 id 为 processEngineConfiguration 的 bean 完成初始化并返回. 1. ProcessEngines包含四个重要的集合 1234567891011// &lt;流程引擎名称, 流程引擎实例&gt;protected static Map&lt;String, ProcessEngine&gt; processEngines = new HashMap&lt;String, ProcessEngine&gt;();// &lt;流程引擎名称, 流程引擎信息类实例&gt;protected static Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByName = new HashMap&lt;String, ProcessEngineInfo&gt;();// &lt;构造流程引擎的资源名称(如文件路径名), 流程引擎信息类实例&gt;protected static Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByResourceUrl = new HashMap&lt;String, ProcessEngineInfo&gt;();// 存储流程引擎信息类实例对象protected static List&lt;ProcessEngineInfo&gt; processEngineInfos = new ArrayList&lt;ProcessEngineInfo&gt;(); 1.1. getDefaultProcessEngine方法体中只有一行代码 123public static ProcessEngine getDefaultProcessEngine() &#123; return getProcessEngine(NAME_DEFAULT);&#125; 类中 NAME_DEFAULT 的值是 default 1.2. getProcessEngine(String processEngineName)123456public static ProcessEngine getProcessEngine(String processEngineName) &#123; if (!isInitialized()) &#123; init(); &#125; return processEngines.get(processEngineName);&#125; 判断该类是否已经被初始化 如果没有初始化, 执行 init() 方法 返回 Map&lt;String, ProcessEngine&gt; processEngines 对应 key 的实例对象 1.2.1. isInitialized()返回类中一个静态常量, 用于标识 1protected static boolean isInitialized; 1.3. init()1234567891011121314151617181920212223242526272829303132333435363738394041public synchronized static void init() &#123; if (!isInitialized()) &#123; if (processEngines == null) &#123; // Create new map to store process-engines if current map is // null processEngines = new HashMap&lt;String, ProcessEngine&gt;(); &#125; ClassLoader classLoader = ReflectUtil.getClassLoader(); Enumeration&lt;URL&gt; resources = null; try &#123; resources = classLoader.getResources("activiti.cfg.xml"); &#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("problem retrieving activiti.cfg.xml resources on the classpath: " + System.getProperty("java.class.path"), e); &#125; // Remove duplicated configuration URL's using set. Some // classloaders may return identical URL's twice, causing duplicate // startups Set&lt;URL&gt; configUrls = new HashSet&lt;URL&gt;(); while (resources.hasMoreElements()) &#123; configUrls.add(resources.nextElement()); &#125; for (Iterator&lt;URL&gt; iterator = configUrls.iterator(); iterator.hasNext();) &#123; URL resource = iterator.next(); log.info("Initializing process engine using configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromResource(resource); &#125; try &#123; resources = classLoader.getResources("activiti-context.xml"); &#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("problem retrieving activiti-context.xml resources on the classpath: " + System.getProperty("java.class.path"), e); &#125; while (resources.hasMoreElements()) &#123; URL resource = resources.nextElement(); log.info("Initializing process engine using Spring configuration '&#123;&#125;'", resource.toString()); initProcessEngineFromSpringResource(resource); &#125; setInitialized(true); &#125; else &#123; log.info("Process engines already initialized"); &#125;&#125; 再判断是否已经初始化 如果未初始化, 先初始化 Map&lt;String, ProcessEngine&gt; processEngines 获取当前类加载器 使用该类加载器指定加载 activiti.cfg.xml 路径下的资源, 并保存在 Set 中 遍历 Set 集合执行 initProcessEngineFromResource(URL resource) 获取 spring 风格配置文件 将类中 initialized 设置为 true 如果已被初始化, 直接返回 1.4. initProcessEngineFromResource(URL resourceUrl)123456789101112131415161718192021222324252627282930private static ProcessEngineInfo initProcessEngineFromResource(URL resourceUrl) &#123; ProcessEngineInfo processEngineInfo = processEngineInfosByResourceUrl.get(resourceUrl.toString()); // if there is an existing process engine info if (processEngineInfo != null) &#123; // remove that process engine from the member fields processEngineInfos.remove(processEngineInfo); if (processEngineInfo.getException() == null) &#123; String processEngineName = processEngineInfo.getName(); processEngines.remove(processEngineName); processEngineInfosByName.remove(processEngineName); &#125; processEngineInfosByResourceUrl.remove(processEngineInfo.getResourceUrl()); &#125; String resourceUrlString = resourceUrl.toString(); try &#123; log.info("initializing process engine for resource &#123;&#125;", resourceUrl); ProcessEngine processEngine = buildProcessEngine(resourceUrl); String processEngineName = processEngine.getName(); log.info("initialised process engine &#123;&#125;", processEngineName); processEngineInfo = new ProcessEngineInfoImpl(processEngineName, resourceUrlString, null); processEngines.put(processEngineName, processEngine); processEngineInfosByName.put(processEngineName, processEngineInfo); &#125; catch (Throwable e) &#123; log.error("Exception while initializing process engine: &#123;&#125;", e.getMessage(), e); processEngineInfo = new ProcessEngineInfoImpl(null, resourceUrlString, getExceptionString(e)); &#125; processEngineInfosByResourceUrl.put(resourceUrlString, processEngineInfo); processEngineInfos.add(processEngineInfo); return processEngineInfo;&#125; 根据路径尝试从 Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByResourceUrl 获取流程引擎类实例 如果不为空 将 List&lt;ProcessEngineInfo&gt; processEngineInfos 中对应的元素删除 流程引擎信息类实例没有 Exception, 将 Map&lt;String, ProcessEngine&gt; processEngines 和 Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByName 中 key 对应的元素都删除 Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByResourceUrl 中 key 对应的元素也删除. 通过 buildProcessEngine 方法获取 ProcessEngine 对象 将 Map&lt;String, ProcessEngine&gt; processEngines 和 Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByName 设置对应的 key 和 value 将 Map&lt;String, ProcessEngineInfo&gt; processEngineInfosByResourceUrl 和 List&lt;ProcessEngineInfo&gt; processEngineInfos 也添加对应元素 1.5. buildProcessEngine(URL resource)123456789101112private static ProcessEngine buildProcessEngine(URL resource) &#123; InputStream inputStream = null; try &#123; inputStream = resource.openStream(); ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(inputStream); return processEngineConfiguration.buildProcessEngine(); &#125; catch (IOException e) &#123; throw new ActivitiIllegalArgumentException("couldn't open resource stream: " + e.getMessage(), e); &#125; finally &#123; IoUtil.closeSilently(inputStream); &#125;&#125; 通过传入的 URL 获取输入流; 通过 createProcessEngineConfigurationFromInputStream() 方法获取流程引擎配置对象 根据流程引擎配置类实例返回流程引擎实例 关闭流 2. ProcessEngineConfiguration 类2.1. createProcessEngineConfigurationFromInputStream(InputStream inputStream)123public static ProcessEngineConfiguration createProcessEngineConfigurationFromInputStream(InputStream inputStream) &#123; return createProcessEngineConfigurationFromInputStream(inputStream, "processEngineConfiguration");&#125; 方法只有一行, 用来添加默认的 beanName: processEngineConfiguration 这个 beanName 非常重要, Activiti 要求在配置文件中必须完成 id 为 processEngineConfiguration 的 bean 2.2. createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName)123public static ProcessEngineConfiguration createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName) &#123; return BeansConfigurationHelper.parseProcessEngineConfigurationFromInputStream(inputStream, beanName);&#125; 3. BeansConfigurationHelper 类3.1. parseProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName)1234public static ProcessEngineConfiguration parseProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName) &#123; Resource springResource = new InputStreamResource(inputStream); return parseProcessEngineConfiguration(springResource, beanName);&#125; 将输入流转化为 org.springframework.core.io.Resource, Spring 的资源抽象接口, 用于后续的 spring 风格配置文件解析; 将配置文件解析为 bean, 最终构造 ProcessEngineConfiguration 并返回 3.2. parseProcessEngineConfiguration(Resource springResource, String beanName)123456789public static ProcessEngineConfiguration parseProcessEngineConfiguration(Resource springResource, String beanName) &#123; DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader xmlBeanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); xmlBeanDefinitionReader.setValidationMode(XmlBeanDefinitionReader.VALIDATION_XSD); xmlBeanDefinitionReader.loadBeanDefinitions(springResource); ProcessEngineConfigurationImpl processEngineConfiguration = (ProcessEngineConfigurationImpl) beanFactory.getBean(beanName); processEngineConfiguration.setBeans(new SpringBeanFactoryProxyMap(beanFactory)); return processEngineConfiguration;&#125; 创建 BeanFactory; 创建 XmlBeanDefinitionReader, 用于读取 XML 中的 bean 定义; 指定 XML 验证方式为 XSD; 读取配置文件资源; 根据 beanName 从 beanFactory 中获取指定对象, 并强转为 ProcessEngineConfigurationImpl; 4. 回到 ProcessEngines 类中此时已经完成了 ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(inputStream); 的执行, 得到了 ProcessEngineConfiguration 对象, 接下来调用 processEngineConfiguration.buildProcessEngine() 来获取 ProcessEngine 并返回.]]></content>
      <categories>
        <category>activiti</category>
        <category>源码</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti(7)--加签功能的实现]]></title>
    <url>%2Fblog%2F2018%2F12%2F23%2FActiviti-7-%E5%8A%A0%E7%AD%BE%E5%8A%9F%E8%83%BD%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[加签的概念 思路: 直接需改模板, 在模板中添加节点以及连线, 并修改实例的走向; 直接修改路程定义对应的缓存数据, 不修改模板, 新增节点与当前需要加签的实例挂钩. 1. 方案一1.1. 实现方式 找到当前实例对象的模板数据 在模板数据的基础上添加新节点以及修改连线, 并更新数据库中的模板. 更新模板对应的流程定义缓存, 必须更新缓存否则加签的节点不会生效. 因为 Activiti 在查找流程定义的时候会先尝试从缓存中进行获取. 完成新增节点额任务后, 再把新增节点以及连线删除, 即还原模板. 1.2. 优缺点 模板是共享的, 因此修改模板就会将所有运行实例对象的模板修改. 实例间应该相互独立, 不能让针对某个实例的加签影响到其他实例. 修改模板容易导致当前实例影响其他实例, 因此该方案不可取; 2. 方案二 模板是共享的, 因此不能修改模板, 否则会影响其他实例. 也不需要修改原有流程的入线即出线, 不修改原有的走向. 由于流程运转的过程中, 需要实时的获取该实例对应的模板数据才能知道应该如何运转. 从流程定义缓存中获取模板数据 如果流程定义缓存丢失, 则需要重新执行模板的解析工作并补充到流程定义缓存中. 因此可以直接修改流程定义缓存数据. 2.1. 思路 在流程缓存中添加一个任务节点, 并未任务节点添加出线信息, 出线连接的是需要到达的目标节点. 添加的目标节点并没有入线, 并不会影响其他实例, 因此其他流程没有机会走到该节点. 加签完成后触发执行实例走到新增的任务节点, 这样当前实例就按照最新的路线进行运转; 如果当前节点在加签后不想直接运转到最新节点, 则可以复制一个当前节点, 继续让流程运转. 加签的最终目的是让实例按照最新的路线走, 与模板中规划的路线脱离关系. 2.2. 引入的问题 新增的任务节点及连线如何存储 流程定义缓存如何修改 加签的节点以及连线信息如何持久化 如果我们重新修改的流程定义缓存丢失, 引擎依然会解析数据库中保存的原有定义, 新增的节点并没有持久化到 DB 流程实例结束后, 当前加签的节点以及连线如何删除. 123456789101112131415161718192021222324252627282930313233343536public void testAddOneTask(String taskId, String targetActivityId) &#123; // 获取当前的任务 TaskEntity taskEntity = (TaskEntity) activitiRule.getTaskService().createTaskQuery().taskId(taskId).singleResult(); log.info("taskEntity: &#123;&#125;", taskEntity); String processDefinitionId = taskEntity.getProcessDefinitionId(); ManagementService managementService = activitiRule.getManagementService(); Process process = managementService.executeCommand(new GetProcessCmd(processDefinitionId)); log.info("process: &#123;&#125;", process); // 创建新节点 UserTask userTask = new UserTask(); userTask.setId("destinyD"); userTask.setName("加签节点 destinyD"); userTask.setAssignee("destiny-d"); userTask.setBehavior(createUserTaskBehavior(userTask)); // 新节点的目标连线 SequenceFlow sequenceFlow = new SequenceFlow(); sequenceFlow.setId("extra"); userTask.setOutgoingFlows(Arrays.asList(sequenceFlow)); sequenceFlow.setTargetFlowElement(process.getFlowElement(targetActivityId)); sequenceFlow.setTargetRef(targetActivityId); process.addFlowElement(userTask); process.addFlowElement(sequenceFlow); // 更新缓存 ProcessDefinitionCacheEntry processDefinitionCacheEntry = managementService.executeCommand(new GetProcessDefinitionCacheEntryCmd(processDefinitionId)); processDefinitionCacheEntry.setProcess(process); Process processCache = managementService.executeCommand(new GetProcessDefinitionCacheEntryCmd(processDefinitionId)).getProcess(); log.info("processCache: &#123;&#125;", processCache); // 跳转 managementService.executeCommand(new JumpCmd(taskId, userTask.getId()));&#125; 但该方法产生跳转后的新 task 仍然无法提交, 会报一下错误: 17:59:18.971 [main] [ERROR] Error while closing command context o.a.e.i.i.CommandContext.logException:122 org.activiti.engine.ActivitiException: Programmatic error: no current flow element found or invalid type: null. Halting. at org.activiti.engine.impl.agenda.TriggerExecutionOperation.run(TriggerExecutionOperation.java:49) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperation(CommandInvoker.java:73) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperations(CommandInvoker.java:57) at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:42) at org.activiti.engine.impl.interceptor.TransactionContextInterceptor.execute(TransactionContextInterceptor.java:48) at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:63) at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:29) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:44) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:39) at org.activiti.engine.impl.TaskServiceImpl.complete(TaskServiceImpl.java:182) at org.destiny.activiti.addsign1.ClientTest.complete(ClientTest.java:56) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.activiti.engine.test.ActivitiRule$1.evaluate(ActivitiRule.java:116) 出线错误的原因是加签方法执行完成后, 缓存中的数据已经被释放, complete 的时候无法继续, 需要在 complete 之前重新向缓存中添加之前的节点和连线 在修改流程定义缓存而不修改模板的实现中, 我们需要一个额外的持久化方式去实现加签部分的持久化 2.3. 持久化加签现场数据1234567891011CREATE TABLE `ACT_ADD_SIGN` ( `ID_` bigint(20) NOT NULL AUTO_INCREMENT, `PROCESS_DEFINITION_ID_` varchar(255) NOT NULL COMMENT '流程定义 ID', `ASSIGNEE_` varchar(32) NOT NULL COMMENT '操作人 ID', `ACT_ID_` varchar(64) NOT NULL COMMENT '活动 ID', `PROCESS_INSTANCE_` varchar(255) NOT NULL COMMENT '流程实例 ID', `PROPERTIES_TEXT_` varchar(2000) DEFAULT NULL COMMENT '参数', `STATE_` int(11) DEFAULT NULL COMMENT '状态位, 0-有效, 1-无效', `CREATE_TIME` bigint(20) DEFAULT NULL COMMENT '创建时间', PRIMARY KEY (`ID_`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 以及对应的 Mapper 文件: 1234567891011121314151617public interface AddSignMapper &#123; @Select("select * from ACT_ADD_SIGN where STATE_ = 0 AND PROCESS_INSTANCE_ID_ = #&#123;processInstanceId&#125;") @Results(&#123; @Result(property = "id", column = "ID_"), @Result(property = "processDefinitionId", column = "PROCESS_DEFINITION_ID_"), @Result(property = "assignee", column = "ASSIGNEE_"), @Result(property = "processInstanceId", column = "PROCESS_INSTANCE_ID_"), @Result(property = "propertiesText", column = "PROPERTIES_TEXT_"), @Result(property = "state", column = "STATE_"), @Result(property = "createTime", column = "CREATE_TIME_"), &#125;) List&lt;AddSign&gt; find(String processInstanceId); @Insert("insert into act_creation(PROCESS_DEFINITION_ID_, PROCESS_INSTANCE_ID_, PROPERTIES_TEXT_, CREATE_TIME_) values(#&#123;processDefinitionId&#125;, #&#123;processInstanceId&#125;, #&#123;propertiesText&#125;, #&#123;createTime&#125;)") int insert(AddSign addSign);&#125; 2.4. 模型定义2.4.1. AddSign12345678910111213@Datapublic class AddSign &#123; private long id; private String processDefinitionId; // 流程定义 id private String assignee; // 加签用户 private String activityId; // 节点 id private String processInstanceId; // 流程实例 id private String propertiesText; // 参数(复合字段) private int state; // 状态 0-可用, 1-不可用 private long createTime; // 创建时间&#125; 2.4.2. TaskModel12345678@Datapublic class TaskModel implements Serializable &#123; private String id; private String name; private String assignee; // 处理人 private int type = 1; // 任务类型, 1-任务节点&#125; 2.4.3. TmpActivityModel1234567@Datapublic class TmpActivityModel implements Serializable &#123; private String activityIds; // 加签的节点id, 多个的话逗号分隔 private String firstId; private String lastId; private List&lt;TaskModel&gt; activityList;&#125; 2.5. 加签功能实现类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@Slf4jpublic class AddSignService &#123; /** * @param procDefId 流程定义 ID * @param procInstId 流程实例 ID * @param processEngine 流程引擎 * @param taskModelList 加签节点列表 * @param firstNodeId 加签开始节点 ID * @param lastNodeId 加签结束节点 ID * @param persistence 是否持久化 * @param onset 是否需要立即跳转 * @param taskId taskID * @param targetNodeId 跳转的目标节点 */ public void addUserTask(String procDefId, String procInstId, ProcessEngine processEngine, List&lt;TaskModel&gt; taskModelList, String firstNodeId, String lastNodeId, boolean persistence, boolean onset, String taskId, String targetNodeId) &#123; ManagementService managementService = processEngine.getManagementService(); ProcessDefinitionCacheEntry processDefinitionCacheEntry = managementService.executeCommand(new GetProcessDefinitionCacheEntryCmd(procDefId)); // 通过缓存获取 Process process = processDefinitionCacheEntry.getProcess(); // 批量生成任务, 循环遍历 TaskModel List&lt;UserTask&gt; userTaskList = Lists.newArrayList(); taskModelList.forEach(taskModel -&gt; &#123; UserTask userTask = ActivityUtils.convertToUserTask(taskModel, processEngine); userTaskList.add(userTask); process.addFlowElement(userTask); &#125;); // 构造并添加连线 for (int i = 0; i &lt; userTaskList.size(); ++i) &#123; UserTask userTask = userTaskList.get(i); SequenceFlow sequenceFlow = null; if (i == userTaskList.size() - 1) &#123; // 如果是最后一个节点 sequenceFlow = ActivityUtils.buildSequenceFlow(userTask.getId() + "--&gt;" + lastNodeId, userTask.getId() + "--&gt;" + lastNodeId, userTask.getId(), lastNodeId); sequenceFlow.setTargetRef(lastNodeId); &#125; else &#123; // 如果不是最后一个 ActivityUtils.buildSequenceFlow(userTask.getId() + "--&gt;" + userTaskList.get(i + 1).getId(), userTask.getId() + "--&gt;" + userTaskList.get(i + 1).getId(), userTask.getId(), userTaskList.get(i + 1).getId()); sequenceFlow.setTargetFlowElement(userTaskList.get(i + 1)); &#125; userTask.setOutgoingFlows(Arrays.asList()); process.addFlowElement(sequenceFlow); &#125; log.info("process: &#123;&#125;", process); // 更新缓存 processDefinitionCacheEntry.setProcess(process); // 如果需要立即生效(直接跳转) if (onset) &#123; managementService.executeCommand(new JumpCmd(taskId, targetNodeId)); &#125; // 如果需要持久化 if (persistence) &#123; persistenceToDB(procDefId, procInstId, firstNodeId, lastNodeId, taskModelList, processEngine); &#125; &#125; /** * 将加签的任务节点添加到数据库 * @param procDefId * @param procInstId * @param firstNodeId * @param lastNodeId * @param taskModelList * @param processEngine */ private void persistenceToDB(String procDefId, String procInstId, String firstNodeId, String lastNodeId, List&lt;TaskModel&gt; taskModelList, ProcessEngine processEngine) &#123; ProcessEngineConfigurationImpl processEngineConfiguration = (ProcessEngineConfigurationImpl) processEngine.getProcessEngineConfiguration(); SqlSession sqlSession = processEngineConfiguration.getSqlSessionFactory().openSession(); AddSignMapper mapper = sqlSession.getMapper(AddSignMapper.class); TmpActivityModel tmpActivityModel = new TmpActivityModel(); tmpActivityModel.setFirstId(firstNodeId); tmpActivityModel.setLastId(lastNodeId); tmpActivityModel.setActivityList(taskModelList); StringBuilder stringBuilder = new StringBuilder(); for (TaskModel taskModel : taskModelList) &#123; stringBuilder.append(taskModel.getId() + ","); &#125; tmpActivityModel.setActivityIds(stringBuilder.toString()); AddSign addSign = new AddSign(); addSign.setProcessDefinitionId(procDefId); addSign.setProcessInstanceId(procInstId); addSign.setPropertiesText(JSON.toJSONString(tmpActivityModel)); addSign.setCreateTime(System.currentTimeMillis()); int insert = mapper.insert(addSign); log.info("insert 结果: &#123;&#125;", insert); sqlSession.commit(); sqlSession.close(); &#125;&#125; 2.6. 测试代码部署流程后, 通过测试代码 12345678910111213141516171819202122@Testpublic void addSignTest() &#123; String taskId = "17508"; TaskEntity taskEntity = (TaskEntity) activitiRule.getTaskService().createTaskQuery() .taskId(taskId) .singleResult(); log.info("taskEntity: &#123;&#125;", taskEntity); String firstNodeId = "destinyA"; String lastNodeId = "destinyB"; List&lt;TaskModel&gt; taskModelList = Lists.newArrayList(); TaskModel taskModel1 = ActivityUtils.buildTaskModel("destinyD", "destinyD", "destiny-d"); TaskModel taskModel2 = ActivityUtils.buildTaskModel("destinyD", "destinyD", "destiny-d"); taskModelList.add(taskModel1); taskModelList.add(taskModel2); AddSignService addSignService = new AddSignService(); addSignService.addUserTask(taskEntity.getProcessDefinitionId(), taskEntity.getProcessInstanceId(), activitiRule.getProcessEngine(), taskModelList, firstNodeId, lastNodeId, true, true, taskEntity.getId(), taskModelList.get(0).getId()); &#125; 执行结束后我们就已经将 destinyD -&gt; destinyE 两个节点加签到 destinyA 之后, destinyB 之前. select NAME_ from ACT_RU_TASK where PROC_INST_ID_ = &#39;17504&#39;; 的执行结果已经变成: destinyD 现在已经完成了加签的一部分代码, 但此时的任务是不能被正确提交的, 会报如下异常: org.activiti.engine.ActivitiException: Programmatic error: no current flow element found or invalid type: null. Halting. at org.activiti.engine.impl.agenda.TriggerExecutionOperation.run(TriggerExecutionOperation.java:49) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperation(CommandInvoker.java:73) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperations(CommandInvoker.java:57) at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:42) at org.activiti.engine.impl.interceptor.TransactionContextInterceptor.execute(TransactionContextInterceptor.java:48) at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:63) at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:29) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:44) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:39) at org.activiti.engine.impl.TaskServiceImpl.complete(TaskServiceImpl.java:182) at org.destiny.activiti.addsign1.ClientTest.complete(ClientTest.java:61) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.activiti.engine.test.ActivitiRule$1.evaluate(ActivitiRule.java:116) 2.7. 流程引擎启动时从 DB 加载流程定义信息当流程引擎启动的时候, 如果 ACT_ADD_SIGN 表有数据, 就需要将对应的加签现场数据保存并添加到缓存中.]]></content>
      <categories>
        <category>Activiti</category>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti(5)--任意节点跳转]]></title>
    <url>%2Fblog%2F2018%2F12%2F22%2FActiviti-5-%E4%BB%BB%E6%84%8F%E8%8A%82%E7%82%B9%E8%B7%B3%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[1. 任意节点跳转以及原理 常规节点跳转 跳转到目标节点 跳转到目标节点的入线 跳转到目标节点的上一个节点并触发连线的条件计算 多实例节点的跳转 普通节点跳转到多实例节点 多实例节点跳转到普通节点 比如总经理审批节点跳转到请假申请节点: 思路: 可以获取总经理审批节点对应的任务 ID, 实例 ID, 执行实例 ID 可以通过 planContiuneProcessInCompensation 方法让当前执行的实例按照我们预期的效果流转 我们可以将当前执行实例中的 currentFlowElement 字段设置为 请假申请 节点 XML 中的 id 值; 因为执行实例运转之后, 当前的任务节点并没有被删除, 所以需要手工删除; 历史表跳转之前的任务节点也不会被完成, 需要手工进行完成. 1.1. 实现方案 获取 ActivitiEngineAgenda commandContext.getExecutionEntityManager() 获取 ExecutionEntityManager commandContext.getTaskEntityManager() 获取 TaskEntityManager 设置执行实例的运行节点 触发执行实例运转 设置删除当前的任务节点 更新历史实例表以及历史任务表, 当前的任务节点为完成状态 123456789101112131415161718192021222324252627282930313233343536@AllArgsConstructorpublic class JumpCmd implements Command&lt;Void&gt; &#123; private String taskId; private String targetNodeId; @Override public Void execute(CommandContext commandContext) &#123; ActivitiEngineAgenda agenda = commandContext.getAgenda(); TaskEntityManager taskEntityManager = commandContext.getTaskEntityManager(); TaskEntity taskEntity = taskEntityManager.findById(taskId); // 执行实例 id String executionId = taskEntity.getExecutionId(); String processDefinitionId = taskEntity.getProcessDefinitionId(); ExecutionEntityManager executionEntityManager = commandContext.getExecutionEntityManager(); HistoryManager historyManager = commandContext.getHistoryManager(); // 执行实例对象 ExecutionEntity executionEntity = executionEntityManager.findById(executionId); Process process = ProcessDefinitionUtil.getProcess(processDefinitionId); FlowElement flowElement = process.getFlowElement(targetNodeId); if (flowElement == null) &#123; throw new RuntimeException("目标节点不存在"); &#125; // 将历史活动表更新 historyManager.recordActivityEnd(executionEntity, "jump"); // 设置当前流程 executionEntity.setCurrentFlowElement(flowElement); // 跳转, 触发执行实例运转 agenda.planContinueProcessInCompensation(executionEntity); // 从runtime 表中删除当前任务 taskEntityManager.delete(taskId); // 将历史任务表更新, 历史任务标记为完成 historyManager.recordTaskEnd(taskId, "jump"); return null; &#125;&#125; 1.2. 测试场景假设有如下流程定义: 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="userTask1"/&gt; &lt;userTask id="userTask1" name="userTask1" activiti:assignee="destiny1"/&gt; &lt;sequenceFlow id="flow2" sourceRef="userTask1" targetRef="userTask2"/&gt; &lt;userTask id="userTask2" name="userTask2" activiti:assignee="destiny2"/&gt; &lt;sequenceFlow id="flow3" sourceRef="userTask2" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 结构如下: start -&gt; userTask1 -&gt; userTask2 -&gt; end 使用如下的执行顺序: startProcessInstance complete 任务 userTask1 执行 ManagementService().executeCommand(new JumpCmd(&quot;7502&quot;, &quot;userTask1&quot;)) complete 任务 userTask1 执行 ManagementService().executeCommand(new JumpCmd(&quot;7502&quot;, &quot;userTask1&quot;)) 然后查询 ACT_HI_ACTINST 表, 能够看到如下执行轨迹: ID_ PROC_DEF_ID_ PROC_INST_ID_ EXECUTION_ID_ ACT_ID_ TASK_ID_ CALL_PROC_INST_ID_ ACT_NAME_ ACT_NAME_ ASSIGNEE_ START_TIME_ END_TIME_ DURATION_ DELETE_REASON_ TENANT_ID_ 6 my-process:1:3 4 5 start startEvent 2019-03-04 00:37:54.328 2019-03-04 00:37:54.330 2 “” 7 my-process:1:3 4 5 userTask1 8 userTask1 userTask destiny1 2019-03-04 00:37:54.331 2019-03-04 00:38:19.920 25589 “” 2501 my-process:1:3 4 5 userTask2 2502 userTask2 userTask destiny2 2019-03-04 00:38:19.933 2019-03-04 00:38:44.834 24901 jump “” 5001 my-process:1:3 4 5 userTask1 5002 userTask1 userTask destiny1 2019-03-04 00:38:44.848 2019-03-04 00:39:02.232 17384 “” 7501 my-process:1:3 4 5 userTask2 7502 userTask2 userTask destiny2 2019-03-04 00:39:02.245 2019-03-04 00:39:19.718 17473 jump “” 10001 my-process:1:3 4 5 userTask1 10002 userTask1 userTask destiny1 2019-03-04 00:39:19.743 “” 可以看到我们已经完成了简单条件下的跳转 1.3. 关于自由跳转时历史活动不更新问题的解决之前遇到一个错误的写法: 123456789101112131415161718192021222324252627282930313233343536@AllArgsConstructorpublic class JumpCmd implements Command&lt;Void&gt; &#123; private String taskId; private String targetNodeId; @Override public Void execute(CommandContext commandContext) &#123; ActivitiEngineAgenda agenda = commandContext.getAgenda(); TaskEntityManager taskEntityManager = commandContext.getTaskEntityManager(); TaskEntity taskEntity = taskEntityManager.findById(taskId); // 执行实例 id String executionId = taskEntity.getExecutionId(); String processDefinitionId = taskEntity.getProcessDefinitionId(); ExecutionEntityManager executionEntityManager = commandContext.getExecutionEntityManager(); HistoryManager historyManager = commandContext.getHistoryManager(); // 执行实例对象 ExecutionEntity executionEntity = executionEntityManager.findById(executionId); Process process = ProcessDefinitionUtil.getProcess(processDefinitionId); FlowElement flowElement = process.getFlowElement(targetNodeId); if (flowElement == null) &#123; throw new RuntimeException("目标节点不存在"); &#125; // 设置当前流程 executionEntity.setCurrentFlowElement(flowElement); // 跳转, 触发执行实例运转 agenda.planContinueProcessInCompensation(executionEntity); // 从runtime 表中删除当前任务 taskEntityManager.delete(taskId); // 将历史活动表更新 historyManager.recordActivityEnd(executionEntity, "jump"); // 将历史任务表更新, 历史任务标记为完成 historyManager.recordTaskEnd(taskId, "jump"); return null; &#125;&#125; 与上文中正确写法的不同之处在于数据库更新操作的顺序. 但仅仅更换顺序也会到导致历史表中数据无法正确结束. 问题的原因在于第 25 行的时候已经为执行实例执行了 setCurrentFlowElement() 操作, 设置了最新的流程元素, 所以如果在后面再执行对 ACT_HI_ACTINST 的更新, 就无法找到正确的 FlowElement. 所以需要将 historyManager.recordActivityEnd(executionEntity, &quot;jump&quot;); 放在第 25 行之前 2. 跳转到目标节点的入线假设有如下流程定义: 12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;userTask id="userTask1" name="userTask1" activiti:assignee="destiny1"/&gt; &lt;userTask id="userTask2" name="userTask2" activiti:assignee="destiny2"/&gt; &lt;userTask id="userTask3" name="userTask3" activiti:assignee="destiny3"/&gt; &lt;endEvent id="end1"/&gt; &lt;endEvent id="end2"/&gt; &lt;sequenceFlow sourceRef="start" targetRef="userTask1"/&gt; &lt;sequenceFlow sourceRef="userTask1" targetRef="userTask2"&gt; &lt;conditionExpression&gt;$&#123;condition==1&#125;&lt;/conditionExpression&gt; &lt;/sequenceFlow&gt; &lt;sequenceFlow sourceRef="userTask1" targetRef="userTask3"&gt; &lt;conditionExpression&gt;$&#123;condition==2&#125;&lt;/conditionExpression&gt; &lt;/sequenceFlow&gt; &lt;sequenceFlow sourceRef="userTask2" targetRef="end1"/&gt; &lt;sequenceFlow sourceRef="userTask3" targetRef="end2"/&gt; &lt;/process&gt;&lt;/definitions&gt; 将原先的跳转命令类稍作修改: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@AllArgsConstructorpublic class SequenceFlowJumpCmd implements Command&lt;Void&gt; &#123; private String taskId; private String targetNodeId; @Override public Void execute(CommandContext commandContext) &#123; ActivitiEngineAgenda agenda = commandContext.getAgenda(); TaskEntityManager taskEntityManager = commandContext.getTaskEntityManager(); TaskEntity taskEntity = taskEntityManager.findById(taskId); // 执行实例 id String executionId = taskEntity.getExecutionId(); String processDefinitionId = taskEntity.getProcessDefinitionId(); ExecutionEntityManager executionEntityManager = commandContext.getExecutionEntityManager(); HistoryManager historyManager = commandContext.getHistoryManager(); // 执行实例对象 ExecutionEntity executionEntity = executionEntityManager.findById(executionId); Process process = ProcessDefinitionUtil.getProcess(processDefinitionId); FlowElement flowElement = process.getFlowElement(targetNodeId); if (flowElement == null) &#123; throw new RuntimeException("目标节点不存在"); &#125; SequenceFlow sequenceFlow = null; if (flowElement instanceof FlowNode) &#123; FlowNode flowNode = (FlowNode) flowElement; // 找到所有的入线, 并取其中唯一的一条 List&lt;SequenceFlow&gt; incomingFlows = flowNode.getIncomingFlows(); sequenceFlow = incomingFlows.get(0); &#125; if (sequenceFlow == null) &#123; throw new RuntimeException("目标连线不存在"); &#125; // 将历史活动表更新 historyManager.recordActivityEnd(executionEntity, "jump"); // 设置当前流程 executionEntity.setCurrentFlowElement(sequenceFlow); // 触发执行实例运转, 第二个参数为是否参与计算 agenda.planTakeOutgoingSequenceFlowsOperation(executionEntity, true); // 从runtime 表中删除当前任务 taskEntityManager.delete(taskId); // 将历史任务表更新, 历史任务标记为完成 historyManager.recordTaskEnd(taskId, "jump"); return null; &#125;&#125; 通过连线触发实例的时候, 连线上的条件不会参与计算 只有实例经过节点, 网关的时候, 连线上的条件才会经过计算 3. 跳转到目标节点入线连接的节点因为实例是从节点离开, 因此后面的连线是可以参与运算的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@AllArgsConstructorpublic class SequenceFlowSourceJumpCmd implements Command&lt;Void&gt; &#123; private String taskId; private String targetNodeId; private Map&lt;String, Object&gt; condition; @Override public Void execute(CommandContext commandContext) &#123; ActivitiEngineAgenda agenda = commandContext.getAgenda(); TaskEntityManager taskEntityManager = commandContext.getTaskEntityManager(); TaskEntity taskEntity = taskEntityManager.findById(taskId); // 执行实例 id String executionId = taskEntity.getExecutionId(); String processDefinitionId = taskEntity.getProcessDefinitionId(); ExecutionEntityManager executionEntityManager = commandContext.getExecutionEntityManager(); HistoryManager historyManager = commandContext.getHistoryManager(); // 执行实例对象 ExecutionEntity executionEntity = executionEntityManager.findById(executionId); Process process = ProcessDefinitionUtil.getProcess(processDefinitionId); FlowElement flowElement = process.getFlowElement(targetNodeId); if (flowElement == null) &#123; throw new RuntimeException("目标节点不存在"); &#125; SequenceFlow sequenceFlow = null; if (flowElement instanceof FlowNode) &#123; FlowNode flowNode = (FlowNode) flowElement; // 找到所有的入线, 并取其中唯一的一条 List&lt;SequenceFlow&gt; incomingFlows = flowNode.getIncomingFlows(); sequenceFlow = incomingFlows.get(0); &#125; if (sequenceFlow == null) &#123; throw new RuntimeException("目标连线不存在"); &#125; FlowElement sourceFlowElement = sequenceFlow.getSourceFlowElement(); executionEntity.setVariables(condition); // 将历史活动表更新 historyManager.recordActivityEnd(executionEntity, "jump"); // 设置当前流程 executionEntity.setCurrentFlowElement(sourceFlowElement); // 触发执行实例运转, 第二个参数为是否参与计算 agenda.planTakeOutgoingSequenceFlowsOperation(executionEntity, true); // 从runtime 表中删除当前任务 taskEntityManager.delete(taskId); // 将历史任务表更新, 历史任务标记为完成 historyManager.recordTaskEnd(taskId, "jump"); return null; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Activiti(6)--加签功能的实现]]></title>
    <url>%2Fblog%2F2018%2F12%2F22%2FActiviti-6-%E5%8A%A0%E7%AD%BE%E5%8A%9F%E8%83%BD%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1. 概述假设有如下流程: 我们在流程进行的时候, 需要在申请和经理审批之间临时新增一个节点, 达到如下的效果: 该行为我们称之为加签. 加签的两种思路 直接修改模板, 在模板中添加节点以及连线, 并修改实例的走向; 直接修改流程定义对应的缓存数据, 不修改模板, 新增的节点与当前需要加签的实例挂钩. 2. 实现方式2.1. 修改模板步骤: 找到当前实例对象对应的模板数据; 在模板数据的基础上添加新节点, 修改连线, 并更新数据库中的模板; 更新模板对应的流程定义缓存, 否则加签节点不会生效; 完成新增的节点任务后, 再把新增的节点以及连线删除, 即还原流程模板. 模板是共享的, 所以把模板修改了, 所有运行实例对应的模板也会被修改; 修改模板容易导致当前实例影响到其他实例, 这种方法并不可取; 2.2 修改流程定义缓存因为模板是共享的, 不修改模板就不会影响其他实例; 也不需要修改原有流程的流向, 要让流程按照新的流向运行. 因为流程在运转过程中, 需要实时获取该实例对应的模板数据才能知道应该如何流转 首先从流程定义缓存中获取模板数据; 如果流程缓存定义丢失, 则需要重新执行模板的解析工作并将其防止到流程缓存中; 因此修改流程定义缓存就可以实现功能. 但仍有一个问题需要解决: 如果流程定义缓存丢失, 引擎默认解析的是数据库中存在的模板数据, 而新增的临时节点不会存在与 XML 中. 2.2.1 步骤 在流程缓存中添加一个任务节点并为任务节点添加出线信息, 出线信息是需要到达的目标节点; 添加的目标节点并没有入线, 也就是说不会影响到其他的实例, 正常的流程实例启动的时候不会走到这个节点; 加签完成后可以触发执行实例走到新增的任务节点, 这样当前实例就按照最新的路线进行运转; 如果当前的节点加签后不想让实例运转到最新的节点, 可以复制一个当前节点, 继续让实例运转; 加签的最终目的是让实例按照最新的路线走, 与模板中规划的路线脱离关系. 需要解决的问题: 新增的节点以及连线如何存储; 流程定义缓存如何修改; 加签的节点以及连线信息如何持久化; 缓存丢失, 新的路线图丢失; 流程实例结束, 当前加签的节点以及连线已经不需要应该如何删除; 修改流程定义缓存后, 由于缓存失效, 依然会报错 此时就需要先添加缓存, 然后完成任务 3. 加签原理代码讲解4. 加签节点存储表设计 Activiti 继承了 MyBatis 框架, 因此可以让我们注入配置文件或者注解类使用 MyBatis. 4.1. 表结构4.2. 实体类4.3. Mapper 类4.4. 注入流程引擎]]></content>
      <categories>
        <category>Activiti</category>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti(4)--多实例实现会签功能]]></title>
    <url>%2Fblog%2F2018%2F12%2F16%2FActiviti-4-%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AE%9E%E7%8E%B0%E4%BC%9A%E7%AD%BE%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[1. Activiti 多实例 多实例节点是在业务流程中定义重复环节的一种方式 从开发角度讲, 多实例类似于循环, 可以根据给定的集合, 为每个元素执行一个环境甚至一个子流程, 既可以顺序依次执行也可以并发同步执行. 多实例是在一个普通节点上添加额外的属性定义, 这样被多实例修饰的节点就会执行多次, 在 BPMN 规范中, 下面的节点都可以成为一个多实例节点: UserTask Script Task Java Service Task Web Service Task Business Rule Task Email Task Manual Task Receive Task Sub-Process Call Activity 每个上级流程为每个实例创建分支的时候都要提供如下变量: nrOfInstances: 实例总数 nrOfActiveInstances: 当前活动的实例数量, 对于顺序执行的多实例, 该值始终为1 nrOfCompletedInstances: 已经完成的实例数量 loopCounter: 当前实例所在循环的索引值, 其他实例不可见, 不会保存到流程实例级别. 可以通过 execution.getVariable(String key) 方法获得这些变量 1.1. isSequential表示节点时顺序执行还是并行执行, 默认为 false, 表示并行执行 1.2. 指定实例数量实例的数量会在进入节点时进行计算, 但也可以直接指定 123456&lt;multiInstanceLoopCharacteristics isSequential="false"&gt; &lt;!-- 可以使用loopCardinality子元素直接指定一个数字 --&gt; &lt;loopCardinality&gt;5&lt;/loopCardinality&gt; &lt;!-- 也可以使用结果为整数的表达式 --&gt; &lt;loopCardinality&gt;$&#123;nrOfOrders-nrOfCancellations&#125;&lt;/loopCardinality&gt;&lt;/multiInstanceLoopCharacteristics&gt; 1.3. 接收并遍历集合除此之外还可以通过 loopDataInputRef 元素设置一个类型为集合的流程变量名, 对于集合中的每个元素都会创建一个实例, 也可以通过 inputDataItem 子元素指定集合 123456&lt;userTask id="someTask" name="Activiti is awesome!" activiti:assignee="$&#123;user&#125;"&gt; &lt;multiInstanceLoopCharacteristics isSequential="false"&gt; &lt;loopDataInputRef&gt;userList&lt;/loopDataInputRef&gt; &lt;inputDataItem name="user"/&gt; &lt;/multiInstanceLoopCharacteristics&gt;&lt;/userTask&gt; loopDataInputRef 中的 userList 表示需要遍历的元素列表 inputDataItem 中的 user 表示每个分支都会拥有一个名为 user 的流程变量, 这个变量会包含集合中的对应元素, 在例子中用来设置用户任务的办理者, 也就是说 userTask 中的 activiti:assignee 属性的值需要和 inputDataItem 一致. 此外, 上述的变量名存在如下缺点: 名称复杂 BPMN2.0 规定不能该节点不能包含表达式 Activiti 通过 multiInstanceCharacteristics 中设置 collection 和 elementVariable 属性来解决这个问题: 123&lt;userTask id="someTask" name="Activiti is awesome!" activiti:assignee="$&#123;user&#125;"&gt; &lt;multiInstanceLoopCharacteristics isSequential="false" activiti:collection="$&#123;userList&#125;" activiti:elementVariable="user"/&gt;&lt;/userTask&gt; 二者实现的功能是相同的, 不过后者可以支持表达式, 这是我们动态配置用户任务属性的重要功能 1.4. 结束条件多实例节点默认会在所有节点完成后结束, 也可以指定一个表达式在每个实例结束时执行, 如果表达式返回 true, 所有其他的实例都会销毁, 多实例节点也会结束, 流程会继续执行. 123456&lt;userTask id="someTask" name="Activiti is awesome!" activiti:assignee="$&#123;user&#125;"&gt; &lt;multiInstanceLoopCharacteristics isSequential="false" activiti:collection="$&#123;userList&#125;" activiti:elementVariable="user"&gt; &lt;!-- 如果有 60% 的任务完成时, 其他任务会被删除, 流程继续进行 --&gt; &lt;completionCondition&gt;$&#123;nrOfCompletedInstances/nrOfInstances &gt;= 0.6&#125;&lt;/completionCondition&gt; &lt;/multiInstanceLoopCharacteristics&gt;&lt;/userTask&gt; 2. 会签逻辑经过以上对 Activiti 多实例的介绍可知, 实现会签功能几个重要的点在于: 利用多实例完成动态实例的创建 根据业务设置合适的结束条件 2.1. 流程定义2.1.1. XML 格式123456789&lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask" /&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:assignee="$&#123;user&#125;"&gt; &lt;multiInstanceLoopCharacteristics isSequential="false" activiti:collection="$&#123;userList&#125;" activiti:elementVariable="user"/&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end" /&gt;&lt;/process&gt; 2.1.2. BpmnModel 模型用到的测试类: 123456789@Slf4j@Componentpublic class UsersBean implements Serializable &#123; public List&lt;String&gt; getUsers(String userId) &#123; log.info("userId: &#123;&#125;", userId); return Arrays.asList(userId + "1", userId + "2", userId + "3"); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Testpublic void testExclusionGatewayModel() &#123; BpmnModel bpmnModel = new BpmnModel(); Process process = new Process(); process.setId("my-process"); StartEvent startEvent = new StartEvent(); startEvent.setId("startEvent"); UserTask someTask = new UserTask(); someTask.setId("someTask"); someTask.setName("Activiti is awesome!"); someTask.setAssignee("$&#123;user&#125;"); MultiInstanceLoopCharacteristics multiInstanceLoopCharacteristics = new MultiInstanceLoopCharacteristics(); multiInstanceLoopCharacteristics.setSequential(false); multiInstanceLoopCharacteristics.setInputDataItem("$&#123;usersBean.getUsers(name)&#125;"); multiInstanceLoopCharacteristics.setElementVariable("user"); multiInstanceLoopCharacteristics.setCompletionCondition("$&#123;nrOfCompletedInstances &gt; 0&#125;"); someTask.setLoopCharacteristics(multiInstanceLoopCharacteristics); EndEvent endEvent = new EndEvent(); endEvent.setId("endEvent"); SequenceFlow flow1 = createSequence("startEvent", "someTask", "flow1", "flow1", null); SequenceFlow flow2 = createSequence("someTask", "endEvent", "flow2", "flow2", null); process.addFlowElement(startEvent); process.addFlowElement(someTask); process.addFlowElement(endEvent); process.addFlowElement(flow1); process.addFlowElement(flow2); bpmnModel.addProcess(process); // client Deployment deployment = activitiRule.getRepositoryService().createDeployment() .addBpmnModel("bpmn", bpmnModel) .deploy(); log.info("deployment: &#123;&#125;", ToStringBuilder.reflectionToString(deployment, ToStringStyle.JSON_STYLE)); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("usersBean", usersBean); map.put("name", "wk"); ProcessInstance processInstance = activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", map); log.info("processInstance: &#123;&#125;", ToStringBuilder.reflectionToString(processInstance, ToStringStyle.JSON_STYLE)); List&lt;Task&gt; taskList = activitiRule.getTaskService().createTaskQuery().list(); log.info("当前 taskList 数量: &#123;&#125;", taskList.size()); for (Task task : taskList) &#123; log.info("task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); &#125; activitiRule.getTaskService().complete(taskList.get(0).getId()); log.info("其中一个节点完成审批"); taskList = activitiRule.getTaskService().createTaskQuery().list(); log.info("第一个节点审批完成后 taskList 数量: &#123;&#125;", taskList.size()); for (Task task : taskList) &#123; log.info("第一个节点审批完成后 task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); &#125;&#125; 2.1.3. 日志输出09:55:17,517 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - processInstance: {&quot;currentFlowElement&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;processInstance&quot;:&quot;ProcessInstance[4]&quot;,&quot;parent&quot;:null,&quot;executions&quot;:[Multi instance root execution[ id &apos;8&apos; ] - activity &apos;someTask - parent &apos;4&apos;],&quot;superExecution&quot;:null,&quot;subProcessInstance&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;name&quot;:null,&quot;description&quot;:null,&quot;localizedName&quot;:null,&quot;localizedDescription&quot;:null,&quot;lockTime&quot;:null,&quot;isActive&quot;:true,&quot;isScope&quot;:true,&quot;isConcurrent&quot;:false,&quot;isEnded&quot;:false,&quot;isEventScope&quot;:false,&quot;isMultiInstanceRoot&quot;:false,&quot;isCountEnabled&quot;:false,&quot;eventName&quot;:null,&quot;eventSubscriptions&quot;:[],&quot;jobs&quot;:[],&quot;timerJobs&quot;:[],&quot;tasks&quot;:[],&quot;identityLinks&quot;:[IdentityLinkEntity[id=24, type=participant, userId=wk1, processInstanceId=4], IdentityLinkEntity[id=27, type=participant, userId=wk2, processInstanceId=4], IdentityLinkEntity[id=30, type=participant, userId=wk3, processInstanceId=4]],&quot;deleteReason&quot;:null,&quot;suspensionState&quot;:1,&quot;startUserId&quot;:null,&quot;startTime&quot;:&quot;Sun Dec 16 21:55:17 CST 2018&quot;,&quot;eventSubscriptionCount&quot;:0,&quot;taskCount&quot;:0,&quot;jobCount&quot;:0,&quot;timerJobCount&quot;:0,&quot;suspendedJobCount&quot;:0,&quot;deadLetterJobCount&quot;:0,&quot;variableCount&quot;:0,&quot;identityLinkCount&quot;:0,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;processDefinitionKey&quot;:&quot;my-process&quot;,&quot;processDefinitionName&quot;:null,&quot;processDefinitionVersion&quot;:1,&quot;deploymentId&quot;:null,&quot;activityId&quot;:null,&quot;activityName&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;businessKey&quot;:null,&quot;parentId&quot;:null,&quot;superExecutionId&quot;:null,&quot;rootProcessInstanceId&quot;:&quot;4&quot;,&quot;rootProcessInstance&quot;:null,&quot;forcedUpdate&quot;:false,&quot;queryVariables&quot;:null,&quot;isDeleted&quot;:false,&quot;variableInstances&quot;:{usersBean=VariableInstanceEntity[id=6, name=usersBean, type=serializable, byteArrayValueId=5]},&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;4&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:true,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 09:59:03,449 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - 当前 taskList 数量: 3 09:59:03,450 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:1,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:&quot;wk1&quot;,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:null,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sun Dec 16 21:59:03 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;14&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;24&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 09:59:03,450 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:1,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:&quot;wk2&quot;,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:null,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sun Dec 16 21:59:03 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;15&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;27&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 09:59:03,451 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:1,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:&quot;wk3&quot;,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:null,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sun Dec 16 21:59:03 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;16&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;30&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} ... 09:55:17,585 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - 其中一个节点完成审批 09:55:17,587 [main] INFO org.destiny.activiti.GatewayExpressSpringTest - 第一个节点审批完成后 taskList 数量: 0 3. 多实例任务节点完成自定义条件]]></content>
      <categories>
        <category>Activiti</category>
        <category>Java</category>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti(3)--数据模型设计]]></title>
    <url>%2Fblog%2F2018%2F12%2F11%2FActiviti-3-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[数据表分类 描述 ACT_GE_* 通用数据表 ACT_RE_* 流程定义存储表 ACT_ID_* 身份信息表 ACT_RU_* 运行时数据库表 ACT_HI_* 历史数据库表, 为了保证运行时数据尽可能少, 流程执行完就会将相关数据迁移到历史表中 核心引擎: activiti.mysql.create.engine.sql 历史数据: activiti.mysql.create.history.sql 身份数据: activiti.mysql.create.identity.sql Activiti 除了核心引擎以外, 其他都是可选的. 首先创建 ACT_GE_PROPERTY 表, 并写入: schema.version(schema 版本) schema.history(schema 历史) next.dbid(自增 id)三条记录 1. 通用数据库 数据表分类 描述 ACT_GE_PROPERTY 属性表(保存流程引擎的 kv 键值属性) ACT_GE_BYTEARRAY 资源表(存储流程定义相关的资源, 如 xml, 流程定义图) 1.1. ACT_GE_PROPERTY对应实体类 org.activiti.engine.impl.persistence.entity.PropertyEntityImpl 1.2 ACT_GE_BYTEARRAY对应实体类 org.activiti.engine.impl.persistence.entity.ByteArrayEntityImpl 其中 GENERATED_ 字段标识该资源文件是自动生成还是人工上传 如果不想添加身份信息相关数据库和历史数据相关数据库, 可以在配置中显式指定 1234567891011&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;property name="jdbcUrl" value="jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000;MVCC=TRUE"/&gt; &lt;property name="jdbcDriver" value="org.h2.Driver"/&gt; &lt;property name="jdbcUsername" value="sa"/&gt; &lt;property name="jdbcPassword" value=""/&gt; &lt;!-- 不创建 ACT_ID_* 相关的表 --&gt; &lt;property name="dbIdentityUsed" value="false"/&gt; &lt;!-- 不创建 ACT_HI_* 相关的表 --&gt; &lt;property name="dbHistoryUsed" value="false"/&gt;&lt;/bean&gt; 2. 流程定义存储表 数据表分类 描述 ACT_RE_DEPLOYMENT 流程部署记录表 ACT_RE_PROCDEF 流程定义信息表 ACT_RE_MODEL 模型信息表(用于 web 设计器) ACT_PROCDEF_INFO 流程定义动态改变信息表 2.1. ACT_RE_DEPLOYMENT对应实体 org.activiti.engine.impl.persistence.entity.DeploymentEntityImpl 关键字段 描述 ID_ 主键 NAME_ 名称 CATEGORY_ 分类 TENANT_ID_ 多租户标志 DEPLOY_TIME_ 部署时间 KEY_ 标志 key ENGINE_VERSION_ 兼容版本, 如果使用 Activiti5, 在升级到6后会有特殊标志 2.2 ACT_RE_PROCDEF对应实体 org.activiti.engine.impl.persistence.entity.ProcessDefinitionEntityImpl 关键字段 描述 DEPLOYMENT_ID_ 关联部署 id RESOURCE_NAME_ 流程定义资源名称 DGRM_RESOURCE_NAME_ 流程图片资源名称 HAS_START_FORM_KEY_ 是否存在开始表单标志 HAS_GRAPHICAL_NOTATION_ 是否有图形信息 SUSPENSION_STATE_ 挂起状态 1 正常, 2 挂起 2.3. 测试代码12345678@Testpublic void testDeploy() &#123; activitiRule.getRepositoryService() .createDeployment() .name("二次审批流程") .addClasspathResource("org/destiny/activiti/SecondApprove.bpmn20.xml") .deploy();&#125; ACT_RE_DEPLOYMENT 表内容: mysql&gt; select * from ACT_RE_DEPLOYMENT \G; *************************** 1. row *************************** ID_: 1 NAME_: 二次审批流程 CATEGORY_: NULL KEY_: NULL TENANT_ID_: DEPLOY_TIME_: 2018-12-11 09:11:27.538 ENGINE_VERSION_: NULL ACT_RE_PROCDEF 表内容: mysql&gt; select * from ACT_RE_PROCDEF \G; *************************** 1. row *************************** ID_: SecondApprove:1:4 REV_: 1 CATEGORY_: http://www.activiti.org/test NAME_: 二级审批 KEY_: SecondApprove VERSION_: 1 DEPLOYMENT_ID_: 1 RESOURCE_NAME_: org/destiny/activiti/SecondApprove.bpmn20.xml DGRM_RESOURCE_NAME_: org/destiny/activiti/SecondApprove.SecondApprove.png DESCRIPTION_: NULL HAS_START_FORM_KEY_: 0 HAS_GRAPHICAL_NOTATION_: 1 SUSPENSION_STATE_: 1 TENANT_ID_: ENGINE_VERSION_: NULL 可以看到, 其中 HAS_START_FORM_KEY_ 为 0, DESCRIPTION_ 为 NULL, 二者都需要去流程定义文件中设置 HAS_START_FORM_KEY_ 需要在 startEvent 中设置 actviti:formKey; DESCRIPTION 需要设置 documentation 修改流程定义文件: 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="SecondApprove" name="二级审批" isExecutable="true"&gt; &lt;documentation&gt;审批流程描述&lt;/documentation&gt; &lt;startEvent id="startEvent" name="开始" activiti:formKey="/process/form/key"&gt;&lt;/startEvent&gt; &lt;userTask id="submitApprove" name="填写申请信息"&gt; 然后重新部署即可看到: mysql&gt; select * from ACT_RE_PROCDEF \G; *************************** 1. row *************************** ID_: SecondApprove:1:4 REV_: 1 CATEGORY_: http://www.activiti.org/test NAME_: 二级审批 KEY_: SecondApprove VERSION_: 1 DEPLOYMENT_ID_: 1 RESOURCE_NAME_: org/destiny/activiti/SecondApprove.bpmn20.xml DGRM_RESOURCE_NAME_: org/destiny/activiti/SecondApprove.SecondApprove.png DESCRIPTION_: NULL HAS_START_FORM_KEY_: 0 HAS_GRAPHICAL_NOTATION_: 1 SUSPENSION_STATE_: 1 TENANT_ID_: ENGINE_VERSION_: NULL *************************** 2. row *************************** ID_: SecondApprove:2:2504 REV_: 1 CATEGORY_: http://www.activiti.org/test NAME_: 二级审批 KEY_: SecondApprove VERSION_: 2 DEPLOYMENT_ID_: 2501 RESOURCE_NAME_: org/destiny/activiti/SecondApprove.bpmn20.xml DGRM_RESOURCE_NAME_: org/destiny/activiti/SecondApprove.SecondApprove.png DESCRIPTION_: 审批流程描述 HAS_START_FORM_KEY_: 0 HAS_GRAPHICAL_NOTATION_: 1 SUSPENSION_STATE_: 1 TENANT_ID_: ENGINE_VERSION_: NULL ACT_RE_PROCDEF 是基于 KEY_ 去升级版本号, 当原有的 key 已经存在, 就会升级版本号, 其中 KEY_, VERSION_, TENANT_ID_ 共同组成一个唯一键 3. 身份数据表设计 数据表设计 描述 ACT_ID_USER 用户的基本信息 ACT_ID_INFO 用户的扩展信息 ACT_ID_GROUP 群组 ACT_ID_MEMBERSHIP 用户与群组关系 3.1. 用户信息表对应实体 org.activiti.engine.impl.persistence.entity.UserEntityImpl +-------------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------------+--------------+------+-----+---------+-------+ | ID_ | varchar(64) | NO | PRI | NULL | | | REV_ | int(11) | YES | | NULL | | | FIRST_ | varchar(255) | YES | | NULL | | | LAST_ | varchar(255) | YES | | NULL | | | EMAIL_ | varchar(255) | YES | | NULL | | | PWD_ | varchar(255) | YES | | NULL | | | PICTURE_ID_ | varchar(64) | YES | | NULL | | +-------------+--------------+------+-----+---------+-------+ 3.2. 用户扩展信息对应实体 org.activiti.engine.impl.persistence.entity.IdentityInfoEntityImpl +------------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------+------+-----+---------+-------+ | ID_ | varchar(64) | NO | PRI | NULL | | | REV_ | int(11) | YES | | NULL | | | USER_ID_ | varchar(64) | YES | | NULL | | | TYPE_ | varchar(64) | YES | | NULL | | | KEY_ | varchar(255) | YES | | NULL | | | VALUE_ | varchar(255) | YES | | NULL | | | PASSWORD_ | longblob | YES | | NULL | | | PARENT_ID_ | varchar(255) | YES | | NULL | | +------------+--------------+------+-----+---------+-------+ USER_ID_: 关联用户 id TYPE_: 类型(固定值) KEY_: 属性名 VALUE_: 属性值 PASSWORD_: 密码(未使用) PARENT_ID_: 上级关联(不建议使用) 3.3. ACT_ID_GROUP对应实体 org.activiti.engine.impl.persistence.entity.GroupEntityImpl +-------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+---------+-------+ | ID_ | varchar(64) | NO | PRI | NULL | | | REV_ | int(11) | YES | | NULL | | | NAME_ | varchar(255) | YES | | NULL | | | TYPE_ | varchar(255) | YES | | NULL | | +-------+--------------+------+-----+---------+-------+ 3.4. 用户组关系表对应实体 org.activiti.engine.impl.persistence.entity.MembershipEntityImpl +-----------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-----------+-------------+------+-----+---------+-------+ | USER_ID_ | varchar(64) | NO | PRI | NULL | | | GROUP_ID_ | varchar(64) | NO | PRI | NULL | | +-----------+-------------+------+-----+---------+-------+ 测试代码: 1234567891011121314151617181920@Testpublic void testIdentity() &#123; IdentityService identityService = activitiRule.getIdentityService(); User user1 = identityService.newUser("user1"); user1.setFirstName("firstName"); user1.setLastName("lastName"); user1.setEmail("user1@126.com"); user1.setPassword("pwd"); identityService.saveUser(user1); User user2 = identityService.newUser("user2"); identityService.saveUser(user2); Group group1 = identityService.newGroup("group1"); group1.setName("for test"); identityService.saveGroup(group1); identityService.createMembership(user1.getId(), group1.getId()); identityService.createMembership(user2.getId(), group1.getId()); // 扩展信息 identityService.setUserInfo(user1.getId(), "age", "18"); identityService.setUserInfo(user1.getId(), "identity", "destiny");&#125; 4. 运行时流程数据表 数据表分类 描述 ACT_RU_EXECUTION 流程实例与分支执行信息 ACT_RU_TASK 用户任务信息 ACT_RU_VARIABLE 变量信息 ACT_RU_IDENTITYLINK 参与者相关信息 ACT_RU_EVENT_SUBSCR 事件监听表 ACT_RU_JOB 作业表 ACT_RU_TIMER_JOB 定时器表 ACT_RU_SUSPENDED_JOB 暂停作业表 ACT_RU_DEADLETTER_JOB 死信表 4.1. ACT_RU_EXECUTION对应实体类 org.activiti.engine.impl.persistence.entity.ExecutionEntityImpl 关键字段 描述 PROC_INST_ID_ 流程实例 ID BUSINESS_KEY_ 业务标志 PARENT_ID_ 父执行信息 PROC_DEF_ID_ 流程定义 ID SUPER_EXEC_ 父流程实例对应的执行 ACT_ID_ 流程定义节点 ID IS_ACTIVE 是否活动的执行 0-非活动, 1-活动 IS_CONCURRENT_ 是否并行分支 0-非, 1-是 IS_SCOPE_ 是否全局流程执行 0-非, 1-是 IS_EVENT_SCOPE_ 是否激活状态 SUSPENSION_STATE 挂起状态 1-正常, 2-挂起 LOCK_TIME_ 锁定时间 4.2. ACT_RU_TASK对应实体类 org.activiti.engine.impl.persistence.entity.TaskEntityImpl 关键字段 描述 EXECUTION_ID_ 执行流 id PROC_INST_ID_ 流程实例 ID PROC_DEF_ID_ 流程定义 ID PARENT_TASK_ID_ 父任务 TASK_DEF_KEY_ 任务定义 ID NAME_ 任务定义名称 OWNER_ 拥有人 ASSIGNEE_ 代理人 DELEGATION_ 委托状态 PENDING-委托中, RESOLVED 已处理 PRIORITY_ 优先级 DUE_DATE_ 过期时间 FORM_KEY_ 表单标志 4.3. ACT_RU_VARIABLE对应实体类 org.activiti.engine.impl.persistence.entity.VariableInstanceEntityImpl 关键字段 描述 TYPE_ 变量名称(integer, string, double, json) NAME_ 变量名 BYTEARRAY_ID_ 资源表 id DOUBLE_ 浮点值 LONG_ 长整型数值 TEXT_ 文本值 4.4. ACT_RU_IDENTITYLINK对应实体类 org.activiti.engine.impl.persistence.entity.IdentityInfoEntityImpl 当用户和流程建立关系的时候, 就会在此表中插入记录 关键字段 描述 ID_ 主键 GROUP_ID_ 用户组 ID TYPE_ 类型 assignee, candidate, owner, starter… USER_ID_ 用户 ID TASK_ID_ 任务 ID PROC_INST_ID_ 流程实例 4.5. ACT_RU_EVENT_SUBSCR对应实体类 org.activiti.engine.impl.persistence.entity.EventSubscriptionEntityImpl 关键字段 描述 EVENT_TYPE_ 事件类型 message, signal EVENT_NAME_ 事件名称 EXECUTION_ID_ 流程执行 ID PROC_INST_ID_ 流程实例 ID ACTIVITY_ID_ 流程定义节点 ID CONFIGURATION_ 配置 4.6. ACT_RU_JOB对应实体类 org.activiti.engine.impl.persistence.entity.JobEntityImpl 关键字段 描述 TYPE_ 类型 LOCK_EXP_TIME_ 锁定过期时间 LOCK_OWNER_ 锁定接点 EXCLUSIVE_ 是否唯一 RETRIES_ 重试次数3 REPEAT_ 重复表达式 R5/PT10S EXCEPTION_STACK_ID_ 异常堆栈(资源表 ID) EXCEPTION_MSG_ 异常信息 DUEDATE_ 过期时间 HANDLER_TYPE_ 处理器类型 HANDLER_CFG 处理器配置 EXECUTION_ID_ 流程执行表 ID 4.7 测试代码12345678910111213@Testpublic void testRuntime() &#123; Deployment deployment = activitiRule.getRepositoryService() .createDeployment() .name("二次审批") .addClasspathResource("org/destiny/activiti/SecondApprove.bpmn20.xml") .deploy(); log.info("deployment: &#123;&#125;", deployment); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("k1", "v1"); ProcessInstance processInstance = activitiRule.getRuntimeService() .startProcessInstanceByKey("SecondApprove", variables);&#125; 4.7.1 ACT_RU_EXECUTION 表执行完成后, ACT_RU_EXECUTION 表会生成如下两条记录, 流程启动和用户任务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162*************************** 1. row *************************** ID_: 5 REV_: 1 PROC_INST_ID_: 5 BUSINESS_KEY_: NULL PARENT_ID_: NULL PROC_DEF_ID_: SecondApprove:1:4 SUPER_EXEC_: NULL ROOT_PROC_INST_ID_: 5 ACT_ID_: NULL IS_ACTIVE_: 1 IS_CONCURRENT_: 0 IS_SCOPE_: 1 IS_EVENT_SCOPE_: 0 IS_MI_ROOT_: 0 SUSPENSION_STATE_: 1 CACHED_ENT_STATE_: NULL TENANT_ID_: NAME_: NULL START_TIME_: 2018-12-12 03:40:16.634 START_USER_ID_: NULL LOCK_TIME_: NULL IS_COUNT_ENABLED_: 0 EVT_SUBSCR_COUNT_: 0 TASK_COUNT_: 0 JOB_COUNT_: 0 TIMER_JOB_COUNT_: 0 SUSP_JOB_COUNT_: 0DEADLETTER_JOB_COUNT_: 0 VAR_COUNT_: 0 ID_LINK_COUNT_: 0*************************** 2. row *************************** ID_: 7 REV_: 1 PROC_INST_ID_: 5 BUSINESS_KEY_: NULL PARENT_ID_: 5 PROC_DEF_ID_: SecondApprove:1:4 SUPER_EXEC_: NULL ROOT_PROC_INST_ID_: 5 ACT_ID_: submitApprove IS_ACTIVE_: 1 IS_CONCURRENT_: 0 IS_SCOPE_: 0 IS_EVENT_SCOPE_: 0 IS_MI_ROOT_: 0 SUSPENSION_STATE_: 1 CACHED_ENT_STATE_: NULL TENANT_ID_: NAME_: NULL START_TIME_: 2018-12-12 03:40:16.636 START_USER_ID_: NULL LOCK_TIME_: NULL IS_COUNT_ENABLED_: 0 EVT_SUBSCR_COUNT_: 0 TASK_COUNT_: 0 JOB_COUNT_: 0 TIMER_JOB_COUNT_: 0 SUSP_JOB_COUNT_: 0DEADLETTER_JOB_COUNT_: 0 VAR_COUNT_: 0 ID_LINK_COUNT_: 0 两条记录的 PROC_DEF_ID_ 相同, 说明是同一个流程的实例. 第一条记录的 ID_ 是5, 第二条记录的 PARENT_ID_ 是 5, 说明第二条是第一条生成的. 第二条记录的 ACT_ID_ 值为 submitApprove, 代表 userTask 的一个节点 第二条记录的 IS_SCOPE 值为 0, 代表不是一个全局的执行流, 而第一条是一个全局执行流. 4.7.2 ACT_RU_TASK 表123456789101112131415161718192021*************************** 1. row *************************** ID_: 10 REV_: 1 EXECUTION_ID_: 7 PROC_INST_ID_: 5 PROC_DEF_ID_: SecondApprove:1:4 NAME_: 填写申请信息 PARENT_TASK_ID_: NULL DESCRIPTION_: NULL TASK_DEF_KEY_: submitApprove OWNER_: NULL ASSIGNEE_: NULL DELEGATION_: NULL PRIORITY_: 50 CREATE_TIME_: 2018-12-12 03:40:16.641 DUE_DATE_: NULL CATEGORY_: NULLSUSPENSION_STATE_: 1 TENANT_ID_: FORM_KEY_: NULL CLAIM_TIME_: NULL PROC_DEF_ID_ 为 SecondApprove:1:4 4.7.3. ACT_RU_VARIABLE 表 保存启动时候设置的变量 12345678910111213*************************** 1. row *************************** ID_: 6 REV_: 1 TYPE_: string NAME_: k1EXECUTION_ID_: 5PROC_INST_ID_: 5 TASK_ID_: NULLBYTEARRAY_ID_: NULL DOUBLE_: NULL LONG_: NULL TEXT_: v1 TEXT2_: NULL 执行设置所属人的代码: 12345678910@Testpublic void testSetOwner() &#123; TaskService taskService = activitiRule.getTaskService(); Task task = taskService .createTaskQuery() .processDefinitionKey("SecondApprove") .singleResult(); // 设置所属人 taskService.setOwner(task.getId(), "destiny");&#125; 4.7.4 ACT_RU_IDENTITYLINK*************************** 1. row *************************** ID_: 2501 REV_: 1 GROUP_ID_: NULL TYPE_: participant USER_ID_: destiny TASK_ID_: NULL PROC_INST_ID_: 5 PROC_DEF_ID_: NULL 而此时在 ACT_RU_TASK 表, 对应的 task 的 OWNER_ 字段已经赋值为 destiny 4.7.5 ACT_RU_TASK*************************** 1. row *************************** ID_: 10 REV_: 2 EXECUTION_ID_: 7 PROC_INST_ID_: 5 PROC_DEF_ID_: SecondApprove:1:4 NAME_: 填写申请信息 PARENT_TASK_ID_: NULL DESCRIPTION_: NULL TASK_DEF_KEY_: submitApprove OWNER_: destiny ASSIGNEE_: NULL DELEGATION_: NULL PRIORITY_: 50 CREATE_TIME_: 2018-12-12 07:19:33.134 DUE_DATE_: NULL CATEGORY_: NULL SUSPENSION_STATE_: 1 TENANT_ID_: FORM_KEY_: NULL CLAIM_TIME_: NULL 5. 历史流程数据表 数据表分类 描述 ACT_HI_PROCINST 历史流程实例表 ACT_HI_ACTINST 历史节点信息表, 执行过程中每经过一个节点就会插入一条记录 ACT_HI_TASKINST 历史任务表 ACT_HI_VARINST 历史变量 ACT_HI_IDENTITYLINK 历史参与者 ACT_HI_DETAIL 历史变更, 当使用 FormService 提交表单时, 表单的属性就会存储在该表, 以及变量的更改 ACT_HI_ATTACHMENT 附件 ACT_HI_COMMENT 评论 ACT_EVT_LOG 事件日志 5.1 ACT_HI_PROCINST| 关键字段 |]]></content>
      <categories>
        <category>Activiti</category>
        <category>Java</category>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti(2)--BPMN2.0规范]]></title>
    <url>%2Fblog%2F2018%2F12%2F08%2FActiviti-2-BPMN2-0%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[BPMN2.0: 是一套业务流程模型与符号建模标准 精准的执行语义来描述元素的操作 以 XML 为载体, 以符号可视化业务 BPMN2.0元素: 流对象 连接对象 数据 泳道 描述对象 其中最重要的流对象, 流对象包括活动, 事件和网关, 通过连接对象连接起来, 用来表示数据的流转, 泳道用来对业务的范围做区分, 描述对象并不影响业务的进行, 为流程图的可读性做补充性的描述. 1. 事件1.1 分类按照位置分类: 开始事件 中间事件/边界事件(中间事件是指出现在流程中, 可以单独作为流程节点的事件, 而边界事件指的是附属于某个流程节点的事件) 结束事件 按照特征分类: 捕获时间, 捕获事件是一直在等待被触发的事件, 所有的开始事件都是等待被触发的事件 抛出事件, 执行到节点会自动执行并抛出结果, 结束事件都属于抛出事件. 按照定义分类: 定时事件 错误事件 信号事件 消息事件 1.1.1 定时事件 在使用定时事件时, 首先需要流程引擎的异步开关打开 指定时间(timeDate) 指定持续时间(timeDuration) 周期执行(timeCycle) 定时事件的定义方式: 1234&lt;timerEventDefinition&gt; &lt;!-- 指定定时时间的类型: timeDate --&gt; &lt;timeDate&gt;2018-01-01T10:10:10&lt;/timeDate&gt;&lt;/timerEventDefinition&gt; 1.1.1.1 定时开始事件 123456&lt;startEvent id="timerStartEvent" name="Timer Start"&gt; &lt;timerEventDefinition&gt; &lt;!--在流程部署完成 5 分钟后, 执行5次 --&gt; &lt;timeCycle&gt;R5/PT5M&lt;/timeCycle&gt; &lt;/timerEventDefinition&gt;&lt;/startEvent&gt; 1.1.1.2 定时边界事件 流程流转到一个普通任务时, 如果在指定时间内没有完成, 就会触发定时边界事件 流程定义1234567891011121314151617&lt;startEvent id="startEvent"/&gt;&lt;userTask id="commonTask" name="Common Task"/&gt;&lt;!-- 声明边界事件, attachedToRef 指定边界事件的宿主 --&gt;&lt;boundaryEvent id="boundaryEvent" name="Timer" attachedToRef="commonTask" cancelActivity="true"&gt; &lt;timerEventDefinition&gt; &lt;!-- 部署完 5 秒之后 --&gt; &lt;timeDuration&gt;PT5S&lt;/timeDuration&gt; &lt;/timerEventDefinition&gt;&lt;/boundaryEvent&gt;&lt;userTask id="timeoutTask" name="Timeout Task"/&gt;&lt;endEvent id="end1"/&gt;&lt;endEvent id="end2"/&gt;&lt;!-- 构建顺序流 --&gt;&lt;sequenceFlow sourceRef="startEvent" targetRef="commonTask"/&gt;&lt;sequenceFlow sourceRef="commonTask" targetRef="end1"/&gt;&lt;sequenceFlow sourceRef="boundaryEvent" targetRef="timeoutTask"/&gt;&lt;sequenceFlow sourceRef="timeoutTask" targetRef="end2"/&gt; 测试代码123456789101112131415161718192021222324/** * 超时边界事件 * 流程启动之后, 流转到 commonTask, 此时让当前线程休眠 10 秒(5秒就会超时) * 定时任务超时后执行 timeoutTask */@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-time-boundary.bpmn20.xml"&#125;)public void testTimerBoundary() throws InterruptedException &#123; activitiRule.getRuntimeService().startProcessInstanceByKey("my-process"); // task 列表 List&lt;Task&gt; taskList = activitiRule.getTaskService().createTaskQuery().list(); log.info("task 总数: &#123;&#125;", taskList.size()); for (Task task : taskList) &#123; log.info("task.name = &#123;&#125;", task.getName()); &#125; // 强制睡眠等待边界事件触发 Thread.sleep(10 * 1000); // task 列表 taskList = activitiRule.getTaskService().createTaskQuery().list(); log.info("休眠后 task 总数: &#123;&#125;", taskList.size()); for (Task task : taskList) &#123; log.info("休眠后 task.name = &#123;&#125;", task.getName()); &#125;&#125; 日志输出11:06:06,568 [main] INFO org.destiny.activiti.bpmn20.TimerEventTest - task 总数: 1 11:06:06,568 [main] INFO org.destiny.activiti.bpmn20.TimerEventTest - task.name = Common Task ... 11:06:16,573 [main] INFO org.destiny.activiti.bpmn20.TimerEventTest - 休眠后 task 总数: 1 11:06:16,573 [main] INFO org.destiny.activiti.bpmn20.TimerEventTest - 休眠后 task.name = Timeout Task 1.1.2 错误事件 网关中由提交的表单信息判断正常结束还是异常结束, 错误事件会被错误信息所触发, 主要用于处理业务异常 流程图简单分析 提交一个新的 sales leader, 创建一个子流程, 在子流程中同时对 customer rating 以及 profitability 进行考察, 如果同时通过, 则结束子流程, 完成主流程的 Store lead in CRM system 任务以及结束节点 如果 profitability 任务没有提供足够的信息, 则会抛出错误事件, 错误事件被边界事件所捕获, 进入 Provide additional details 流程, 并进入开始子流程 流程定义1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;error id="notEnoughInfoError" errorCode="not_enough_info" /&gt;&lt;process id="reviewSaledLead" name="Review sales lead"&gt; &lt;startEvent id="theStart" activiti:initiator="initiator" /&gt; &lt;sequenceFlow id="flow1" sourceRef="theStart" targetRef="provideNewSalesLead"/&gt; &lt;userTask id="provideNewSalesLead" name="Provide new sales lead" activiti:assignee="$&#123;initiator&#125;"&gt; &lt;extensionElements&gt; &lt;activiti:formProperty id="customerName" name="Customer name" type="string" required="true"/&gt; &lt;activiti:formProperty id="potentialProfit" name="Potential profit" type="long" /&gt; &lt;activiti:formProperty id="details" name="Details" type="string"/&gt; &lt;/extensionElements&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="provideNewSalesLead" targetRef="reviewSalesLeadSubProcess"/&gt; &lt;!-- 子流程 --&gt; &lt;subProcess id="reviewSalesLeadSubProcess" name="Review sales lead"&gt; &lt;startEvent id="subProcessStart" /&gt; &lt;sequenceFlow id="flow3" sourceRef="subProcessStart" targetRef="fork"/&gt; &lt;sequenceFlow id="flow4" sourceRef="fork" targetRef="reviewProfitability"/&gt; &lt;parallelGateway id="fork" /&gt; &lt;sequenceFlow id="flow5" sourceRef="fork" targetRef="reviewCustomerRating"/&gt; &lt;userTask id="reviewCustomerRating" name="Review customer rating" activiti:candidateGroups="accountancy" /&gt; &lt;sequenceFlow id="flow6" sourceRef="reviewCustomerRating" targetRef="subProcessEnd1"/&gt; &lt;endEvent id="subProcessEnd1" /&gt; &lt;userTask id="reviewProfitability" name="Review profitability" activiti:candidateGroups="management"&gt; &lt;documentation&gt; $&#123;initiator&#125; has published a new sales lead: $&#123;customerName&#125;. Details: $&#123;details&#125; &lt;/documentation&gt; &lt;extensionElements&gt; &lt;activiti:formProperty id="notEnoughInformation" name="Do you believe this customer is profitable?" type="enum" required="true"&gt; &lt;activiti:value id="false" name="Yes" /&gt; &lt;activiti:value id="true" name="No (= request more info)" /&gt; &lt;/activiti:formProperty&gt; &lt;/extensionElements&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow7" sourceRef="reviewProfitability" targetRef="enoughInformationCheck"/&gt; &lt;exclusiveGateway id="enoughInformationCheck" name="Enough information?" /&gt; &lt;sequenceFlow id="flow8" sourceRef="enoughInformationCheck" targetRef="notEnoughInformationEnd"&gt; &lt;conditionExpression&gt;$&#123;notEnoughInformation == 'true'&#125;&lt;/conditionExpression&gt; &lt;/sequenceFlow&gt; &lt;sequenceFlow id="flow9" sourceRef="enoughInformationCheck" targetRef="subProcessEnd2"&gt; &lt;conditionExpression&gt;$&#123;notEnoughInformation == 'false'&#125;&lt;/conditionExpression&gt; &lt;/sequenceFlow&gt; &lt;endEvent id="subProcessEnd2" /&gt; &lt;endEvent id="notEnoughInformationEnd"&gt; &lt;errorEventDefinition errorRef="notEnoughInfoError" /&gt; &lt;/endEvent&gt; &lt;/subProcess&gt; &lt;sequenceFlow id="flow10" sourceRef="reviewSalesLeadSubProcess" targetRef="storeLeadInCrmSystem"/&gt; &lt;boundaryEvent attachedToRef="reviewSalesLeadSubProcess" cancelActivity="true" id="catchNotEnoughInformationError" &gt; &lt;errorEventDefinition errorRef="notEnoughInfoError" /&gt; &lt;/boundaryEvent&gt; &lt;sequenceFlow id="flow11" sourceRef="catchNotEnoughInformationError" targetRef="provideAdditionalDetails"/&gt; &lt;userTask id="provideAdditionalDetails" name="Provide additional details" activiti:assignee="$&#123;initiator&#125;"&gt; &lt;documentation&gt;Provide additional details for $&#123;customerName&#125;.&lt;/documentation&gt; &lt;extensionElements&gt; &lt;activiti:formProperty id="details" name="Additional details" type="string" required="true"/&gt; &lt;/extensionElements&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow12" sourceRef="provideAdditionalDetails" targetRef="reviewSalesLeadSubProcess"/&gt; &lt;task id="storeLeadInCrmSystem" name="Store lead in CRM system" /&gt; &lt;sequenceFlow id="flow13" sourceRef="storeLeadInCrmSystem" targetRef="processEnd"/&gt; &lt;endEvent id="processEnd" /&gt;&lt;/process&gt; 测试代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class BoundaryErrorEventTest extends PluggableActivitiTestCase &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Override protected void setUp() throws Exception &#123; super.setUp(); // 设置当前用户 Authentication.setAuthenticatedUserId("destiny"); &#125; @Override public void tearDown() throws Exception &#123; Authentication.setAuthenticatedUserId(null); super.tearDown(); &#125; @Deployment(resources = &#123;"org/destiny/activiti/reviewSalesLead.bpmn20.xml"&#125;) public void testReviewSalesLeadProcess() &#123; Map&lt;String, Object&gt; variables = new HashMap&lt;&gt;(); variables.put("details", "interesting"); variables.put("customerName", "Camery"); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("reviewSaledLead", variables); log.info("processInstance: &#123;&#125;", ToStringBuilder.reflectionToString(processInstance, ToStringStyle.JSON_STYLE)); Task task = taskService.createTaskQuery() .taskAssignee("destiny") .singleResult(); log.info("task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); // 使用断言确认 assertEquals(task.getName(), "Provide new sales lead"); // 提交节点 taskService.complete(task.getId()); // 进入并行网关, 会同时生成两个 task Task ratingTask = taskService.createTaskQuery().taskCandidateGroup("accountancy").singleResult(); log.info("ratingTask: &#123;&#125;", ToStringBuilder.reflectionToString(ratingTask, ToStringStyle.JSON_STYLE)); assertEquals(ratingTask.getName(), "Review customer rating"); Task profitabilityTask = taskService.createTaskQuery().taskCandidateGroup("management").singleResult(); log.info("profitabilityTask: &#123;&#125;", ToStringBuilder.reflectionToString(profitabilityTask, ToStringStyle.JSON_STYLE)); assertEquals(profitabilityTask.getName(), "Review profitability"); // Review profitability 提交后就会触发 errorEvent variables = new HashMap&lt;&gt;(); variables.put("notEnoughInformation", true); taskService.complete(profitabilityTask.getId(), variables); // 查找流程发起者 destiny 对应的 task // 此时 errorEvent 会被边界条件捕获, 流转到 Review profitability Task provideDetailsTask = taskService.createTaskQuery().taskAssignee("destiny").singleResult(); log.info("provideDetailsTask: &#123;&#125;", ToStringBuilder.reflectionToString(provideDetailsTask, ToStringStyle.JSON_STYLE)); assertEquals(provideDetailsTask.getName(), "Provide additional details"); // 完成 Review profitability 节点后, 会重新进入子流程 taskService.complete(provideDetailsTask.getId()); List&lt;Task&gt; reviewTasks = taskService.createTaskQuery().orderByTaskName().asc().list(); for (Task reviewTask : reviewTasks) &#123; log.info("reviewTask: &#123;&#125;", ToStringBuilder.reflectionToString(reviewTask, ToStringStyle.JSON_STYLE)); &#125; assertEquals(reviewTasks.get(0).getName(), "Review customer rating"); assertEquals(reviewTasks.get(1).getName(), "Review profitability"); taskService.complete(reviewTasks.get(0).getId()); variables.put("notEnoughInformation", false); taskService.complete(reviewTasks.get(1).getId(), variables); assertProcessEnded(processInstance.getId()); &#125;&#125; 日志输出 分析日志可以看到, 没有错误所有的断言全部通过, 证明整个流程无误(日志量比较大, 为了能够清晰描述流程特地将日志格式调整) 03:53:20,823 [main] INFO org.activiti.engine.ProcessEngines - initialised process engine default 03:53:23,006 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,008 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : theStart (StartEvent, parent id 5 (active) 03:53:23,009 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,009 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : theStart (StartEvent, parent id 5 (active) 03:53:23,010 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,010 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : theStart -&gt; provideNewSalesLead, parent id 5 (active) 03:53:23,010 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,011 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : provideNewSalesLead (UserTask, parent id 5 (active) 03:53:23,053 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - processInstance: {&quot;currentFlowElement&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;processInstance&quot;:&quot;ProcessInstance[5]&quot;,&quot;parent&quot;:null,&quot;executions&quot;:[Execution[ id &apos;10&apos; ] - activity &apos;provideNewSalesLead - parent &apos;5&apos;],&quot;superExecution&quot;:null,&quot;subProcessInstance&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;name&quot;:null,&quot;description&quot;:null,&quot;localizedName&quot;:null,&quot;localizedDescription&quot;:null,&quot;lockTime&quot;:null,&quot;isActive&quot;:true,&quot;isScope&quot;:true,&quot;isConcurrent&quot;:false,&quot;isEnded&quot;:false,&quot;isEventScope&quot;:false,&quot;isMultiInstanceRoot&quot;:false,&quot;isCountEnabled&quot;:false,&quot;eventName&quot;:null,&quot;eventSubscriptions&quot;:[],&quot;jobs&quot;:[],&quot;timerJobs&quot;:[],&quot;tasks&quot;:[],&quot;identityLinks&quot;:[IdentityLinkEntity[id=7, type=starter, userId=destiny, processInstanceId=5]],&quot;deleteReason&quot;:null,&quot;suspensionState&quot;:1,&quot;startUserId&quot;:&quot;destiny&quot;,&quot;startTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;eventSubscriptionCount&quot;:0,&quot;taskCount&quot;:0,&quot;jobCount&quot;:0,&quot;timerJobCount&quot;:0,&quot;suspendedJobCount&quot;:0,&quot;deadLetterJobCount&quot;:0,&quot;variableCount&quot;:0,&quot;identityLinkCount&quot;:0,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;processDefinitionKey&quot;:&quot;reviewSaledLead&quot;,&quot;processDefinitionName&quot;:&quot;Review sales lead&quot;,&quot;processDefinitionVersion&quot;:1,&quot;deploymentId&quot;:null,&quot;activityId&quot;:null,&quot;activityName&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;businessKey&quot;:null,&quot;parentId&quot;:null,&quot;superExecutionId&quot;:null,&quot;rootProcessInstanceId&quot;:&quot;5&quot;,&quot;rootProcessInstance&quot;:null,&quot;forcedUpdate&quot;:false,&quot;queryVariables&quot;:null,&quot;isDeleted&quot;:false,&quot;variableInstances&quot;:{details=VariableInstanceEntity[id=8, name=details, type=string, textValue=interesting], customerName=VariableInstanceEntity[id=9, name=customerName, type=string, textValue=Camery], initiator=VariableInstanceEntity[id=6, name=initiator, type=string, textValue=destiny]},&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;5&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:true,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,075 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:1,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:&quot;destiny&quot;,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Provide new sales lead&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:null,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;10&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;taskDefinitionKey&quot;:&quot;provideNewSalesLead&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;13&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,081 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 03:53:23,082 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : provideNewSalesLead (UserTask, parent id 5 (active) 03:53:23,083 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,083 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : provideNewSalesLead (UserTask, parent id 5 (active) 03:53:23,084 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,084 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : provideNewSalesLead -&gt; reviewSalesLeadSubProcess, parent id 5 (active) 03:53:23,084 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,084 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) 03:53:23,086 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,087 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) └── 17 : subProcessStart (StartEvent, parent id 14 (active) 03:53:23,087 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,087 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) └── 17 : subProcessStart (StartEvent, parent id 14 (active) 03:53:23,087 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,088 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) └── 17 : subProcessStart -&gt; fork, parent id 14 (active) 03:53:23,088 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,088 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) └── 17 : fork (ParallelGateway, parent id 14 (active) 03:53:23,088 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,089 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) └── 17 : fork (ParallelGateway, parent id 14 (not active) 03:53:23,089 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,089 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : fork -&gt; reviewProfitability, parent id 14 (active) └── 20 : fork -&gt; reviewCustomerRating, parent id 14 (active) 03:53:23,089 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,090 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : reviewProfitability (UserTask, parent id 14 (active) └── 20 : fork -&gt; reviewCustomerRating, parent id 14 (active) 03:53:23,090 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,090 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : reviewProfitability (UserTask, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,092 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,092 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 10 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : reviewProfitability (UserTask, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,114 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - ratingTask: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Review customer rating&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:null,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;20&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;taskDefinitionKey&quot;:&quot;reviewCustomerRating&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;25&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,116 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - profitabilityTask: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Review profitability&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;destiny has published a new sales lead: Camery. Details: interesting&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;17&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;taskDefinitionKey&quot;:&quot;reviewProfitability&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;22&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,122 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 03:53:23,125 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : reviewProfitability (UserTask, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,126 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,126 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : reviewProfitability (UserTask, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,126 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,127 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : reviewProfitability -&gt; enoughInformationCheck, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,127 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,127 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : enoughInformationCheck (ExclusiveGateway, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,131 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,131 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : enoughInformationCheck -&gt; notEnoughInformationEnd, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,132 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,132 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : enoughInformationCheck -&gt; notEnoughInformationEnd, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,132 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,132 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : notEnoughInformationEnd (EndEvent, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,133 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 03:53:23,134 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 14 (active) ├── 17 : notEnoughInformationEnd (EndEvent, parent id 14 (active) └── 20 : reviewCustomerRating (UserTask, parent id 14 (active) 03:53:23,139 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,139 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 17 : notEnoughInformationEnd (EndEvent, parent id 14 (not active) (ended) └── 20 : reviewCustomerRating (UserTask, parent id 14 (not active) (ended) └── 16 : catchNotEnoughInformationError (BoundaryEvent, parent id 5 (active) 03:53:23,139 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,139 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 17 : notEnoughInformationEnd (EndEvent, parent id 14 (not active) (ended) └── 20 : reviewCustomerRating (UserTask, parent id 14 (not active) (ended) └── 16 : catchNotEnoughInformationError -&gt; provideAdditionalDetails, parent id 5 (active) 03:53:23,139 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,140 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 14 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 17 : notEnoughInformationEnd (EndEvent, parent id 14 (not active) (ended) └── 20 : reviewCustomerRating (UserTask, parent id 14 (not active) (ended) └── 16 : provideAdditionalDetails (UserTask, parent id 5 (active) 03:53:23,150 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - provideDetailsTask: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:1,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:&quot;destiny&quot;,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Provide additional details&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;Provide additional details for Camery.&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;16&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;taskDefinitionKey&quot;:&quot;provideAdditionalDetails&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;32&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,152 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 03:53:23,153 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : provideAdditionalDetails (UserTask, parent id 5 (active) 03:53:23,154 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,154 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : provideAdditionalDetails (UserTask, parent id 5 (active) 03:53:23,155 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,155 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : provideAdditionalDetails -&gt; reviewSalesLeadSubProcess, parent id 5 (active) 03:53:23,155 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,155 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) 03:53:23,156 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,157 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : subProcessStart (StartEvent, parent id 33 (active) 03:53:23,157 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,157 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : subProcessStart (StartEvent, parent id 33 (active) 03:53:23,157 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,158 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : subProcessStart -&gt; fork, parent id 33 (active) 03:53:23,158 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,158 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : fork (ParallelGateway, parent id 33 (active) 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : fork (ParallelGateway, parent id 33 (not active) 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) ├── 36 : fork -&gt; reviewProfitability, parent id 33 (active) └── 39 : fork -&gt; reviewCustomerRating, parent id 33 (active) 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) ├── 36 : reviewProfitability (UserTask, parent id 33 (active) └── 39 : fork -&gt; reviewCustomerRating, parent id 33 (active) 03:53:23,159 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,160 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) ├── 36 : reviewProfitability (UserTask, parent id 33 (active) └── 39 : reviewCustomerRating (UserTask, parent id 33 (active) 03:53:23,161 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,162 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 16 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (ended) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) ├── 36 : reviewProfitability (UserTask, parent id 33 (active) └── 39 : reviewCustomerRating (UserTask, parent id 33 (active) 03:53:23,180 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - reviewTask: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Review customer rating&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:null,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;39&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;taskDefinitionKey&quot;:&quot;reviewCustomerRating&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;44&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,180 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - reviewTask: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Review profitability&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;destiny has published a new sales lead: Camery. Details: interesting&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Sat Dec 08 15:53:23 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;36&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;5&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;reviewSaledLead:1:4&quot;,&quot;taskDefinitionKey&quot;:&quot;reviewProfitability&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;41&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} 03:53:23,183 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 03:53:23,190 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 39 : reviewCustomerRating (UserTask, parent id 33 (active) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,190 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,190 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 39 : reviewCustomerRating (UserTask, parent id 33 (active) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,191 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,191 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 39 : reviewCustomerRating -&gt; subProcessEnd1, parent id 33 (active) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,191 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,191 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 39 : subProcessEnd1 (EndEvent, parent id 33 (active) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,191 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,192 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 39 : subProcessEnd1 (EndEvent, parent id 33 (active) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,192 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : 03:53:23,193 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 39 : subProcessEnd1 (EndEvent, parent id 33 (active) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,203 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 03:53:23,204 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,205 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,205 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability (UserTask, parent id 33 (active) 03:53:23,206 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,206 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : reviewProfitability -&gt; enoughInformationCheck, parent id 33 (active) 03:53:23,206 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,206 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : enoughInformationCheck (ExclusiveGateway, parent id 33 (active) 03:53:23,206 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,206 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : enoughInformationCheck -&gt; subProcessEnd2, parent id 33 (active) 03:53:23,207 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,207 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : enoughInformationCheck -&gt; subProcessEnd2, parent id 33 (active) 03:53:23,207 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,207 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (active) 03:53:23,207 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,207 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (active) 03:53:23,208 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : 03:53:23,208 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) (scope) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (active) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (active) 03:53:23,211 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,211 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (active) 03:53:23,211 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,211 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : reviewSalesLeadSubProcess -&gt; storeLeadInCrmSystem, parent id 5 (active) 03:53:23,211 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : storeLeadInCrmSystem (ManualTask, parent id 5 (active) 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : storeLeadInCrmSystem (ManualTask, parent id 5 (active) 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : storeLeadInCrmSystem -&gt; processEnd, parent id 5 (active) 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : processEnd (EndEvent, parent id 5 (active) 03:53:23,212 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : 03:53:23,213 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : processEnd (EndEvent, parent id 5 (active) 03:53:23,213 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : 03:53:23,213 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - 5 (process instance) └── 33 : reviewSalesLeadSubProcess (SubProcess, parent id 5 (not active) (scope) (ended) ├── 35 : catchNotEnoughInformationError (BoundaryEvent, parent id 33 (not active) (ended) └── 36 : subProcessEnd2 (EndEvent, parent id 33 (not active) (ended) └── 49 : processEnd (EndEvent, parent id 5 (active) 03:53:23,281 [main] INFO org.activiti.engine.impl.test.AbstractTestCase - database was clean 1.1.3. 信号事件1.1.3.1. 信号开始事件 信号开始事件的启动方式与普通开始事件启动方式很接近, 需要发出对应的信号去启动它 123456&lt;signal id="theSignal" name="The signal"/&gt;&lt;process id="processWithSignalStart1"&gt; &lt;startEvent id="theStart"&gt; &lt;signalEventDefinition id="theSignalEventDefinition" signalRef="theSignal"/&gt; &lt;/startEvent&gt;&lt;/process&gt; 1.1.3.2 信号中间事件123456789101112&lt;signal id="alterSignal" name="alter"/&gt;&lt;process id="catchSignal"&gt; &lt;!-- 信号抛出事件 --&gt; &lt;intermediateThrowEvent id="throwSignalEvent" name="Alter"&gt; &lt;signalEventDefinition signalRef="alterSignal"/&gt; &lt;/intermediateThrowEvent&gt; &lt;!-- 信号捕获事件 --&gt; &lt;intermediateCatchEvent id="throwSignalEvent" name="On Alter"&gt; &lt;signalEventDefinition signalRef="alterSignal"/&gt; &lt;/intermediateCatchEvent&gt;&lt;/process&gt; 1.1.4 消息事件 消息事件的定义和信号事件的定义非常相近 123456789101112&lt;message id="newInvoice" name="newInvoiceMessage"/&gt;&lt;message id="payment" name="paymentMessage"/&gt;&lt;process id="catchSignal"&gt; &lt;startEvent id="messageStart"&gt; &lt;messsageEventDefinition messageRef="newInvoice"/&gt; &lt;/startEvent&gt; &lt;!-- 信号捕获事件 --&gt; &lt;intermediateCatchEvent id="paymentEvt"&gt; &lt;messageEventDefinition messageRef="payment"/&gt; &lt;/intermediateCatchEvent&gt;&lt;/process&gt; 3. 顺序流和和网关顺序流的分类: 顺序流 条件顺序流 默认顺序流 3.1. 网关网关的分类: 排他网关(Exclusive Gateway) 并行网关(Parallel Gateway) 包容网关(Inclusive Gateway), 类似排他网关和并行网关的组合体, 即支持多条路, 有支持表达式 事件网关(Event-based Gateway), 每个分支都有一个捕获事件等待被触发, 一个触发后, 其他都会失效 3.1.1. 排他网关 分支判断只能选一支持默认 流程定义12345678910111213141516&lt;exclusiveGateway id="exclusiveGateway1" name="Exclusive Gateway"/&gt;&lt;userTask id="userTask1" name="精英"/&gt;&lt;userTask id="userTask2" name="优秀"/&gt;&lt;userTask id="userTask3" name="普通"/&gt;&lt;sequenceFlow id="flow2" sourceRef="exclusiveGateway1" targetRef="userTask1"&gt; &lt;conditionExpression xsi:type="tFormalExpression"&gt; &lt;![CDATA[score &gt;= 90]]&gt; &lt;/conditionExpression&gt;&lt;/sequenceFlow&gt;&lt;sequenceFlow id="flow3" sourceRef="exclusiveGateway1" targetRef="userTask2"&gt; &lt;conditionExpression xsi:type="tFormalExpression"&gt; &lt;![CDATA[score &gt;= 75 &amp;&amp; score &lt; 90]]&gt; &lt;/conditionExpression&gt;&lt;/sequenceFlow&gt;&lt;!-- 默认数据流 --&gt;&lt;sequenceFlow id="flow4" sourceRef="exclusiveGateway1" targetRef="userTask1"/&gt; 测试代码123456789101112@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-exclusive.bpmn20.xml"&#125;)public void testExclusiveGateway() &#123; Map&lt;String, Object&gt; variables = new HashMap&lt;&gt;(); variables.put("key1", 3); variables.put("score", 91); ProcessInstance processInstance = activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); // org.destiny.activiti.bpmn20.GatewayTest - task.name = 精英 log.info("task.name = &#123;&#125;", task.getName()); assertEquals(task.getName(), "精英");&#125; 3.1.2. 并行网关 让流程从单线程变为并发情况, 原有的一条流转数据变为两条, 可以同时进行确认支付和确认收货, 当这两个条件同时满足时, 继续进行后面的操作 流程并发 分支 合并 忽略条件(即使填了条件也不会生效) 非对称(不要求所有的分支最终都合并在一起) 流程定义12345678910&lt;parallelGateway id="parallelGateway1" name="Parallel Gateway"/&gt;&lt;userTask id="userTask1" name="确认支付"/&gt;&lt;userTask id="userTask2" name="确认收货"/&gt;&lt;sequenceFlow id="flow3" sourceRef="parallelGateway1" targetRef="userTask1"/&gt;&lt;sequenceFlow id="flow4" sourceRef="parallelGateway1" targetRef="userTask2"/&gt;&lt;parallelGateway id="parallelGateway2" name="parallelGateway"/&gt;&lt;sequenceFlow id="flow8" sourceRef="userTask1" targetRef="parallelGateway2"/&gt;&lt;sequenceFlow id="flow9" sourceRef="userTask2" targetRef="parallelGateway2"/&gt;&lt;userTask id="userTask3" name="订单完成"/&gt;&lt;sequenceFlow id="flow10" sourceRef="parallelGateway2" targetRef="userTask3"/&gt; 测试代码12345678910111213141516171819202122232425@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-parallel.bpmn20.xml"&#125;)public void testParallelGateway() &#123; activitiRule.getRuntimeService().startProcessInstanceByKey("my-process"); List&lt;Task&gt; taskList = activitiRule.getTaskService().createTaskQuery().list(); log.info("过并行网关时的 task 数量: &#123;&#125;", taskList.size()); for (Task task : taskList) &#123; log.info("task name: &#123;&#125;", task.getName()); &#125; assertEquals(2, taskList.size()); activitiRule.getTaskService().complete(taskList.get(0).getId()); List&lt;Task&gt; taskList1 = activitiRule.getTaskService().createTaskQuery().list(); log.info("提交第 1 个任务时的 task 数量: [&#123;&#125;]", taskList1.size()); for (Task task : taskList1) &#123; log.info("task name: &#123;&#125;", task.getName()); &#125; assertEquals(1, taskList1.size()); activitiRule.getTaskService().complete(taskList.get(1).getId()); List&lt;Task&gt; taskList2 = activitiRule.getTaskService().createTaskQuery().list(); log.info("提交第 2 个任务时的 task 数量: [&#123;&#125;]", taskList2.size()); for (Task task : taskList2) &#123; log.info("task name: &#123;&#125;", task.getName()); &#125; assertEquals(1, taskList1.size());&#125; 日志输出06:17:51,705 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - 过并行网关时的 task 数量: 2 06:17:51,705 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - task name: 确认支付 06:17:51,706 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - task name: 确认收货 06:17:51,710 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 06:17:51,721 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - 提交第 1 个任务时的 task 数量: [1] 06:17:51,721 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - task name: 确认收货 06:17:51,724 [main] INFO org.activiti.engine.impl.interceptor.DebugCommandInvoker - Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : 06:17:51,738 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - 提交第 2 个任务时的 task 数量: [1] 06:17:51,738 [main] INFO org.destiny.activiti.bpmn20.GatewayTest - task name: 订单完成 3.1.3. 包容性网关 可以理解为排他网关和并行网关的结合体 排他网关有条件, 只能选择一条路径 并行网关不带条件, 所有路径都会执行 包容性网关有条件, 且支持并行运行 并发 分支 合并 条件 非对称 事件网关 会根据连接的捕获时间决定流程的走向, 只能走一条线路 流程暂停 事件订阅 捕获事件 单一执行]]></content>
      <categories>
        <category>Activiti</category>
        <category>工作流</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti6.0用户指引中文版]]></title>
    <url>%2Fblog%2F2018%2F12%2F05%2FActiviti6-0%E7%94%A8%E6%88%B7%E6%8C%87%E5%BC%95%E4%B8%AD%E6%96%87%E7%89%88%2F</url>
    <content type="text"><![CDATA[1. 引导1.1. License 许可Activiti 是在 Apache V2 license 许可下发布的. 1.2. 下载http://activiti.org/download.html 1.3. 源代码该发行版以 jar 文件的形式包含了大多数源代码, Activiti 的源代码可以在 https://github.com/Activiti/Activiti 找到. 1.4. Required software 必需的软件1.4.1. JDK 7+Activiti 需要 JDK 版本高于或等于 7, 前往 Oracle Java SE downloads 进行下载. 在该页面上有相关的下载说明, 可以通过在命令行运行 java -version 命令来验证安装是否成功. 该命令会打印出安装的 JDK 版本. 1.4.2. IDE2. Getting Started 启动2.1. One minute version 一分钟版在从 Activiti website 下载了 Activiti UI 的 WAR 包之后, 按照这些步骤去以默认配置运行样例. 你需要安装 Java runtime 和 Apache Tomcat(实际上, 任意一个 web 容器都可以正常运行, 因为我们只依赖与 Servlet 的能力, 但我们主要在 Tomcat 上进行测试) 将下载的 activiti-app.war 文件复制到 Tomcat 的 webapps 路径下 通过 bin 路径下的 startup.sh 或 startop.bat 启动 Tomcat 当 Tomcat 启动后, 打开浏览器并前往 http://localhost:8080/activiti-app, 使用账号 admin, 密码 test 登录 这样就可以了, ActivitiUI 应用默认使用基于内存的 H2 数据库 2.2 Activiti setup Activiti 的安装要安装 Activiti, 需要安装 Java runtime 和 Apache Tomcat, 并且确认系统变量 JAVA_HOME 已经正确的设置, 具体设置的方式取决于你的操作系统. 只需要将 war 文件从 Activiti 下载页面下载到 Tomcat 安装路径下的 webapps 路径就可以让 Activiti UI 和 REST 应用启动. 默认情况下 UI 应用使用内存数据库运行. 示例用户: userId Password Security roles admin test admin 现在可以访问的应用: Webapp Name URL Description Activiti UI http://localhost:8080/activiti-app 流程引擎用户控制台, 通过该工具可以开启新的流程, 分配任务, 查看和认领任务等 需要注意的是, Activiti UI 项目实例的启动只是一个简单快速演示功能的方式, 并不是说只能使用这种方式使用 Activiti. Activiti 只是一个 jar 文件, 可以嵌入到任何 Java 环境中, 比如 swing, Tomcat, JBoss, WebSphere 等. 或者也可以选择将Activiti作为一个典型的独立BPM服务器来运行, 只要能在 Java 中完成的, 就能使用 Activiti. 2.3. Activiti database setup 数据库安装如同在一分钟版示例说的, Activiti UI 应用默认使用内存数据库 H2. 要让 Activiti UI 应用使用独立的 H2 或者其他的数据库, 可以修改 WEB-INF/classes/META-INF/activiti-app 路径下的 activiti-app.properties 文件 2.4 Include the Activiti jar and its denpendices 包含 jar 及其依赖为了包含 Activiti jar 和它的依赖库, 我们决定使用 maven, 因为它简化了我们双方的依赖管理. 根据引导 http://www.activiti.org/community.html#maven.repository 来引入必要的依赖. 作为选择, 如果你不想使用 maven, 可以直接在项目中引入 jar 文件. Activiti 下载的压缩包包含一个文件夹 libs, 其中包含了所有 Activiti jar 文件(以及源代码 jar). 依赖不是通过这种方式提供的, Activiti 必须的依赖如下所示(使用 mvn dependency:tree 生成): org.activiti:activiti-engine:jar:6.x +- org.activiti:activiti-bpmn-converter:jar:6.x:compile | \- org.activiti:activiti-bpmn-model:jar:6.x:compile | +- com.fasterxml.jackson.core:jackson-core:jar:2.2.3:compile | \- com.fasterxml.jackson.core:jackson-databind:jar:2.2.3:compile | \- com.fasterxml.jackson.core:jackson-annotations:jar:2.2.3:compile +- org.activiti:activiti-process-validation:jar:6.x:compile +- org.activiti:activiti-image-generator:jar:6.x:compile +- org.apache.commons:commons-email:jar:1.2:compile | +- javax.mail:mail:jar:1.4.1:compile | \- javax.activation:activation:jar:1.1:compile +- org.apache.commons:commons-lang3:jar:3.3.2:compile +- org.mybatis:mybatis:jar:3.3.0:compile +- org.springframework:spring-beans:jar:4.1.6.RELEASE:compile | \- org.springframework:spring-core:jar:4.1.6.RELEASE:compile +- joda-time:joda-time:jar:2.6:compile +- org.slf4j:slf4j-api:jar:1.7.6:compile +- org.slf4j:jcl-over-slf4j:jar:1.7.6:compile 注意, 如果需要使用 mail service task 才需要引入 mail 依赖 jar. 所有的依赖可以很轻松的通过使用 mvn denpendency:cpoy-dependencies 在 activiti源代码 上下载. 2.5. Next steps 下一步3. Configuration 配置3.1. Creating a ProcessEngine 创建一个流程引擎Activiti 流程引擎通过 XML 文件 activiti.cfg.xml 配置, 需要注意的是不适用于 Spring 风格下的流程引擎创建. 获取 流程引擎 最简单的方式是使用 org.activiti.engine.ProcessEngines 类: 1ProcessEngine processEngine = ProcessEngines.getDefauleProcesEngine(); 这样的方式会在 classpath 上寻找 activiti.cfg.xml 文件, 并且基于文件中的配置去构造引擎. 下面的片段展示了一个配置文件的样例, 后面的章节会给出配置参数的详细介绍. 1234567891011121314151617181920&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="jdbcUrl" value="jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000" /&gt; &lt;property name="jdbcDriver" value="org.h2.Driver" /&gt; &lt;property name="jdbcUsername" value="sa" /&gt; &lt;property name="jdbcPassword" value="" /&gt; &lt;property name="databaseSchemaUpdate" value="true" /&gt; &lt;property name="asyncExecutorActivate" value="false" /&gt; &lt;property name="mailServerHost" value="mail.my-corp.com" /&gt; &lt;property name="mailServerPort" value="5025" /&gt; &lt;/bean&gt;&lt;/beans&gt; 值得注意的是, 这个 XML 配置文件实际上是一个 Spring 配置文件. 这并不意味着 Activiti 只能运行在 Spring 环境中. 我们仅仅是在内部利用 Spring 解析和依赖注入的能力来构建引擎. ProcessEngineConfiguration 对象也可以被配置文件编程式的创建, 也可以用一个不同 bean id. 12345678910// 基于默认配置文件 activiti.cfg.xmlProcessEngineConfiguration.createProcessEngineConfigurationFromResourceDefault();// 指定路径ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource);// 指定路径和提取的 bean idProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName);// 指定输入流ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream);// 指定输入流和 bean idProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName); 与此同时, 也可以不使用配置文件, 直接通过默认创建配置(参考不同的支持类) 12ProcessEngineConfiguraion.createStandaloneProcessEngineConfiguration();ProcessEngineConfiguraion.createStandaloneInMemProcessEngineConfiguration(); 所有这些 ProcessEngineConfiguraion.createXXX() 方法返回一个后续可调整的 ProcessEngineConfiguraion 方便链式调用, 在调用 buildProcessEngine() 操作后, 就会创建一个 ProcessEngine 12345ProcessEngine processEngine = ProcessEngineConfiguraion.createStandaloneInMemProcessEngineConfiguration() .setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_FALSE) .setJdbcUrl("jdbc:h2:mem:my-own-db;DB_CLOSE_DELAY=1000") .setAsyncExcutorActivate(false) .buildProcessEngine(); 3.2. ProcessEngineConfiguration beanactiviti.cfg.xml 必须包含一个 id 为 processEngineConfiguraion 的 bean 123&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;!-- ... --&gt;&lt;/bean&gt; 这个 bean 会用来构建 ProceeEngine, 有多个类可以用来定义 processEngineConfiguration, 这些类代表了不同的环境, 并且设置了对应的默认值. 最佳的实践是选择与你当前环境最符合的类, 这样可以少配置几个引擎的参数, 下面是当前可用的类: org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration: 这个 ProcessEngine 单独运行, Activiti 会自己处理事务, 默认情况下, 数据库只会在引擎启动的时候检查(并且如果没有 Activiti 的表或者表的版本不正确时会抛出异常); org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration: 这是一个方便的单元测试类, Activiti 会自己控制事务, 默认使用一个基于内存的 H2 数据库, 数据库分别会在启动和关闭的时候创建以及销毁, 当使用它的时候, 或许不需要额外的配置(除了使用 job 执行器或者邮件功能以外); org.activiti.spring.SpringProcessEngineConfiguration: 在 Spring 环境下使用流程引擎, 参考 Spring 集成; org.activiti.engine.impl.cfg.JtaProcessEngineConfiguration: 单独运行的流程引擎, 并使用 JTA 事务. 3.3. Database Configuration 数据库配置有两种方式配置数据库给 Activiti 引擎使用, 第一种方式是定义 JDBC 的数据库配置文件 jdbcUrl: 数据库连接 jdbcDriver: 驱动类 jdbcUsername: 数据库用户名 jdbcPassword: 数据库用户密码 基于 JDBC 配置文件构造出的数据源将默认使用 MyBatis 连接池, 下面的配置可以用来构造连接池: jdbcMaxActiveConnections: 任意时间数据库连接池中的最大连接数, 默认为 10; jdbcMaxIdleConnections: 连接池中处于空闲状态的连接的最大值; jdbcMaxCheckoutTime: 连接被取出使用的最长时间, 超过时间会被强制回收. 默认为20000(20 秒); jdbcMaxWaitTime: 这是一个底层配置, 当获得的时间较长时, 给连接池一个打印日志并重新尝试获得连接的机会, 默认为20000(20 秒). 数据库连接池默认配置: 1234&lt;property name="jdbcUrl" value="jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000" /&gt;&lt;property name="jdbcDriver" value="org.h2.Driver" /&gt;&lt;property name="jdbcUsername" value="sa" /&gt;&lt;property name="jdbcPassword" value="" /&gt; 我们的基准表明, MyBatis 连接池在大量并发请求下并不是最有效率的, 因此, 建议使用 javax.sql.DataSource 的实现 并且注入到 ProcessEngine 配置中(比如 DBCP, C3P0, Hikari, Tomcat Connection Pool等): 123456789101112&lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" &gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/activiti" /&gt; &lt;property name="username" value="activiti" /&gt; &lt;property name="password" value="activiti" /&gt; &lt;property name="defaultAutoCommit" value="false" /&gt;&lt;/bean&gt;&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; ... 注意, Activiti 并没有包含这些数据源, 因此你必须确保这些类库在你的类路径下. 不管是采用 JDBC 还是 DataSource 的方式, 下面的配置可以被设置: databaseType: 通常是不需要去单独制定这项配置, 因为会被数据库连接的元数据自动分析出来, 只有当自动制定失败的时候才需要被设置. 可能的值有 {h2, mysql, oracle, postgres, mssql, db2}. 这项配置会决定哪些创建/删除脚本和查询语句会被使用. 参考 支持数据库章节 了解支持哪些类型. databaseSchemaUpdate: 允许设置的策略去决定数据库表在流程启动和结束的时候被如何处理: false(默认): 当 ProcessEngine 启动的时候, 检查数据库表的版本是否匹配依赖库的版本, 并在不匹配的时候抛出异常; true: 在 ProcessEngine 构建时, 执行检查, 如果有需要就执行更新, 如果数据库表不存在, 就重新创建; create-drop: 在 ProcessEngine 启动的时候创建数据库表, 并且在 ProcessEngine 关闭的时候删除数据库表. 4. The Activiti API Activiti API4.1. The Process Engine API ans Service ProcessEngine 的 API 和服务引擎的相关 API 是与 Activiti 交互最多的方式, 最重要的开始点就是 ProcessEngine, 它可以被多种在 配置部分 描述的方式创建, 你可以获得多种包含 工作流/BPM 方法的服务. ProcessEngine 和服务对象都是线程安全的, 因此可以在整个应用中维护一个实例. 12345678910ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();Engine.getRuntimeService();RepositoryService repositoryService = processEngine.getRepositoryService();TaskService taskService = processEngine.getTaskService();ManagementService managementService = processEngine.getManagementService();IdentityService identityService = processEngine.getIdentityService();HistoryService historyService = processEngine.getHistoryService();FormService formService = processEngine.getFormService();DynamicBpmnService dynamicBpmnService = processEngine.getDynamicBpmnService(); ProcessEngines.getDefaultProcessEngine() 会在第一次调用时初始化并构建一个 ProcessEngine, 并且后面始终返回相同的实例. 对应的可以创建和关闭所有 ProcessEngine: ProcessEngine.init() 和 ProcessEngine.destroy() ProcessEngine 类会扫描所有的 activiti.cfg.xml 和 activiti-context.xml 文件, 对于 activtivi.cfg.xml 文件, 流程引擎会使用专有的方式构建: ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(inputStream).buildProcessEngine()]]></content>
      <categories>
        <category>Activiti</category>
        <category>工作流</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti工作流引擎]]></title>
    <url>%2Fblog%2F2018%2F11%2F26%2FActiviti%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前段时间入职字节跳动, 目前负责 Lark 工作流审批功能的开发, 选用工作流引擎 Activiti 进行开发, 因此在此记录下对 Activiti 的学习过程. 概念 工作流引擎是用来驱动业务, 按照流程图次逐步流转的核心框架, 在复杂多变的场景下采用工作流引擎可以大大降低业务部署成本. 通过标准的业务流程模型作为业务与开发工作的桥梁, 有效减少业务团队与技术交流的障碍. 工作流引擎最早用于企业 OA, CRM, 流程审批等系统的流程审批.现在的工作流引擎已经大量运用到互联网电商, 金融出行, 中台支撑等. 工作流引擎在互联网公司快速盛行, 掌握工作流引擎技术可以提升技术架构和业务建模能力. 目录: 工作流入门 Activiti 6.0 源码浅析 Activiti 6.0 引擎配置 Activiti 6.0 核心 API 数据设计与模型映射 BPMN 2.0 规范 集成 SpringBoot 2.0 搭建工作流平台 1. 工作流入门1.1 工作流介绍1.1.1 出差流程审批业务场景: 审批流程模型化: 从一个开始节点, 经过多个任务节点和分支节点, 最终流向结束节点. 1.1.2 电商购物流程 抽象成泳道图: 节点 抽象名称 功能 电商购物流程 泳池(Pool) 用户/电商平台/仓储物流 泳道(Line) 校验库存 服务任务(Service Task) 不需要人工参与, 需要系统自动化完成的操作节点 1.1.3 工作流是什么 工作流:是对工作流程以及各个步骤之间的业务规则的抽象, 概括描述. 工作流建模:将工作流程中的工作如何前后组织在一起的逻辑和规则, 在计算机中以恰当的模型表达并对其实施计算. 要解决的问题:为实现某个业务目标, 利用计算机在多个参与者之间按某种预定规则自动传递文档, 信息或任务. 关键词 概念 工作流管理系统 处理工作流的电脑软件系统, 主要功能是通过计算机技术的支持去定义, 执行和管理工作流, 协调工作流执行过程中工作之间以及群体之间的信息交互 计算机支持的协同工作 研究一个群体如何在计算机的帮助下实现协同工作的, 工作流属于计算机支持的协同工作的一部分 工作流管理联盟 工作流技术标准化的工业组织, 发布了用于工作流管理系统之间互操作的工作流参考模型, 并相继制定了一些列工业标准 1.1.4 为什么需要工作流日常开发中经常遇到的问题: 产品需求遗漏, 开发上线之后需求经常改; 业务代码复杂, 开发时间紧迫; 代码后期维护不足, 逐渐难以维护. 使用工作流能够带来的改变: 可以快速响应, 灵活调整线上产品流程; 业务和开发基于流程模型沟通, 基于业务建模快速部署; 流程可视化, 方便查看流程的运行进展. 使用工作流对团队的作用: 提高效率, 减少等待; 规范行为, 落实制度; 协同内外, 快速响应; 监控全面, 提升执行. 1.2 工作流技术选型 二者都是成熟的工作流框架 jBPM Activiti Hibernate ByBatis Drools Flow JBPM4 JPA Spring Message RESTful 1.3 Activiti6.0 快速体验1.3.1 准备物料 Activiti 软件包: activiti-6.0.0.zip JDK Servlet 容器 (如 Tomcat) 安装 sdkman12345curl -s "https://get.sdkman.io" | bashsource "$HOME/.sdkman/bin/sdkman-init.sh"sdk version 安装 JDK12345sdk install java 8u161-oraclejava -versionecho $JAVA_HOME 安装 Tomcat1234567wget http://mirror.bit.edu.cn/apache/tomcat/tomcat/8/v8.0.50/bin/apache-tomcat-8.0.50.ziptar -zxvf apache-tomcat-8.0.50.zip./apache-tomcat-8.0.50/bin/startup.shjdp-mlv 部署 Activiti123456wget https://github.com/Activiti/Activiti/releases/download/activiti-6.0.0/activiti-6.0.0.ziptar -zxvf activiti-6.0.0.zipcp activiti-6.0.0/wars/activiti-app.war apache-tomcat-8.0.50/webappscp activiti-6.0.0/wars/activiti-admin.war apache-tomcat-8.0.50/webapps 此时打开浏览器, 输入 http://localhost:8080/activiti-app 即可进入流程引擎的登录界面 账号: admin 密码: test 1.3.2 设计一个审批流程设计如下流程: 开始 -&gt; TL 审批 -&gt; HR 审批 -&gt; 结束 流程参与者 ID Email Name admin admin Administrator userdev userdev@126.com userdevDEV userhr userhr@126.com userhrHR usertl usertl@126.com usertlTL 2. 源码概述12345git clone git@github.com:DestinyWang/Activiti.gitgit checkout -b study6 activiti-6.0.0mvn clean test-compile 路径 功能 Activiti/activiti-engine/src/main/java/org/activiti/engine/cfg Activiti 的启动依赖 activiti.cfg.xml, 在该目录完成 Activiti/activiti-engine/src/main/java/org/activiti/engine/compatibility Activiti 从 5 升级到 6 的时候有部分不兼容, 在该目录完成适配 Activiti/activiti-engine/src/main/java/org/activiti/engine/debug 调试相关目录 Activiti/activiti-engine/src/main/java/org/activiti/engine/delegate 需要制定的节点 Task 都需要实现 JavaDelegate Activiti/activiti-engine/src/main/java/org/activiti/engine/event 定义了事件和监听机制 Activiti/activiti-engine/src/main/java/org/activiti/engine/form 通用表单 Activiti/activiti-engine/src/main/java/org/activiti/engine/history 历史数据归档 Activiti/activiti-engine/src/main/java/org/activiti/engine/identity 身份认证相关操作 Activiti/activiti-engine/src/main/java/org/activiti/engine/impl 各个接口层的实现 Activiti/activiti-engine/src/main/java/org/activiti/engine/logging LogMDC 将重要的变量(如流程 id 放在上下文, logback 可以打印出来) Activiti/activiti-engine/src/main/java/org/activiti/engine/management 管理相关 Activiti/activiti-engine/src/main/java/org/activiti/engine/parse 流程文件是 xml, 需要解析和验证 Activiti/activiti-engine/src/main/java/org/activiti/engine/query 抽象了一些查询接口, 基于 mybatis Activiti/activiti-engine/src/main/java/org/activiti/engine/repository 抽象流程部署到数据库的过程 Activiti/activiti-engine/src/main/java/org/activiti/engine/runtime 与 history 相对应, 是流程在流转过程中的数据 Activiti/activiti-engine/src/main/java/org/activiti/engine/task 每个流程在需要人工处理的时候都会对应一个 task Activiti/activiti-engine/src/main/java/org/activiti/engine/test 支持集成测试的帮助类 核心模块: module/activiti-engine: 核心引擎 module/activiti-spring: Spring 集成模块 module/activiti-spring-boot: SpringBoot 集成模块 module/activiti-rest: 对外提供 rest api 模块 module/activiti-form-engine: 表单引擎模块 module/activiti-ldap: 集成 ldap 用户模块 Activiti-engine 依赖的模块: bpmn-converter: 模型转换 process-validation: 流程校验 image-generator: 流程图绘制(BPMN 转 PNG) dmn-api: 决策标准 form-api/form-model: form 表单相关 2.1 基于源码运行 activiti-app2.1.1 启动 activiti-app12345cd modules/activiti-ui/activiti-appmvn clean tomcat7:runopen http://localhost:9999/activi-app 2.2 剖析 activiti-appactiviti-ui 的组成: activiti-app: 集成发布的 war 工程 activiti-app-conf: UI 独立域业务外的配置 activiti-app-logic: UI 的业务逻辑 activiti-app-rest: 提供接口的 rest api 3. HelloWorld 填写审批信息: 姓名, 时间, 是否提交 主管审批: 审批结果, 备注 审批结果, 备注 3.1 在 IDEA 中完成流程图的设计并配置 配置点: 节点 id, 名称; 对每个网关的分支做判断(基于填写信息); Task 节点接收的表单信息. 3.1.2 Task 节点接收的表单信息填写申请信息 Id Name Type Expression Variable Default Date Pattern Readable Writable Required Values message 申请信息 string True name 申请人姓名 string True submitTime 提交时间 date yyyy-MM-dd True submitType 确认申请 string True 主管审批 Id Name Type Expression Variable Default Date Pattern Readable Writable Required Values tlApprove 主管审批结果 string false tlMessage 主管审批备注 string true 人事审批 Id Name Type Expression Variable Default Date Pattern Readable Writable Required Values hrApprove 人事审批结果 string true hrMessage 人事审批备注 string true 3.1.3 排他网关配置 排他网关需要对流入网关的某个值做判断, 从而决定流程后续的流向 flow3 配置${submitType==&quot;Y&quot; || submitType==&quot;y&quot;} flow4 配置${submitType==&quot;N&quot; || submitType==&quot;n&quot;} flow6 配置${tlApprove == &quot;Y&quot; || tlApprove == &quot;y&quot;} flow7 配置${tlApprove == &quot;N&quot; || tlApprove == &quot;n&quot;} flow9 配置${hrApprove == &quot;Y&quot; || tlApprove == &quot;y&quot;} flow10 配置${hrApprove == &quot;N&quot; || tlApprove == &quot;n&quot;} 配置后的流程图 3.2 helloworld程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class DemoMain &#123; private static final Logger logger = LoggerFactory.getLogger(DemoMain.class); public static void main(String[] args) throws ParseException &#123; logger.info("----- 启动我们的程序 -----"); // 1. 创建流程引擎 ProcessEngine processEngine = getProcessEngine(); // 2. 部署流程定义文件 ProcessDefinition processDefinition = getProcessDefinition(processEngine); // 3. 启动运行流程 ProcessInstance processInstance = getProcessInstance(processEngine, processDefinition); // 4. 处理流程任务 processTask(processEngine, processInstance); logger.info("----- 结束我们的程序 -----"); &#125; /** * 处理流程任务 * * @param processEngine 流程引擎 * @param processInstance 流程实例 * @throws ParseException */ private static void processTask(ProcessEngine processEngine, ProcessInstance processInstance) throws ParseException &#123; Scanner scanner = new Scanner(System.in); while (processInstance != null &amp;&amp; !processInstance.isEnded()) &#123; logger.info("processInstanceId: [&#123;&#125;]", processInstance.getId()); logger.info("processInstance.processInstanceId: [&#123;&#125;]", processInstance.getProcessInstanceId()); TaskService taskService = processEngine.getTaskService(); List&lt;Task&gt; list = taskService.createTaskQuery().list(); logger.info("待处理任务数量: [&#123;&#125;]", list.size()); for (Task task : list) &#123; logger.info("待处理任务: [&#123;&#125;]", task.getName()); Map&lt;String, Object&gt; variables = getVariables(processEngine, scanner, task); taskService.complete(task.getId(), variables); processInstance = processEngine.getRuntimeService() .createProcessInstanceQuery() .processInstanceId(processInstance.getId()) .singleResult(); logger.info("当前 ProcessInstance :&#123;&#125;", processInstance); &#125; &#125; scanner.close(); &#125; /** * 获取变量 * * @param processEngine * @param scanner * @param task * @return * @throws ParseException */ private static Map&lt;String, Object&gt; getVariables(ProcessEngine processEngine, Scanner scanner, Task task) throws ParseException &#123; FormService formService = processEngine.getFormService(); TaskFormData taskFormData = formService.getTaskFormData(task.getId()); List&lt;FormProperty&gt; formProperties = taskFormData.getFormProperties(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); for (FormProperty property : formProperties) &#123; String line = null; if (StringFormType.class.isInstance(property.getType())) &#123; // 如果是 String 类型, 不需要做任何格式化 logger.info("请输入 [&#123;&#125;] ?", property.getName()); line = scanner.nextLine(); variables.put(property.getId(), line); &#125; else if (DateFormType.class.isInstance(property.getType())) &#123; // 如果是日期类型 logger.info("请输入 [&#123;&#125;] ?, 格式 (yyyy-MM-dd)", property.getName()); line = scanner.nextLine(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd"); Date date = simpleDateFormat.parse(line); variables.put(property.getId(), date); &#125; else &#123; logger.info("类型不支持: &#123;&#125;", property.getType()); &#125; logger.info("您输入的内容是 [&#123;&#125;]", line); &#125; return variables; &#125; private static ProcessInstance getProcessInstance(ProcessEngine processEngine, ProcessDefinition processDefinition) &#123; RuntimeService runtimeService = processEngine.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceById(processDefinition.getId()); logger.info("启动流程: [&#123;&#125;]", processInstance.getProcessDefinitionKey()); return processInstance; &#125; private static ProcessDefinition getProcessDefinition(ProcessEngine processEngine) &#123; RepositoryService repositoryService = processEngine.getRepositoryService(); DeploymentBuilder deploymentBuilder = repositoryService.createDeployment(); deploymentBuilder.addClasspathResource("SecondApprove.bpmn20.xml"); Deployment deployment = deploymentBuilder.deploy(); String deploymentId = deployment.getId(); // deploymentId: 1 logger.info("deploymentId: [&#123;&#125;]", deploymentId); ProcessDefinition processDefinition = repositoryService. createProcessDefinitionQuery(). deploymentId(deploymentId) .singleResult(); // processDefinition.getId() 是 SecondApprove:1:4, 根据部署 id 和流程 id 组装出的数据 logger.info("流程定义文件: [&#123;&#125;], 流程 id: [&#123;&#125;]", processDefinition.getName(), processDefinition.getId()); return processDefinition; &#125; private static ProcessEngine getProcessEngine() &#123; ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration(); ProcessEngine processEngine = configuration.buildProcessEngine(); String name = processEngine.getName(); String version = ProcessEngine.VERSION; logger.info("流程引擎名称: [&#123;&#125;], 版本: [&#123;&#125;]", name, version); return processEngine; &#125;&#125; 4. Activiti 引擎配置4.1 流程引擎配置流程引擎配置的载体就是 ProcessEngineConfiguration 及其子类, Activiti 是通过 activiti.cfg.xml 来完成配置 然后构建出流程引擎 ProcessEngine, 最终获取业务开发中需要的各个 Service. ProcessorEngineConfiguration: 查找并解析 XML 配置文件 activiti.cfg.xml 提供多个静态方法创建配置对象 实现几个基于不同场景的子类, 配置方式灵活 123456789101112131415161718&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/activitiDB?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8"/&gt; &lt;property name="jdbcUsername" value="root"/&gt; &lt;property name="jdbcPassword" value="root"/&gt; &lt;!-- false: 不会自动创建表, 没有表, 则抛异常 --&gt; &lt;!-- create-drop: 先删除, 再创建表 --&gt; &lt;!-- true: 没有表时，自动创建--&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;/bean&gt;&lt;/beans&gt; ProcessEngineConfigurationImpl: 抽象类, 配置了 ProcessEngineConfiguration 大部分属性;StandaloneProcessEngineConfiguration: 独立部署运行, 可以通过 new 的方式创建;SpringProcessEngineConfiguration: 完成与 Spring 的集成, 同时扩展了数据源配置, 事务, 自动装载部署文件的目录. 4.2 数据库配置 缺省配置默认使用 H2 内存数据库; 配置 JDBC 属性, 使用 MyBatis 提供的连接池; 配置 DataSource, 可自选第三方实现. 配置 JDBC 属性使用 MyBatis 提供的连接池 基本属性 连接池配置 jdbcUrl jdbcMaxActiveConnections(最大活跃连接数) jdbcDriver jdbcMaxIdleConnections(最大空闲连接数) jdbcUsername jdbcMaxCheckoutTime(最大) jdbcPassword jdbcMaxWaitTIme(最大等待时间) 配置第三方实现的 DataSource Druid: 为监控而生的数据库连接池 Dbcp: Tomcat 自带 HikariCP: 极速数据源连接池, Spring 默认 4.2.1 Druid 数据源连接池123456789101112131415161718&lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- false: 不会自动创建表, 没有表, 则抛异常 --&gt; &lt;!-- create-drop: 先删除, 再创建表 --&gt; &lt;!-- true: 没有表时，自动创建--&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt;&lt;/bean&gt;&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/activitiDB"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;property name="initialSize" value="1"/&gt; &lt;property name="maxActive" value="20"/&gt; &lt;property name="filters" value="stat,slf4f"/&gt;&lt;/bean&gt; 4.2.2 数据库更新策略 配置 databaseSchemaUpdate: false: 启动时检查数据库版本, 发生不匹配则抛出异常(线上默认) true: 启动时自动检查并更新数据库表, 不存在会创建(开发环境默认) create-drop: 启动时创建数据库表结构, 结束时删除表结构 4.3 日志和数据记录配置4.3.1 日志组件的关系及 MDC 日志分类 描述 分类内容 日志门面 直接应用在程序中记录日志的组件 slf4j, commons-logging, log4j 日志实现 日志门面不能直接打日志, 需要日志实现 logback, log4j, log4j2, Java util logging 桥接方式 有些特殊需求, 例如需要 slf4j 作为门面, 但需要以 log4j 作为实现 slf4j-log4j12, slf4j-jdk14, … 改变依赖 将原有门面的功能委托给其他实现, 主要用于解决历史软件内部依赖的改变 jcl-over-slf4j, log4j-over-slf4j, … 配置开启 MDC(Mapped Diagnostic Context): 可以理解为将上下文数据存储在 ThreadLocal 中 默认没有开启, 需要手动设置 LogMDC.setMDCEnable(true) 配置 logback.xml, 日志模板添加 %X{mdcProcessInstanceID}, 即打印当前 instance 的 id 流程只有在执行过程出现异常的时候才会记录 MDC 信息 4.3.1.1 默认日志输出测试类123456789101112131415161718public class ConfigMDCTest &#123; /** * 自动构建 ProcessEngine */ @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test @Deployment(resources = &#123;"my-process.bpmn20.xml"&#125;) public void test() &#123; ProcessInstance processInstance = activitiRule.getRuntimeService().startProcessInstanceByKey("my-process"); assertNotNull(processInstance); Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); assertEquals("Activiti is awesome!", task.getName()); activitiRule.getTaskService().complete(task.getId()); &#125;&#125; logback.xml1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="utf-8" ?&gt;&lt;configuration debug="false" scan="true" scanPeriod="30 seconds"&gt; &lt;property name="log.dir" value="target/logs"/&gt; &lt;property name="encoding" value="UTF-8"/&gt; &lt;property name="plain" value="%msg%n"/&gt; &lt;property name="std" value="%d&#123;HH:mm:ss.SSS&#125; [%thread] [%level] %msg %X&#123;user&#125; %logger&#123;10&#125;.%M:%L%n"/&gt; &lt;property name="normal" value="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;10&#125;.%M:%L - %msg%n"/&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;std&#125;&lt;/pattern&gt; &lt;charset&gt;$&#123;encoding&#125;&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; ... &lt;root&gt; &lt;appender-ref ref="stdout"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt;&lt;/configuration&gt; 日志输出00:19:43.624 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 00:19:45.162 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 00:19:45.174 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.mysql.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:19:45.176 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:19:46.466 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.mysql.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:19:46.466 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:19:46.922 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.mysql.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:19:46.922 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:19:47.035 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 4.3.1.2 MDC 日志输出测试类1234567891011121314151617public class ConfigMDCTest &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test @Deployment(resources = &#123;"my-process.bpmn20.xml"&#125;) public void test() &#123; // 开启 MDC, 整个过程在正常情况下是不会激活 MDC 的 LogMDC.setMDCEnabled(true); ProcessInstance processInstance = activitiRule.getRuntimeService().startProcessInstanceByKey("my-process"); assertNotNull(processInstance); Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); assertEquals("Activiti is awesome!", task.getName()); activitiRule.getTaskService().complete(task.getId()); &#125;&#125; BPMN 流程图1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!-- org.destiny.activiti.delegate.MDCErrorDelegate 是一个会自动抛出异常 "test only" 的JavaDelegate --&gt; &lt;serviceTask id="someTask" activiti:class="org.destiny.activiti.delegate.MDCErrorDelegate"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; logback12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="utf-8" ?&gt;&lt;configuration debug="false" scan="true" scanPeriod="30 seconds"&gt; &lt;property name="log.dir" value="target/logs"/&gt; &lt;property name="encoding" value="UTF-8"/&gt; &lt;property name="plain" value="%msg%n"/&gt; &lt;property name="std" value="%d&#123;HH:mm:ss.SSS&#125; [%thread] [%level] %msg %X&#123;user&#125; %logger&#123;10&#125;.%M:%L%n"/&gt; &lt;!-- - MDC 配置: - ProcessDefinitionId: 流程定义 id - executionId: - mdcProcessInstanceId: 流程实例 id - mdcBusinessKey: 业务 key --&gt; &lt;property name="mdc" value="%d&#123;HH:mm:ss.SSS&#125; [%thread] [%level] %msg ProcessDefinitionId=%X&#123;mdcProcessDefinitionID&#125; executionId=%X&#123;mdcExecutionId&#125; mdcProcessInstanceId=%X&#123;mdcProcessInstanceId&#125; mdcBusinessKey=%X&#123;mdcBusinessKey&#125; %logger&#123;10&#125;.%M:%L%n"/&gt; &lt;property name="normal" value="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;10&#125;.%M:%L - %msg%n"/&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;!-- 此处将默认值输出由 std 改为 mdc --&gt; &lt;!--&lt;pattern&gt;$&#123;std&#125;&lt;/pattern&gt;--&gt; &lt;pattern&gt;$&#123;mdc&#125;&lt;/pattern&gt; &lt;!--&lt;pattern&gt;$&#123;mdc&#125;&lt;/pattern&gt;--&gt; &lt;charset&gt;$&#123;encoding&#125;&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; ... &lt;root&gt; &lt;appender-ref ref="stdout"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt;&lt;/configuration&gt; 日志输出00:32:57.204 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 00:32:58.659 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 00:32:58.671 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.mysql.create.engine.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:32:58.673 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:33:00.219 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.mysql.create.history.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:33:00.220 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:33:00.657 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.mysql.create.identity.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:33:00.657 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:33:00.771 [main] [INFO] ProcessEngine default created ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 00:33:00.932 [main] [INFO] MDCErrorDelegate.execute ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.d.MDCErrorDelegate.execute:24 00:33:00.935 [main] [ERROR] Error while closing command context ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.CommandContext.logException:122 java.lang.RuntimeException: test only ... 可以看到, 在 ERROR 行中, 打印出了 MDC 信息 4.3.1.3 使用拦截器让每个流程节点都把 MDC 信息打印出来新建拦截器12345678910111213141516171819202122232425262728public class MDCCommandInvoker extends DebugCommandInvoker &#123; /** * 先判断可运行的对象是不是 Activiti 支持的 Operation * 如果是, 将它强转, 并取出执行对象并输出 * * @param runnable */ @Override public void executeOperation(Runnable runnable) &#123; boolean mdcEnabled = LogMDC.isMDCEnabled(); LogMDC.setMDCEnabled(true); if (runnable instanceof AbstractOperation) &#123; AbstractOperation operation = (AbstractOperation) runnable; if (operation.getExecution() != null) &#123; // 如果是可操作对象, 将该信息放入 MDC 上下文对象 LogMDC.putMDCExecution(operation.getExecution()); &#125; &#125; super.executeOperation(runnable); LogMDC.clear(); if (!mdcEnabled) &#123; // 如果 MDC 原本不生效, 需要将 MDC 重新置为 false LogMDC.setMDCEnabled(false); &#125; &#125;&#125; 配置该拦截器 修改默认配置文件 activiti.cfg.xml, 新增该 MDCCommandInvoker 123456789101112131415161718&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;!-- 配置数据库连接 --&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/activitiDB?createDatabaseIfNotExist=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=false"/&gt; &lt;property name="jdbcUsername" value="root"/&gt; &lt;property name="jdbcPassword" value="123456"/&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;property name="commandInvoker" ref="commandInvoker"/&gt; &lt;/bean&gt; &lt;bean id="commandInvoker" class="org.destiny.activiti.interceptor.MDCCommandInvoker"/&gt;&lt;/beans&gt; 最终产出日志00:56:35.631 [main] [INFO] Loading XML bean definitions from class path resource [activiti_mdc.cfg.xml] ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 00:56:37.141 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 00:56:37.153 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.mysql.create.engine.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:56:37.154 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:56:38.655 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.mysql.create.history.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:56:38.656 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:56:39.109 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.mysql.create.identity.sql ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 00:56:39.110 [main] [INFO] Found MySQL: majorVersion=5 minorVersion=7 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.d.DbSqlSession.executeSchemaResource:1162 00:56:39.218 [main] [INFO] ProcessEngine default created ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 00:56:39.403 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.407 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.409 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.410 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.411 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.412 [main] [INFO] 4 (process instance) └── 5 : start -&gt; someTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.412 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.412 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.497 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.501 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.502 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.503 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.504 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.504 [main] [INFO] 4 (process instance) └── 5 : someTask -&gt; end, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.505 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.505 [main] [INFO] 4 (process instance) └── 5 : end (EndEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.505 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.506 [main] [INFO] 4 (process instance) └── 5 : end (EndEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 00:56:39.507 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:33 00:56:39.507 [main] [INFO] 4 (process instance) └── 5 : end (EndEvent, parent id 4 (active) ProcessDefinitionId=my-process:1:3 executionId=5 mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.i.DebugCommandInvoker.executeOperation:34 可以看到最终所有级别的日志都输出了 MDC 信息 4.3.2 配置历史记录级别配置 HistoryLevel: none: 不记录历史记录, 性能高, 流程结束后不可读取; activiti: 归档流程实例和活动实例, 流程变量不同步; audit: 默认值, 在 activiti 基础上同步变量值, 保存表单属性; full: 性能较差, 记录所有实例和变量细节变化. 4.3.3 配置基于 DB 的事件日志配置 Event Logging 实验性的事件记录机制, 性能影响较大; 开启默认记录所有数据的变化过程, 导致表记录快速增长; 日志内容基于 JSON 格式, 建议存入 MongoDB, Elastic Search; 4.4 命令拦截器的配置4.4.1 命令模式与责任链模式4.4.1.1 Command 命令拦截器使用命令模式实现, 多个拦截器会组成一个拦截器链, 实现了责任链模式 Command: 命令接口 ConcreteCommand: 命令实现, 构造命令的时候, 需要传入接受者, 即 Received Receiver: Client 在实现 Command 接口的时候传入 Invoker: 调用者, 最终调用 ConcreteCommand 对象 4.4.1.2 Chain of Responsibility customPre, default, customPost 中 execute() 的实现基本都是调用了 next 的 execute(), 只有 CommandInvoker 真正完成了执行器. CustomPre: default 之前的拦截器 default: Activiti 默认的 CommandInterceptor CustomPost: default 之后的拦截器 CommandInvoker: 最终的命令执行者 4.4.2 命令拦截器的配置 配置Interceptor customProCommandInterceptors: 配置在默认拦截器之前 customPostCommandInterceptors: 配置在默认拦截器之后 commandInvoker: 配置在最后的执行器 4.4.3 示例 需求实现一个可以统计所有命令完成时间的拦截器 拦截器实现12345678910111213141516public class DurationCommandInterceptor extends AbstractCommandInterceptor &#123; private static final Logger logger = LoggerFactory.getLogger(DurationCommandInterceptor.class); @Override public &lt;T&gt; T execute(CommandConfig config, Command&lt;T&gt; command) &#123; // 记录当前时间 long start = System.currentTimeMillis(); try &#123; return this.getNext().execute(config, command); &#125; finally &#123; long duration = System.currentTimeMillis() - start; logger.info("&#123;&#125; 执行时长: &#123;&#125; 毫秒", command.getClass().getSimpleName(), duration); &#125; &#125;&#125; 配置文件1234567891011121314151617&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;property name="commandInvoker" ref="commandInvoker"/&gt; &lt;property name="customPreCommandInterceptors"&gt; &lt;list&gt; &lt;bean class="org.destiny.activiti.interceptor.DurationCommandInterceptor"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="commandInvoker" class="org.destiny.activiti.interceptor.MDCCommandInvoker"/&gt;&lt;/beans&gt; 日志输出10:10:09.371 [main] [INFO] SchemaOperationsProcessEngineBuild 执行时长: 113 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.372 [main] [INFO] ProcessEngine default created ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 10:10:09.391 [main] [INFO] ValidateExecutionRelatedEntityCountCfgCmd 执行时长: 14 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.394 [main] [INFO] 执行时长: 1 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.401 [main] [INFO] GetNextIdBlockCmd 执行时长: 4 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.508 [main] [INFO] GetProcessDefinitionInfoCmd 执行时长: 2 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.513 [main] [INFO] DeployCmd 执行时长: 116 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.616 [main] [INFO] CompleteTaskCmd 执行时长: 22 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 10:10:09.630 [main] [INFO] DeleteDeploymentCmd 执行时长: 14 毫秒 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.i.DurationCommandInterceptor.execute:33 4.5 作业执行器 Job Executor4.5.1 作业执行器的配置 asyncExecutorActivate: 激活作业执行器 asyncExecutorXXX: 异步执行器的属性配置 asyncExecutor: 异步执行器 bean 定时开始事件 timeDate: 指定启动时间 timeDuration: 指定持续时间间隔后执行 timeCycle:R5/P1DT1H 指定时间段后周期执行 4.5.2 配置自定义线程池 corePoolSize: 核心线程数 maxPoolSize: 最大线程数 queueCapacity: 阻塞队列大小 如果核心线程数没满, 每当有一个任务, 不管原有线程是否空闲都会开启一个新的线程去执行, 直到达到核心线程数;如果所有核心线程都在运行, 每当有一个任务, 会先放在阻塞队列等待, 直到核心线程执行完上一个任务, 会取阻塞队列第一个任务继续执行;如果队列已满, 会继续创建新的线程, 直到达到最大线程数;如果最大线程数和队列都已满, 此时会执行拒绝策略. 4.5.3 流程定义定时启动流程4.5.4 Demo配置异步执行器12345678910111213141516171819202122232425262728293031323334&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration"&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;property name="commandInvoker" ref="commandInvoker"/&gt; &lt;!-- 打开异步执行器 --&gt; &lt;property name="asyncExecutorActivate" value="true"/&gt; &lt;property name="asyncExecutor" value="asyncExecutor"/&gt; &lt;!-- 事件监听 --&gt; &lt;property name="eventListeners"&gt; &lt;list&gt; &lt;bean class="org.destiny.activiti.listener.JobEventListener"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="asyncExecutor" class="org.activiti.engine.impl.asyncexecutor.DefaultAsyncJobExecutor"&gt; &lt;property name="executorService" ref="executorService"/&gt; &lt;/bean&gt; &lt;bean id="executorService" class="org.springframework.scheduling.concurrent.ThreadPoolExecutorFactoryBean"&gt; &lt;property name="threadNamePrefix" value="activiti-job-"/&gt; &lt;property name="corePoolSize" value="5"/&gt; &lt;property name="maxPoolSize" value="20"/&gt; &lt;property name="queueCapacity" value="100"/&gt; &lt;property name="rejectedExecutionHandler"&gt; &lt;bean class="java.util.concurrent.ThreadPoolExecutor$AbortPolicy"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="commandInvoker" class="org.destiny.activiti.interceptor.MDCCommandInvoker"/&gt;&lt;/beans&gt; 流程定义文件12345678910111213&lt;process id="my-process"&gt; &lt;!--&lt;startEvent id="start"/&gt;--&gt; &lt;startEvent id="start"&gt; &lt;timerEventDefinition&gt; &lt;!-- 每 10 秒执行一次, 共执行 5 次 --&gt; &lt;timeCycle&gt;R5/PT10S&lt;/timeCycle&gt; &lt;/timerEventDefinition&gt; &lt;/startEvent&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt;&lt;/process&gt; 添加监听器12345678910111213141516171819public class JobEventListener implements ActivitiEventListener &#123; public static final Logger logger = LoggerFactory.getLogger(JobEventListener.class); @Override public void onEvent(ActivitiEvent event) &#123; ActivitiEventType eventType = event.getType(); String name = eventType.name(); if (name.startsWith("TIMER") || name.startsWith("JOB")) &#123; logger.info("监听 Job 事件: &#123;&#125; \t &#123;&#125;", eventType, event.getProcessInstanceId()); &#125; &#125; @Override public boolean isFailOnException() &#123; return false; &#125;&#125; 日志输出11:34:50.048 [main] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:34:50.056 [main] [INFO] start ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.c.ConfigJobTest.test:33 11:34:50.080 [main] [INFO] 定时任务 TimerJobEntity [id=4], 默认重试次数: 3 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.c.ConfigJobTest.test:36 11:34:50.080 [main] [INFO] jobList.size: 1 ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.c.ConfigJobTest.test:38 11:35:09.981 [activiti-job-1] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:09.990 [activiti-job-1] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:09.990 [activiti-job-1] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:19.950 [activiti-job-2] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:19.951 [activiti-job-2] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:19.951 [activiti-job-2] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:29.958 [activiti-job-3] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:29.959 [activiti-job-3] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:29.960 [activiti-job-3] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:39.966 [activiti-job-4] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:39.970 [activiti-job-4] [INFO] 监听 Job 事件: TIMER_SCHEDULED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:39.971 [activiti-job-4] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:49.975 [activiti-job-5] [INFO] 监听 Job 事件: TIMER_FIRED null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 11:35:49.975 [activiti-job-5] [INFO] 监听 Job 事件: JOB_EXECUTION_SUCCESS null ProcessDefinitionId= executionId= mdcProcessInstanceId= mdcBusinessKey= o.d.a.l.JobEventListener.onEvent:34 4.6 Activiti 与 Spring 集成4.6.1 集成 Spring 配置 添加依赖: 12345&lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt;&lt;/dependency&gt; 基于 Spring 的默认配置: activiti-context.xml, 如果配置该文件, Activiti 在启动过程中就会查找基于 Spring 的 ProcessEngineConfiguration 对象; Activiti 核心服务注入 Spring 容器 4.6.2 基于 Spring 对 Activiti 的管理4.6.2.1 集成 Spring 事务管理器activiti-context.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 配置 ProcessEngineConfiguration --&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.spring.SpringProcessEngineConfiguration"&gt; &lt;!-- Spring 需要单独配置 DataSource --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="transactionManager" ref="transactionManager"/&gt; &lt;property name="databaseSchemaUpdate" value="true"/&gt; &lt;/bean&gt; &lt;!-- 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="driverClassName" value="org.h2.Driver"/&gt; &lt;property name="url" value="jdbc:h2:mem:activiti"/&gt; &lt;property name="username" value="sa"/&gt; &lt;property name="password" value=""/&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 流程引擎对象 --&gt; &lt;bean id="processEngine" class="org.activiti.spring.ProcessEngineFactoryBean"&gt; &lt;property name="processEngineConfiguration" ref="processEngineConfiguration"/&gt; &lt;/bean&gt; &lt;!-- 将服务暴露给 Spring --&gt; &lt;bean id="runtimeService" factory-bean="processEngine" factory-method="getRuntimeService"/&gt; &lt;bean id="repositoryService" factory-bean="processEngine" factory-method="getRepositoryService"/&gt; &lt;bean id="formService" factory-bean="processEngine" factory-method="getFormService"/&gt; &lt;bean id="taskService" factory-bean="processEngine" factory-method="getTaskService"/&gt; &lt;bean id="historyService" factory-bean="processEngine" factory-method="getHistoryService"/&gt; &lt;!-- 配置 activitiRule 用于测试 --&gt; &lt;bean id="activitiRule" class="org.activiti.engine.test.ActivitiRule"&gt; &lt;property name="processEngine" ref="processEngine"/&gt; &lt;/bean&gt;&lt;/beans&gt; 4.6.2.2 定义文件表达式中使用 Spring BeanHelloBean12345678public class HelloBean &#123; private static final Logger logger = LoggerFactory.getLogger(HelloBean.class); public void sayHello() &#123; logger.info("sayHello"); &#125;&#125; my-process-spring.bpmn20.xml123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="helloBean"/&gt; &lt;!-- 从 Spring 容器中查找 Hello bean, 并且调用 sayHello() 方法 --&gt; &lt;serviceTask id="helloBean" activiti:expression="$&#123;helloBean.sayHello()&#125;"/&gt; &lt;sequenceFlow id="flow3" sourceRef="helloBean" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试类12345678910111213141516171819202122232425262728@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"classpath:activiti-context.xml"&#125;)public class ConfigSpringTest &#123; public static final Logger logger = LoggerFactory.getLogger(ConfigSpringTest.class); @Rule @Autowired public ActivitiRule activitiRule; @Autowired private RuntimeService runtimeService; @Autowired private TaskService taskService; @Test @Deployment(resources = &#123;"my-process-spring.bpmn20.xml"&#125;) public void test() &#123; ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); Task task = taskService.createTaskQuery().processInstanceId(processInstance.getId()).singleResult(); taskService.complete(task.getId()); logger.info("processInstance: [&#123;&#125;]", processInstance); logger.info("task: [&#123;&#125;]", task); &#125;&#125; 4.6.2.3 自动部署资源文件4.6.3 基于 Spring 的流程单元测试 添加依赖 spring-test 辅助测试 Rule: ActivitiRule 辅助测试 TestCase: SpringActivitiTestCase 5. Activiti 核心 API 服务名称 功能 RepositoryServie 负责对静态文件的管理, 涉及部署对象和资源对象, 其二者是一对多的关系 RuntimeService 负责对流程进行控制的服务, 可以对流程实例完成启动, 暂停, 挂起等操作 TaskService 负责管理运行中的 UserTask(人工任务) IdentityService 负责对用户和用户组的管理 FormService 负责解析流程定义中的表单, 对表单的数据类型做渲染 HistoryService 提供了对运行结束的流程实例的查询和删除操作 ManagementService 提供了对流程引擎基础的管理, 提供对定时任务 Job 的管理, 获取表结构, 表明的操作 DynamicBpmnService 提供了对动态的流程定义模型做修改 5.1 RepositoryService 管理流程定义文件 xml 及静态资源服务 对特定的流程的暂停和激活 流程定义启动权限管理 部署文件构造器 DeploymentBuilder 部署文件查询器 DeploymentQuery 流程定义文件查询对象 ProcessDefinitionQuery 流程部署文件对象 Deployment 流程定义文件对象 ProcessDefinition 流程定义的 Java 格式 BpmnModel RepositoryService API: 方法名 功能 createDeployment 添加资源文件 deleteDeployment 删除资源文件 setDeploymentCategory 指定分类名称 createProcessDefinitionQuery 创建流程定义查询对象 createNativeProcessDefinitionQuery 通过 SQL 查询流程定义对象 suspendProcessDefinitionByXX 通过某些条件暂停/挂起流程定义对象, 使之不能再生成新的流程实例 activateProcessDefinitionByXX 通过某些条件激活流程定义对象, 使之可以继续生成新的流程实例 getProcssDiagram 获取流程图的数据流 getBpmnModel 获取 BpmnModel 对象 addCandidateStarterUser 设置某个流程文件只能由指定的用户去启动 addCandidateStarterGroup 设置某个流程文件只能由指定的用户组去启动 … … 5.1.1 ProcessDefinitionId 的含义1234567891011121314151617181920212223242526272829303132333435363738@Testpublic void testRepository() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); DeploymentBuilder deploymentBuilder1 = repositoryService.createDeployment(); deploymentBuilder1 // 一个部署对象就记录了一次部署 .name("测试部署资源1") // 设置名称 .addClasspathResource("org/destiny/activiti/my-process.bpmn20.xml") .addClasspathResource("org/destiny/activiti/SecondApprove.bpmn20.xml") .deploy(); // 完成部署 DeploymentBuilder deploymentBuilder2 = repositoryService.createDeployment(); deploymentBuilder2 // 一个部署对象就记录了一次部署 .name("测试部署资源2") // 设置名称 .addClasspathResource("org/destiny/activiti/my-process.bpmn20.xml") .addClasspathResource("org/destiny/activiti/SecondApprove.bpmn20.xml") .deploy(); // 完成部署 // 查询部署对象 List&lt;Deployment&gt; deploymentList = repositoryService.createDeploymentQuery() .orderByDeploymenTime().asc() .list(); logger.info("size of deploymentList: &#123;&#125;", deploymentList.size()); for (Deployment deployment : deploymentList) &#123; logger.info("deployment: &#123;&#125;", deployment); &#125; // 流程定义 List&lt;ProcessDefinition&gt; processDefinitionList = repositoryService .createProcessDefinitionQuery() .orderByProcessDefinitionKey().asc() .listPage(0, 100); for (ProcessDefinition processDefinition : processDefinitionList) &#123; logger.info("processDefinition: &#123;&#125;, version: &#123;&#125;, key: &#123;&#125;, name: &#123;&#125;", processDefinition, processDefinition.getVersion(), processDefinition.getKey(), processDefinition.getName()); &#125;&#125; 生成的日志: 08:42:45,507 [main] INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [activiti.cfg.xml] 08:42:47,193 [main] INFO org.activiti.engine.compatibility.DefaultActiviti5CompatibilityHandlerFactory - Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. 08:42:47,207 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql 08:42:47,268 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql 08:42:47,274 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql 08:42:47,280 [main] INFO org.activiti.engine.impl.ProcessEngineImpl - ProcessEngine default created 08:42:49,736 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - size of deploymentList: 2 08:42:49,736 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - deployment: DeploymentEntity[id=1, name=测试部署资源1] 08:42:49,736 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - deployment: DeploymentEntity[id=7, name=测试部署资源2] 08:42:49,742 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[SecondApprove:1:5], version: 1, key: SecondApprove, name: 二级审批 08:42:49,742 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[SecondApprove:2:11], version: 2, key: SecondApprove, name: 二级审批 08:42:49,742 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[my-process:1:6], version: 1, key: my-process, name: null 08:42:49,743 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinition: ProcessDefinitionEntity[my-process:2:12], version: 2, key: my-process, name: null 两个 DeploymentEntity, 一个 id 为 1, 一个 id 为 7, id 的设置使用全局自增, 说明在两个 Deployment 对象的部署过程中插入了 6 条记录: 1 个部署记录; 2 个流程定义记录; 2 个 xml 文件对应的数据流记录; 1 个流程定义所生成的图片记录;(my-process 没有生成图片) 5.1.2 流程挂起/激活测试代码: 1234567891011121314151617181920212223@Test@org.activiti.engine.test.Deployment(resources = "org/destiny/activiti/my-process.bpmn20.xml")public void testSuspend() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().singleResult(); String processDefinitionId = processDefinition.getId(); logger.info("processDefinitionId: &#123;&#125;", processDefinitionId); repositoryService.suspendProcessDefinitionById(processDefinitionId); try &#123; logger.info("开始启动"); activitiRule.getRuntimeService().startProcessInstanceById(processDefinitionId); logger.info("启动成功"); &#125; catch (Exception e) &#123; logger.error("启动失败, 原因: &#123;&#125;", e.getMessage()); &#125; repositoryService.activateProcessDefinitionById(processDefinitionId); logger.info("激活后开始启动"); activitiRule.getRuntimeService().startProcessInstanceById(processDefinitionId); logger.info("激活后启动成功");&#125; 输出日志: 09:12:42,071 [main] INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [activiti.cfg.xml] 09:12:43,614 [main] INFO org.activiti.engine.compatibility.DefaultActiviti5CompatibilityHandlerFactory - Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. 09:12:43,627 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql 09:12:43,682 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql 09:12:43,688 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql 09:12:43,692 [main] INFO org.activiti.engine.impl.ProcessEngineImpl - ProcessEngine default created 09:12:43,882 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinitionId: my-process:1:3 09:12:43,887 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 开始启动 09:12:43,893 [main] ERROR org.activiti.engine.impl.interceptor.CommandContext - Error while closing command context org.activiti.engine.ActivitiException: Cannot start process instance. Process definition null (id = my-process:1:3) is suspended at org.activiti.engine.impl.util.ProcessInstanceHelper.createAndStartProcessInstance(ProcessInstanceHelper.java:67) at org.activiti.engine.impl.util.ProcessInstanceHelper.createAndStartProcessInstance(ProcessInstanceHelper.java:51) at org.activiti.engine.impl.cmd.StartProcessInstanceCmd.createAndStartProcessInstance(StartProcessInstanceCmd.java:109) at org.activiti.engine.impl.cmd.StartProcessInstanceCmd.execute(StartProcessInstanceCmd.java:102) at org.activiti.engine.impl.cmd.StartProcessInstanceCmd.execute(StartProcessInstanceCmd.java:37) at org.activiti.engine.impl.interceptor.CommandInvoker$1.run(CommandInvoker.java:37) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperation(CommandInvoker.java:78) at org.activiti.engine.impl.interceptor.CommandInvoker.executeOperations(CommandInvoker.java:57) at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:42) at org.activiti.engine.impl.interceptor.TransactionContextInterceptor.execute(TransactionContextInterceptor.java:48) at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:63) at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:29) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:44) at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:39) at org.activiti.engine.impl.RuntimeServiceImpl.startProcessInstanceById(RuntimeServiceImpl.java:114) at org.destiny.activiti.coreapi.RepositoryServiceTest.testSuspend(RepositoryServiceTest.java:86) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.activiti.engine.test.ActivitiRule$1.evaluate(ActivitiRule.java:116) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) 09:12:43,895 [main] ERROR org.destiny.activiti.coreapi.RepositoryServiceTest - 启动失败, 原因: Cannot start process instance. Process definition null (id = my-process:1:3) is suspended 09:12:43,897 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 激活后开始启动 09:12:43,923 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 激活后启动成功 5.1.3 绑定用户/用户组 测试代码: 123456789101112131415161718192021222324252627282930/** * 测试用户组 * repositoryService 只提供了构建关系的方式, 具体的校验逻辑需要自己完成 * 可以取出用户/用户组信息, 自行通过逻辑判断 */@Test@org.activiti.engine.test.Deployment(resources = "org/destiny/activiti/my-process.bpmn20.xml")public void testCandidateStarter() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().singleResult(); String processDefinitionId = processDefinition.getId(); logger.info("processDefinitionId: &#123;&#125;", processDefinitionId); // userId/groupM 是对应的用户/用户组管理服务中创建的 id repositoryService.addCandidateStarterUser(processDefinitionId, "user"); repositoryService.addCandidateStarterGroup(processDefinitionId, "groupM"); List&lt;IdentityLink&gt; identityLinkList = repositoryService.getIdentityLinksForProcessDefinition(processDefinitionId); for (IdentityLink identityLink : identityLinkList) &#123; logger.info("删除前: identityLink: [&#123;&#125;]", identityLink); &#125; repositoryService.deleteCandidateStarterGroup(processDefinitionId, "groupM"); repositoryService.deleteCandidateStarterUser(processDefinitionId, "user"); List&lt;IdentityLink&gt; identityLinkList1 = repositoryService.getIdentityLinksForProcessDefinition(processDefinitionId); for (IdentityLink identityLink : identityLinkList1) &#123; logger.info("删除后: identityLink: [&#123;&#125;]", identityLink); &#125;&#125; 日志输出: 10:08:35,380 [main] INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [activiti.cfg.xml] 10:08:36,784 [main] INFO org.activiti.engine.compatibility.DefaultActiviti5CompatibilityHandlerFactory - Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. 10:08:36,796 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql 10:08:36,842 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql 10:08:36,846 [main] INFO org.activiti.engine.impl.db.DbSqlSession - performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql 10:08:36,849 [main] INFO org.activiti.engine.impl.ProcessEngineImpl - ProcessEngine default created 10:08:37,009 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - processDefinitionId: my-process:1:3 10:08:37,016 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 删除前: identityLink: [IdentityLinkEntity[id=4, type=candidate, userId=user, processDefId=my-process:1:3]] 10:08:37,016 [main] INFO org.destiny.activiti.coreapi.RepositoryServiceTest - 删除前: identityLink: [IdentityLinkEntity[id=5, type=candidate, groupId=groupM, processDefId=my-process:1:3]] 5.2 RuntimeService 流程运行控制服务功能: 启动流程及对流程数据的控制 流程实例(ProcessInstance)与执行流(Execution)查询(当创建实例的时候, 一般也会创建一个执行流) 触发流程操作, 接受信号的消息 Runtime 启动流程及变量管理: 启动流程的常用方式(id, key, message) 启动流程可选参数: businessKey variables tenantId 变量(variables)的设置和获取 5.2.1 基本操作5.2.1.1 根据流程定义 key 启动流程 每次流程部署时, 对应 ProcessDefintion 的 id 和 version 都会改变, 根据 ProcessDefintionKey 默认取最后一个版本的数据 1234567891011@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testStartProcess() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance);&#125; 5.2.1.2 根据流程定义 id 使用 ProcessDefintionId 进行获取的时候, 需要先通过 RepositoryService 获取到对应的 id 1234567891011121314/** * 根据流程定义 id 启动流程 */@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testStartProcessById() &#123; RepositoryService repositoryService = activitiRule.getRepositoryService(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().singleResult(); RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); ProcessInstance processInstance = runtimeService.startProcessInstanceById(processDefinition.getId(), variables); log.info("processInstance: &#123;&#125;", processInstance);&#125; 5.2.1.3 通过 ProcessInstanceBuilder 完成流程的设置以及启动12345678910111213@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testProcessBuilder() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); ProcessInstance processInstance = runtimeService.createProcessInstanceBuilder() .businessKey("businessKey001") .processDefinitionKey("my-process") .variables(variables) .start(); log.info("processInstance: &#123;&#125;", processInstance);&#125; 5.2.1.4 设置和获取流程变量1234567891011121314151617@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testVariables() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("key1", "value1"); variables.put("key2", "value2"); variables.put("key3", "value3"); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance); // 覆盖原有内容 runtimeService.setVariable(processInstance.getId(), "key3", "newValue4"); runtimeService.setVariable(processInstance.getId(), "key4", "value4"); // 根据流程实例 id 获取流程变量 Map&lt;String, Object&gt; map = runtimeService.getVariables(processInstance.getId()); log.info("variable map: &#123;&#125;", map);&#125; 日志输出: 11:55:06.844 [main] [INFO] variable map: {key1=value1, key2=value2, key3=newValue4, key4=value4} o.d.a.c.RuntimeServiceTest.testVariables:94 5.2.1.5 对流程实例的查询123456789101112@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testProcessInstanceQuery() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance); ProcessInstance processInstance1 = runtimeService.createProcessInstanceQuery() .processInstanceId(processInstance.getId()) .singleResult(); log.info("processInstance1: &#123;&#125;", processInstance1);&#125; 5.2.1.6 对执行流的查询12345678910111213@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process.bpmn20.xml"&#125;)public void testExecutionQuery() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); Map&lt;String, Object&gt; variables = Maps.newHashMap(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process", variables); log.info("processInstance: &#123;&#125;", processInstance); List&lt;Execution&gt; executionList = runtimeService.createExecutionQuery() .listPage(0, 100); for (Execution execution : executionList) &#123; log.info("execution: &#123;&#125;", execution); &#125;&#125; 5.2.2 流程实例与执行流 流程实例(ProcessInstance) 表示一次工作流业务的数据实体, 当每次启动流程的时候, 生成一个流程实例 执行流(Execution) 表示流程实例中具体的执行路径, 如果简单的流程只有一条执行路径, 那么此时流程实例和执行流是一对一的关系 流程实例接口继承与执行流 5.2.3 流程触发 使用 trigger 触发 receiveTask 节点 触发信号捕获事件 singalEventRecivied(信号可以全局发送) 触发消息捕获事件 messageEventReceived(消息只能针对某一个流程实例) 5.2.3.1 流程触发 trigger 流程配置文件12345678910111213141516&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!--&lt;userTask id="someTask" name="Activiti is awesome!"/&gt;--&gt; &lt;receiveTask id="someTask"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567891011121314151617@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-trigger.bpmn20.xml"&#125;)public void testTrigger() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); // 开始流程后流程实例就会在 receiveTask 节点等待处理 Execution execution = runtimeService.createExecutionQuery() .activityId("someTask") .singleResult(); log.info("execution: &#123;&#125;", execution); runtimeService.trigger(execution.getId()); // 再次查询 execution = runtimeService.createExecutionQuery() .activityId("someTask") .singleResult(); log.info("execution: &#123;&#125;", execution);&#125; 输出日志1214:59:58.256 [main] [INFO] execution: Execution[ id &apos;5&apos; ] - activity &apos;someTask - parent &apos;4&apos; o.d.a.c.RuntimeServiceTest.testTrigger:13714:59:58.291 [main] [INFO] execution: null o.d.a.c.RuntimeServiceTest.testTrigger:142] 当完成了触发之后, 执行对象已经执行完成 5.2.3.2 流程触发 singalEventReceived 流程开始后, 流程会暂停在中间节点(SingalCatchingEvent), 当它获取到信号时间的时候, 才会继续流转 流程定义文件12345678910111213141516171819&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;signal id="signalStart" name="my-signal"/&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="signal-received"/&gt; &lt;!-- 定义捕获边界事件, 当该节点接收到 my-signal 信号后会继续向后流转 --&gt; &lt;intermediateCatchEvent id="signal-received"&gt; &lt;signalEventDefinition signalRef="signalStart"/&gt; &lt;/intermediateCatchEvent&gt; &lt;!--&lt;userTask id="someTask" name="Activiti is awesome!"/&gt;--&gt; &lt;sequenceFlow id="flow2" sourceRef="signal-received" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码123456789101112131415161718@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-signal.bpmn20.xml"&#125;)public void testSignalEventReceived() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); // 查询数据库是否有一个正在等待信号的节点 Execution execution = runtimeService.createExecutionQuery() .signalEventSubscriptionName("my-signal") .singleResult(); log.info("execution: &#123;&#125;", execution); // 触发信号 runtimeService.signalEventReceived("my-signal"); // 重新执行查询 execution = runtimeService.createExecutionQuery() .signalEventSubscriptionName("my-signal") .singleResult(); log.info("execution: &#123;&#125;", execution);&#125; 日志输出15:14:42.184 [main] [INFO] execution: Execution[ id &apos;5&apos; ] - activity &apos;signal-received - parent &apos;4&apos; o.d.a.c.RuntimeServiceTest.testSignalEventReceived:155 15:14:42.216 [main] [INFO] execution: null o.d.a.c.RuntimeServiceTest.testSignalEventReceived:163 5.2.3.3 流程触发 messageEventReceived 消息触发与信号触发非常相似, 唯一的不同是: 信号与具体的流程实例无关, 消息在执行过程中必须制定流程实例 id 流程定义文件12345678910111213141516171819&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;message id="messageStart" name="my-message"/&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="message-received"/&gt; &lt;!-- 定义捕获边界事件, 当该节点接收到 my-message 消息后会继续向后流转 --&gt; &lt;intermediateCatchEvent id="message-received"&gt; &lt;messageEventDefinition messageRef="messageStart"/&gt; &lt;/intermediateCatchEvent&gt; &lt;!--&lt;userTask id="someTask" name="Activiti is awesome!"/&gt;--&gt; &lt;sequenceFlow id="flow2" sourceRef="message-received" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码123456789101112131415161718@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-message.bpmn20.xml"&#125;)public void testMessageEventReceived() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByKey("my-process"); // 查询数据库是否有一个正在等待信号的节点 Execution execution = runtimeService.createExecutionQuery() .messageEventSubscriptionName("my-message") // 查询订阅了该信号的执行流 .singleResult(); log.info("execution: &#123;&#125;", execution); // 触发消息, 不同于信号的触发, message 在触发时需要指定 executionId runtimeService.messageEventReceived("my-message", execution.getId()); // 重新执行查询 execution = runtimeService.createExecutionQuery() .messageEventSubscriptionName("my-message") .singleResult(); log.info("execution: &#123;&#125;", execution);&#125; 日志输出15:37:52.024 [main] [INFO] execution: Execution[ id &apos;5&apos; ] - activity &apos;message-received - parent &apos;4&apos; o.d.a.c.RuntimeServiceTest.testMessageEventReceived:175 15:37:52.054 [main] [INFO] execution: null o.d.a.c.RuntimeServiceTest.testMessageEventReceived:183 5.2.3.4 流程基于 message 启动流程定义12345678910111213141516171819&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;!-- 此时既可以基于 key 启动, 也可以基于 message 启动 --&gt; &lt;message id="messageStart" name="my-message"/&gt; &lt;process id="my-process"&gt; &lt;!-- 需要将 messageEventDefinition 放在开始节点 --&gt; &lt;startEvent id="start"&gt; &lt;messageEventDefinition messageRef="messageStart"/&gt; &lt;/startEvent&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!"/&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-message-start.bpmn20.xml"&#125;)public void testMessageStart() &#123; RuntimeService runtimeService = activitiRule.getRuntimeService(); ProcessInstance processInstance = runtimeService.startProcessInstanceByMessage("my-message"); log.info("processInstance: &#123;&#125;", processInstance);&#125; 日志输出15:45:12.844 [main] [INFO] processInstance: ProcessInstance[5] o.d.a.c.RuntimeServiceTest.testMessageStart:195 基于 message 启动流程时, ProcessInstance 的 id 是 5, 意味着在流程订阅表中多插入了一条数据, 在实际启动过程中, 还是通过 message 找到 ProcessDefinition 的 key, 最终根据 key 来启动 5.3 TaskService 任务管理服务TaskService 提供的功能: 对用户任务管理和流程的控制 设置用户任务的权限信息(拥有者/候选人/办理人) 针对用户任务添加任务附件, 任务评论和事件记录 TaskService 对 Task 管理与流程控制: Task 对象的创建, 删除 查询 Task, 并驱动 Task 节点完成执行 Task 相关参数变量设置 local 变量 非 local 变量 5.3.1 基本操作5.3.1.1 获取 task/ 设置变量/ 驱动完成流程定义文件1234567891011121314151617181920&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!-- 添加候选人 --&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:candidateUsers="destiny,destiny1,destiny2"&gt; &lt;!-- 添加描述, message 会根据上下文中传入的 message 变量值去替换 --&gt; &lt;documentation&gt; some task $&#123;message&#125; &lt;/documentation&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码12345678910111213141516171819202122232425262728293031323334@Test @Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;) public void testTaskService() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); TaskService taskService = activitiRule.getTaskService(); // 部署流程定义文件 ProcessInstance processInstance = activitiRule.getRuntimeService() .startProcessInstanceByKey("my-process", variables); Task task = taskService.createTaskQuery().singleResult(); log.info("task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); log.info("task.description: &#123;&#125;", task.getDescription()); // 设置变量 taskService.setVariable(task.getId(), "k1", "v1"); taskService.setVariableLocal(task.getId(), "localK1", "localV1"); // local 只在 task 范围可见 Map&lt;String, Object&gt; taskServiceVariables = taskService.getVariables(task.getId()); Map&lt;String, Object&gt; taskServiceVariablesLocal = taskService.getVariablesLocal(task.getId()); // 根据流程获取 Map&lt;String, Object&gt; processVariables = activitiRule.getRuntimeService().getVariables(task.getExecutionId()); log.info("taskServiceVariables: &#123;&#125;", taskServiceVariables); // &#123;k1=v1, localK1=localV1, message=my test message&#125; log.info("taskServiceVariablesLocal: &#123;&#125;", taskServiceVariablesLocal); // &#123;localK1=localV1&#125; log.info("processVariables: &#123;&#125;", processVariables); // &#123;k1=v1, message=my test message&#125; Map&lt;String, Object&gt; completeVar = Maps.newHashMap(); completeVar.put("cKey1", "cValue1"); taskService.complete(task.getId(), completeVar); Task task1 = taskService.createTaskQuery().taskId(task.getId()).singleResult(); log.info("task1: &#123;&#125;", task1); &#125; 日志输出16:13:26.654 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 16:13:28.438 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 16:13:28.451 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:13:28.527 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:13:28.535 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:13:28.541 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 16:13:28.793 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.796 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.798 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.799 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.800 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.800 [main] [INFO] 4 (process instance) └── 6 : start -&gt; someTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.802 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.802 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.878 [main] [INFO] task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;some task my test message&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Mon Dec 03 16:13:28 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;6&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;9&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskService:33 16:13:28.878 [main] [INFO] task.description: some task my test message o.d.a.c.TaskServiceTest.testTaskService:34 16:13:28.893 [main] [INFO] taskServiceVariables: {k1=v1, localK1=localV1, message=my test message} o.d.a.c.TaskServiceTest.testTaskService:46 16:13:28.893 [main] [INFO] taskServiceVariablesLocal: {localK1=localV1} o.d.a.c.TaskServiceTest.testTaskService:47 16:13:28.893 [main] [INFO] processVariables: {k1=v1, message=my test message} o.d.a.c.TaskServiceTest.testTaskService:48 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : someTask -&gt; end, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:13:28.893 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:13:28.893 [main] [INFO] task1: null o.d.a.c.TaskServiceTest.testTaskService:55 5.3.1.2 TaskService 设置 Task 权限信息 候选用户(candidateUser) 和候选组(candidateGroup) 指定拥有人(Owner)和办理人(Assignee) 通过 claim 设置办理人(发现 task 已经有指定办理人且不是 claim 指定的人就会抛出异常) 流程定义1234567891011121314151617181920&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start"/&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;!-- 添加候选人 --&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:candidateUsers="destiny,destiny1,destiny2"&gt; &lt;!-- 添加描述, message 会根据上下文中传入的 message 变量值去替换 --&gt; &lt;documentation&gt; some task $&#123;message&#125; &lt;/documentation&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;)public void testTaskServiceUser() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); TaskService taskService = activitiRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); log.info("task: &#123;&#125;", ToStringBuilder.reflectionToString(task, ToStringStyle.JSON_STYLE)); log.info("task.description: &#123;&#125;", task.getDescription()); taskService.setOwner(task.getId(), "user1"); // 可能存在覆盖已有代办放的问题, 因此不推荐 // taskService.setAssignee(task.getId(), "destiny"); // 查询在候选人列表, 且未指定办理人的 task 列表 List&lt;Task&gt; taskList = taskService.createTaskQuery() .taskCandidateOrAssigned("destiny") .taskUnassigned() .listPage(0, 100); // 使用 claim 设置候选人 for (Task task1 : taskList) &#123; try &#123; taskService.claim(task1.getId(), "destiny"); &#125; catch (Exception e) &#123; log.warn(e.getMessage(), e); &#125; &#125; // 查看当前 task 的所有用户关系内容 List&lt;IdentityLink&gt; identityLinkList = taskService.getIdentityLinksForTask(task.getId()); for (IdentityLink identityLink : identityLinkList) &#123; log.info("identityLink: &#123;&#125;", identityLink); &#125; // 完成任务, 首先找到处于代办状态的所有 task List&lt;Task&gt; destinys = taskService.createTaskQuery().taskAssignee("destiny").listPage(0, 100); for (Task destiny : destinys) &#123; variables.clear(); variables.put("cKey1", "cValue1"); taskService.complete(destiny.getId(), variables); &#125; destinys = taskService.createTaskQuery().taskAssignee("destiny").listPage(0, 100); log.info("是否存在: &#123;&#125;", CollectionUtils.isEmpty(destinys));&#125; 输出日志16:41:28.534 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 16:41:30.373 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 16:41:30.385 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:41:30.443 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:41:30.449 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 16:41:30.453 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 16:41:30.631 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.636 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.638 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.638 [main] [INFO] 4 (process instance) └── 6 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.639 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.640 [main] [INFO] 4 (process instance) └── 6 : start -&gt; someTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.640 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.641 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.715 [main] [INFO] task: {&quot;owner&quot;:null,&quot;assigneeUpdatedCount&quot;:0,&quot;originalAssignee&quot;:null,&quot;assignee&quot;:null,&quot;delegationState&quot;:null,&quot;parentTaskId&quot;:null,&quot;name&quot;:&quot;Activiti is awesome!&quot;,&quot;localizedName&quot;:null,&quot;description&quot;:&quot;some task my test message&quot;,&quot;localizedDescription&quot;:null,&quot;priority&quot;:50,&quot;createTime&quot;:&quot;Mon Dec 03 16:41:30 CST 2018&quot;,&quot;dueDate&quot;:null,&quot;suspensionState&quot;:1,&quot;category&quot;:null,&quot;isIdentityLinksInitialized&quot;:false,&quot;taskIdentityLinkEntities&quot;:[],&quot;executionId&quot;:&quot;6&quot;,&quot;execution&quot;:null,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;processInstance&quot;:null,&quot;processDefinitionId&quot;:&quot;my-process:1:3&quot;,&quot;taskDefinitionKey&quot;:&quot;someTask&quot;,&quot;formKey&quot;:null,&quot;isDeleted&quot;:false,&quot;isCanceled&quot;:false,&quot;eventName&quot;:null,&quot;currentActivitiListener&quot;:null,&quot;tenantId&quot;:&quot;&quot;,&quot;queryVariables&quot;:null,&quot;forcedUpdate&quot;:false,&quot;claimTime&quot;:null,&quot;variableInstances&quot;:null,&quot;usedVariablesCache&quot;:{},&quot;transientVariabes&quot;:null,&quot;cachedElContext&quot;:null,&quot;id&quot;:&quot;9&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskServiceUser:69 16:41:30.715 [main] [INFO] task.description: some task my test message o.d.a.c.TaskServiceTest.testTaskServiceUser:70 16:41:30.739 [main] [INFO] identityLink: IdentityLinkEntity[id=10, type=candidate, userId=destiny, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=12, type=candidate, userId=destiny1, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=14, type=candidate, userId=destiny2, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=null, type=assignee, userId=destiny, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.740 [main] [INFO] identityLink: IdentityLinkEntity[id=null, type=owner, userId=user1, taskId=9] o.d.a.c.TaskServiceTest.testTaskServiceUser:94 16:41:30.749 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TriggerExecutionOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.751 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.752 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.753 [main] [INFO] 4 (process instance) └── 6 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.754 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.754 [main] [INFO] 4 (process instance) └── 6 : someTask -&gt; end, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.755 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.755 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.755 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.755 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.757 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.EndExecutionOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 16:41:30.757 [main] [INFO] 4 (process instance) └── 6 : end (EndEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 16:41:30.770 [main] [INFO] 是否存在: true o.d.a.c.TaskServiceTest.testTaskServiceUser:106 5.3.2 TaskService 设置 Task 附加信息 任务附件(Attachment)创建与查询 任务评论(Comment)创建与查询 事件记录(Event)创建于查询 5.3.2.1 任务附件(Attachment)创建与查询流程定义同上 测试代码12345678910111213141516@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;)public void testTaskAttachment() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); TaskService taskService = activitiRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); // 可以上传数据流或 url Attachment attachment = taskService.createAttachment("url", task.getId(), task.getProcessInstanceId(), "name", "desc", "/url/test.png"); log.info("attachment: &#123;&#125;", attachment); List&lt;Attachment&gt; taskAttachments = taskService.getTaskAttachments(task.getId()); for (Attachment taskAttachment : taskAttachments) &#123; log.info("taskAttachment: &#123;&#125;", ToStringBuilder.reflectionToString(taskAttachment, ToStringStyle.JSON_STYLE)); &#125;&#125; 日志输出17:12:47.043 [main] [INFO] attachment: org.activiti.engine.impl.persistence.entity.AttachmentEntityImpl@72b16078 o.d.a.c.TaskServiceTest.testTaskAttachment:119 17:12:47.050 [main] [INFO] taskAttachment: {&quot;name&quot;:&quot;name&quot;,&quot;description&quot;:&quot;desc&quot;,&quot;type&quot;:&quot;url&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;url&quot;:&quot;/url/test.png&quot;,&quot;contentId&quot;:null,&quot;content&quot;:null,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:12:47 CST 2018&quot;,&quot;id&quot;:&quot;16&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskAttachment:122 5.3.2.2 任务评论(Comment)创建与查询流程定义同上 测试代码123456789101112131415161718192021@Test@Deployment(resources = &#123;"org/destiny/activiti/my-process-task.bpmn20.xml"&#125;)public void testTaskComment() &#123; Map&lt;String, Object&gt; variables = Maps.newHashMap(); variables.put("message", "my test message"); activitiRule.getRuntimeService().startProcessInstanceByKey("my-process", variables); TaskService taskService = activitiRule.getTaskService(); Task task = taskService.createTaskQuery().singleResult(); // 添加评论 taskService.addComment(task.getId(), task.getProcessInstanceId(), "record note1"); taskService.addComment(task.getId(), task.getProcessInstanceId(), "record note2"); List&lt;Comment&gt; taskComments = taskService.getTaskComments(task.getId()); for (Comment taskComment : taskComments) &#123; log.info("taskComment: &#123;&#125;", ToStringBuilder.reflectionToString(taskComment, ToStringStyle.JSON_STYLE)); &#125; // 事件记录 List&lt;Event&gt; taskEvents = taskService.getTaskEvents(task.getId()); for (Event taskEvent : taskEvents) &#123; log.info("taskEvent: &#123;&#125;", ToStringBuilder.reflectionToString(taskEvent, ToStringStyle.JSON_STYLE)); &#125;&#125; 日志输出17:05:17.107 [main] [INFO] taskComment: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note2&quot;,&quot;fullMessage&quot;:&quot;record note2&quot;,&quot;id&quot;:&quot;17&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:140 17:05:17.107 [main] [INFO] taskComment: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note1&quot;,&quot;fullMessage&quot;:&quot;record note1&quot;,&quot;id&quot;:&quot;16&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:140 17:05:17.109 [main] [INFO] taskEvent: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note2&quot;,&quot;fullMessage&quot;:&quot;record note2&quot;,&quot;id&quot;:&quot;17&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:146 17:05:17.110 [main] [INFO] taskEvent: {&quot;type&quot;:&quot;comment&quot;,&quot;userId&quot;:null,&quot;time&quot;:&quot;Mon Dec 03 17:05:17 CST 2018&quot;,&quot;taskId&quot;:&quot;9&quot;,&quot;processInstanceId&quot;:&quot;4&quot;,&quot;action&quot;:&quot;AddComment&quot;,&quot;message&quot;:&quot;record note1&quot;,&quot;fullMessage&quot;:&quot;record note1&quot;,&quot;id&quot;:&quot;16&quot;,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.TaskServiceTest.testTaskComment:146 Comment 和 Event 的区别所有对 task 的操作都会生成新的 Event 记录, comment 只是其中的一种, 比如在上例中新增 owner 或 assignee, 也会产生新的 event 记录 5.4 身份管理服务 Activiti 提供了相对比较简单的用户/用户组管理 主要功能: 管理用户(User) 管理用户组(Group) 用户与用户组的关系(Membership)(多对多关系) 5.4.1 创建用户/用户组/对应关系流程定义 此处不需要基于流程定义完成 测试代码123456789101112131415161718192021222324252627282930313233343536373839404142@Slf4jpublic class IdentityServiceTest &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test public void testIdentity() &#123; IdentityService identityService = activitiRule.getIdentityService(); User user1 = identityService.newUser("user1"); user1.setEmail("destinywk@163.com"); User user2 = identityService.newUser("user2"); user2.setEmail("destinywk@126.com"); identityService.saveUser(user1); identityService.saveUser(user2); Group group1 = identityService.newGroup("group1"); identityService.saveGroup(group1); Group group2 = identityService.newGroup("group2"); identityService.saveGroup(group2); // 创建关系 identityService.createMembership("user1", "group1"); identityService.createMembership("user2", "group1"); identityService.createMembership("user1", "group2"); List&lt;User&gt; userList = identityService.createUserQuery() .memberOfGroup("group1") .listPage(0, 100); for (User user : userList) &#123; log.info("user: &#123;&#125;", ToStringBuilder.reflectionToString(user, ToStringStyle.JSON_STYLE)); &#125; List&lt;Group&gt; groupList = identityService.createGroupQuery() .groupMember("user1").listPage(0, 100); for (Group group : groupList) &#123; log.info("group: &#123;&#125;", ToStringBuilder.reflectionToString(group, ToStringStyle.JSON_STYLE)); &#125; &#125;&#125; 日志输出17:37:12.982 [main] [INFO] Loading XML bean definitions from class path resource [activiti.cfg.xml] o.s.b.f.x.XmlBeanDefinitionReader.loadBeanDefinitions:316 17:37:14.894 [main] [INFO] Activiti 5 compatibility handler implementation not found or error during instantiation : org.activiti.compatibility.DefaultActiviti5CompatibilityHandler. Activiti 5 backwards compatibility disabled. o.a.e.c.DefaultActiviti5CompatibilityHandlerFactory.createActiviti5CompatibilityHandler:38 17:37:14.910 [main] [INFO] performing create on engine with resource org/activiti/db/create/activiti.h2.create.engine.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 17:37:14.971 [main] [INFO] performing create on history with resource org/activiti/db/create/activiti.h2.create.history.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 17:37:14.978 [main] [INFO] performing create on identity with resource org/activiti/db/create/activiti.h2.create.identity.sql o.a.e.i.d.DbSqlSession.executeSchemaResource:1147 17:37:14.982 [main] [INFO] ProcessEngine default created o.a.e.i.ProcessEngineImpl.&lt;init&gt;:87 17:37:15.041 [main] [INFO] user: {&quot;firstName&quot;:null,&quot;lastName&quot;:null,&quot;email&quot;:&quot;destinywk@163.com&quot;,&quot;password&quot;:null,&quot;pictureByteArrayRef&quot;:&quot;ByteArrayRef[id=null, name=null, entity=null]&quot;,&quot;id&quot;:&quot;user1&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:46 17:37:15.042 [main] [INFO] user: {&quot;firstName&quot;:null,&quot;lastName&quot;:null,&quot;email&quot;:&quot;destinywk@126.com&quot;,&quot;password&quot;:null,&quot;pictureByteArrayRef&quot;:&quot;ByteArrayRef[id=null, name=null, entity=null]&quot;,&quot;id&quot;:&quot;user2&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:46 17:37:15.048 [main] [INFO] group: {&quot;name&quot;:null,&quot;type&quot;:null,&quot;id&quot;:&quot;group1&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:52 17:37:15.048 [main] [INFO] group: {&quot;name&quot;:null,&quot;type&quot;:null,&quot;id&quot;:&quot;group2&quot;,&quot;revision&quot;:1,&quot;isInserted&quot;:false,&quot;isUpdated&quot;:false,&quot;isDeleted&quot;:false} o.d.a.c.IdentityServiceTest.testIdentity:52 身份管理服务的调用过程: 会将 User 封装成一个 Command, 交由命令执行器去执行, 最后调用 MyBatis 底层接口去操作 DB 5.5 表单管理服务 FormService功能: 解析流程定义中表单项的配置 提供提交表单的方式驱动用户节点流转 获取自定义外部表单 key 5.5.1流程定义123456789101112131415161718192021222324&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:omgdc="http://www.omg.org/spec/DD/20100524/DC" xmlns:omgdi="http://www.omg.org/spec/DD/20100524/DI" typeLanguage="http://www.w3.org/2001/XMLSchema" expressionLanguage="http://www.w3.org/1999/XPath" targetNamespace="http://www.activiti.org/test"&gt; &lt;process id="my-process"&gt; &lt;startEvent id="start" activiti:formKey="/rest/process/form/start"&gt; &lt;!-- 配置表单项 --&gt; &lt;extensionElements&gt; &lt;activiti:formProperty id="message" name="信息" type="string" required="true"/&gt; &lt;/extensionElements&gt; &lt;/startEvent&gt; &lt;sequenceFlow id="flow1" sourceRef="start" targetRef="someTask"/&gt; &lt;userTask id="someTask" name="Activiti is awesome!" activiti:formKey="/rest/process/form/userTask"&gt; &lt;extensionElements&gt; &lt;!-- 配置表单项 --&gt; &lt;activiti:formProperty id="yesOrNo" name="审批" type="string" required="true"/&gt; &lt;/extensionElements&gt; &lt;/userTask&gt; &lt;sequenceFlow id="flow2" sourceRef="someTask" targetRef="end"/&gt; &lt;endEvent id="end"/&gt; &lt;/process&gt;&lt;/definitions&gt; 测试代码1234567891011121314151617181920212223242526272829303132333435363738@Slf4jpublic class FormServiceTest &#123; @Rule public ActivitiRule activitiRule = new ActivitiRule(); @Test @Deployment(resources = &#123;"org/destiny/activiti/my-process-form.bpmn20.xml"&#125;) public void testFormService() &#123; FormService formService = activitiRule.getFormService(); // 获取流程定义文件 ProcessDefinition processDefinition = activitiRule.getRepositoryService().createProcessDefinitionQuery().singleResult(); // 获取 startForm 的 key 和 data String startFormKey = formService.getStartFormKey(processDefinition.getId()); log.info("startFormKey: &#123;&#125;", startFormKey); StartFormData startFormData = formService.getStartFormData(processDefinition.getId()); log.info("startFormKey: &#123;&#125;", ToStringBuilder.reflectionToString(startFormData, ToStringStyle.JSON_STYLE)); for (FormProperty startFormProperty : startFormData.getFormProperties()) &#123; log.info("startFormProperty: &#123;&#125;", ToStringBuilder.reflectionToString(startFormProperty, ToStringStyle.JSON_STYLE)); &#125; // 启动流程 Map&lt;String, String&gt; properties = Maps.newHashMap(); properties.put("message", "my test message"); formService.submitStartFormData(processDefinition.getId(), properties); // 查询 task Task task = activitiRule.getTaskService().createTaskQuery().singleResult(); // 获取 taskForm 的 data TaskFormData taskFormData = formService.getTaskFormData(task.getId()); log.info("taskFormData: &#123;&#125;", ToStringBuilder.reflectionToString(taskFormData, ToStringStyle.JSON_STYLE)); for (FormProperty taskFormProperty : taskFormData.getFormProperties()) &#123; log.info("taskFormProperty: &#123;&#125;", ToStringBuilder.reflectionToString(taskFormProperty, ToStringStyle.JSON_STYLE)); &#125; &#125;&#125; 日志输出18:15:27.539 [main] [INFO] startFormKey: /rest/process/form/start o.d.a.c.FormServiceTest.testFormService:36 18:15:27.547 [main] [INFO] startFormKey: {&quot;processDefinition&quot;:&quot;ProcessDefinitionEntity[my-process:1:3]&quot;,&quot;formKey&quot;:&quot;/rest/process/form/start&quot;,&quot;deploymentId&quot;:&quot;1&quot;,&quot;formProperties&quot;:[org.activiti.engine.impl.form.FormPropertyImpl@3bde62ff]} o.d.a.c.FormServiceTest.testFormService:38 18:15:27.547 [main] [INFO] startFormProperty: {&quot;id&quot;:&quot;message&quot;,&quot;name&quot;:&quot;信息&quot;,&quot;type&quot;:&quot;org.activiti.engine.impl.form.StringFormType@2baa8d82&quot;,&quot;isRequired&quot;:true,&quot;isReadable&quot;:true,&quot;isWritable&quot;:true,&quot;value&quot;:null} o.d.a.c.FormServiceTest.testFormService:40 18:15:27.561 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.564 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.565 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.TakeOutgoingSequenceFlowsOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.566 [main] [INFO] 4 (process instance) └── 5 : start (StartEvent, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.567 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.567 [main] [INFO] 4 (process instance) └── 5 : start -&gt; someTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.568 [main] [INFO] Execution tree while executing operation class org.activiti.engine.impl.agenda.ContinueProcessOperation : o.a.e.i.i.DebugCommandInvoker.executeOperation:33 18:15:27.568 [main] [INFO] 4 (process instance) └── 5 : someTask (UserTask, parent id 4 (active) o.a.e.i.i.DebugCommandInvoker.executeOperation:34 18:15:27.602 [main] [INFO] taskFormData: {&quot;task&quot;:&quot;Task[id=10, name=Activiti is awesome!]&quot;,&quot;formKey&quot;:&quot;/rest/process/form/userTask&quot;,&quot;deploymentId&quot;:&quot;1&quot;,&quot;formProperties&quot;:[org.activiti.engine.impl.form.FormPropertyImpl@4e4efc1b]} o.d.a.c.FormServiceTest.testFormService:53 18:15:27.602 [main] [INFO] taskFormProperty: {&quot;id&quot;:&quot;yesOrNo&quot;,&quot;name&quot;:&quot;审批&quot;,&quot;type&quot;:&quot;org.activiti.engine.impl.form.StringFormType@2baa8d82&quot;,&quot;isRequired&quot;:true,&quot;isReadable&quot;:true,&quot;isWritable&quot;:true,&quot;value&quot;:null} o.d.a.c.FormServiceTest.testFormService:55 5.6 HistoryService 历史数据管理服务作用: 管理流程实例哦结束后的历史数据 构建历史数据的查询对象 根据流程实例 id 删除流程历史数据 历史数据实体 描述 HistoricProcessInstance 历史流程实例实体类 HistoricVariableInstance 流程或任务变量值的实体 HistoricActivityInstance 单个活动节点执行的信息 HistoricTaskInstance 用户任务实例的信息 HistoricDetail 历史流程活动任务详细信息 HistoryService 构建历史查询对象: create[历史数据实体]Query createNative[历史数据实体]Query createProcessInstanceHistoryLogQuery: 只能查出一个流程实例的一个对象, 每次只能查出一条记录, 包含流程实体所有的其他数据, 包括task, Activiti, comment 等信息 HistoryService 删除历史操作 deleteHistoricProcessInstance, 采用级联操作, 删除与流程实例相关的所有历史信息 deleteHistoricTaskInstance, 范围相对较小, 只删除 Task 及 Task 相关的变量 5.7 ManagementService 管理服务作用: Job 任务管理 数据库相关通用操作 执行流程引擎命令(Command) 5.7.1 Job 任务管理 工作查询对象 描述 JobQuery 查询一般工作 TimerJobQuery 查询定时任务 SuspendedKobQUery 查询中断工作 DeadLetterJobQuery 查询无法执行的工作(一般重试三次) 5.7.2 数据库相关操作 查询表结构元数据 通用表查询 执行自定义的 sql 查询 5.8 DynamicBpmnService 动态流程定义服务 不推荐使用 6 数据库设计和模型映射 数据表分类 描述 ACT_GE_* 通用数据表 ACT_RE_* 流程定义存储表 ACT_ID_* 身份信息表 ACT_RU_* 运行时数据库表 ACT_HI_* 历史数据库表 6.1 MySql 建表语句 除了核心引擎是必选的, 其他两个不是必须的 核心引擎: activiti.mysql.create.engine.sql 历史数据: activiti.mysql.create.history.sql 身份信息: activiti.mysql.create.identity.sql 6.1.1 通用数据库 数据表分类 描述 ACT_GE_PROPERTY 属性表(保存流程引擎的 key-value 键值属性) ACT_GE_BYTEARRAY 资源表(存储流程定义相关的资源) 7 BPMN2.0 概述 是一套业务流程模型与符号建模标准 精准的执行语义来描述元素的操作 以 XML 为载体, 以符号可视化业务 BPMN2.0元素: 流对象 连接对象 数据 泳道 描述对象 7.1 流对象 活动(Activities): User Task, Service Task… 事件(Events): Start Event, End Event… 网关(Gateway): Exclusive Gateway… 8 Activiti 集成 Spring BootActiviti6.0 依赖的 SpringBoot 版本是 1.2.6 如果直接与 SpringBoot 2.0.0 集成的话, 会出现 ClassNotFound 等问题 因此在集成 SpringBoot 2.0.0 的时候, 需要 Activiti6.0 源码进行部分改动 升级 Activiti 6.0 依赖 SpringBoot 版本为 2.0.0 的改动 升级 SpringBoot 依赖并解决编译错误 更新 activiti-spring-boot-starter-basic 版本并安装 集成使用 Activiti 的 AutoConfiguration 功能 如果直接将 SpringBoot 2.0.0 和 activiti-spring-boot-starter-basic 6.0.0 集成, 会发生如下错误: java.lang.IllegalStateException: Failed to load ApplicationContext Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;documentationPluginsBootstrapper&apos; defined in URL [jar:file:/Users/destiny/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar!/springfox/documentation/spring/web/plugins/DocumentationPluginsBootstrapper.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;webMvcRequestHandlerProvider&apos; defined in URL [jar:file:/Users/destiny/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;requestMappingHandlerMapping&apos; defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;webMvcRequestHandlerProvider&apos; defined in URL [jar:file:/Users/destiny/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;requestMappingHandlerMapping&apos; defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;requestMappingHandlerMapping&apos; defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... Caused by: java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ... 真正的原因是对应的类无法找到 8.1 修改 activiti 源码以适应 SpringBoot 2.0.0 版本升级8.1.1 将 activiti 中 SpringBoot 依赖升级到 2.0.0修改 Activiti 源码中 modules/activiti-spring-boot/pom.xml pom 文件, 将其中 1&lt;spring.boot.version&gt;1.2.6.RELEASE&lt;/spring.boot.version&gt; 修改为 1&lt;spring.boot.version&gt;2.0.0.RELEASE&lt;/spring.boot.version&gt; 然后重新编译源码, 此时以下几个类会报错 8.1.1.1 org.activiti.spring.boot.actuate.endpoint.ProcessEngineEndpoint 主要的问题是 SpringBoot 从 1 升级到 2 的时候, 对 EndPoint 的使用方式发生了改变:1.x 是继承一个抽象类 AbstractEndpoint2.x 修改为使用对应的注解 修改后的源码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package org.activiti.spring.boot.actuate.endpoint;import org.activiti.engine.ProcessEngine;import org.activiti.engine.impl.cfg.ProcessEngineConfigurationImpl;import org.activiti.engine.impl.persistence.deploy.DefaultDeploymentCache;import org.activiti.engine.impl.persistence.deploy.DeploymentCache;import org.activiti.engine.impl.persistence.deploy.ProcessDefinitionCacheEntry;import org.activiti.engine.repository.ProcessDefinition;import org.springframework.boot.actuate.endpoint.annotation.Endpoint;import org.springframework.boot.actuate.endpoint.annotation.ReadOperation;import java.util.*;/** * Registers a Boot Actuator endpoint that provides information on the * running process instance and renders BPMN diagrams of the deployed processes. * * @author Josh Long *///@ConfigurationProperties(prefix = "endpoints.activiti")@Endpoint(id = "activiti") // 使用注解 Endpointpublic class ProcessEngineEndpoint &#123; // 不再继承 AbstractEndpoint private final ProcessEngine processEngine; public ProcessEngineEndpoint(ProcessEngine processEngine) &#123; this.processEngine = processEngine; // 不再继承 Endpoint, 因此不需要调用 super 构造方法 &#125; @ReadOperation // 不需要 @Override public Map&lt;String, Object&gt; activiti() &#123; Map&lt;String, Object&gt; metrics = new HashMap&lt;String, Object&gt;(); // Process definitions metrics.put("processDefinitionCount", processEngine.getRepositoryService().createProcessDefinitionQuery().count()); // List of all process definitions List&lt;ProcessDefinition&gt; processDefinitions = processEngine.getRepositoryService().createProcessDefinitionQuery().orderByProcessDefinitionKey().asc().list(); List&lt;String&gt; processDefinitionKeys = new ArrayList&lt;String&gt;(); for (ProcessDefinition processDefinition : processDefinitions) &#123; processDefinitionKeys.add(processDefinition.getKey() + " (v" + processDefinition.getVersion() + ")"); &#125; metrics.put("deployedProcessDefinitions", processDefinitionKeys); // Process instances Map&lt;String, Object&gt; processInstanceCountMap = new HashMap&lt;String, Object&gt;(); metrics.put("runningProcessInstanceCount", processInstanceCountMap); for (ProcessDefinition processDefinition : processDefinitions) &#123; processInstanceCountMap.put(processDefinition.getKey() + " (v" + processDefinition.getVersion() + ")", processEngine.getRuntimeService().createProcessInstanceQuery().processDefinitionId(processDefinition.getId()).count()); &#125; Map&lt;String, Object&gt; completedProcessInstanceCountMap = new HashMap&lt;String, Object&gt;(); metrics.put("completedProcessInstanceCount", completedProcessInstanceCountMap); for (ProcessDefinition processDefinition : processDefinitions) &#123; completedProcessInstanceCountMap.put(processDefinition.getKey() + " (v" + processDefinition.getVersion() + ")", processEngine.getHistoryService().createHistoricProcessInstanceQuery().finished().processDefinitionId(processDefinition.getId()).count()); &#125; // Open tasks metrics.put("openTaskCount", processEngine.getTaskService().createTaskQuery().count()); metrics.put("completedTaskCount", processEngine.getHistoryService().createHistoricTaskInstanceQuery().finished().count()); // Tasks completed today metrics.put("completedTaskCountToday", processEngine.getHistoryService().createHistoricTaskInstanceQuery().finished().taskCompletedAfter( new Date(System.currentTimeMillis() - secondsForDays(1))).count()); // Process steps metrics.put("completedActivities", processEngine.getHistoryService().createHistoricActivityInstanceQuery().finished().count()); // Process definition cache DeploymentCache&lt;ProcessDefinitionCacheEntry&gt; deploymentCache = ((ProcessEngineConfigurationImpl) processEngine.getProcessEngineConfiguration()).getProcessDefinitionCache(); if (deploymentCache instanceof DefaultDeploymentCache) &#123; metrics.put("cachedProcessDefinitionCount", ((DefaultDeploymentCache) deploymentCache).size()); &#125; return metrics; &#125; private long secondsForDays(int days) &#123; int hour = 60 * 60 * 1000; int day = 24 * hour; return days * day; &#125;&#125; 8.1.1.2 org.activiti.spring.boot.actuate.endpoint.ProcessEngineMvcEndpoint 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package org.activiti.spring.boot.actuate.endpoint;import java.io.InputStream;import org.activiti.bpmn.BpmnAutoLayout;import org.activiti.bpmn.model.BpmnModel;import org.activiti.engine.RepositoryService;import org.activiti.engine.repository.ProcessDefinition;import org.activiti.image.ProcessDiagramGenerator;import org.activiti.image.impl.DefaultProcessDiagramGenerator;import org.springframework.core.io.InputStreamResource;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * Renders a valid running BPMN process definition as a BPMN diagram. * * This is duplicative of the functionality in the full REST API implementation. * * @author Joram Barrez * @author Josh Long */public class ProcessEngineMvcEndpoint &#123; // 同样不再继承 EndpointMvcAdapter private final RepositoryService repositoryService; private final ProcessEngineEndpoint processEngineEndpoint; // 创建一个 ProcessEngineEndpoint 私有变量 public ProcessEngineMvcEndpoint(ProcessEngineEndpoint processEngineEndpoint, RepositoryService repositoryService) &#123;// super(processEngineEndpoint); this.processEngineEndpoint = processEngineEndpoint; this.repositoryService = repositoryService; &#125; /** * Look up the process definition by key. For example, * this is &lt;A href="http://localhost:8080/activiti/processes/fulfillmentProcess"&gt;process-diagram for&lt;/A&gt; * a process definition named &#123;@code fulfillmentProcess&#125;. */ @RequestMapping(value = "/processes/&#123;processDefinitionKey:.*&#125;", method = RequestMethod.GET, produces = MediaType.IMAGE_JPEG_VALUE) @ResponseBody public ResponseEntity processDefinitionDiagram(@PathVariable String processDefinitionKey) &#123; ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(processDefinitionKey) .latestVersion() .singleResult(); if (processDefinition == null) &#123; return ResponseEntity.status(HttpStatus.NOT_FOUND).body(null); &#125; ProcessDiagramGenerator processDiagramGenerator = new DefaultProcessDiagramGenerator(); BpmnModel bpmnModel = repositoryService.getBpmnModel(processDefinition.getId()); if (bpmnModel.getLocationMap().size() == 0) &#123; BpmnAutoLayout autoLayout = new BpmnAutoLayout(bpmnModel); autoLayout.execute(); &#125; InputStream is = processDiagramGenerator.generateJpgDiagram(bpmnModel); return ResponseEntity.ok(new InputStreamResource(is)); &#125;&#125; 8.1.1.3 org.activiti.spring.boot.EndpointAutoConfiguration 报错原因: SpringBoot2 不再使用 AbstractEndpoint开启该表达式 AutoConfiguration 不会生效, 因此需要删除 1234567891011121314151617181920212223242526272829303132package org.activiti.spring.boot;import org.activiti.engine.ProcessEngine;import org.activiti.engine.RepositoryService;import org.activiti.spring.boot.actuate.endpoint.ProcessEngineEndpoint;import org.activiti.spring.boot.actuate.endpoint.ProcessEngineMvcEndpoint;//import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * The idea behind this module is that Spring Security could * talk to the &#123;@link org.activiti.engine.IdentityService&#125; * as required. * * @author Josh Long */@Configuration//@ConditionalOnClass (name = "org.springframework.boot.actuate.endpoint.AbstractEndpoint")public class EndpointAutoConfiguration &#123; @Bean public ProcessEngineEndpoint processEngineEndpoint(ProcessEngine engine) &#123; return new ProcessEngineEndpoint(engine); &#125; @Bean public ProcessEngineMvcEndpoint processEngineMvcEndpoint( ProcessEngineEndpoint engineEndpoint, RepositoryService repositoryService) &#123; return new ProcessEngineMvcEndpoint(engineEndpoint, repositoryService); &#125;&#125; 8.1.1.4 org.activiti.spring.boot.DataSourceProcessEngineAutoConfiguration 报错原因: ConditionalOnMissingClass 注解中的 name 已经不能使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.activiti.spring.boot;import java.io.IOException;import javax.sql.DataSource;import org.activiti.spring.SpringAsyncExecutor;import org.activiti.spring.SpringProcessEngineConfiguration;import org.springframework.boot.autoconfigure.AutoConfigureAfter;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingClass;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;/** * @author Joram Barrez * @author Josh Long */@Configuration@AutoConfigureAfter(DataSourceAutoConfiguration.class)public class DataSourceProcessEngineAutoConfiguration &#123; @Configuration// @ConditionalOnMissingClass(name= "javax.persistence.EntityManagerFactory") @ConditionalOnMissingClass(value= "javax.persistence.EntityManagerFactory") // 将 name 替换为 value @EnableConfigurationProperties(ActivitiProperties.class) public static class DataSourceProcessEngineConfiguration extends AbstractProcessEngineAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public PlatformTransactionManager transactionManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; @Bean @ConditionalOnMissingBean public SpringProcessEngineConfiguration springProcessEngineConfiguration( DataSource dataSource, PlatformTransactionManager transactionManager, SpringAsyncExecutor springAsyncExecutor) throws IOException &#123; return this.baseSpringProcessEngineConfiguration(dataSource, transactionManager, springAsyncExecutor); &#125; &#125;&#125; 8.1.1.4 org.activiti.spring.boot.SecurityAutoConfiguration 报错原因: 包结构发生改变, 导致原有的类全路径不可用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import org.activiti.engine.IdentityService;import org.activiti.rest.security.BasicAuthenticationProvider;import org.activiti.spring.security.IdentityServiceUserDetailsService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.AutoConfigureBefore;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.authentication.AuthenticationProvider;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.authentication.configurers.GlobalAuthenticationConfigurerAdapter;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;/** * Installs a Spring Security adapter for the Activiti * &#123;@link org.activiti.engine.IdentityService&#125;. * * @author Josh Long */@Configuration//@AutoConfigureBefore(org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration.class)@AutoConfigureBefore(org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration.class) // 修改类路径public class SecurityAutoConfiguration &#123; @Configuration @ConditionalOnClass( UserDetailsService.class) public static class UserDetailsServiceConfiguration extends GlobalAuthenticationConfigurerAdapter &#123; @Override public void init(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService( userDetailsService()); &#125; @Bean public UserDetailsService userDetailsService() &#123; return new IdentityServiceUserDetailsService(this.identityService); &#125; @Autowired private IdentityService identityService; &#125; @Configuration @ConditionalOnClass(name = &#123;"org.activiti.rest.service.api.RestUrls", "org.springframework.web.servlet.DispatcherServlet"&#125;) @EnableWebSecurity public static class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean public AuthenticationProvider authenticationProvider() &#123; return new BasicAuthenticationProvider(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authenticationProvider(authenticationProvider()) .csrf().disable() .authorizeRequests() .anyRequest().authenticated() .and() .httpBasic(); &#125; &#125;&#125; 8.2 对 Activiti 版本做更改12345678910111213141516171819&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starters&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;activiti-spring-boot-starter-basic&lt;/artifactId&gt; &lt;!-- 在此处新增版本 --&gt; &lt;version&gt;6.0.0-boot2&lt;/version&gt; &lt;!-- &lt;properties&gt; &lt;spring.framework.version&gt;4.1.4.RELEASE&lt;/spring.framework.version&gt; &lt;/properties&gt; --&gt; ...&lt;/project&gt; 尝试执行 mvn clean install 此时 maven 会去尝试下载 6.0.0-boot2 版本, 但显然公网仓库中不会存在 [INFO] Scanning for projects... [INFO] [INFO] ----------&lt; org.activiti:activiti-spring-boot-starter-basic &gt;----------- [INFO] Building activiti-spring-boot-starter-basic 6.0.0-boot2 [INFO] --------------------------------[ jar ]--------------------------------- [WARNING] The POM for org.activiti:activiti-engine:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-spring:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-rest:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-common-rest:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-image-generator:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-bpmn-model:jar:6.0.0-boot2 is missing, no dependency information available [WARNING] The POM for org.activiti:activiti-bpmn-layout:jar:6.0.0-boot2 is missing, no dependency information available [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.850 s [INFO] Finished at: 2018-12-03T23:15:57+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal on project activiti-spring-boot-starter-basic: Could not resolve dependencies for project org.activiti:activiti-spring-boot-starter-basic:jar:6.0.0-boot2: The following artifacts could not be resolved: org.activiti:activiti-engine:jar:6.0.0-boot2, org.activiti:activiti-spring:jar:6.0.0-boot2, org.activiti:activiti-rest:jar:6.0.0-boot2, org.activiti:activiti-common-rest:jar:6.0.0-boot2, org.activiti:activiti-image-generator:jar:6.0.0-boot2, org.activiti:activiti-bpmn-model:jar:6.0.0-boot2, org.activiti:activiti-bpmn-layout:jar:6.0.0-boot2: Failure to find org.activiti:activiti-engine:jar:6.0.0-boot2 in http://maven.aliyun.com/nexus/content/groups/public was cached in the local repository, resolution will not be reattempted until the update interval of nexus-aliyun has elapsed or updates are forced -&gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException 错误原因: activiti-spring-boot-starter-basic 的版本号被修改为 6.0.0-boot2, 但安装的时候, 对应的 activiti-engine 版本只有 6.0.0, 并没有 6.0.0-boot2可以将所有需要找 6.0.0-boot2 的版本修改为去找 6.0.0 将根 pom 中所有的 ${project.version} 修改为 6.0.0]]></content>
      <categories>
        <category>Activiti</category>
        <category>Java</category>
        <category>工作流</category>
      </categories>
      <tags>
        <tag>Activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java逃逸分析]]></title>
    <url>%2Fblog%2F2018%2F09%2F07%2FJava%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. 逃逸概念的引入 我们都知道, Java 创建的对象都是被分配到堆内存上, 但是事实并不是这么绝对, 通过对Java对象分配的过程分析, 可以知道有两个地方会导致 Java 中创建出来的对象并不一定分别在所认为的堆上. 这两个点分别是 Java 中的 逃逸分析 和 TLAB(Thread Local Allocation Buffer)线程私有的缓存区。 2. 逃逸分析基本概念逃逸分析, 是一种可以有效减少 Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法. 通过逃逸分析, Hotspot编译器 能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上. 在计算机语言编译器优化原理中, 逃逸分析是指分析指针动态范围的方法, 它同编译器优化原理的指针分析和外形分析相关联. 当变量(或者对象)在方法中分配后, 其指针有可能被返回或者被全局引用, 这样就会被其他过程或者线程所引用, 这种现象称作指针(或者引用)的 逃逸(Escape) . 通俗点讲, 如果一个对象的指针被多个方法或者线程引用时, 那么我们就称这个对象的指针发生了逃逸. 2.1. 具体分析逃逸分析研究对于 java 编译器有什么好处呢? 我们知道 java 对象总是在堆中被分配的, 因此 java 对象的创建和回收对系统的开销是很大的. java 语言被批评的一个地方, 也是认为 java 性能慢的一个原因就是 java 不支持栈上分配对象, JDK6里的 Swing 内存和性能消耗的瓶颈就是由于 GC 来遍历引用树并回收内存的, 如果对象的数目比较多, 将给 GC 带来较大的压力, 也间接得影响了性能. 减少临时对象在堆内分配的数量, 无疑是最有效的优化方法. java 中应用里普遍存在一种场景, 一般是在方法体内, 声明了一个局部变量, 并且该变量在方法执行生命周期内未发生逃逸, 按照 JVM 内存分配机制, 首先会在堆内存上创建类的实例(对象), 然后将此对象的引用压入调用栈, 继续执行, 这是 JVM 优化前的方式. 当然, 我们可以采用逃逸分析对 JVM 进行优化, 即针对栈的重新分配方式, 首先我们需要分析并且找到未逃逸的变量, 将该变量类的实例化内存直接在栈里分配, 无需进入堆, 分配完成之后, 继续调用栈内执行, 最后线程执行结束, 栈空间被回收, 局部变量对象也被回收, 通过这种方式的优化, 与优化前的方案主要区别在于对象的存储介质, 优化前是在堆中, 而优化后的是在栈中, 从而减少了堆中临时对象的分配(较耗时), 最终完成性能的优化. 逃逸分析实际上是 JVM 的一种为优化提供支持的分析手段, 逃逸分析的范围分为两个, 方法逃逸和线程逃逸 2.2.1 方法逃逸 不逃逸出当前方法, 就是说在一个方法内 new 出来的对象, 它的引用没有泄露到这个方法之外123456789101112131415public class Foo &#123; int a; int b; public Foo() &#123; &#125;&#125;public int bar(int a, int b) &#123; Foo foo = new Foo(); foo.a = a; foo.b = b; // foo 对象没有逃逸出 bar 方法, 只在 bar 方法里当做局部变量存在 return foo.a + foo.b;&#125; 在上面的例子中, Foo 对象就没有逃逸出 bar 方法, 只有一个局部 foo 变量引用这个对象, foo 变量既没有被当做返回值, 也没有当做另一个方法的参数. 但其实我们一般写的普通 Java Bean 都会有 getter /setter 1234567891011121314151617public class Foo &#123; int a; int b; public Foo(int a, int b) &#123; this.a = a; this.b = b; &#125; public int getA() &#123; return a; &#125; public int getB() &#123; return b; &#125;&#125; 如果在 bar() 方法里依然给 Foo 实例对象赋值, 那肯定就会调用到 Foo 的成员方法 setA(), setB(), 把局部变量 foo 的 this 作为参数传递给 foo 的成员方法, 这个时候变量 foo 确实逃逸除了 bar 方法, 而 JIT 提供了 方法内联, 在完成方法内联后, 这个参数传递实际上优化掉了. 2.2.2 线程逃逸 不逃逸出当前线程, 指的是实例对象没有被别的类引用到. 该对象的引用赋值到其他对象的字段, 或其他类的静态字段上, 没办法让它进入一个全局可见的范围, 这个时候我们认为该实例没有逃逸出当前线程 12345678910public int bar(int a, int b) &#123; Foo foo = new Foo(); foo.a = a; foo.b = b; return doBar(foo);&#125;public int doBar(Foo foo) &#123; return foo.a + foo.b;&#125; bar() 方法调用了 doBar(), 把 foo 实例作为入参传入了 doBar(), 这个时候认为 foo 逃逸除了 bar 方法, 但是 bar 和 doBar 都在一个类中, 并没有被其他类引用, 我们认为 foo 对象没有逃逸出线程. 2.3. JVM 为逃逸分析所做的优化2.3.1 标量替换 Java 中标量的意思是不能再分割的量, 如基本类型和 Reference 类型, 反之成为聚合量, 如果把一个对象拆开, 将它的成员变量分割成标量, 这个就叫标量替换. 如果逃逸分析发现一个对象不会被外部访问, 并且该对象可以被拆散, 那么经过优化后, 并不直接生成该对象, 而是在栈上创建若干个成员变量, 原本的对象就无需再堆上整体分配空间了. 栈帧内分配对象的行为成为栈上分配, 目的是减少新生代的 GC 频率, 见解提高 JVM 性能, 通过 -XX+EliminateAllcations 可以开启标量替换. 2.3.2 锁消除优化 Java 方法中返回值如果没有被其他类用到, 那这个对象就不会逃逸出线程, 我们知道变量的读写竞争的时候需要加锁访问, 如果确定该变量不会逃逸出该线程, 那同步访问控制就可以优化掉. 2.4 实操12345678910111213141516171819public class User &#123; private Sting name; private int age; // getters / setters / constructors&#125;public int bar(Foo foo) &#123; User user = new User(23); return foo.getA() + foo.getB() + user.getAge();&#125;public static void main(String[] args) &#123; Foo foo = new Foo(); for(int i = 0; i &lt; 1000000000; ++i) &#123; foo.setA(4); foo.setB(45); &#125;&#125; 2.4.1 关闭逃逸分析启动 JVM 参数 -server -XX:-DoEscapeAnalysis 使用 jmap -histo 2.4.2 打开逃逸分析JVM 参数 -server -XX:+DoEscapeAnalysis 可以看到, 只有少量的对象在堆上实例化, 大部分对象的属性被标量替换了. 3. JIT 编译在 JVM 中触发 JIT 编译是基于两个计数器: 一个方法被调用的次数 存在有分支的方法中的循环次数, 如果方法里面有一个很长的循环, 这时候需要编译到这个循环, 每一次分支的循环被调用, 该分支的计数器都会增加 增加 -XX:+PrintCompileation 参数观察 JVM 输出的编译日志 - 96 1 3 java.lang.String::equals (81 bytes) 96 4 3 java.io.UnixFileSystem::normalize (75 bytes) 97 9 3 java.lang.String::hashCode (55 bytes) 97 8 3 java.lang.Object::&lt;init&gt; (1 bytes) 97 7 3 java.lang.AbstractStringBuilder::ensureCapacityInternal (16 bytes) 98 3 3 java.lang.String::length (6 bytes) 98 10 3 java.lang.Math::min (11 bytes) 98 2 3 java.lang.System::getSecurityManager (4 bytes) 98 6 3 java.util.Arrays::copyOf (19 bytes) 98 11 n 0 java.lang.System::arraycopy (native) (static) 98 12 3 java.lang.String::indexOf (70 bytes) 98 15 3 sun.nio.cs.UTF_8$Encoder::encode (359 bytes) 99 13 4 java.lang.String::charAt (29 bytes) 99 16 3 java.lang.String::lastIndexOf (52 bytes) 99 5 3 java.util.HashMap::hash (20 bytes) 100 18 3 java.lang.String::&lt;init&gt; (82 bytes) 100 14 3 java.lang.StringBuilder::toString (17 bytes) 100 19 3 java.lang.String::startsWith (72 bytes) 100 20 1 java.util.ArrayList::size (5 bytes) 100 17 1 java.lang.ref.Reference::get (5 bytes) 101 21 1 sun.instrument.TransformerManager::getSnapshotTransformerList (5 bytes) 101 22 3 java.lang.String::startsWith (7 bytes) 101 23 3 java.lang.String::indexOf (166 bytes) 102 26 1 java.lang.Object::&lt;init&gt; (1 bytes) 102 8 3 java.lang.Object::&lt;init&gt; (1 bytes) made not entrant 102 30 3 org.destiny.demo.Foo::setA (6 bytes) 102 31 3 org.destiny.demo.Foo::setB (6 bytes) 102 32 3 org.destiny.demo.User::bar (25 bytes) 102 33 3 org.destiny.demo.User::&lt;init&gt; (10 bytes) 103 34 1 org.destiny.demo.Foo::setA (6 bytes) 103 30 3 org.destiny.demo.Foo::setA (6 bytes) made not entrant 103 35 1 org.destiny.demo.Foo::setB (6 bytes) 103 31 3 org.destiny.demo.Foo::setB (6 bytes) made not entrant 103 27 1 org.destiny.demo.Foo::getA (5 bytes) 103 28 1 org.destiny.demo.Foo::getB (5 bytes) 103 29 1 org.destiny.demo.User::getAge (5 bytes) 103 24 3 java.lang.String::endsWith (17 bytes) 103 36 4 org.destiny.demo.User::bar (25 bytes) 103 25 3 java.lang.ref.SoftReference::get (29 bytes) 104 32 3 org.destiny.demo.User::bar (25 bytes) made not entrant 104 37 1 java.lang.ThreadLocal::access$400 (5 bytes) 106 38 3 java.lang.String::indexOf (7 bytes) 106 39 3 java.lang.Character::toLowerCase (9 bytes) 106 40 3 java.lang.CharacterDataLatin1::toLowerCase (39 bytes) 108 41 % 3 org.destiny.demo.User::main @ 18 (48 bytes) 108 42 3 org.destiny.demo.User::main (48 bytes) 109 43 % 4 org.destiny.demo.User::main @ 18 (48 bytes) 112 41 % 3 org.destiny.demo.User::main @ -2 (48 bytes) made not entrant 150 43 % 4 org.destiny.demo.User::main @ -2 (48 bytes) made not entrant 编译日志分为 7 列, 依次是 时间(基于 JVM 启动的时间戳) 编译任务 id(基本递增) 编译属性 tiered_level(分为 4 级) 方法信息 占用字节数 deopt 其中, 编译属性 attribute 分为: 属性值 属性描述 % The compilation is OSR s The method is synchronized ! The method has an exception handler b Compliation occurred in blocking mode n Compliation occurred for a wrapper to a native method tiered_level: 值 描述 0 Interpreted Code 1 Simple C1 Compiled Code 2 Limited C1 Compiled Code 3 Full C1 Compiled Code 4 C2 Compile Code]]></content>
      <categories>
        <category>JVM</category>
        <category>逃逸分析</category>
      </categories>
      <tags>
        <tag>逃逸分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务总结]]></title>
    <url>%2Fblog%2F2018%2F09%2F02%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1. 定义事务能够提供一种将一个活动涉及到的所有操作纳入到一个不可分割的执行单元的机制. 组成事务的操作只有在操作均能正常执行的情况下才能提交, 只要其中任意一步执行失败, 都将导致整个操作回滚. 2. 数据库本地事务2.1 ACID 特性 描述 原子性 一个事务的所有操作, 要么全部完成, 要么全部不完成, 不会结束在中间某个环节 一致性 在一个事务执行之前和执行之后, 数据库必须保持处于一致的状态. 如果事务成功执行, 系统中所有的变化都将正确地被应用, 反之, 所有变化都将被回滚 隔离性 当不同的事务操作相同的数据的时候, 每个事务都有各自的完整数据空间, 由事务所做的修改必须与任何其他事务所做的修改隔离, 事务不会看到数据的中间状态. 持久性 只要事务成功结束, 它对数据库所做的更新就必须永久保存下来 而事务的 ACID 是通过 InnoDB 日志和锁来保证. 事务的隔离性是通过数据库锁的机制来实现; 持久性是通过 redo log(重做日志) 来实现的 原子性和一致性是通过 undo log(回滚日志) Undo log: 为了满足事务的原子性, 在操作任何数据之前, 首先将数据备份到一个地方, 然后对数据进行修改, 如果出现了错误, 或者用户执行 RollBack, 系统可以利用 Undo log 中的备份将数据恢复到事务开始之前的状态 Redo log: 记录新数据的备份, 在事务提交之前, 只要将 Redo log 持久化即可, 当系统崩溃时, 虽然数据没有持久化, 但是 Redo log 已经持久化, 系统可以根据 Redo log 的内容, 将所有数据恢复到最新状态. 3. 分布式事务3.1 分布式事务概念指事物的参与者, 支持事务的服务器, 资源服务器以及事务管理器分别位于不同的分布式系统之上. 本质上讲, 分布式事务就是为了保证不同数据库的数据一致性. 3.2 场景3.2.1 service 多个节点 随着互联网快速发展, SOA, 微服务等架构模式正在被大规模使用, 一个公司内, 用户的资产可能被分为好多个部分, 比如余额, 积分, 优惠券等 这样的话传统的单机事务实现方式无法保证积分扣减成功之后, 优惠券也能正确完成扣减操作. 3.2.2 resource 多个节点 同样, 由于单表数据过大需要进行拆分, 一次转账业务需要在北京的 MySQL 实例向 上海的 MySQL 实例转账, 同样无法保证他们能同时成功. 3.3 分布式事务基础3.3.1 CAP C: 对某个执行的客户端来说, 读操作能返回最新的写操作. 对于数据分布在不同节点上的数据来说, 如果在某个节点更新了数据, 那么在其他节点都能读取到最新的数据, 那么就成为强一致, 反之就是分布式不一致; A: 非故障的节点在一定时间内返回合理的响应(不是错误或超时), 可用性的关键在于: 合理的时间 和 合理的响应, 请求不能无限期得不到响应, 并且需要得到系统正确的返回结果; P: 当出现网络分区后, 系统依然能够正常工作. 在分布式系统中, 网络永远无法 100% 可靠, 分区是一个一定会出现的情况, 如果我们选择 AC 而放弃 P, 当分区发生时, 为了保证一致性, 这个时候必须拒绝请求, 当时 A 又不允许拒绝, 所以分布式系统理论上不可能选择 CA 架构, 只能选择 CP 或者 AP 架构. 对于 CP 来说, 放弃可用性, 追求一致性和分区容错性, 比如 Zookeeper 就是追求强一致. 对于 AP 来说, 放弃一致性(强一致), 追求分区容错和可用, 这是很多分布式系统的选择. CAP 是忽略网络延迟的, 也就是当事务提交时, 从节点 A 复制到节点 B, 但是在现实中总会有一定的时间延迟. 3.3.2 BASE基本可用, 软状态, 最终一致性的缩写 本质上是 AP 的一个扩张, 通过软状态实现基本可用和最终一致性. BA: 基本可用, 分布式系统出现故障时, 允许损失部分可用功能, 保证核心功能可用; 软状态: 允许系统中存在中间状态, 这个状态不影响系统可用性, 这里指的是 CAP 中的不一致; 最终一致性: 经过一段时间后, 所有节点数据都将达到一致. 4. 分布式事务的解决方案4.1 是否真的需要分布式事务首先要明确是否真的需要分布式事务? 是否存在由于服务拆分过细导致不合理的分布式系统设计? 可以先考虑将多个微服务聚合成一个单机服务, 避免引入不必要的成本和复杂度. 4.2 2PC 第一阶段: 事务管理器要求每个涉及到事务的数据库预提交此操作, 并反映是否可以提交 第二节点: 事务协调器要求每个数据库提交数据, 或者回滚 优点: 保证数据强一致, 实现简单; 缺点: 事务管理器存在单机风险; 整个过程存在同步阻塞; 数据可能不一致; 不支持高并发. 4.3 TCC相比 2PC, 解决了以下问题 解决了协调者单点, 引入集群 引入超时, 超时后进行补偿, 并且不会锁定整个资源, 将资源转换为业务逻辑形式 数据一致性, 有了补偿机制后, 由业务管理其控制一致性 Try 阶段: 尝试执行, 完成所有业务检查(一致性), 预留必须业务资源(准隔离性) Confirm 阶段: 确认执行真正的业务, 不做任何业务检查, 只使用 Try 阶段预留的业务资源, Confirm 操作满足幂等性. 要求具备幂等设计, Confirm 失败后需要进行重试. Cancel 阶段: 取消执行, 释放 Try 阶段预留的业务资源, 也需要满足幂等性. 4.4 本地消息表将需要分布式处理的任务通过消息日至的方式来异步执行 消息日志可以存储到本地文本, 数据库或者消息队列, 再通过业务规则或人工发起重试, 人工重试更多应用于支付系统 举一个购物的例子 当账户扣款的时候, 需要在扣款相关的服务上新增一个本地消息表, 需要把记录扣款和写入扣减商品库存的本地消息表放入同一个事务. 有个定时任务去轮询本地事务表, 把没有发送的消息扔给商品服务, 让它扣减库存, 到达商品服务后, 先写入这个服务器的事务表, 再进行扣减, 扣减成功后, 更新事务表中的状态; 商品服务器通过定时任务扫描消息表或者直接通过扣款服务吗扣款服务本地消息表进行更新; 针对特定情况, 定时扫描未成功处理的消息, 进行重新发送, 在商品服务收到消息后, 先判断是否是重复消息, 如果已经接受, 再判断是否执行, 如果执行再马上又进行通知事务, 如果未执行, 就需要重新执行需要由业务保证幂等. 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 4.5 MQ 事务还是以转账的模型举例: 1. 先发送消息 如果消息发送成功，但是扣款失败，消费端就会消费此消息，进而向Smith账户加钱。 2. 先扣款 如果扣款成功，发送消息失败，就会出现Bob扣钱了，但是Smith账户未加钱。 3. RocketMQ 的实现 发送 Prepared 消息时，会拿到消息的地址; 执行本地事物; 通过第一阶段拿到的地址去访问消息, 并修改消息的状态. 这样可以保证消息发送消息和本地事务执行成功保持原子性操作. 问题1: 如果步骤 3 失败怎么办RocketMQ会定期扫描消息集群中的事物消息，如果发现了Prepared消息，它会向消息发送端(生产者)确认，Bob的钱到底是减了还是没减呢？ 如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 12345678910111213141516// =============================发送事务消息的一系列准备工作========================================// 未决事务，MQ服务器回查客户端// 也就是上文所说的，当RocketMQ发现`Prepared消息`时，会根据这个Listener实现的策略来决断事务TransactionCheckListener transactionCheckListener = new TransactionCheckListenerImpl();// 构造事务消息的生产者TransactionMQProducer producer = new TransactionMQProducer("groupName");// 设置事务决断处理类producer.setTransactionCheckListener(transactionCheckListener);// 本地事务的处理逻辑，相当于示例中检查Bob账户并扣钱的逻辑TransactionExecuterImpl tranExecuter = new TransactionExecuterImpl();producer.start()// 构造MSG，省略构造参数Message msg = new Message(......);// 发送消息SendResult sendResult = producer.sendMessageInTransaction(msg, tranExecuter, null);producer.shutdown(); 接着查看 sendMessageInTransaction 方法的源码，总共分为3个阶段：发送 Prepared 消息、执行本地事务、发送确认消息。 1234567891011// ================================事务消息的发送过程=============================================public TransactionSendResult sendMessageInTransaction(.....) &#123; // 逻辑代码，非实际代码 // 1.发送消息 sendResult = this.send(msg); // sendResult.getSendStatus() == SEND_OK // 2.如果消息发送成功，处理与消息关联的本地事务单元 LocalTransactionState localTransactionState = tranExecuter.executeLocalTransactionBranch(msg, arg); // 3.结束事务 this.endTransaction(sendResult, localTransactionState, localException);&#125; endTransaction 方法会将请求发往 broker(mq server) 去更新事务消息的最终状态： 根据 sendResult 找到 Prepared 消息, sendResult 包含事务消息的 ID 根据 localTransaction 更新消息的最终状态 问题2: Consumer 消费失败怎么办如果 Bob 的账户的余额已经减少，且消息已经发送成功，Smith 端开始消费这条消息，这个时候就会出现消费失败和消费超时两个问题. 解决超时问题的思路就是一直重试，直到消费端消费消息成功，整个过程中有可能会出现消息重复的问题，按照前面的思路解决即可。]]></content>
      <categories>
        <category>分布式事务</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现简易JVM]]></title>
    <url>%2Fblog%2F2018%2F06%2F24%2F%E5%AE%9E%E7%8E%B0%E7%AE%80%E6%98%93JVM%2F</url>
    <content type="text"><![CDATA[1. 概述 Java 源代码经过编译生成 class 文件 在不同的操作系统上分别实现 JVM, JVM 在不同操作系统上实现差异很大, 如线程, 图形界面等, 由 JVM 屏蔽与操作系统的接口 1.1 Class 文件格式 1.1.1 魔数 &amp; 版本 &amp; 常量池个数 Magic Number 确定这是一个 Java 文件 Minor / Major Version: 版本号 16 进制 Major Version (0x34) = 52 常量池个数 (0x36) = 54 大端模式(Big-Endian): 高位在前 00 36 而不是 36 00 1.1.2 常量池 0036 代表常量池常量的个数, 后面的 07 通过查表发现含义为 ClassInfo 的 tag 值, 而 name_index 值为 2, 代表类名在第二个常量中. 第二个常量开头为 01, 查表得知是一个 Utf8 字符串, 0021 代表长度 length 值为 33. 而后面 33 个字节 63 6F 6D 2F 63 6F 64 65 72 69 73 69 6E 67 2F 65 78 61 6D 70 6C 65 2F 45 6D 70 6C 6F 79 65 65 56 31 转换成字符串之后的值为 com/coderising/example/EmployeeV1 1234CONSTANT_Class_info &#123; u1 tag; // 值为7 u2 name_index; // 名称索引&#125; 12345CONSTANT_Utf8_info &#123; u1 tag; // 值为1 u2 length; // 长度 u1 bytes[length]; // 内容&#125; 1.1.2.1 常量池实例 索引 类型 操作数 1 操作数 2 含义 #1 ClassInfo #2 #2 Utf8 org/destiny/jvm/model/Employee #3 ClassInfo #4 #4 Utf8 java/lang/Object #5 Utf8 name #6 Utf8 Ljava/lang/String #7 Utf8 age #8 Utf8 I #9 Utf8 #10 Utf8 … #11 Utf8 … #12 MethodRef #3 #13 java.lang.Object&lt;init&gt;()V #13 NameAndType #9 #14 &lt;init&gt;()V #14 Utf8 ()V #15 FieldRef #1 #16 org/destiny/jvm/model/Employee 包含一个 Ljava/lang/String 类型的变量 name #16 NameAndType #5 #6 Ljava/lang/String 类型的变量 name 1.1.3 访问标志 标志名称 标志值 含义 ACC_PUBLIC 0x0001 public 类型 ACC_FINAL 0x0002 声明为 final 类型 ACC_SUPER 0x0020 是否允许使用 invokespecial 字节码指令的新语义 ACC_INTERFACE 0x0200 声明为接口 ACC_ABSTRACT 0x0400 Abstract 类型 ACC_SYNTHETIC 0x1000 这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 注解 ACC_ENUM 0x4000 枚举 1.1.4 类索引, 父类索引类索引和父类索引都是指向常量池的索引 由于 Java 采用动态连接 动态连接是一个将符号引用解析为直接引用的过程。当java虚拟机执行字节码时，如果它遇到一个操作码，这个操作码第一次使用一个指向另一个类的符号引用 那么虚拟机就必须解析这个符号引用。在解析时，虚拟机执行两个基本任务 查找被引用的类，（如果必要的话就装载它） 将符号引用替换为直接引用，这样当它以后再次遇到相同的引用时，它就可以立即使用这个直接引用，而不必花时间再次解析这个符号引用了。 1.1.5 接口1.1.6 字段123456789u2 fields_count; // 字段数量field_info &#123; u2 access_flags; // 访问控制符 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attribute_count; // 该字段的属性数量 attribute_info attributes[attribute_count]; // 属性信息&#125; 标志字符含义 header 1 header 2 B byte C char D double F float I int J long S short Z boolean V void L 对象类型的通用前缀, 如 Ljava/lang/Object 1.1.7 方法123456789u2 methods_count; // 方法数量method_info &#123; u2 access_flags; // 访问标志 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attributes_count; // 该字段的属性数量 attribute_info attributes[attributes_count]; // 属性信息&#125; (Ljava/lang/String;)V 表示 参数为 String, 返回值为 void 的方法(Ljava/lang/String;IF)V 表示 参数为 String, int, float, 返回值为 void 的方法 1.1.8 属性 方法和字段都可能有属性 方法中可能有 Code 属性, 字段可能有 Constant Value 属性 属性中可能嵌套属性 code 属性中还可能有 Line Number Table, Local Variable Table, Stack Map Table 等属性 虚拟机的实现中还可以自定义属性 1.1.8.1 Constant Value如果某字段为静态类型(access_flag 中包含 ACC_STATIC 标志) 将会被分配 Constant Value 属性 12345ConstantValue_attribute &#123; u2 attribute_name_index; // 必须是对常量池的一个有效索引, 常量池在该索引处的项必须是 UTF8Info, 表示字符串 "ConstantValue" u4 attribute_length; // 固定为 2 u2 constantvalue_index; // 必须是对常量池的一个有效索引, 常量池在该索引处的项给出该属性表示的常量值, 可能的值有 Constant_String, Constant_Long 等&#125; 1.1.8.2 Code1234567891011121314151617Code_attribute &#123; u2 attribute_name_index; // 指向常量池, 应该是 UTF8Info, 且值为 "Code" u4 attribute_length; // 属性长度, 不包括开始的 6 个字节 u2 max_stack; // 操作数栈的最大深度 u2 max_locals; // 最大局部变量表个数 u4 code_length; // 该方法的代码长度 u1 code[code_length]; // 真正的字节码 u2 exception_table_length; // 捕获异常表的长度 &#123; u2 start_pc; // 捕获起始地址 u2 end_pc; // 捕获结束地址 u2 handler_pc; // u2 catch_type; // 异常类型 &#125; exception_table[exception_table_length]; // 捕获异常表 u2 attributes_count; // attribute_info attributes[attributes_count];&#125; Code 属性中的字节码 字节码 命令 含义 2A aload_0 从局部变量表第 0 个值压入操作数栈 B4 00 15 getfield #21 获取对象的字段值 10 1E bipush 30 将 30 压入栈中 A2 00 0E if_icmp_ge 20 将当前 1.1.8.3 LineNumbercode属性的一个子属性 可选的变长属性, 维护 Java 源代码行号与字节码行号(偏移量之间的对应关系) 123456789LineNumberTable_attribute &#123; u2 attribute_name_index; u4 attribute_length; u2 line_number_table_length; &#123; u2 start_pc; // 字节码偏移量 u2 line_number; // 行号 &#125; line_number_table[line_number_table_length];&#125; 1.1.8.4 LocalVariableTable 属性code属性的一个子属性 可选的变长属性, 维护栈帧中局部变量表中变量与 Java 源码中定义变量的关系 123456789101112LocalVariableTable_attribute &#123; u2 attribute_name_index; u4 attribute_length; u2 local_variable_table_length; &#123; u2 start_pc; // 局部变量位于 [start_pc, start_pc + length)之间 u2 length; u2 name_index; // 局部变量的名称索引 u2 descriptor_index; // 局部变量的描述符索引 u2 index; // 局部变量在栈帧中的索引 &#125; local_variable_table[local_variable_table_length];&#125; 1.2 JVM 运行时动态行为 线程中包含函数栈帧, 其中每个函数帧表示某一个函数的调用过程 在每一个函数帧的内部, JVM 又细分了 局部变量表, 操作数栈 等 局部变量和操作数栈中的变量会引用堆中的对象 常量池引用指向方法区, 方法区保存了类的元数据以及方法的字节码 1.2.1 实例Java 源码:123456789public class Test &#123; void add(int i, int j) &#123; int num = i + j; &#125; void demo() &#123; add(10, 20); &#125;&#125; 转换成字节码后:12345678910111213demo:0: aload_01: bipush 103: bipush 205: invokevirtial #28: returnadd:0: aload_11: aload_22: iadd3: istore_34: return 调用 add 函数, 生成新的函数帧 0: aload_1: 将局部变量表第 1 个变量压入操作数栈;1: aload_2: 将局部变量表第 2 个变量压入操作数栈;2: iadd: 将操作数栈顶端的两个元素弹出, 相加并将结果压入栈顶3: istore_3: 将操作数栈栈顶元素放在局部变量表第 3 个元素中4: return: 执行完毕 2. ClassLoader2.1 Java 是动态链接 C: 编译 -&gt; 链接 -&gt; 生成 .exe -&gt; 执行 函数 A 调用函数 B, 在链接时会直接在函数 A 中记录函数 B 的地址 Java: 编译 -&gt; .class -&gt; 装载执行 类 A 中使用了另一个类 B, 在 A.class 中只保存类 B 的名称, 而不会保留 B 的 “地址” 在运行时根据名称来查找类, 装载类 2.2 类加载器的委托模型 工作原理 2.3 类加载器的命名空间 类加载器 + 类名 唯一确定一个类, 只有同一个加载器加载的类才是相同的类. 2.4 验证 2.5 自定义类加载器12345678910111213141516171819202122232425262728293031public class MyClassLoader extends ClassLoader &#123; private List&lt;String&gt; classPaths = new LinkedList&lt;&gt;(); protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] byteCodes = loadByteCode(name); if (byteCodes == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, byteCodes, 0, byteCodes.length); &#125; &#125; private byte[] loadClassFile(String classFileName) &#123; for (String classPath: classPaths) &#123; String realPath = classPath + File.separatorChar + classFileName.replace('.', File.separatorChar) + ".class"; File file = new File(classFileName); if (file.exists()) &#123; try &#123; return IOUtils.toByteArray(new FileInputStream(file)); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125;&#125; DefineClass 方法 protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int length) throws ClassFormatError; 只要传递给该方法一个合法字节数组, 就可以转化成一个 Class 对象, 这就意味着可以从任何地方组装类: 磁盘 zip 文件 网络 运行时动态生成 3. 常量池3.1 常见结构 123456789101112131415161718192021222324252627282930313233CONSTANT_Class_info &#123; u1 tag; // 7 u2 name_index; &#125;CONSTANT_Utf8_info &#123; u1 tag; // 1 u2 length; // 长度 u1 bytes[length]; // content&#125;CONSTANT_String_info &#123; u1 tag; // u2 string_index;&#125;CONSTANT_Fieldref_info &#123; u1 tag; // 9 u2 class_index; // u2 name_and_type_index;&#125;CONSTANT_Methodref_info &#123; u1 tag; // 10 u2 class_index; u2 name_and_type_index;&#125;CONSTANT_NameAndType_info &#123; u1 tag; // 12 u2 class_index; u2 descriptor_index;&#125; 3.2 访问标志 标志名称 标志值 含义 ACC_PUBLIC 0x0001 public 类型 ACC_FINAL 0x0002 声明为 final 类型 ACC_SUPER 0x0020 是否允许使用 invokespecial 字节码指令的新语义 ACC_INTERFACE 0x0200 声明为接口 ACC_ABSTRACT 0x0400 Abstract 类型 ACC_SYNTHETIC 0x1000 这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 注解 ACC_ENUM 0x4000 枚举 4. 字段 &amp; 方法4.1 字段123456789u2 fields_count; // 字段数量field_info &#123; u2 access_flags; // 访问控制符 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attribute_count; // 该字段的属性数量 attribute_info attributes[attribute_count]; // 属性信息&#125; 可以看到上图中有两个字段, 分别为 String 类型的 name, 和 int 类型的 age Name Index 表示常量池中变量名称的索引 Desc Index 表示常量池中变量类型的索引 4.2 方法123456789u2 methods_count; // 方法数量method_info &#123; u2 access_flags; // 访问标志 u2 name_index; // 指向常量池的入口 u2 descriptor_index; // 指向常量池的入口 u2 attributes_count; // 该字段的属性数量 attribute_info attributes[attributes_count]; // 属性信息&#125; 以第一个方法为例: Name Index 表示方法名称为 &lt;init&gt;, 即构造方法 Desc Index 表示方法签名为 (Ljava/lang/String;I)V, 即 (String, int):void 4.3 属性4.3.1 Code 属性1234567891011121314151617Code_attribute &#123; u2 attribute_name_index; // 指向常量池, 应该是 UTF8Info, 且值为 "Code" u4 attribute_length; // 属性长度, 不包括开始的 6 个字节 u2 max_stack; // 操作数栈的最大深度 u2 max_locals; // 最大局部变量表个数 u4 code_length; // 该方法的代码长度 u1 code[code_length]; // 真正的字节码 u2 exception_table_length; // 捕获异常表的长度 &#123; u2 start_pc; // 捕获起始地址 u2 end_pc; // 捕获结束地址 u2 handler_pc; // u2 catch_type; // 异常类型 &#125; exception_table[exception_table_length]; // 捕获异常表 u2 attributes_count; // 嵌套属性数量 attribute_info attributes[attributes_count]; // 嵌套属性&#125; code 属性一般由两个常见的子属性, 分别是: LineNumberTable LocalVariableTable 4.3.2 LocalLineTable通过该属性可以完成字节码与 Java 源码的行号映射 可以在 debug 的时候准确找到源码 并且抛出异常的时候堆栈信息可以找到对应行号 12345678910LineNumberTable_arrtibute &#123; u2 attribute_name_index; // 指向常量池, 必须是值为 "LineNumberTable" 的 Utf8 常量 u4 arrtibute_length; // 当前属性长度, 不包括开始的 6 个字节 u2 line_number_table_length; // line_number_table 数组元素个数 &#123; u2 start_pc; // start_pc 值必须是 code[] 数组的一个索引 u2 line_number; // 源文件的行号 &#125; line_number_table[line_number_table_length];&#125; 4.3.3 LocalVariableTableLocalVariableTable 属性建立了方法中的局部变量与源代码中的局部变量之间的对应关系。 每个 LocalVariableTable 的 local_variable_table 部分可以看做是一个数组， 每个数组项是一个叫做local_variable_info的结构， 该结构描述了某个局部变量的变量名和描述符， 还有和源代码的对应关系。 下面讲解 local_variable_info 的各个部分： start_pc 是当前 local_variable_info 所对应的局部变量的作用域的起始字节码偏移量； length 是当前 local_variable_info 所对应的局部变量的作用域的大小。 也就是从字节码偏移量 start_pc 到 start_pc+length 就是当前局部变量的作用域范围； name_index 指向常量池中的一个 CONSTANT_Utf8_info ， 该 CONSTANT_Utf8_info 描述了当前局部变量的变量名； descriptor_index 指向常量池中的一个 CONSTANT_Utf8_info ， 该 CONSTANT_Utf8_info 描述了当前局部变量的描述符； index 描述了在该方法被执行时，当前局部变量在栈中局部变量表中的位置。 由此可知， 方法中的每个局部变量都会对应一个local_variable_info 。 12345678910111213LocalVariableTable_attribute &#123; u2 attribute_name_index; // 指向常量池, 必须是值为 "LocalVariableTable_attribute" 的 Utf8 常量 u4 attribute_length; // 当前属性长度, 不包括开始的 6 个字节 u2 local_variable_table_length; // local_variable_table[] 的元素个数 &#123; u2 start_pc; // 局部变量的索引都在范围 [start_pc, start_pc + length) u2 length; u2 name_index; // 变量名索引, 在常量池中 u2 descriptor_index; // 变量描述索引(在常量池中) u2 index; // 此局部变量在当前栈帧的局部变量表中的索引 &#125; local_variable_table[local_variable_table_length]&#125; 解析以上字节码得到: start pc length slot name descript 0 15 0 this Lorg/destiny/jvm/model/Employee 0 15 1 name Ljava/lang/String 0 15 2 age I 在解析 code 属性时需要注意的两点: code 属性中包含了方法真正的字节码 code 属性中包含几个子属性, 包括 LineNumberTable, LocalVariableTable等, 也需要进行解析. 在 Field, Method, Attribute 三者中, 我们可以抽象出如下的关系: 4.3.4 Exceptions如果代码中出现了try{}catch{}块,那么try{}块内的机器指令的地址范围记录下来, 并且记录对应的catch{}块中的起始机器指令地址. 当运行时在try块中有异常抛出的话, JVM会将catch{}块对应懂得其实机器指令地址传递给PC寄存器，从而实现指令跳转. 1234567u2 exception_table_length; // 捕获异常表的长度&#123; u2 start_pc; // 捕获起始地址 u2 end_pc; // 捕获结束地址 u2 handler_pc; // u2 catch_type; // 异常类型&#125; exception_table[exception_table_length]; // 捕获异常表 exception_table 记录了该 code 属性中所有显示抛出的异常信心, 包括异常的作用于及类型. 5. 字节码指令5.1 main 方法字节码Employee 的 main 方法:1234public static final main(String[] args) &#123; Employee employee = new Employee("destiny", 24); employee.sayHello();&#125; 经过编译后的字节码: 5.1.1 newnew indexbyte1 indexbyte2 操作: 创建一个对象 (indexbyte1 &lt;&lt; 8) | indexbyte2 得到一个指向常量池的索引 BB 00 01 对应 new #1, 对应的类就是 org/destiny/jvm/model/Employee 在堆中创建一个新对象 将该对象的引用压入栈中 5.1.2 dup 操作: 复制操作数栈栈顶的值, 并压入栈中 5.1.3 ldcldc index 操作: 从运行时常量池中提取数据压入栈中 ldc #43, 43 在常量池中的值为字符串 destiny 5.1.4 bipushbipush byte 将有符号 byte 扩展为一个 int 类型的值 value, 然后将 value 压入到操作数栈中. byte 是一个立即数而非常量池引用 5.1.5 invokespecial indexbyte1 indexbyte2 操作: 对一个对象进行初始化, 父类的初始化, 调用私有方法(因为没有多态性为) (indexbyte1 &lt;&lt; 8) | indexbyte2 得到一个指向常量池的索引 invokespecial #45 常量池 #45 是一个 methodref: &lt;init&gt;:(Ljava/lang/String;I)V 需要形成新的栈帧 5.1.6 astore_n 操作: 将栈顶的 reference 类型数据保存到局部变量表中 astore_0 astore_1 astore_2 astore_3 5.1.7 aload_n 操作: 从局部变量表中加载一个 reference 类型的值到操作数栈中 aload_0 aload_1 aload_2 aload_3 5.1.8 invokevirtual indexbyte1 indexbyte2 操作: 调用实例方法, 依据实例的具体类型进行分派(多态) (indexbyte1 &lt;&lt; 8) | indexbyte2 invokevirtual #47 =&gt; sayHello: ()V 也需要形成新的栈帧 5.1.9 return 操作: 方法返回, 从当前函数栈帧退出, 无返回值. 5.2 方法指令1234public Employee(String name, int age) &#123; this.name = name; this.age = age;&#125; 5.2.1 aload_0 操作: 从局部变量表中加载 index 为 0 的 reference 类型的值到操作数栈中 5.2.2 aload_1 5.2.3 putfield indexbyte1 indexbyte2 操作: 给一个对象字段赋值 (indexbyte1 &lt;&lt; 8) | indexbyte2 putfield #15 =&gt; putfield name:Ljava/lang/String 5.3.3 iload_2 操作: 从局部变量中把 index 为 2 的 int 类型的值加载到操作数栈中 reference 类型使用 aload, int 类型使用 iload 5.4 字节码指令的设计实现使用 命令模式 来抽象该场景, 即将所有字节码指令抽象为命令对象, 基类声明 command 方法, 再根据操作数的不同泛化出不同的抽象子类 6 JVM 执行引擎 6.1 Java 命令1java -cp path1;path2 org.destiny.jvm.Employee cp: classpath(s), 默认是当前路径 class name: 系统需要找到这个类的 main 方法, 然后执行它的字节码 6.2 执行过程 加载类 工具: ClassFileLoader 目的地: 方法区 获取类的 public static void main(String[] args) 方法 从方法区寻找 执行 main 方法的字节码 字节码指令 栈帧(StackFrame) 堆(Heap) 6.3 字节码指令的分类 类型 指令 依次执行 newbipushldcdup 暂停当前栈帧并创建新栈帧 invokespecialinvokevirtual 跳转到另一行去执行 if_icmp_geif_icmplegoto 退出当前栈帧 return 7. 垃圾回收机制7.1 Java 对象的内存布局 MarkWord: 标注对象的元信息 GC 年龄 锁的标志位 ClassPointer: 指向方法区的类信息的指针 InstanceData: 类实例对象的数据 方法信息保存在方法区 padding: 填充 7.2 对象分配和垃圾回收 对象优先分配在新生代 如果 Eden 区没有足够的空间, 则触发一次 MinorGC Java 对象大多具有生命周期短暂的特点, MinorGC 非常频繁, 速度也很快 大对象直接进入老年代 可以根据参数设置阈值 长期存活对象进入老年代 每个对象都有一个年龄(age), 在 MarkWord 中 如果 age 超过阈值, 则晋升到老年代 动态年龄判断 如果在 Survivor 空间中相同年龄的所有对象大小的总数和大于 Survivor 空间的一半, 年龄大于或等于该年龄的对象可以直接进入老年代 MinorGC 时 新生代与老年代的关系]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[quartz 入门]]></title>
    <url>%2Fblog%2F2018%2F04%2F25%2Fquartz-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1. 任务调度概述各种企业应用几乎都会碰到任务调度的需求。 在特定的时间点执行指定的操作。 任务调度本身涉及多线程并发、运行时间规则指定和解析、运行现场保持和恢复、线程池维护等诸多方面的问题。 2. Quartz Quartz允许开发人员灵活地定义触发器的调度时间，并可对触发器和任务进行关联映射； Quartz提供了调度运行环境的持久化和保存； Quartz还提供了组件式的侦听器、插件、线程池等功能。 2.1 Quartz基础结构Quartz对任务调度领域的问题进行了高度的抽象，提出了调度器、任务、触发器这3个核心的概念。 2.1.1 Job是一个接口，只有一个方法void execute(JobExecutionContext context)，开发者通过实现该接口来定义需要执行的任务，JobExecutionContext 类提供了调度上下文的各种信息。Job 运行时的信息保存在 JobDataMap 实例中。 2.1.2 JobDetailQuartz 在每次执行 Job 的时候，都重新创建一个 Job 实例，所以它不是直接接收一个 Job 实例，而是接收一个 Job 实现类，以便运行时通过 newInstance() 反射调用机制实例化 Job。因此需要通过一个类来描述 Job 的实现类及其他相关信息，如 Job 名称、描述、关联监听器等信息，而 JobDetail 承担了这一角色。通过该类的构造函数 JobDetail(java.lang.String name, java.lang.String group, java.lang.Class jobClass)，可以更具体地了解它的功能。该构造函数要求指定 Job 的实现类，以及任务在 Schedule 中的组名和 Job 名称。 2.1.3 Trigger描述触发 Job 执行的时间触发规则。主要有 SimpleTrigger 和 CronTrigger 这两个子类。当仅需要触发一次或者以固定间隔周期性执行的时候， SimpleTrigger 是最佳选择；而 CronTrigger 则可以通过 Cron 表达式定义出各种复杂的调度方案，如每天早上 9:00 执行，每周一、周三下午 5:00 执行等。 2.1.4 Calendarorg.quartz.Calendar 和 java.util.Calendar 不同，它是一些日历特定时间点的集合。一个 Trigger 可以和多个 Calendar 关联，以便排除或包含某些时间点。假设安排每周一早晨 10:00 执行任务，但是如果遇到法定节假日不执行任务，这时就需要在 Trigger 触发机制的基础上使用 Calendar 进行定点排除。针对不同的时间段类型，如 AnnualCalendar、MonthlyCalendar、WeeklyCalendar 分别针对每年、每月和每周进行定义。 2.1.5 Scheduler代表一个 Quartz 的独立运行容器，Trigger 和 JobDetail 可以注册到 Scheduler 中，二者在 Scheduler 中拥有各自的组及名称。组及名称是 Scheduler 查找定位容器中某个对象的依据， Trigger 的组及明恒的组合必须唯一， JobDetail 的组及名称的组合也必须唯一（但可以和 Trigger 的组及名称相同，因为二者处在不同的容器中）。Scheduler 定义了多个接口方法，允许外部通过组及名称访问和控制容器中的 Trigger 和 JobDetail。Scheduler 可以将 Trigger 绑定到某一个 JobDetail 中，这样当 Trigger 被触发时，对应的 Job 就会被执行。一个 Job 可以对应多个 Trigger，但一个 Trigger 只能对应一个 Job。可以通过 SchedulerFactory 创建一个 Scheduler 实例。Scheduler 拥有一个 SchedulerContext，保存着 Scheduler 上下文信息，可以对照 ServletContext 来理解 SchedulerContext。 Job 和 Trigger 都可以访问 SchedulerContext 内的信息。SchedulerContext 内部通过一个 Map，以键值对的方式维护这些上下文数据。SchedulerContext 为保存和获取数据提供了多个 put() 和 getXxx() 方法。可以通过 Scheduler#getContext() 方法获取 SchedulerContext 实例。 2.1.6 ThreadPoolSchedule 使用一个线程池作为任务运行的基础设施，任务通过共享线程池中的线程来提高效率。 Job 有一个 StatefulJob 子接口，代表有状态的任务。该接口是一个没有方法的标签接口，其目的是让 Quartz 知道任务类型，以便采取不同的措施。无状态任务在执行时拥有自己的 JobDataMap 复制，对 JobDataMap 的更改不会影响下次执行。而有状态任务共享同一个 JobDataMap 实例，每次任务执行时对 JobDataMap 所做的更改会保存下来。后面的执行可以看到更改。 因此，无状态任务可以并发执行，而有状态任务的 StatefulJob 不能并发执行。如果上一次的 StatefulJob 还没有执行完成，则下次的任务将阻塞等待。有状态任务比无状态任务需要考虑更多的因素，所以尽量避免使用无状态任务。 如果 Quartz 使用了数据库持久化任务调度信息，则无状态的 JobDataMap 仅会在 Scheduler 注册的任务时保存一次，而有状态任务对应的 JobDataMap 在每次执行任务后都会进行保存。 Trigger 自身也可以拥有一个 JobDataMap，其关联的 JobDataMap 可以通过 JobExecutionContext#getTrigger().getJobDataMap() 方法获取。不管是有状态还是无状态的任务，在任务执行期间对 Trigger 的 JobDataMap 所做的更改都不会进行持久化。 Quartz 拥有完善的事件和监听体系，大部分组件都拥有事件，如任务执行前事件、执行后事件、触发器触发前事件、触发器触发后事件、调度器开始事件、调度器关闭事件等。可以注册相应的监听器处理感兴趣的事件。 2.2 SimpleTriggerSimpleTrigger 有多个重载的构造函数，用于在不同场合下构造出对应的实例。 SimpleTrigger(String name, String group)：指定所属组和名称； SimpleTrigger(String name, String group, Date startTime)：指定触发的开始时间； SimpleTrigger(String name, String group, Date startTime, Date endTime, int repeatCount, long repeatInterval)：指定开始时间、结束时间、重复执行次数、时间间隔； SimpleTrigger(String name, String group, String jobName, String jobGroup, Date startTime, Date endTime, int repeatCount, long repeatInterval)：最复杂的一个构造函数，通过 jobName 和 jobGroup，使该 Trigger 和 Scheduler 中的某个任务关联起来。 2.2.1 代码实例 2.2.1.1 SimpleJob123456public class SimpleJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(jobExecutionContext.getTrigger().getName() + " triggered. time is:" + System.currentTimeMillis()); &#125;&#125; 2.2.1.2 SimpleTriggerRunner12345678910111213141516171819202122232425262728293031public class SimpleTriggerRunner &#123; public static void main(String[] args) &#123; try &#123; // 创建一个 JobDetail 实例，指定 SimpleJob JobDetail jobDetail = JobBuilder.newJob(SimpleJob.class) .withIdentity("jName", "jGroup") .build(); // 通过 SimpleTrigger 定义调度规则：【立即启动】、【每2秒运行一次】、【用运行10次】 SimpleTrigger simpleTrigger = TriggerBuilder.newTrigger() .withIdentity("tName", "tGroup") .startNow() .withSchedule( SimpleScheduleBuilder.simpleSchedule() .withIntervalInSeconds(2) // 调度间隔 .withRepeatCount(10) // 调度次数 ).build(); // 通过 SchedulerFactory 获取一个调度器实例 SchedulerFactory factory = new StdSchedulerFactory(); Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, simpleTrigger); scheduler.start(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.2.1.3 运行结果tName1 triggered. time is:1524563336613 tName1 triggered. time is:1524563338522 tName1 triggered. time is:1524563340522 tName1 triggered. time is:1524563342524 tName1 triggered. time is:1524563344523 tName1 triggered. time is:1524563346523 tName1 triggered. time is:1524563348523 tName1 triggered. time is:1524563350524 tName1 triggered. time is:1524563352524 tName1 triggered. time is:1524563354524 tName1 triggered. time is:1524563356523 2.3 使用 CronTriggerCronTrigger 能够提供比 SimpleTrigger 更有实际意义的调度方案，调度规则基于 Cron表达式。 CronTrigger 支持日历相关的周期性时间间隔（比如每月第一个周一执行），而不是简单的周期时间间隔。 2.3.1 Cron 表达式Quartz 使用类似 Linux 下的 Cron 表达式定义时间规则。Cron 表达式由 6 或 7 个空格分割的时间字段组成。 位置 时间域名 允许值 允许的特殊字符 1 秒 [0, 60) ,-*/ 2 分钟 [0, 60) ,-*/ 3 小时 [1, 24) ,-*/ 4 日期 [1, 32) ,-*?/LWC 5 月份 [1, 13) ,-*/ 6 星期 [1, 8) ,-*/LC?# 7 年（可选） 空值 或 [1970, 2100) ,-*/ 特殊字符： 特殊字符 作用 * 表示对应时间域的每一个时刻，如 * 在分钟时段就表示每分钟 ? 只能在日期和星期中使用，占位符，无意义 - 表达范围，如在小时中使用 10-12，表示从 10 点到 12 点 , 列表纸，如在星期中使用 MON,WED,FRI，表示周一、周三、周五 / x/y 表示等步长序列，x 为起始值，y 为增量步长，如在分钟中使用 0/15，表示0、15、30、45秒 L 只能在日期和星期中使用，代表 Last 的意思，日期中表示当月最后一天，星期表示周六 W 只能出现在日期中，是对前导日期的修饰，表示里该日期最近的工作日 LW 只能出现在日期中，表示当月最后一个工作日 # 只能在星期字段中使用，表示当月的某个工作日，6#3表示当月第三个周五，4#5 表示当月第五个周三，如果不存在则不触发 C 只能在日期和星期中使用，Calendar，表示计划所关联的日期。5C 在日期中相当于 5日之后的那一天，1C 在星期中相当于 周天后的那一天 示例 表达式 说明 0 0 12 * * ? 每天 12:00 运行 0 15 10 ? * * 每天 10:15 运行 0 15 10 * * ? 每天 10:15 运行 0 15 10 * * ? * 每天 10:15 运行 0 15 10 * * ? 2008 在 2008 年的每天 10:15 运行 0 * 14 * * ? 每天 14 点到 15 点每分钟运行一次，开始于 14:00，结束于 14:59 0 0/5 14 * * ? 每天 14 点到 15 点每 5 分钟运行一次，开始于 14:00，结束语 14:55 0 0/5 14,18 * * ? 每天 14 点到 15 点每 5 分钟运行一次，此外每天 18 点到 19 点每 5 分钟也运行一次 0 10,44 14 ? 3 WED 3 月的每周三的 14:10 到 14:44，每分钟运行一次 0 15 10 ? * MON-FRI 每个工作日的 10:15 运行一次 0 15 10 15 * ? 每月 15 日的 10:15 运行一次 0 15 10 L * ? 每月最后一天的 10:15 运行一次 0 15 10 ? * 6L 每月的最后一个周五的 10:15 运行一次 0 15 10 ? * 6L 2014-2016 2014、2015、2016 年每个月的最后一个周五的 10:15 运行 0 15 10 ? * 6#3 每月第三个周五的 10: 15 运行 2.3.2 示例123456789101112131415161718192021222324public class CronTriggerRunner &#123; public static void main(String[] args) &#123; try &#123; JobDetail jobDetail = new JobDetail("jName1", "jGroup1", SimpleJob.class); // 创建 CronTrigger 指定组及名称 CronTrigger cronTrigger = new CronTrigger("tName1", "tGroup1"); // 新建并设置 Cron 表达式：从每分钟的 0 秒开始，每隔5秒触发一次 CronExpression cronExpression = new CronExpression("0/5 * * * * ?"); cronTrigger.setCronExpression(cronExpression); SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, cronTrigger); scheduler.start(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.3 运行结果tName1 triggered. time is:1524645830011 tName1 triggered. time is:1524645835006 tName1 triggered. time is:1524645840006 tName1 triggered. time is:1524645845002 tName1 triggered. time is:1524645850003 tName1 triggered. time is:1524645855004 tName1 triggered. time is:1524645860003 tName1 triggered. time is:1524645865003 tName1 triggered. time is:1524645870005 tName1 triggered. time is:1524645875006 tName1 triggered. time is:1524645880000 tName1 triggered. time is:1524645885000 tName1 triggered. time is:1524645890007 tName1 triggered. time is:1524645895005 tName1 triggered. time is:1524645900005 由于打印的时间是以毫秒作为单位的，因此可以看毫秒数的倒数第4位，都是以 5 作为步长的。 2.4 Calendar在实际任务调度中，不可能一成不变地按照某个特定周期调度任务，必须考虑到现实生活中日历上的特殊日期。 下面的例子中，该任务每小时运行一次，并将 五一劳动节 和 国庆节 排除在外 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142public class CalendarExample &#123; public static void main(String[] args) throws SchedulerException &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); // 法定节日是以年作为周期的，所以使用 AnnualCalendar AnnualCalendar holidays = new AnnualCalendar(); // 五一劳动节 Calendar laborDay = new GregorianCalendar(); laborDay.add(Calendar.MONTH, 5); laborDay.add(Calendar.DATE, 1); // 国庆节 Calendar nationalDay = new GregorianCalendar(); nationalDay.add(Calendar.MONTH, 10); nationalDay.add(Calendar.DATE, 1); ArrayList&lt;Calendar&gt; calendarList = new ArrayList&lt;&gt;(); calendarList.add(laborDay); calendarList.add(nationalDay); // 排除这两个日期 holidays.setDaysExcluded(calendarList); // 向 Scheduler 注册日历 scheduler.addCalendar("holidays", holidays, false, false); // 4月1日上午10点 Date runDate = TriggerUtils.getDateOf(0, 0, 10, 1, 4); JobDetail jobDetail = new JobDetail("jName1", "jGroup1", SimpleJob.class); SimpleTrigger trigger = new SimpleTrigger( "tName1", "tGroup1", runDate, null, SimpleTrigger.REPEAT_INDEFINITELY, 60L * 60L * 1000L); // 让 Trigger 应用指定的日历规则 trigger.setCalendarName("holidays"); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); &#125; &#125; 2.5 任务调度信息存储在默认情况下，Quartz 将任务调度的运行信息保存在内存中。这种方法提供了最佳的性能，但缺乏持久性。 如果需要持久化任务调度信息，则 Quartz 允许用户通过调整其属性文件，将这些信息保存到数据库中。 2.5.1 通过配置文件调整任务调度信息Quartz JAR 文件的 org.quartz 包含了一个 quartz.properties 属性配置文件，并提供了默认属性。可以通过在类路径下新建一个 quartz.properties 文件来覆盖默认配置。 # 集群的配置，这里不使用集群 org.quartz.scheduler.instanceName = DefaultQuartzScheduler org.quartz.scheduler.rmi.export= false org.quartz.scheduler.warpJobExecutionInUserTransaction = false # 配置调度器的线程池 org.quartz.threadPool.class = org.quartz.simple.SimpleThreadPool org.quartz.threadPool.threadCount = 10 org.quartz.threadPool.threadPriority = 5 org.quartz.threadPool.threadInheritContextClassLoaderOfInitializingThread # 配置任务调度现场数据保存机制 org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore 如果任务数目很大，则可以通过增大线程池获得更好的性能。 默认情况下，Quartz 采用 org.quartz.simpl.RAMJobStore 保存任务的现场数据，而通过以下设置可以将任务调度现场数据保存到数据库中 org.quartz.jobStore.class = org.quratz.impl.jdbcjobstore.JobStoreTX # 数据库表前缀 org.quartz.jobStore.tablePrefix = QRTZ_ # 数据源名称 org.quartz.jobStore.dataSource = qzDS # 定义数据源的具体属性 org.quartz.dataSource.qzDS.driver = com.mysql.jdbc.Driver org.quartz.dataSource.qzDS.URL = jdbc:mysql://localhost:3306/quartz org.quartz.dataSource.qzDS.user = root org.quartz.dataSource.qzDS.password = 123456 org.quartz.dataSource.qzDS.maxConnections = 10 要将任务调度数据保存到数据库中，就必须使用 org.quratz.impl.jdbcjobstore.JobStoreTX，并提供相应的数据库配置信息。 用户必须事先在相应的数据库中创建 Quartz 的数据表，在 Quartz 的完整发布包的 docs/dbTables 目录下拥有对应不同数据库的 SQL 脚本。 选择自己使用的数据库对应的脚本执行即可。 执行结果： 2.5.2 查询数据库中的运行信息首先，引入依赖：1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.45&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 任务的现场保存对于上层的 Quartz 来说是完全透明的。使用该配置文件后将之前的代码重新运行，就能在数据库中看到对应的数据。 当调度程序中途停止之后，任务调度的现场数据将记录在数据库表中，在系统重启时就可以在此基础上继续任务的调度。 1234567891011121314151617181920212223242526public class JDBCJobStoreRunner &#123; public static void main(String[] args) &#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); // 获取调度器中所有的触发组 String[] triggerGroups = scheduler.getTriggerGroupNames(); // 重新恢复在 tGroup1 组中名为 tName1 的触发器的运行 for (int i = 0; i &lt; triggerGroups.length; ++ i) &#123; String[] triggerNames = scheduler.getTriggerNames(triggerGroups[i]); for (int j = 0; j &lt; triggerNames.length; ++ j) &#123; Trigger trigger = scheduler.getTrigger(triggerGroups[i], triggerNames[j]); if (trigger instanceof SimpleTrigger &amp;&amp; trigger.getFullName().equals("tGroup1.tName1")) &#123; // 恢复运行 scheduler.rescheduleJob(triggerNames[j], triggerGroups[i], trigger); &#125; &#125; &#125; scheduler.start(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 如果调度程序执行后非正常退出，就可以通过 JDBCJobStoreRunner 根据记录在数据库中的现场数据恢复任务的调度。Scheduler 中的所有 Trigger 及 JobDetail 的运行信息都会保存在数据库中，这里仅恢复 tGroup1 组中名为 tName1 的触发器。触发器采用 GROUP.TRIGGER_NAME 的全名格式，通过 Scheduler#reschduleJob(String triggerName, String groupName, Trigger trigger) 方法即可重新调度关联某个 Trigger 任务。 2.5.3 不同时期 QRTZ_SIMPLE_TRIGGERS 表的数据 执行 代码 中的 SimpleTriggerRunner 一段时间后退出 quartz 数据库状态如下 这时 QRTZ_SIMPLE_TRIGGERS 表中的数据如下 REPEAT_COUNT: 触发器器需要执行的总次数 REPEAT_INTERVAL: 调度间隔(单位：毫秒) TIMES_TRIGGERED: 触发器已经调度的次数 1234567891011121314151617181920212223242526public class JDBCJobStoreRunner &#123; public static void main(String[] args) &#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobKey jobKey = new JobKey("jName", "jGroup"); List&lt;? extends Trigger&gt; triggers = scheduler.getTriggersOfJob(jobKey); // SELECT TRIGGER_NAME, TRIGGER_GROUP FROM &#123;QRTZ_&#125;TRIGGERS WHERE SCHED_NAME = &#123;DefaultQuartzScheduler&#125; AND JOB_NAME = ? AND JOB_GROUP = ? // 其中 &#123;QRTZ_&#125; 和 &#123;DefaultQuartzScheduler&#125; 均来自 quartz.properties 的配置 // 重新恢复在jGroup1组中，名为job1_1的 job的触发器运行 if(triggers.size() &gt; 0)&#123; for (Trigger tg : triggers) &#123; // 根据类型判断 if ((tg instanceof CronTrigger) || (tg instanceof SimpleTrigger)) &#123; // 恢复job运行 scheduler.resumeJob(jobKey); &#125; &#125; scheduler.start(); &#125; &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 此时原先被中断的任务已经恢复。 可以看到，将剩余12次全部执行完成。 再次查看 QRTZ_SIMPLE_TRIGGER 表，发现触发器已经完成调度并被清除。 3. 集成 SpringSpring 为创建 Quartz 的 Scheduler、Trigger、JobDetail 提供了便利的 FactoryBean 类，以便能够在 Spring 容器中享受注入的好处。 Spring 提供了两方面的支持： 为 Quartz 的主要组件提供了更具 Bean 风格的扩展类 提供创造 Scheduler 的BeanFactory 类，方便在 Spring 环境下创建对应的组件对象，并结合 Spring 容器生命周期执行启动和停止的动作。 3.1 创建 JobDetail由于 JobDetail 使用带参构造函数，不方便通过 Spring 配置，因此 Spring 通过扩展 JobDetail 提供了更具 Bean 风格的 JobDetailFactoryBean，此外，Spring 还提供了 MethodInvokingJobDetailFactoryBean，用于将 Spring 容器中 Bean 的方法包装成 Quartz 任务，使开发者不必为 Job 创建对应的类。 3.1.1 JobDetailFactoryBean12345678910111213141516171819@Configuration@ComponentScan(basePackages = &#123;"example5"&#125;)public class QuartzConf &#123; @Bean public JobDetailFactoryBean jobDetailFactoryBean() &#123; JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); jobDetailFactoryBean.setJobClass(SimpleJob.class); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("size", 10); jobDetailFactoryBean.setJobDataAsMap(map); jobDetailFactoryBean.setApplicationContextJobDataKey("applicationContext"); return jobDetailFactoryBean; &#125;&#125; JobDetailFactoryBean 封装了 SimpleJob 任务类，并为 Job 对应的 JobDataMap 设置了一个 key 为 size，value 为 10的数据。此外，通过指定 ApplicationContextJobDataKey，让 Job 的JobDataMap 持有 Spring ApplicationContext 的引用。 jobClass：实现 Job 接口的任务类； beanName：默认为 bean 的id，显示指定 Bean 名称，对应任务的名称； jobDataAsMap：类型为 Map，为任务所对应的 JobDataMap 提供值。提供这个数据是因为用户无法在 Spring 配置文件中为 JobDataMap 类型的属性提供信息； applicationContextJobDataKey：用户可以将 Spring ApplicationContext 的引用保存到 JobDataMap 中，以便在 Job 的代码中访问 ApplicaitonContext。为了达到这个目的，用户需要指定一个 key 对应这个 ApplicationContext，如果不设置就不会将 ApplicationContext 放入 JobDataMap中； jobListenerNames：类型为 String[]，指定注册在 Scheduler 中的 JobListener 名称。 3.2 创建 TriggerSpring 按照相似的思路分为 SimpleTrigger 和 CronTrigger 提供了更具 Bean 风格的 SimpleTriggerFactoryBean 和 CronTriggerFactoryBean 的扩展类， 3.2.1 SimpleTriggerFactoryBean1234567891011121314@Bean(name = "simpleTrigger")public SimpleTriggerFactoryBean simpleTriggerFactoryBean() &#123; SimpleTriggerFactoryBean simpleTriggerFactoryBean = new SimpleTriggerFactoryBean(); simpleTriggerFactoryBean.setJobDetail(jobDetailFactoryBean().getObject()); simpleTriggerFactoryBean.setStartDelay(1000); simpleTriggerFactoryBean.setRepeatInterval(2000); simpleTriggerFactoryBean.setRepeatCount(20); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("count", 10); simpleTriggerFactoryBean.setJobDataAsMap(map); return simpleTriggerFactoryBean;&#125; 定义了一个 Trigger，该 Trigger 和 JobDetail 相关联，延迟 1 秒后启动，时间间隔为 2 秒，重复执行 20 次。 Trigger 中设置的 JobDataMap 在执行任务时必须通过以下方式获取12345public class SimpleJob implements StatefulJob &#123; public void execute(JobExecutionContext context) throws JobExecutionException &#123; Map dataMap = context.getTrigger().getJobDataMap(); &#125;&#125; 3.2.2 CronTriggerFactoryBean1234567@Bean(name = "cronTriggerFactoryBean")public CronTriggerFactoryBean cronTriggerFactoryBean() &#123; CronTriggerFactoryBean cronTriggerFactoryBean = new CronTriggerFactoryBean(); cronTriggerFactoryBean.setJobDetail(jobDetailFactoryBean().getObject()); cronTriggerFactoryBean.setCronExpression("0/5 * * * * ?"); return cronTriggerFactoryBean;&#125; 3.3 SchedulerQuartz 的 SchedulerFactory 是标准的工厂类，不太适合在 Spring 环境下使用。此外，为了保证 Scheduler 能够感知到 Spring 的生命周期，Spring 提供了 SchedulerFactory。 12345678910111213@Beanpublic SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 注册一个或多个 Trigger schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean().getObject()); // 以 Map 类型设置 SchedulerContext Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeout", 30); schedulerFactoryBean.setSchedulerContextAsMap(map); // 显示指定 Quartz 配置文件的路径 schedulerFactoryBean.setConfigLocation(new ClassPathResource("quartz.properties")); return schedulerFactoryBean;&#125; triggers：属性为 trigger[]，可以注册多个 Trigger schedulerContextAsMap：Scheduler拥有类似 ServletContext 的 SchedulerContext，允许用户以 Map 的形式设置 SchedulerContext 的参数值 configLocation：指定配置文件路径 calendars：类型为 Map，通过该属性向 Scheduler 注册 JobDetail jobDetails：类型为 JobDetail[]，通过该属性向 Scheduler 注册 JobDetail autoStartup：SchedulerFactoryBean 初始化之后是否立即启动，默认为 true startupDelay：SchedulerFactoryBean 启动后的延迟时间，默认为 0 SchedulerFactoryBean 的一项重要功能是允许用户将 Quartz 配置文件中的信息转移到 Spring 配置文件中 12345678910111213141516171819@Beanpublic SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 注册一个或多个 Trigger schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean().getObject()); // 以 Map 类型设置 SchedulerContext Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeout", 30); schedulerFactoryBean.setSchedulerContextAsMap(map); // 显示指定 Quartz 配置文件的路径 schedulerFactoryBean.setConfigLocation(new FileSystemResource("classpath:quartz.properties")); //------------------ 集成 Quartz 配置文件 ------------------// Properties properties = new Properties(); properties.setProperty("org.quartz.threadPool.class", "org.quartz.simpl.SimpleThreadPool"); properties.setProperty("org.quartz.threadPool.threadCount", "10"); schedulerFactoryBean.setQuartzProperties(properties); return schedulerFactoryBean;&#125; 3.4 测试代码此处有一个坑，就说从 Spring 容器中根据 beanName 获取的 schedulerFactoryBean 其实是 org.quartz.impl.StdScheduler 对象，如果使用 org.springframework.scheduling.quartz.SchedulerFactoryBean 会抛出以下异常 从 Spring 容器中直接获取 Scheduler 即可。1234567891011public class SimpleTriggerRunner &#123; public static void main(String[] args) throws SchedulerException &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(QuartzConf.class); // 此处一定要取 Scheduler 而不是 SchedulerFactoryBean，因为它是一个工厂bean，得到的不是它本身，而是它负责创建的 org.quartz.impl.StdScheduler 对象 Scheduler scheduler = context.getBean("schedulerFactoryBean", Scheduler.class); scheduler.start(); &#125;&#125; 4. 附录4.1 tables_mysql_innodb.sql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151-- In your Quartz properties file, you'll need to set -- org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate-- By: Ron Cordell - roncordell-- I didn't see this anywhere, so I thought I'd post it here. This is the script from Quartz to create the tables in a MySQL database, modified to use INNODB instead of MYISAM.DROP TABLE IF EXISTS QRTZ_JOB_LISTENERS;DROP TABLE IF EXISTS QRTZ_TRIGGER_LISTENERS;DROP TABLE IF EXISTS QRTZ_FIRED_TRIGGERS;DROP TABLE IF EXISTS QRTZ_PAUSED_TRIGGER_GRPS;DROP TABLE IF EXISTS QRTZ_SCHEDULER_STATE;DROP TABLE IF EXISTS QRTZ_LOCKS;DROP TABLE IF EXISTS QRTZ_SIMPLE_TRIGGERS;DROP TABLE IF EXISTS QRTZ_CRON_TRIGGERS;DROP TABLE IF EXISTS QRTZ_BLOB_TRIGGERS;DROP TABLE IF EXISTS QRTZ_TRIGGERS;DROP TABLE IF EXISTS QRTZ_JOB_DETAILS;DROP TABLE IF EXISTS QRTZ_CALENDARS;CREATE TABLE QRTZ_JOB_DETAILS(JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,DESCRIPTION VARCHAR(250) NULL,JOB_CLASS_NAME VARCHAR(250) NOT NULL,IS_DURABLE VARCHAR(1) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,IS_STATEFUL VARCHAR(1) NOT NULL,REQUESTS_RECOVERY VARCHAR(1) NOT NULL,JOB_DATA BLOB NULL,PRIMARY KEY (JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_JOB_LISTENERS (JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,JOB_LISTENER VARCHAR(200) NOT NULL,PRIMARY KEY (JOB_NAME,JOB_GROUP,JOB_LISTENER),INDEX (JOB_NAME, JOB_GROUP),FOREIGN KEY (JOB_NAME,JOB_GROUP)REFERENCES QRTZ_JOB_DETAILS(JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,DESCRIPTION VARCHAR(250) NULL,NEXT_FIRE_TIME BIGINT(13) NULL,PREV_FIRE_TIME BIGINT(13) NULL,PRIORITY INTEGER NULL,TRIGGER_STATE VARCHAR(16) NOT NULL,TRIGGER_TYPE VARCHAR(8) NOT NULL,START_TIME BIGINT(13) NOT NULL,END_TIME BIGINT(13) NULL,CALENDAR_NAME VARCHAR(200) NULL,MISFIRE_INSTR SMALLINT(2) NULL,JOB_DATA BLOB NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (JOB_NAME, JOB_GROUP),FOREIGN KEY (JOB_NAME,JOB_GROUP)REFERENCES QRTZ_JOB_DETAILS(JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_SIMPLE_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,REPEAT_COUNT BIGINT(7) NOT NULL,REPEAT_INTERVAL BIGINT(12) NOT NULL,TIMES_TRIGGERED BIGINT(10) NOT NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_CRON_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,CRON_EXPRESSION VARCHAR(120) NOT NULL,TIME_ZONE_ID VARCHAR(80),PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_BLOB_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,BLOB_DATA BLOB NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_TRIGGER_LISTENERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,TRIGGER_LISTENER VARCHAR(200) NOT NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP,TRIGGER_LISTENER),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_CALENDARS (CALENDAR_NAME VARCHAR(200) NOT NULL,CALENDAR BLOB NOT NULL,PRIMARY KEY (CALENDAR_NAME))TYPE=InnoDB;CREATE TABLE QRTZ_PAUSED_TRIGGER_GRPS (TRIGGER_GROUP VARCHAR(200) NOT NULL,PRIMARY KEY (TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_FIRED_TRIGGERS (ENTRY_ID VARCHAR(95) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,INSTANCE_NAME VARCHAR(200) NOT NULL,FIRED_TIME BIGINT(13) NOT NULL,PRIORITY INTEGER NOT NULL,STATE VARCHAR(16) NOT NULL,JOB_NAME VARCHAR(200) NULL,JOB_GROUP VARCHAR(200) NULL,IS_STATEFUL VARCHAR(1) NULL,REQUESTS_RECOVERY VARCHAR(1) NULL,PRIMARY KEY (ENTRY_ID))TYPE=InnoDB;CREATE TABLE QRTZ_SCHEDULER_STATE (INSTANCE_NAME VARCHAR(200) NOT NULL,LAST_CHECKIN_TIME BIGINT(13) NOT NULL,CHECKIN_INTERVAL BIGINT(13) NOT NULL,PRIMARY KEY (INSTANCE_NAME))TYPE=InnoDB;CREATE TABLE QRTZ_LOCKS (LOCK_NAME VARCHAR(40) NOT NULL,PRIMARY KEY (LOCK_NAME))TYPE=InnoDB;INSERT INTO QRTZ_LOCKS values('TRIGGER_ACCESS');INSERT INTO QRTZ_LOCKS values('JOB_ACCESS');INSERT INTO QRTZ_LOCKS values('CALENDAR_ACCESS');INSERT INTO QRTZ_LOCKS values('STATE_ACCESS');INSERT INTO QRTZ_LOCKS values('MISFIRE_ACCESS');commit;]]></content>
      <categories>
        <category>quartz</category>
      </categories>
      <tags>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft协议(1)——一致性原理分析]]></title>
    <url>%2Fblog%2F2018%2F04%2F14%2FRaft%E5%8D%8F%E8%AE%AE-1-%E2%80%94%E2%80%94%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[概述在一个由 Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人） 就像一个民主社会，领袖由民众投票选出。刚开始没有领袖，所有集群中的参与者都是群众，那么首先开启一轮大选，在大选期间所有群众都能参与竞选，这时所有群众的角色就变成了候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除领袖的候选人又变回群众角色服从领袖领导。这里提到一个概念「任期」，用术语 Term 表达。关于 Raft 协议的核心概念和术语就这么多而且和现实民主制度非常匹配，所以很容易理解。三类角色的变迁图如下，结合后面的选举过程来看很容易理解。 Raft 集群中节点状态转化 Leader 选举过程在极简的思维下，一个最小的 Raft 民主集群需要三个参与者（如下图：A、B、C），这样才可能投出多数票。初始状态 ABC 都是 Follower，然后发起选举这时有三种可能情形发生。下图中前二种都能选出 Leader，第三种则表明本轮投票无效（Split Votes），每方都投给了自己，结果没有任何一方获得多数票。之后每个参与方随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机 timeout，最先从 timeout 中恢复发起投票的一方向还在 timeout 中的另外两方请求投票，这时它们就只能投给对方了，很快达成一致。 选出 Leader 后，Leader 通过定期向所有 Follower 发送心跳信息维持其统治。若 Follower 一段时间未收到 Leader 的心跳则认为 Leader 可能已经挂了再次发起选主过程。 Leader 节点对一致性的影响Raft 协议强依赖 Leader 节点的可用性来确保集群数据的一致性。数据的流向只能从 Leader 节点向 Follower 节点转移。当 Client 向集群 Leader 节点提交数据后，Leader 节点接收到的数据处于未提交状态（Uncommitted），接着 Leader 节点会并发向所有 Follower 节点复制数据并等待接收响应，确保至少集群中超过半数节点已接收到数据后再向 Client 确认数据已接收。一旦向 Client 发出数据接收 Ack 响应后，表明此时数据状态进入已提交（Committed），Leader 节点再向 Follower 节点发通知告知该数据状态已提交。 在这个过程中，主节点可能在任意阶段挂掉，看下 Raft 协议如何针对不同阶段保障数据一致性的。 数据到达 Leader 节点前这个阶段 Leader 挂掉不影响一致性，不多说。 数据到达 Leader 节点，但未复制到 Follower 节点这个阶段 Leader 挂掉，数据属于未提交状态，Client 不会收到 Ack 会认为超时失败可安全发起重试。Follower 节点上没有该数据，重新选主后 Client 重试重新提交可成功。原来的 Leader 节点恢复后作为 Follower 加入集群重新从当前任期的新 Leader 处同步数据，强制保持和 Leader 数据一致。 数据到达 Leader 节点，成功复制到 Follower 所有节点，但还未向 Leader响应这个阶段 Leader 挂掉，虽然数据在 Follower 节点处于未提交状态（Uncommitted）但保持一致，重新选出 Leader 后可完成数据提交，此时 Client 由于不知到底提交成功没有，可重试提交。针对这种情况 Raft 要求 RPC 请求实现幂等性，也就是要实现内部去重机制。 数据到达 Leader 节点，成功复制到 Follower 部分节点，但还未向 Leader 响应接受这个阶段 Leader 挂掉，数据在 Follower 节点处于未提交状态（Uncommitted）且不一致，Raft 协议要求投票只能投给拥有最新数据的节点。所以拥有最新数据的节点会被选为 Leader 再强制同步数据到 Follower，数据不会丢失并最终一致。 数据到达 Leader 节点，成功复制到 Follower 所有或多数节点，数据在所有节点都处于已提交状态，但还未响应 Client这个阶段 Leader 挂掉，Cluster 内部数据其实已经是一致的，Client 重复重试基于幂等策略对一致性无影响。 网络分区导致的脑裂情况，出现双 Leader网络分区将原先的 Leader 节点和 Follower 节点分隔开，Follower 收不到 Leader 的心跳将发起选举产生新的 Leader。这时就产生了双 Leader，原先的 Leader 独自在一个区，向它提交数据不可能复制到多数节点所以永远提交不成功。向新的 Leader 提交数据可以提交成功，网络恢复后旧的 Leader 发现集群中有更新任期（Term）的新 Leader 则自动降级为 Follower 并从新 Leader 处同步数据达成集群数据一致。 算法以正确性、高效性、简洁性作为主要设计目标。虽然这些都是很有价值的目标，但这些目标都不会达成直到开发者写出一个可用的实现。所以我们相信可理解性同样重要。]]></content>
      <categories>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>一致性算法</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ-(5)——ActiveMQ结合Spring开发]]></title>
    <url>%2Fblog%2F2018%2F04%2F14%2FActiveMQ-5-%E2%80%94%E2%80%94ActiveMQ%E7%BB%93%E5%90%88Spring%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[步骤依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; 在Spring中配置jmsTemplate12345678910111213141516171819202122&lt;!--JMS连接池工厂--&gt;&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://localhost:61616"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"/&gt;&lt;/bean&gt;&lt;!--目的地--&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg index="0" value="spring-queue"/&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="defaultDestination" ref="destination"/&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"/&gt; &lt;/property&gt;&lt;/bean&gt; 如果是topic 添加topic的配置 修改jmsTemplate配置中的defaultDestination 12345678910111213141516171819202122&lt;!--JMS连接池工厂--&gt;&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://localhost:61616"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"/&gt;&lt;/bean&gt;&lt;!--目的地--&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg index="0" value="spring-topic"/&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="defaultDestination" ref="destination"/&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"/&gt; &lt;/property&gt;&lt;/bean&gt; 如果在Spring中配置消费者的话，就不需要启动消费者相当于注册了一个默认消息监听器 当JMS Provider接受到消息之后就会触发listener的onMessage()方法 1234567&lt;bean id="jmsContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="destination" ref="destination"/&gt; &lt;property name="messageListener" ref="messageListener"/&gt;&lt;/bean&gt;&lt;bean id="messageListener"class="org.destiny.activemq.spring.MyMessageListener"/&gt; 12345678910111213package org.destiny.activemq.spring;public class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println("receive: " + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 最佳实践 Camel框架支持大量的企业集成模式，可以大大简化集成组件间的大量服务和复杂的消息流。而Spring更注重简单性。 Spring消息发送的核心架构是JmsTemplate，隔离了像打开、关闭Session和Producer等操作。因此应用开发人员仅仅需要关注实际的业务逻辑。但JmsTemplate损害了ActiveMQ的PooledConnectionFactory对Session和消息Producer的缓存机制带来的性能提升。 新的Spring中，可以设置org.springframework.jms.connection.CachingConnectionFactory的sessionCacheSize，或者直接使用ActiveMQ的PooledConnectionFactory。 不建议使用JmsTemplate的receive()，因为JmsTemplate上的所有调用都是同步的，这意味着调用的线程会阻塞，直到方法返回，性能影响较大。 尽量使用DefaultMessageListenerContainer，它允许异步接受消息并缓存session和消息Consuer。]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(4)——Broker的启动方式]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2FActiveMQ-4-%E2%80%94%E2%80%94Broker%E7%9A%84%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Broker：相当于一个ActiveMQ服务器实例。 命令行启动参数示例 activemq start：默认使用acitvemq.xml来启动 activemq start xbean:file:../conf/activemq.xml：使用指定的配置文件来启动。 用ActiveMQ来构建Java应用用ActiveMQ Broker作为独立的消息服务器来构建JAVA应用。ActiveMQ也支持在VM中通信基于嵌入式的Broker，能够无缝集成其他Java应用。 嵌入式BrokerBrokerService启动Broker1234567public static void main(String[] args) throws Exception &#123; // 开启ActiveMQ Broker BrokerService brokerService = new BrokerService(); brokerService.setUseJmx(true); brokerService.addConnector("tcp://localhost:61616"); brokerService.start();&#125; BrokerFactory启动Broker1234567public static void main(String[] args) throws Exception &#123; // 开启ActiveMQ Broker String uri = "properties:broker.properties"; BrokerService brokerService = BrokerFactory.createBroker(new URI(uri)); brokerService.addConnector("tcp://localhost:61616"); brokerService.start();&#125; 配置文件broker.properties123useJmx=truepersistent=falsebrokerName=Cheese 利用Spring集成Broker123456789&lt;bean id="broker" class="org.apache.activemq.broker.BrokerService" init-method="start" destroy-method="stop"&gt; &lt;property name="brokerName" value="myBroker"/&gt; &lt;property name="persistent" value="false"/&gt; &lt;property name="transportConnectorURIs"&gt; &lt;list&gt; &lt;value&gt;tcp://localhost:61616&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 启动多个Broker如果需要启动多个Broker，那么需要为每个Broker设置一个名字12]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(3)——JMS可靠性机制]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2FActiveMQ-3-%E2%80%94%E2%80%94JMS%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[消息接受确认JMS消息只有在被确认之后，才认为已经被成功地消费了。消费的成功通常包含三个阶段：客户端接受消息、客户端处理消息和消息被确认。在事务性会话中，当一个事务被提交的时候，确认自动发生。在非事务性会话中，消息何时被确认取决于创建会话时的应答模式。该参数有三个可选方案： Session.AUTO_ACKNOWLEDGE当客户成功的从receive()方法返回的时候，或者从MessageListener.onMessage()方法成功返回的时候，会话自动确认客户端收到的消息。 Session.CLIENT_ACKNOWLEDGE客户端通过调用消息的acknowledge()方法确认消息。在这种模式中，确认是在会话层上进行，确认一个被消费的消息将自动确认所有已被会话消费的消息。 1Session session = connection.createSession(false, Session.CLIENT_ACKNOWLEDGE); Session.DUPS_ACKNOWLEDGE只是会话迟钝的确认消息的提交。如果JMS Provider失败，那么可能会导致一些重复的消息。如果是重复的消息，那么JMS Provider必须把消息头的JMSRedelivered字段设置为true 消息的持久性，JMS支持两种消息提交模式PERSISTENTJMS Provider永久保存消息，以保证消息不会因为JMS Provider的失败而丢失。 NON_PERSISTENT不要求JMS Provider持久保存消息 消息的临时目的地可以通过Session的createTemporaryQueue()和createTemporaryTopic()方法来创建临时目的地。他们的存在时间只限于创建他们的连接所保持的时间，只有创建该临时目的地的连接上的消息消费者才能够从临时目的地中提取消息。 本地事务在一个JMS客户端，可以使用本地事务来组合消息的发送和签收。Session接口提供了commit()和rollback()方法。 事务提交意味着生产的所有消息被发送，消费的所有消息被确认。 事务回滚意味着生产的所有消息被销毁，消费的所有消息被恢复并重新提交，除非他们已过期。 PTP模型该模型定义了客户端如何向队列发送消息，从队列接受消息。 PTP模型是基于队列的，生产者发消息到队列，消费者从队列接受消息，队列使得消息的异步传输成为可能。 特点 Session在关闭时，如果有消息已经被接受，但还没有确认，那么当消费者下次连接到相同的队列时，这些消息还会被再次接受。 如果用户在receive()方法中设定了消息选择条件，那么不符合条件的消息会留在队列中。 队列可以长久地保存消息直到消费者收到消息，消费者不需要因为担心消息丢失而时刻与队列保持激活的连接状态。 Pub/Sub模型该模型定义了如何向一个内容节点发布和订阅消息。 主题可以被认为是消息的传输中介，发布者发布消息到主题，订阅者从主题订阅消息，二者相互独立，不需要接触。 特点 消息订阅分为非持久订阅和持久订阅 非持久订阅时，只有当客户端处于激活状态才能收到某个主题的消息；离线时发布到主题的消息将会丢失。 持久订阅时，客户端向JMS Provider注册一个自己身份的ID，当客户端处于离线状态时，Provider会为这个ID保存所有发送到主题的消息。 如果用户在receive()方法中设定了消息选择条件，那么不符合条件的消息不会被接收。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(2)——JMS规范]]></title>
    <url>%2Fblog%2F2018%2F04%2F11%2FActiveMQ-2-%E2%80%94%E2%80%94JMS%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[定义JMS(Java Message Service)，Java消息服务 JMS定义了Java访问消息中间件的接口，并没有给予实现。 实现JMS接口的消息中间件成为JMSProvider，如ActiveMQ。 JMS规范 JMS message：JMS的消息，由三部分组成：消息头、消息属性、消息体 JMS Producer：消息生产者，创建和发送消息 JMS Consumer：消息消费者，接受和处理消息，消息的消费可以采用以下两种方式之一： 同步消费：通过调用消费者的receive方法从目的地中显示提取消息，receive方法可以一直阻塞到消息到达 异步消费：客户可以为消费者注册一个Listener，以定义在消息到达时所采取的动作。 JMS domains：消息传递域，JMS定义了两周消息传递域： 点对点：每个消息只能有一个消费者，生产者和消费者没有时间上的相关性，无论消费者在生产者发送消息的时候是否处于运行状态，都可以提取消息； 发布订阅：每个消息可以被多个消费者消费，生产者和消费者有时间上的相关性，订阅一个主题的消费者只能消费它订阅之后发布的消息 ConnectionFactory：连接工厂，用来创建连接对象，已连接到JMS的Provider JMS Connection：封装了客户与JMS提供者之间的一个虚拟连接 JMS Session：是生产和消费消息的一个单线程上下文 会话用于创建消息生产者、消费者和消息等。会话提供了一个事务性的上下文，在这个上下文中，一组发送和接受被组合到了一个原子操作中。 Destination：消息发送到的目的地。 Acknowledge：签收。消费者收到消息后，需要告诉JMS Provider消息已被消费。 Transaction：事务 JMS Client：用来收发消息的Java应用 JMS Message结构组成 消息头 属性 消息体 消息头消息头包含识别信息和路由信息 JMSDestination：消息发送的目的地，主要是指Queue或Topic。 JMSDeliveryMode：传送模式，持久或非持久。 持久消息应该会且只会被发送一次，JMS提供者出现故障，消息也不会丢失，会在服务器恢复之后再次传递。 非持久的消息最多会被发送一次，这意味着服务器出现故障，该消息会永远丢失。 JMSExpiration：消息过期时间，为0表示永不过期。 JMSPriority：消息优先级，数字越大，级别越高，加急消息要先于普通消息。 JMSMessageId：唯一标识。 JMSCorrelationID：用来连接到另一个消息，典型应用是在回复消息中关联到原消息。 JMSReplyTo：提供本消息回复消息的目的地址，由开发者提供 JMSType：消息的类型识别符 JMSRedelivered：如果一个客户端收到了一个设置了JMSRedelivered属性的消息，则表示客户端可能收到过该消息，但没有签收。 消息体 TextMessage：文本消息 MapMessage：映射消息 BytesMessage：二进制消息 StreamMessage：流式消息 ObjectMessage：对象消息 属性应用程序设置和添加的属性1message.setStringProperty("username", username); JMS定义的属性12// 返回所有连接支持的JMSX属性的名字connection.getMetaData().getJMSXPropertyNames(); JMS供应商特定的属性JMS定义的属性 JMSXUserID：发送消息的用户标识 JMSXAppID：发送消息的应用标识 JMSXDeliveryCount：转发消息重试次数 JMSXGroupID：消息所在的消息组的标识 JMSXGroupSeq：组内消息的序号]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(1)——概览&入门]]></title>
    <url>%2Fblog%2F2018%2F04%2F09%2FActiveMQ-1-%E2%80%94%E2%80%94%E6%A6%82%E8%A7%88-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[概览ActiveMQ简介 什么是ActiveMQ ActiveMQ的作用 ActiveMQ的特点 消息中间件的功能、特点、应用场景等 ActiveMQ安装和基本使用通过源码安装、基本的配置实例、启动、测试运行、关闭等 JMS基本概念、消息结构、可靠性机制、PTP、Pub/Sub、API结构、JMS应用开发的基本步骤、持久和非持久的Topic 同ActiveMQ构建应用 多种启动Broker的方法 单独应用的开发 结合Spring开发 ActiveMQ的Transport多种运输协议的功能、配置和使用 ActiveMQ的消息存储队列和Topic、KahaDB、AMQ、JDBC、MMS等 ActiveMQ的Network 在一台服务器上启动多个Broker 静态网络连接的功能、配置 “丢失”消息的处理 容错或可负载均衡的连接 动态网络连接等 ActiveMQ集群 队列消费者集群 Broker的集群 MasterSlave等 Destination高级特性 通配符 组合队列 配置启动的Destination 删除不活动的Destination 虚拟Destination 镜像队列 Message Dispatch高级特性 消息游标 异步发送 分发策略 优化批量控制 Message高级特性 消息属性 Advisory Message 延迟和定时消息投递 Blob消息 消息转换 Consumer高级特性 消息异步分发 消息优先级 管理持久化消息 消息分组 消息重抵策略 杂项 监控和管理 集成ActiveMQ和Tomcat ActiveMQ优化ActiveMQ简介介绍ActiveMQ是Apache推出的一款开源的、完全支持JMS和J2EE规范的JMSProvider实现的消息中间件(Message Oriented Middleware, MOM)。 作用用来帮助实现高可用、高性能、可伸缩、易用和安全的企业级面向消息服务的系统。 ActiveMQ安装和基本使用下载并安装服务端 从http://activemq.apache.org/download.html下载最新的ActiveMQ 直接解压1$ tar -zxvf apache-activemq-5.9.0-bin.tar.gz activemq 启动运行 普通启动 1234$ pwd/usr/local/activemq/bin$ ./activemq start 启动并指定日志文件 1$ ./activemq start &gt; /tmp/activemqlog 检查是否已经启动ActiveMQ默认采用61616端口提供JMS服务，使用8061端口提供管理控制台服务，执行以下命令以便检验是否已经成功启动ActiveMQ服务： 查看61616端口是否已经打开： netstat -an | grep 61616 查看控制台输出或者日志文件 直接访问ActiveMQ的管理页面：http://localhost:8161/admin，默认的用户名和密码是admin/admin 关闭ActiveMQ1$ ./activemq stop 基本的消息发送配置MAVEN所需的依赖12345678910&lt;dependency&gt; &lt;gruopId&gt;org.apache.activemq&lt;/gruopId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;gruopId&gt;org.apache.xbean&lt;/gruopId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; 消息生产者123456789101112131415161718192021222324252627public static void main(String[] args) throws JMSException, InterruptedException &#123; // 创建连接工厂，连接工程负责与ActiveMQ服务端建立连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616"); // 由连接工厂创建连接 Connection connection = connectionFactory.createConnection(); // 启动连接 connection.start(); // 通过连接创建会话 Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); // 通过会话创建目的地，名称表示对列名 Destination destination = session.createQueue("my-queue"); // 通过 session 创建生产者 MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; 100; ++i) &#123; TextMessage message = session.createTextMessage("message -- " + i); Thread.sleep(100); // 通过消息生产者发出消息 producer.send(message); System.out.println("创建成功"); &#125; session.commit(); session.close(); connection.close();&#125; 运行结果： 消息消费者123456789101112131415161718192021222324public static void main(String[] args) throws JMSException, InterruptedException &#123; // 创建连接工厂，连接工厂负责与ActiveMQ服务端建立连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616"); // 由连接工厂创建连接 Connection connection = connectionFactory.createConnection(); // 启动连接 connection.start(); // 通过连接创建会话 Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); // 通过会话创建目的地，名称表示对列名 Destination destination = session.createQueue("my-queue"); // 通过 session 创建生产者 MessageConsumer consumer = session.createConsumer(destination); for (int i = 0; i &lt; 100; ++i) &#123; TextMessage message = (TextMessage) consumer.receive(); session.commit(); System.out.println("收到消息: " + message.getText()); &#125; session.close(); connection.close();&#125; 运行结果： JMS模型]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[盘点实际项目中常用的加密算法及使用场景]]></title>
    <url>%2Fblog%2F2018%2F04%2F08%2F%E7%9B%98%E7%82%B9%E5%AE%9E%E9%99%85%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[MD5定义MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4。 特点 压缩性：任意长度的数据，算出的MD5值长度都是固定的。 容易计算：从原数据计算出MD5值很容易。 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 MD5的作用是让大容量信息在用数字签名软件签署私人密钥前被”压缩”成一种保密的格式（就是把一个任意长度的字节串变换成一定长的十六进制数字串）。除了MD5以外，其中比较有名的还有sha-1、RIPEMD以及Haval等。 应用场景一致性验证MD5的典型应用是对一段信息（Message）产生信息摘要（Message-Digest），以防止被篡改。MD5就可以为任何文件（不管其大小、格式、数量）产生一个同样独一无二的“数字指纹”，如果任何人对文件做了任何改动，其MD5值也就是对应的“数字指纹”都会发生变化。 数字签名MD5的典型应用是对一段Message(字节串)产生fingerprint(指纹），以防止被“篡改”。举个例子，你将一段话写在一个叫 readme.txt文件中，并对这个readme.txt产生一个MD5的值并记录在案，然后你可以传播这个文件给别人，别人如果修改了文件中的任何内容，你对这个文件重新计算MD5时就会发现（两个MD5值不相同）。如果再有一个第三方的认证机构，用MD5还可以防止文件作者的“抵赖”，这就是所谓的数字签名应用。 安全访问认证MD5还广泛用于操作系统的登陆认证上，如Unix、各类BSD系统登录密码、数字签名等诸多方面。如在Unix系统中用户的密码是以MD5（或其它类似的算法）经Hash运算后存储在文件系统中。当用户登录的时候，系统把用户输入的密码进行MD5 Hash运算，然后再去和保存在文件系统中的MD5值进行比较，进而确定输入的密码是否正确。通过这样的步骤，系统在并不知道用户密码的明码的情况下就可以确定用户登录系统的合法性。这可以避免用户的密码被具有系统管理员权限的用户知道。 缺点与不足2014年中国山东大学的王小云教授公布破译了MD5、HAVAL-128、 MD4和RIPEMD算法的报告。通过加速的杂凑与冲撞方法破译了MD5算法。 实践 RSA定义RSA为公钥加密体制 乙方生成两把秘钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 甲方获取乙方的公钥，然后用它对信息加密。 乙方得到加密后的信息，用私钥解密。 特点便于理解，使用广泛RSA算法是第一个能同时用于加密和数字签名的算法，也易于理解和操作。RSA是被研究得最广泛的公钥算法，从提出到现今的三十多年里，经历了各种攻击的考验，逐渐为人们接受，普遍认为是目前最优秀的公钥方案之一。 缺点与不足：加密和解密花费时间长、速度慢，只适合对少量数据进行加密为提高保密强度，RSA密钥至少为500位长，一般推荐使用1024位。这就使加密的计算量很大。为减少计算量，在传送信息时，常采用传统加密方法与公开密钥加密方法相结合的方式，即信息采用改进的DES或IDEA对话密钥加密，然后使用RSA密钥加密对话密钥和信息摘要。对方收到信息后，用不同的密钥解密并可核对信息摘要。 实践ssh口令登录1234567sequenceDiagram客户端-&gt;&gt;服务端: 口令登录服务端-&gt;&gt;客户端: 发送1024为公钥指纹客户端-&gt;&gt;服务端: 指纹保存在$HOME/.ssh/known_hosts，接受远程主机秘钥服务端-&gt;&gt;客户端: 请求输入密码客户端-&gt;&gt;服务端: 输入密码服务端-&gt;&gt;客户端: 接受或拒绝链接 ssh公钥登录12345sequenceDiagram客户端-&gt;&gt;服务端: 登录请求服务端-&gt;&gt;客户端: 发送随机字符串客户端-&gt;&gt;服务端: 发送加密后的随机字符串服务端-&gt;&gt;客户端: 接受或拒绝链接 客户端事先把自己的公钥保存在服务端的指定目录: $HOME/.ssh/authorized_keys 客户端生成秘钥: ssh-keygen，运行结束后，在$HOME/.ssh/目录下，会新生成两个文件: id_rsa.pub和id_rsa。前者是公钥，后者是私钥。 将公钥发送给远程主机: ssh-copy-id user@host]]></content>
      <categories>
        <category>加密</category>
      </categories>
      <tags>
        <tag>开发</tag>
        <tag>算法</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（二）Nginx实现动静分离]]></title>
    <url>%2Fblog%2F2018%2F04%2F03%2F%EF%BC%88%E4%BA%8C%EF%BC%89Nginx%E5%AE%9E%E7%8E%B0%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[概念在反向代理时，如果是静态资源，就直接从Nginx发布的路径中去读取，而不需要从后台服务器获取。 但这种情况下需要保证后端跟前端的程序保持一致，可以使用Rsync做服务端自动同步或者使用NFS、MFS分布式共享存储。 概念图 原理Nginx可以拦截请求 因此可以利用这一特性，将拦截到的静态请求进行重定向。 12345678910111213141516171819202122232425server &#123; listen 80; server_name destiny; access_log logs/host.access.log main; index index.html index.htm index.jsp; root /usr/local/tomcat-9.0.0-RC5-1/webapps/ROOT/; # 不区分大小写的正则匹配 location ~* .*\.(jpg|jepg|fig|png|wsf|ico)$ &#123; if(-f $request_filename) &#123; # expires 15d; break; &#125; &#125; # 不区分大小写的正则匹配 locatin ~* .*\.(html|htm|js|css)$ &#123; # expires 1d; &#125; location / &#123; proxy_pass http://10.211.55.5 &#125;&#125; 在前两个location中，没有配置后端服务器的路径Nginx就会默认去寻找root的资源 Nginx会以root为根路径，将请求的路径拼在其后去查找，如果能访问到，Nginx就可以直接将该文件返回。 如果能够查询到响应的文件，就会直接返回。 指令index(默认主页设置模块)如果URL中没有指定文件，则设置一个默认主页。 可以指定多个文件，如果第一个文件没有找到，将会查找后面指定的文件 index index.html index.htm index.jsp root请求到达后的文件根目录 123location /i/ &#123; root /spool/w3;&#125; 如果请求/i/top.gif文件，Nginx将转到/spool/w3/i/top.gif文件 在请求中root会添加这个location到它的值后面，即”/i/top.gif”并不会请求”/spool/w3/top.gif”文件，如果要实现上述类似于apache alias的功能，可以使用alias指令。 简单来说，root是拼接，alias是替换。 实现当访问静态资源的请求进入(假设为http://10.211.55.4:80/static/person.jpg)时，会被配置文件中的第一个location拦截 location会将root中配置的路径和访问路径拼接在一起，新的路径为/usr/local/tomcat-9.0.0-RC5-1/webapps/ROOT/static/person.jpg，在Nginx的路径中进行查找。 初始情况，不加Nginx的情况下启动Tomcat 访问10.211.55.4:8080即可访问Tomcat主页。 查看logs/localhost_access_log.2018-04-03.txt可以看到访问日志 此时可以看到，请求了多个静态文件。 加入Nginx将包含上图中文件的路径/usr/local/apache-tomcat-7.0.73/webapps/ROOT/配置进Nginx配置文件中的root属性。 并配置location用于拦截jpg/jepg/fig/png/wsf/ico后缀的文件。 然后sbin/nginx -s reload重启Nginx 效果展示分别重启Tomcat和Nginx后，再访问10.211.55.4(Nginx自动监听80端口并转发至8080) 删除浏览器缓存 此时再查看日志，已经请求中已经不再对静态资源进行请求]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从头搭建github博客]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2F%E4%BB%8E%E5%A4%B4%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[安装Node.js并配置Node.js环境成功界面如下： 安装git并配置git环境 注册Github并新建项目首页 新建仓库页参考其他博客的时候，很多博客中都提到 项目名必须是 github账户名.github.io 但经本人测试其实项目名称可以任意选取，如本人的仓库名就是blog，而非destinywang.github.io 设置进入项目的setting选项卡中 下拉到Github Pages，此时该项目已经被部署，可以通过提供的外网链接去访问。 安装HexoHexo中文网站 Hexo是个快捷，简介且高效的博客框架 让上百个页面在几秒内完成渲染 Hexo支持Github Flavored Markdown的所有功能 在合适的位置创建文件夹 以上操作需要在空文件夹中进行 123$ npm install hexo -g # 安装Hexo$ hexo -v # 检查Hexo是否安装成功$ hexo init # 初始化文件夹 Hexo init npm install此命令用于安装所需要的组件 hexo g首次体验Hexo hexo s此命令会在本地开启Hexo的服务器 可以在发布到github之前先在本地进行调试 然后再浏览器中输入localhost:4000/blog/如果出现如下界面就成功了 将Hexo和Github page联系起来设置本地git如果是第一次使用git的话需要设置name和email 1234$ ssh-keygen -t rsa -C &quot;your email&quot; # 生成秘钥，路径在~/.ssh下，windows用户的路径为C:\Users\Administrator\.ssh$ eval &quot;$(ssh-agent -s)&quot; # 添加秘钥到ssh-agent$ ssh-add ~/.ssh/id_rsa # 添加生成的SSH key到ssh-agent 登录github，进行设置 进入用户的setting页面 在SSH and GPG keys选项卡中添加一个ssh key，并将id_rsa.pub(公钥)的内容复制上去 配置Deployment为了保证Hexo能够正确的通过Git进行add、commit、pull、push等操作需要将本地及远程的git仓库信息进行配置 当前站点文件夹的状态： 修改_config.yml文件，将deployment部分相关的内容进行替换 type: 部署类型 repository: 远程仓库路径，即github中的仓库路径 branch: 分支名 新建一篇博客在终端中执行命令hexo new post 博客名 会在source/_posts路径下生成对应的博客文件test.md 安装hexo-deployer-git扩展文件1$ npm install hexo-deployer-git --save 编辑文章1$ vim source/_posts/test.md 打开test.md文件，按照正常的Markdown文件编辑即可 部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475$ hexo d -gINFO Start processingINFO Files loaded in 640 msINFO Generated: tags/index.htmlINFO Generated: about/index.htmlINFO Generated: 2018/04/01/jvm/index.htmlINFO Generated: 2018/04/01/test/index.htmlINFO Generated: 2018/04/01/hello-world-1/index.htmlINFO Generated: archives/index.htmlINFO Generated: tags/jvm/index.htmlINFO Generated: archives/2018/index.htmlINFO Generated: archives/2018/04/index.htmlINFO Generated: tags/java基础/index.htmlINFO Generated: index.htmlINFO Generated: 2018/04/01/hello-world/index.htmlINFO Generated: 2018/04/01/一-Nginx基本知识/index.htmlINFO Generated: tags/Nginx/index.htmlINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/avatar.gifINFO Generated: images/apple-touch-icon-next.pngINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/algolia_logo.svgINFO Generated: images/cc-by-nc.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/cc-by-sa.svgINFO Generated: images/cc-by.svgINFO Generated: images/cc-zero.svgINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/favicon-32x32-next.pngINFO Generated: images/loading.gifINFO Generated: images/logo.svgINFO Generated: images/placeholder.gifINFO Generated: images/quote-r.svgINFO Generated: images/searchicon.pngINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: images/quote-l.svgINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: images/blog-logo.jpegINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: css/main.cssINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: js/src/affix.jsINFO Generated: js/src/exturl.jsINFO Generated: js/src/algolia-search.jsINFO Generated: js/src/bootstrap.jsINFO Generated: js/src/love.jsINFO Generated: js/src/js.cookie.jsINFO Generated: js/src/post-details.jsINFO Generated: js/src/motion.jsINFO Generated: js/src/scrollspy.jsINFO Generated: js/src/scroll-cookie.jsINFO Generated: lib/font-awesome/bower.jsonINFO Generated: js/src/utils.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.min.jsINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/velocity/velocity.min.jsINFO Generated: js/src/schemes/pisces.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.pack.jsINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: lib/jquery/index.jsINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: lib/velocity/velocity.jsINFO 61 files generated in 1.13 sINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...[master 966acc9] Site updated: 2018-04-01 21:18:16 1 file changed, 1 insertion(+), 1 deletion(-)To github.com:DestinyWang/blog.git + fa066f8...966acc9 HEAD -&gt; master (forced update)Branch &apos;master&apos; set up to track remote branch &apos;master&apos; from &apos;git@github.com:DestinyWang/blog.git&apos;.INFO Deploy done: git 至此，博客已经部署成功，可以去http://用户名.github.io查看。 安装Next1$ git clone https://github.com/iissnan/hexo-theme-next themes/next 下载到站点文件夹路径下的themes/next 启用Next主体在站点目录中，打开配置文件_config.yml，修改theme: next123$ pwd~/blog$ vim _config.yml 主题设定在next主题目录下的_config.yml，修改scheme: Pisces 123$ pwd~/blog$ vim themes/next/_config.yml 语言设定Hexo提供了多种语言支持，包括简体中文zh-Hans在站点根目录下修改配置文件_config.yml中的language为zh-Hans 123$ pwd~/blog$ vim _config.yml 修改菜单栏在主题目录下修改配置文件_config.yml中的menu 123$ pwd~/blog$ vim themes/next/_config.yml 设置菜单项图标对应字段是menu_icons同样在主题目录下的_config.yml中修改 格式为item name: icon name，其中item name 与所配置的菜单名字对应，icon name是Font Awesome图标的名字。而 enable可用于控制是否显示图标，你可以设置成 false 来去掉图标。 123$ pwd~/blog$ vim themes/next/_config.yml 设置侧栏位置修改主题目录下sidebar的position值 123$ pwd~/blog$ vim themes/next/_config.yml 设置头像在站点根目录下载配置文件中新增avatar，值设置为头像的链接地址。地址可以是网络地址，也可以是本地地址（放置在source/images/目录下） 设置文章代码主题在主题目录下修改配置文件_config.yml，字段highlight_theme，默认值为nomal。可以设置为night 123$ pwd~/blog$ vim themes/next/_config.yml 添加分类在站点路径下新建页面categories 123456$ pwd~/blog$ hexo new page categories# 在 source/categories 目录中修改index.mdvim source/categories/index.md 12# 在主题的 _config.yml 中取消注释:$ vim _config.yml 在要分类的文章中加入 category 属性: 添加标签页面标签是对博客分类的方式比如一个系列的博客都是将神经网络，那么就可以给每篇博客加上神经网络的tag 1234567$ pwd~/blog$ hexo new page tagsINFO Created: ~/blog/source/tags/index.md# 在新建的index.md中添加type: &quot;tags&quot;vim source/tags/index.md 后面只需要在博客的开头中添加tags: [A, B, C]即可 成功后，标签部分的导航栏为 Aboute Me1234567$ pwd~/blog$ hexo new page aboutINFO Created: ~/blog/source/about/index.md# 在新建的index.md中添加如下内容vim source/about/index.md 成功后效果如下所示： 添加github导航条从这里选择主题 然后将代码复制到themes/next/layout/_layout.swig 123$ pwd~/blog$ vim themes/next/layout/_layout.swig 成功后的效果如下： 修改内容区域宽度默认情况Next 对内容的宽度的设定如下： 700px，当屏幕宽度 &lt; 1600px 900px，当屏幕宽度 &gt;= 1600px 移动设备下，宽度自适应 非Pisces Scheme主题修改1$ vim source/css_variables/custom.styl 修改内容： 12345// 修改成你期望的宽度$content-desktop = 700px// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px Pisces Scheme主题修改1$ vim themes\next\source\css\_schemes\Picses\_layout.styl 修改内容： 123.header &#123;width: 1150px;&#125;.container .main-inner &#123;width: 1150px;&#125;.content-wrap &#123;width: calc(100% - 260px);&#125; 设置首页不显示全文(只显示预览)打开主题路径下的_config.yml1$ vim themes/next/_config.yml 修改auto_excerpt12345# Automatically Excerpt. Not recommand.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150 将enable属性改为true 修改code代码块自定义样式1$ vim themes/next/source/css/_custom/custom.styl 取消文章目录对标题的自动编号 nexT对 markdown 语法的标题 # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 会默认进行标号分配，这样有可能会打乱文章原有标题 取消方式： 修改主题配置文件 1$ vim theme/next/_config 将 number 设为 false 结束至此，博客基本设置OK但还有很多地方可以继续挖掘 后续会持续更新]]></content>
      <tags>
        <tag>github博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（一）Nginx基本知识]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2F%EF%BC%88%E4%B8%80%EF%BC%89Nginx%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[简介Nginx是一款轻量级的Web服务器，也是一款轻量级的反向代理服务器 用途 直接支持Rails和PHP程序 作为HTTP反向代理服务器 作为负载均衡服务器 作为邮件代理服务器 帮助实现动静分离 特点高稳定、高性能、资源占用少、功能丰富、模块化结构、支持热部署 安装Nginx 依赖gcc openssl-devel pcre-devel zlib zlib-devel 1yum install gcc openssl-devel pcre-devel zlib zlib-devel 安装 $ ./configure --prefix=/usr/local/nginx --withhttp_stub_status_module $ make $ make install 常见的Nginx安装配置选项 Nginx基本运行// 测试配置文件 $ sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful // 启动 $ sbin/nginx // 停止 $ sbin/nginx -s stop $ sbin/nginx -s quit // 重启 $ sbin/nginx -s reload // 查看进程 ps -ef | grep nginx Nginx的基本配置默认启动Nginx的时候，使用的配置文件是conf/nginx.conf文件 也可以在启动Nginx的时候，通过-c来指定要去读的配置文件 常见的配置文件 文件名 用途 nginx.conf 应用程序的基本配置文件 mime.types MIME类型关联的扩展文件 fastcgi.conf 与fastcgi相关的配置，与PHP相关 proxy.conf 与proxy相关的配置（反向代理） sites.conf 配置Nginx提供的网站，包括虚拟主机 nginx.cong1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950user root;worker_processes 1;error_log logs/error.log crit;pid logs/nginx.pid; # nginx 进程号文件路径events &#123; # 事件模块 use epoll; # 文件的模型 worker_connections 24; # 每个worker的connections&#125;http &#123; # web反向代理 include mime.type; # 引入mime.type include proxy.conf; # 引入proxy.conf defualt_type application/octet-stream; # mine.type 的缺省类型 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; # 日志格式，远程地址 - 远程用户 时间 等 &apos;$status $body_bytes_sent &quot;$http_referer&quot;&apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; access_log logs/access.log main; # 使用为main的格式 upstream test.com &#123; # 负载均衡模块 server 127.0.0.1:8080 weight = 5; &#125; server &#123; lisent 80; server_name detiny; access_log logs/host.access.log main; index index.html index.htm index.jsp; root /Users/destiny/Download/apache-tomcat-9.0.1/webapps/ROOT/; location ~* .*\.(jpg|jepg|gif|png|wsf|ico)$ &#123; # 如果是图片，就去root路径查询 if(-f $request_filename) &#123; break; &#125; &#125; location / proxy_pass http://destiny.com; &#125; &#125;&#125; Nginx的进程结构启动Nginx的时候，会启动一个Master进程，这个进程不处理客户端的任何请求，主要用来产生worker进程 而每个worker进程用来处理一个Request Niginx 模块分为：核心模块、时间模块、标准HTTP模块、可选HTTP模块、邮件模块、第三方模块和补丁等。 基本模块Nginx默认的功能模块，它们提供的指令，允许使用定义Nginx基本功能的变量，在编译的时候不能被禁用，包括: 核心模块：基本功能和指令，如进程管理和安全 事件模块：在Nginx内配置网络使用的能力 配置模块：提供包含机制 常用模块Nginx常用的核心模块指令 error_log include pid user worker_cpu_affinity worker_processes error_log语法： error_log file [ debug|info|notice|warn|error|crit ] Nginx支持将不同的虚拟主机的日志记录在不同的路径 12345678910111213http &#123; error_log logs/http_error.log error; server &#123; server_name one; access_log logs/one_access.log; error_log logs/one_error.log error; &#125; server &#123; server_name two; access_log logs/two_access.log; error_log logs/two_error.log error; &#125;&#125; include从外部引入文件，支持文件通配符 pid指定pid文件，可以使用kill命令 user为了提高安全性，指定允许操作Nginx的用户 语法：user user [group] worker_cpu_affinity指定工作进程指定到某个CPU上 // 指定每个进程绑定一个CPU worker_processes 4; worker_cpu_affinity 0001 0010 0100 1000; // 指定第一个进程到CPU0/CPU2，第二个进程到CPU1/CPU3 worker_processes 2; worker_cpu_affinity 0101 1010; worker_processes一个工作进程为一个单线程的进程 如果Nginx工作在一些CPU密集型的环境中，并且你的机器拥有2块以上的CPU，则可以将worker_processes的数目设置为CPU核数。 如果你的机器运行在需要处理大量静态文件的环境，并且文件的大小总和超出了可用的内存，那么可以增加worker_processes的以便充分利用磁盘带宽。 日志模块控制Nginx如何记录请求日志 12345log_format gzip $remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot;&apos; &apos;&quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&apos;; access_log /spool/logs/nginx-access.log gzip buffer=32k; access_log语法：access_log path [format [buffer=size | off]] 默认值：access_log log/access.log combined 使用字段：http、server、location 注意： Nginx指定的用户必须有创建日志的权限 log_format语法：log_format name format [format ...] 默认值：log_format combined &quot;...&quot; 使用字段：http、server 变量名 含义 $body_bytes_sent 减去应答头后传送给客户端的字节数 $bytes_sent 传送给客户端的字节数 $connection 连接数 $msec 正在写入日志条目的当前时间 $pipe 如果请求为管道的 request_length 请求主体的长度 $request_time 从一个请求发出到Nginx工作的时间 $status 应答的状态 $time_local 写入普通日志格式的当地时间 事件模块 use connection use语法：use [ kqueue | rtsig | epoll | /dev/poll | select | poll | eventport] connections语法：worker_connections 最大连接数 = worker_processes * worker_connections // 反向代理环境下 最大连接数 = worker_processes * worker_connections / 4 原因：浏览器默认打开两个连接到服务器，Nginx使用来自相同地址池的fds与前后端相连接 HTTP模块基本配置Nginx的HTTP配置主要包括三个区块，结构如下 alias语法：alias file-path | directory-path; 使用字段：location alias是替换路径，而root是追加路径，将location后的路径追到root之后 12345location /i/ &#123; alias /spool/w3/images/&#125;请求 /i/top.gif 将返回这个文件 &quot;/spool/w3/images/top.gif&quot;。 error_page语法：error_page code [ code ... ] [ = | = answer-code ] uri | @named_location 使用字段：http、server、location、location中的if字段 这个参数可以为错误代码指定相应的错误页面 1234error_page 4040 /404.html;error_page 502 503 504 /50x.html;error_page 403 http://example.com/forbidden.html;error_page 404 = @fetch; 同样，你也可以将原有响应代码修改为另一个响应代码 12error_page 404 = 200 /empty.gif;error_page 404 = 403 /forbindden.gif; internal语法：internal 使用字段：location internal指定某个location只能被内部的请求调用，外部的调用会返回404. location区段通过指定模式来与客户端请求的URI相匹配 location [=|~|~*|^~|@] pattern { # ... } 没有修饰符，表示必须以指定的模式开始123456server &#123; server_name destiny.com; location /abc &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 http://destiny.com/abc/ http://destiny.com/abcde =，表示必须与指定的模式精准匹配123456server &#123; server_name destiny.com; location = /abc &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) 不能匹配 http://destiny.com/abc/ http://destiny.com/abcde ~，表示指定的正则表达式要区分大小写 ~表示按照正则表达式的语法与pattern进行匹配 123456server &#123; server_name destiny.com; location ~ ^/abc$ &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) 不能匹配 http://destiny.com/ABC/ http://destiny.com/abc/ http://destiny.com/abcde ~*，表示正则表达式不区分大小写123456server &#123; server_name destiny.com; location ~* ^/abc$ &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) http://destiny.com/ABC/ 不能匹配 http://destiny.com/abc/ http://destiny.com/abcde ^~，表示正则表达式不区分大小写 类似于无修饰符的行为，也是以指定模式开始，但如果模式匹配，那么久停止搜索其他模式了。 @，定义命名location区段，这些区段客户端不能访问，只可以由内部产生的请求来访问多个location的优先级问题 带有=的精准匹配 没有修饰符的精准匹配 正则表达式按照定义顺序 ^~的开头匹配 ~或~* 修饰符 没有修饰符的，如果指定字符串与URI开头匹配 Http反向代理模块 Nginx通常被用作后端服务器的反向代理，这样就可以很方便的实现动静分离，以及负载均衡，从而大大提高服务器的处理能力。 Http Proxy模块，功能很多，最常用的是proxy_pass 如果要使用proxy_cache的话，需要集成第三方的ngx_cache_purge模块，用来清除指定的URL缓存。 反向代理 普通的正向代理，为客户端提供代理服务 123456graph TDA[客户端]--&gt;|发出请求|B&#123;代理&#125;B --&gt; |代理访问并返回响应|AB --&gt; |代理访问|C[服务器A]B --&gt; |代理访问|D[服务器B]B --&gt; |代理访问|E[服务器C] 反向代理，为服务端提供代理服务 123456graph TDA[客户端A]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;B[客户端B]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;C[客户端C]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;D --&gt; |代理客户端访问|E[服务器]E --&gt; |返回请求|D Http代理模块这个模块可以转发请求到其他的服务器 location / { proxy_pass http://localhost:8080; # 转发指令，把当前的指令转发到指定路径 proxy_set_header X-Real-IP $remote_addr; # 设置http请求头 } proxy_buffer_size设置从被代理服务器(真实服务器)读取的第一部分应答的缓冲区大小 语法：proxy_buffer_size the_size通常情况下这部分应答中包含一个小的应答头 proxy_buffering为后端服务器启用响应缓冲 如果启用缓冲，Nginx假设被代理服务器能够非常快的传递响应，并将其放入缓冲区 如果禁用缓冲，从后端传来的应答将立即被传送到客户端 语法：proxy_buffering on|off proxy_pass设置被代理服务器的地址和被映射的URL 地址可以使用主机名或IP+端口号的形式]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
