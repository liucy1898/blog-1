<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Netty(1)基本概念]]></title>
    <url>%2Fblog%2F2018%2F06%2F24%2FNetty-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[1. Netty 架构设计Netty应用中必不可少的组件： 组件 作用 Bootstrap / ServerBootstrap 一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。 EventLoop 为 Channel 处理 IO 操作，一个 EventLoop 可以为多个 Channel 服务。 EventLoopGroup 包含多个 EventLoopGroup Channel 一个 Socket 连接，或者其他和 IO 操作相关的组件，它和 EventLoop 一起用来参与 IO 处理。 Future / ChannelFuture 在 Netty 中所有的 IO 操作都是异步的，因此，你不能立刻得知消息是否被正确处理，但是我们可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures ,他们可以注册一个监听，当操作执行成功或失败时监听会自动触发。总之，所有的操作都会返回一个 ChannelFuture。 ChannelInitializer 当一个链接建立时，我们需要知道怎么来接收或者发送数据，当然，我们有各种各样的 Handler 实现来处理它，那么 ChannelInitializer 便是用来配置这些 Handler ，它会提供一个 ChannelPipeline，并把 Handler 加入到 ChannelPipeline。 ChannelHandler 为了支持各种协议和处理数据的方式，便诞生了 Handler 组件。Handler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。 ChannelPipeline 一个 Netty 应用基于 ChannelPipeline 机制，这种机制需要依赖于 EventLoop 和 EventLoopGroup ，因为它们三个都和事件或者事件处理相关 1.1 Netty 是如何处理连接请求和业务逻辑Netty是一个非阻塞的、事件驱动的、网络编程框架。 一个Channel会对应一个EventLoop，而一个EventLoop会对应着一个线程，也就是说，仅有一个线程在负责一个Channel的IO操作。 当一个连接到达，Netty会注册一个channel，然后EventLoopGroup会分配一个EventLoop绑定到这个channel,在这个channel的整个生命周期过程中，都会由绑定的这个EventLoop来为它服务，而这个EventLoop就是一个线程。 EventLoopGroup 和 EventLoop 的关系 1.2 BootsStrapping 我们利用 BootsStrapping 来配置 netty 应用，它有两种类型，一种用于 Client 端：BootsStrap，另一种用于Server端：ServerBootstrap，要想区别如何使用它们，你仅需要记住一个用在 Client 端，一个用在 Server 端。下面我们来详细介绍一下这两种类型的区别： ServerBootstrap 用于 Server 端，通过调用 bind() 方法来绑定到一个端口监听连接； Bootstrap 用于 Client 端，需要调用 connect() 方法来连接服务器端，但我们也可以通过调用 bind() 方法返回的 ChannelFuture 中获取 Channel 去 connect 服务器端。 客户端的 Bootstrap 一般用一个 EventLoopGroup，而服务器端的 ServerBootstrap 会用到两个（这两个也可以是同一个实例）。为何服务器端要用到两个 EventLoopGroup 呢？这么设计有明显的好处，如果一个 ServerBootstrap 有两个 EventLoopGroup，那么就可以把第一个 EventLoopGroup 用来专门负责绑定到端口监听连接事件，而把第二个 EventLoopGroup 用来处理每个接收到的连接。 1.3 ChannelHandler应用程序中用到的最多的应该就是ChannelHandler，我们可以这么想象，数据在一个ChannelPipeline中流动，而ChannelHandler便是其中的一个个的小阀门，这些数据都会经过每一个ChannelHandler并且被它处理。 一个ChannelPipeline可以把两种Handler（ChannelInboundHandler和ChannelOutboundHandler）混合在一起，当一个数据流进入ChannelPipeline时，它会从ChannelPipeline头部开始传给第一个ChannelInboundHandler，当第一个处理完后再传给下一个，一直传递到管道的尾部。与之相对应的是，当数据被写出时，它会从管道的尾部开始，先经过管道尾部的“最后”一个ChannelOutboundHandler，当它处理完成后会传递给前一个ChannelOutboundHandler。 数据在各个Handler之间传递，这需要调用方法中传递的ChanneHandlerContext来操作， 在netty的API中提供了两个基类分ChannelOutboundHandlerAdapter和ChannelOutboundHandlerAdapter，他们仅仅实现了调用ChanneHandlerContext来把消息传递给下一个Handler，因为我们只关心处理数据，因此我们的程序中可以继承这两个基类来帮助我们做这些，而我们仅需实现处理数据的部分即可。 我们知道InboundHandler和OutboundHandler在ChannelPipeline中是混合在一起的，那么它们如何区分彼此呢？其实很容易，因为它们各自实现的是不同的接口，对于inbound event，Netty会自动跳过OutboundHandler,相反若是outbound event，ChannelInboundHandler会被忽略掉。 当一个ChannelHandler被加入到ChannelPipeline中时，它便会获得一个ChannelHandlerContext的引用，而ChannelHandlerContext可以用来读写Netty中的数据流。因此，现在可以有两种方式来发送数据，一种是把数据直接写入Channel，一种是把数据写入ChannelHandlerContext，它们的区别是写入Channel的话，数据流会从Channel的头开始传递，而如果写入ChannelHandlerContext的话，数据流会流入管道中的下一个Handler。 1.4 Encoders, Decoders and Domain LogicEncoders和Decoders因为我们在网络传输时只能传输字节流，因此，才发送数据之前，我们必须把我们的message型转换为bytes，与之对应，我们在接收数据后，必须把接收到的bytes再转换成message。我们把bytes to message这个过程称作Decode(解码成我们可以理解的)，把message to bytes这个过程成为Encode。 Netty中提供了很多现成的编码/解码器，我们一般从他们的名字中便可知道他们的用途，如ByteToMessageDecoder、MessageToByteEncoder，如专门用来处理Google Protobuf协议的ProtobufEncoder、 ProtobufDecoder。 我们前面说过，具体是哪种Handler就要看它们继承的是InboundAdapter还是OutboundAdapter，对于Decoders,很容易便可以知道它是继承自ChannelInboundHandlerAdapter或 ChannelInboundHandler，因为解码的意思是把ChannelPipeline传入的bytes解码成我们可以理解的message（即Java Object），而ChannelInboundHandler正是处理Inbound Event，而Inbound Event中传入的正是字节流。Decoder会覆盖其中的“ChannelRead()”方法，在这个方法中来调用具体的decode方法解码传递过来的字节流，然后通过调用ChannelHandlerContext.fireChannelRead(decodedMessage)方法把编码好的Message传递给下一个Handler。与之类似，Encoder就不必多少了。 Domain Logic其实我们最最关心的事情就是如何处理接收到的解码后的数据，我们真正的业务逻辑便是处理接收到的数据。Netty提供了一个最常用的基类SimpleChannelInboundHandler，其中T就是这个Handler处理的数据的类型（上一个Handler已经替我们解码好了），消息到达这个Handler时，Netty会自动调用这个Handler中的channelRead0(ChannelHandlerContext,T)方法，T是传递过来的数据对象，在这个方法中我们便可以任意写我们的业务逻辑了。 2. Hello World2.1 依赖12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.0.21.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.2 Server 端 ChannelHandler我们不需要使每一个 InboundChannel 继承自 ChannelInboundHandler，因为直接继承的话需要实现 ChannelInboundHandler 中的所有接口，在一般的 Channel 中没必要这么做，只需要继承 ChannelInboundHandelAdapter，继承它的适配器就可以。 需要实现几个重要的方法，包括读取方法 channelRead(ChannelHandlerContext, ctx) 和异常处理方法 exceptionCaught(ChannelHandlerContext ctx, Throwable cause) 即可。 123456789101112131415161718192021public class HelloWorldServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("HelloWorldServerHandler.channelActive"); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("HelloWorldServerHandler.channelRead"); System.out.println(ctx.channel().remoteAddress().toString() + "-&gt; server: " + msg.toString()); ctx.write("server write: " + msg); ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 2.3 服务端需要一个 ServerBootStrap，用于引导 Netty Server 端的初始化工作。我们需要指定它的 transports，是 NIO还 是 OIO ,还需要指定端口号，安装 server 端的处理器，也就是我们之前写的 HelloWorldServerHandler ，还有一些 Option 的配置。 123456789101112131415161718192021222324252627282930313233343536373839public class HelloWorldServer &#123; private int port; public HelloWorldServer(int port) &#123; this.port = port; &#125; public void start() &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap().group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class).localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() .addLast("decoder", new StringDecoder()) .addLast("encoder", new StringEncoder()) .addLast(new HelloWorldServerHandler()); &#125; &#125;).option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture future = serverBootstrap.bind(port).sync(); future.channel().write("Hello Netty Client, I am a Server"); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; int port = 9527; new HelloWorldServer(port).start(); &#125;&#125; 2.4 Client 端 ChannelHandler整体与 HelloWorldServerHandler 类似 123456789101112131415161718public class HelloWorldClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("HelloWorldClientHandler.channelActive"); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("HelloWorldClientHandler.channelRead: ==&gt;" + msg); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 2.5 Client 端12345678910111213141516171819202122232425262728public class HelloWorldClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() .addLast("decoder", new StringDecoder()) .addLast("encoder", new StringEncoder()) .addLast(new HelloWorldClientHandler()); &#125; &#125;); ChannelFuture future = bootstrap.connect("127.0.0.1", 9527).sync(); future.channel().writeAndFlush("Hello Netty Server, I am a common client"); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 分别启动 Server 端 和 Client 端 即可看到运行结果。 具体过程如下： HelloWorldServer 启动，完成 ChannelHandler 的初始化，监听指定端口，在 ChannelFuture future = serverBootstrap.bind(port).sync() 处进行阻塞； HelloWorldClient 启动，完成 ChannelHandler 的初始化，并向 127.0.0.1:9527 发送一条信息，同时阻塞等待返回结果； HelloWorldServerHandler 读取到 HelloWorldClient 发送的消息，并写入自己的消息 ctx.write(&quot;server write: &quot; + msg) HelloWorldClientHandler 读取到 HelloWorldServerHandler； 发送的消息，打印到控制台。 3. Hello World 结构图 4. ChannelHandler、ChannelHandlerContext 和 ChannelPipeline ChannelInboundHandlerAdapter ChannelOutboundHandlerAdapter 我们平时继承的最多的就是 ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter ，这两个不是接口也不是抽象类，所以我们可以仅仅重写我们需要的方法，没有必须要实现的方法 ChannelHandler, ChannelHandlerContext , ChannelPipeline 这三者的关系很特别，相辅相成，一个 ChannelPipeline 中可以有多个 ChannelHandler 实例，而每一个 ChannelHandler 实例与 ChannelPipeline 之间的桥梁就是 ChannelHandlerContext 实例 如果能够获取到 ChannelHandlerContext 实例的话，就可以获取到需要的一切。同时，可以根据 ChannelHandlerContext 执行 ChannelHandler 中的方法 4.1 示例 首先新增两个 ChannelHandler 修改 HelloWorldClient 中的代码 4.1.1 BaseClient1Handler12345678910111213public class BaseClient1Handler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("BaseClient1Handler.channelActive"); ctx.fireChannelActive(); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("BaseClient1Handler.channelInactive"); &#125;&#125; 4.1.2 BaseClient2Handler1234567public class BaseClient2Handler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("BaseClient2Handler.channelActive"); &#125;&#125; 4.1.3 HelloWorldClient12345678910111213141516171819202122232425262728293031public class HelloWorldClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() .addLast("decoder", new StringDecoder()) .addLast("encoder", new StringEncoder())// .addLast(new HelloWorldClientHandler()); .addLast(new BaseClient1Handler()) .addLast(new BaseClient2Handler()); &#125; &#125;); ChannelFuture future = bootstrap.connect("127.0.0.1", 9527).sync(); future.channel().writeAndFlush("Hello Netty Server, I am a common client"); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 4.1.4 执行结果 此时看到，BaseClient1Handler 和 BaseClient2Handler 都执行了 channelActive() 方法。 但如果把 BaseClient1Handler 的 ctx.fireChannelActive() 去掉，那么只会有 BaseClient1Handler 执行该方法 也就是说如果一个 channelPipeline 中有多个 channelHandler 时，且这些 channelHandler 中有同样的方法时， 例如这里的 channelActive 方法，只会调用处在第一个的 channelHandler 中的 channelActive 方法， 如果你想要调用后续的 channelHandler 的同名的方法就需要调用以 &quot;fire&quot; 为开头的方法了，这样做很灵活 这样设计的优点： 每一个 handler 只需要关注自己要处理的方法，如果你不关注 channelActive 方法时，你自定义的 channelhandler 就不需要重写 channelActive 方法; 异常处理，如果 exceptionCaught 方法每个 handler 都重写了，只需有一个类捕捉到然后做处理就可以了，不需要每个 handler 都处理一遍; 灵活性，也许左侧第一个 ChannelHandler 根本不需要管理某个业务逻辑，但是从第二个 ChannelHandler 就需要关注处理某个业务需求了，那么就可以很灵活地从第二个 ChannelHandler 开始处理业务，不需要从channel中的第一个 ChannelHandler 开始处理. 5. ByteBuf网络传输的载体是 byte, 这是任何框架谁也逃脱不了的一种规定. JAVA 的 NIO 提供了 ByteBuffer, 用来完成这项任务. 读的时候，可读的区域是下标区间是 [readerIndex，writeIndex) ，可写区间的是 [writerIndex,capacity-1] ，但是 discardable 这段区间就会变得相对无用，既不能读，也不能写 从内存分配角度看，ByteBuf 可以分为两类： 堆内存字节缓冲区: 特点是内存的分配和回收速度快，可以被 JVM 自动回收，缺点是如果进行 Socket 的 I/O 读写，需要额外做一次内存复制，将堆内存对应的缓冲区复制到内核 Channel 中，性能会有一定程度的下降。 直接内存字节缓冲区: 非堆内存，它在堆外进行内存分配，相比于堆内存，它的分配和回收速度会慢一些，但是将它写入或者从 Socket Channel 中读取时，由于少了一次内存复制，速度比堆内存快。 ByteBuf 最佳实践: 在 I/O 通信线程的读写缓冲区使用 DirectByteBuf, 后端业务消息的编码模块使用 HeapByteBuf, 这样组合可以达到性能最优.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo踩坑总结]]></title>
    <url>%2Fblog%2F2018%2F05%2F20%2Fdubbo%E8%B8%A9%E5%9D%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[2. 注册服务 IP 解析异常在使用 dubbo 注册服务的时候遇到了 IP 解析错误导致无法正常访问的问题。 在实际问题中，consumer 无法连接到 provider 的服务。其具体表现为： 本机的 IP 设置为 192.168.1.116，但 dubbo 绑定的却是 dubbo://30.250.11.135:20880，本机 ping 30.250.11.135 提示连接超时，provider 可以启动成功，但是 consumer 无法连接，提示连接超时。 2.1 复现场景2.1.1 provider1234567891011121314151617181920212223&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd "&gt; &lt;!-- 具体的实现 bean --&gt; &lt;bean id="provider" class="org.destiny.dubbo.impl.ProviderImpl"/&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="demo-provider"/&gt; &lt;!-- 使用 Zookeeper 注册中心暴露服务地址 --&gt; &lt;dubbo:registry address="zookeeper://10.211.55.4:2181"/&gt; &lt;!-- 用 dubbo 协议在 20880 端口暴露服务 --&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt; &lt;!-- 增加暴露远程服务配置，写操作可以设置 retries=0 避免重复调用 SOA 服务 --&gt; &lt;dubbo:service retries="0" interface="org.destiny.dubbo.Provider" ref="provider"/&gt;&lt;/beans&gt; provider 的启动日志如下： 2.1.2 consumer12345678910111213141516171819&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd "&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="demo-consumer"/&gt; &lt;!-- 使用 Zookeeper 注册中心暴露服务地址 --&gt; &lt;dubbo:registry address="zookeeper://10.211.55.4:2181"/&gt; &lt;dubbo:protocol name="dubbo" port="20880"/&gt; &lt;!-- 生成远程代理，可以像本地使用 bean 一样使用 demoService，检查级联依赖默认为 true，当有依赖服务的时候，需要根据需求进行设置 --&gt; &lt;dubbo:reference id="consumer" interface="org.destiny.dubbo.Provider" check="false"/&gt;&lt;/beans&gt; consumer 启动日志如下： 2.2 定位问题 在 provider 启动时，定位到日志中第一次出现 30.250.11.135 的的位置： current host 然后全局搜索 current host，定位到对应源码：com.alibaba.dubbo.common.logger.support.FailsafeLogger 怀疑 NetUtils.getLocalHost() 获取到的 IP 就是 30.250.11.135 单独执行 System.out.println(NetUtils.getLocalHost())，发现结果确实是 30.250.11.135 此时结果已经很明确了，是 NetUtils.getLocalHost() 返回的 IP 地址已经错误，导致上面的问题发生。 2.3 分析问题通过阅读 dubbo 相关部分源码，其大致运行过程如下： dubbo 在获取本地 IP 的时候，先调用 NetUtils.getLocalHost()，如果该方法返回一个合法的地址，则直接认为是一本地 IP 的地址。 如果 NetUtils.getLocalHost() 没有返回合法地址，则会遍历本地所有网卡，并返回第一个合法的 IP 作为本地 IP。 而问题就出在 NetUtils.getLocalHost() 返回的并不是真正的本机 IP，却被 dubbo 误认为正确。 NetUtils.getLocalHost() 的原理是通过获取本机的 hostname，然后对此 hostname 做解析，从而获取 IP 地址； 而如果在本机的 /etc/hosts/ 文件中对这个主机名指向了一个错误的 IP 地址，那么 NetUtils.getLocalHost() 就会返回这个错误的 IP 地址； 如果 hostname 是到 DNS 中去解析的，而碰巧 DNS 也是错误的，那么返回的同样是错误的 IP。 因此就可以解释我们遇到的问题了： provider 实际上是运行在 A 地址上，但是 dubbo 检测到本地的 IP 是 B，然后在 Zookeeper 上注册自己服务地址的时候，使用的是 B 地址，那么当 consumer 连接到 Zookeeper 上的时候，查询到 provider 是在 B 地址上，但显然 B 地址上没有该服务，甚至根本无法连接到。因此就出现了该问题。 这个地址就是一开始被 dubbo 意外解析到的 30.250.11.135。 2.4 解决问题 先检查 /etc/hosts 文件中设置的 A 地址指向哪里 再检查 DNS 解析出的地址 /etc/hosts 文件修改前： 向 /etc/hosts 文件中追加 destiny 127.0.0.1 /etc/hosts 文件修改后： 2.5 引申 —— 如何在 Java 代码中正确的读取本地 IP 地址目前最普遍的方法是使用 `InetAddress.getLocalHost().getHostAddress()` 获取 但该方法只能获取简单网络环境下的 IP 地址 如果当前的网络环境比较复杂，存在多个网卡，则会被忽视 比如列出我当前本机的 ifconfig 命令直接结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374$ ifconfiglo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384 options=1203&lt;RXCSUM,TXCSUM,TXSTATUS,SW_TIMESTAMP&gt; inet 127.0.0.1 netmask 0xff000000 inet6 ::1 prefixlen 128 inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1 nd6 options=201&lt;PERFORMNUD,DAD&gt;gif0: flags=8010&lt;POINTOPOINT,MULTICAST&gt; mtu 1280stf0: flags=0&lt;&gt; mtu 1280XHC20: flags=0&lt;&gt; mtu 0en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ether 98:01:a7:a2:9a:c1 inet6 fe80::1ca6:7ed1:3b63:235f%en0 prefixlen 64 secured scopeid 0x5 inet 192.168.1.103 netmask 0xffffff00 broadcast 192.168.1.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activep2p0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 2304 ether 0a:01:a7:a2:9a:c1 media: autoselect status: inactiveawdl0: flags=8943&lt;UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1484 ether ba:98:20:03:2e:f7 inet6 fe80::b898:20ff:fe03:2ef7%awdl0 prefixlen 64 scopeid 0x7 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activeen1: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether 6a:00:02:3e:5e:80 media: autoselect &lt;full-duplex&gt; status: inactiveen2: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether 6a:00:02:3e:5e:81 media: autoselect &lt;full-duplex&gt; status: inactivebridge0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=63&lt;RXCSUM,TXCSUM,TSO4,TSO6&gt; ether 6a:00:02:3e:5e:80 Configuration: id 0:0:0:0:0:0 priority 0 hellotime 0 fwddelay 0 maxage 0 holdcnt 0 proto stp maxaddr 100 timeout 1200 root id 0:0:0:0:0:0 priority 0 ifcost 0 port 0 ipfilter disabled flags 0x2 member: en1 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 8 priority 0 path cost 0 member: en2 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 9 priority 0 path cost 0 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: &lt;unknown type&gt; status: inactiveutun0: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 2000 inet6 fe80::a5b9:4c1f:b4b8:9414%utun0 prefixlen 64 scopeid 0xb nd6 options=201&lt;PERFORMNUD,DAD&gt;utun1: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380 inet6 fe80::3de1:6926:1140:2956%utun1 prefixlen 64 scopeid 0xc inet6 fdd5:8db9:2302:60f0:3de1:6926:1140:2956 prefixlen 64 nd6 options=201&lt;PERFORMNUD,DAD&gt;utun2: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380 inet6 fe80::4568:978c:85d3:ecd9%utun2 prefixlen 64 scopeid 0xd nd6 options=201&lt;PERFORMNUD,DAD&gt;vnic0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=3&lt;RXCSUM,TXCSUM&gt; ether 00:1c:42:00:00:08 inet 10.211.55.2 netmask 0xffffff00 broadcast 10.211.55.255 media: autoselect status: activevnic1: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=3&lt;RXCSUM,TXCSUM&gt; ether 00:1c:42:00:00:09 inet 10.37.129.2 netmask 0xffffff00 broadcast 10.37.129.255 media: autoselect status: active 可以看到有很多类型的网络接口(network interfaces)： loopback 地址: 最常见的就是 127.0.0.1，即本地回环地址，只对本机可见，一般用于调试。 site local address 地址: private 私有地址，属于本地组织内部访问，只能在本地局域网可见，同样 10.xxx.xxx.xxx 等也属于私有地址 link local 地址: 属于连接本地地址，在单独网段可用 UP BROADCAST RUNNING MULTICAST 地址：如果网卡信息中包含 UP BROADCAST RUNNING MULTICAST，则支持广播和组播 除此之外的地址都是点对点可用的刚开的 IPv4 地址 刚才提到的 InetAddress.getLocalHost().getHostAddress() 一般情况下只会在如下两种情况中返回正确结果： 只使用 wifi 只使用网线 而在复杂环境下，获取 IP 地址最好能够遍历所有的网卡，然后依次筛选，最终找到符合条件的网卡的 IP：1234567891011121314151617181920212223242526272829303132public static InetAddress getLocalHostLANAddress() throws SocketException &#123; try &#123; InetAddress candidateAddress = null; // 遍历所有网络接口 Enumeration&lt;NetworkInterface&gt; networkInterfaces = NetworkInterface.getNetworkInterfaces(); while (networkInterfaces.hasMoreElements()) &#123; NetworkInterface networkInterface = networkInterfaces.nextElement(); // 在所有的接口下再遍历 IP Enumeration&lt;InetAddress&gt; inetAddresses = networkInterface.getInetAddresses(); while (inetAddresses.hasMoreElements()) &#123; InetAddress inetAddress = inetAddresses.nextElement(); if (!inetAddress.isLoopbackAddress()) &#123; // 排除 loopback 类型地址 if (inetAddress.isSiteLocalAddress()) &#123; // 如果是 site-local 地址，直接返回 return inetAddress; &#125; else if (candidateAddress == null) &#123; // 如果是 site-local 地址未被发现，先记录候选地址 candidateAddress = inetAddress; &#125; &#125; &#125; &#125; if (candidateAddress != null) &#123; return candidateAddress; &#125; &#125;catch (Exception e) &#123; System.err.println("获取本机 IP 失败"); e.printStackTrace(); &#125; return null;&#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>踩坑总结</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene(二) —— 搭建简易搜索引擎]]></title>
    <url>%2Fblog%2F2018%2F05%2F07%2FLucene-%E4%BA%8C-%E2%80%94%E2%80%94-%E6%90%AD%E5%BB%BA%E7%AE%80%E6%98%93%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[1. 前期准备1.1 爬取数据 爬取网站数据，为实现搜索引擎做准备 wget -o /tmp/wget.log -P /root/data --no-parent --no-verbose -m -D destiny -N --convert-links --random-wait -A html,HTML https://destinywang.github.io/blog/ 将 本人个人博客 爬取的结果为： 放在浏览器中展示的效果为： 在 html 文件中，实际的文件格式如下图所示： 以此类推，可以多爬几个 HTML 文件。 1.2 HTML parser在搜索中，我们往往更关注文字部分，而对于 HTML 标签最好能够予以过滤，为此，我们使用 jericho 进行 HTML 过滤 添加依赖：123456&lt;!-- https://mvnrepository.com/artifact/net.htmlparser.jericho/jericho-html --&gt;&lt;dependency&gt; &lt;groupId&gt;net.htmlparser.jericho&lt;/groupId&gt; &lt;artifactId&gt;jericho-html&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt;&lt;/dependency&gt; 1.3 IKAnalyzer 中文分词器之前的示例中，使用的是默认的StandardAnalyzer分词器，不能有效的进行中文分词，下面演示下如何在Lucene5.0中使用IKAnalyzer分词器。 首先下载IKAnalyzer分词器源码，IKAnalyzer分词器源码托管在OSChina 不过目前项目已经停止更新了，IKAnalyzer 由于已经停止更新，所以并不支持 Lucene5，这里需要对源码做一些修改，否则启动时会抛出如下异常： 1.3.1 下载 IKAnalyzer 源码并打开1$ git clone git@gitee.com:wltea/IK-Analyzer-2012FF.git 然后在 IDE 中打开 1.3.2 修改 IKAnalyzer 源码由于Lucene5.0 API上有些变化，我们需要对IK源码做些修改 1.3.2.1 IKTokenizer 类第一处需要修改的就是IKTokenizer类，在其构造函数里把 //super(in); 这句注释掉即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * IK 中文分词 版本 5.0.1 * IK Analyzer release 5.0.1 * * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * * 源代码由林良益(linliangyi2005@gmail.com)提供 * 版权声明 2012，乌龙茶工作室 * provided by Linliangyi and copyright 2012 by Oolong studio * * */ package org.wltea.analyzer.lucene; import java.io.IOException; import java.io.Reader; import org.apache.lucene.analysis.Tokenizer; import org.apache.lucene.analysis.tokenattributes.CharTermAttribute; import org.apache.lucene.analysis.tokenattributes.OffsetAttribute; import org.apache.lucene.analysis.tokenattributes.TypeAttribute; import org.apache.lucene.util.Version; import org.wltea.analyzer.core.IKSegmenter; import org.wltea.analyzer.core.Lexeme; /** * IK分词器 Lucene Tokenizer适配器类 * 兼容Lucene 4.0版本 */ public final class IKTokenizer extends Tokenizer &#123; //IK分词器实现 private IKSegmenter _IKImplement; //词元文本属性 private final CharTermAttribute termAtt; //词元位移属性 private final OffsetAttribute offsetAtt; //词元分类属性（该属性分类参考org.wltea.analyzer.core.Lexeme中的分类常量） private final TypeAttribute typeAtt; //记录最后一个词元的结束位置 private int endPosition; private Version version = Version.LATEST; /** * Lucene 4.0 Tokenizer适配器类构造函数 * @param in * @param useSmart */ public IKTokenizer(Reader in , boolean useSmart)&#123; //super(in); offsetAtt = addAttribute(OffsetAttribute.class); termAtt = addAttribute(CharTermAttribute.class); typeAtt = addAttribute(TypeAttribute.class); _IKImplement = new IKSegmenter(input , useSmart); &#125; /* (non-Javadoc) * @see org.apache.lucene.analysis.TokenStream#incrementToken() */ @Override public boolean incrementToken() throws IOException &#123; //清除所有的词元属性 clearAttributes(); Lexeme nextLexeme = _IKImplement.next(); if(nextLexeme != null)&#123; //将Lexeme转成Attributes //设置词元文本 termAtt.append(nextLexeme.getLexemeText()); //设置词元长度 termAtt.setLength(nextLexeme.getLength()); //设置词元位移 offsetAtt.setOffset(nextLexeme.getBeginPosition(), nextLexeme.getEndPosition()); //记录分词的最后位置 endPosition = nextLexeme.getEndPosition(); //记录词元分类 typeAtt.setType(nextLexeme.getLexemeTypeString()); //返会true告知还有下个词元 return true; &#125; //返会false告知词元输出完毕 return false; &#125; /* * (non-Javadoc) * @see org.apache.lucene.analysis.Tokenizer#reset(java.io.Reader) */ @Override public void reset() throws IOException &#123; super.reset(); _IKImplement.reset(input); &#125; @Override public final void end() &#123; // set final offset int finalOffset = correctOffset(this.endPosition); offsetAtt.setOffset(finalOffset, finalOffset); &#125; &#125; 1.3.2.2 IKAnalyzercreateComponents()方法是继承Luecene的Analyzer接口的 由于Lucene5.0里把createComponents()方法的第二个参数去掉了 所以需要对该方法做同样的修改 而上文中真正抛出异常的地方也在于此。 123456789/** * 重载Analyzer接口，构造分词组件 */ @Override protected TokenStreamComponents createComponents(String text) &#123; Reader reader = new BufferedReader(new StringReader(text)); Tokenizer _IKTokenizer = new IKTokenizer(reader , this.useSmart()); return new TokenStreamComponents(_IKTokenizer); &#125; 1.3.3 将依赖安装到本地仓库1$ mvn install:install-file -DgroupId=org.wltea.analyzer -DartifactId=IKAnalyzer -Dversion=5.0 -Dpackaging=jar -Dfile=/User/destiny/.m2/repository/IKAnalyzer-5.0.jar 1.3.4 导入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.wltea.analyzer&lt;/groupId&gt; &lt;artifactId&gt;IKAnalyzer&lt;/artifactId&gt; &lt;version&gt;5.0&lt;/version&gt; &lt;/dependency&gt; 2. 核心代码2.1 HTML 对象在搜索结果中，返回给用户的主要信息包括： 文档标题 文档正文（缩略信息） URL 所以对应的实体类：123456789101112131415161718192021222324252627282930public class HtmlBean &#123; private String title; // 标题 private String content; // 正文 private String url; // URL public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125;&#125; 2.2 HTML 转换对象由于爬取的原始数据中，HTML 正文含有大量的标签，对搜索而言没有意义，因此使用 jericho 进行过滤。 12345678910111213141516171819202122232425public class HtmlBeanUtil &#123; /** * 将文件转换为 HtmlBean 页面对象 * @param file * @return */ public static HtmlBean parseHtml(File file) &#123; // 解析 HTML HtmlBean htmlBean = new HtmlBean(); try &#123; Source source = new Source(file); // 取第一个标题元素 Element firstElement = source.getFirstElement(HTMLElementName.TITLE); htmlBean.setTitle(firstElement.getTextExtractor().toString()); htmlBean.setContent(source.getTextExtractor().toString()); htmlBean.setUrl("http://" + file.getAbsolutePath()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return htmlBean; &#125;&#125; 2.3 创建索引1234567891011121314151617181920212223242526272829303132333435363738394041public class LuceneService &#123; public static final String INDEX_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/index"; public static final String DATA_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/html"; public void createIndex() &#123; try &#123; // 目录对象，需要由 Path 进行初始化 Directory directory = FSDirectory.open(Paths.get(INDEX_DIR)); // 创建分词器 Analyzer analyzer = new StandardAnalyzer(); // 由分词器对 IndexWriterConfig 进行初始化 IndexWriterConfig indexWriterConfig = new IndexWriterConfig(analyzer); indexWriterConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND); IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig); File file = new File(DATA_DIR); // 用递归的方式获取指定路径的文件列表(org.apache.commons.io) Collection&lt;File&gt; files = FileUtils.listFiles(file, TrueFileFilter.INSTANCE, TrueFileFilter.INSTANCE); // 将每个文件转换成 Document 对象 for (File file1 : files) &#123; System.out.println("file: " + file1.getName()); HtmlBean htmlBean = HtmlBeanUtil.parseHtml(file1); Document document = new Document(); document.add(new StringField("title", htmlBean.getTitle(), Field.Store.YES)); document.add(new TextField("content", htmlBean.getContent(), Field.Store.YES)); document.add(new StringField("url", htmlBean.getUrl(), Field.Store.YES)); indexWriter.addDocument(document); &#125; indexWriter.close(); &#125; catch (Exception e) &#123; System.err.println(e.getMessage()); &#125; &#125;&#125; 2.4 搜索123456789101112131415161718192021222324252627282930313233@RequestMapping("/search/&#123;keyword&#125;")public List&lt;HtmlBean&gt; search(@PathVariable(value = "keyword") String keyword) &#123; try &#123; Directory directory = FSDirectory.open(Paths.get(INDEX_DIR)); IndexReader indexReader = DirectoryReader.open(directory); IndexSearcher indexSearcher = new IndexSearcher(indexReader); // 创建中文分词器 Analyzer analyzer = new IKAnalyzer(); // 多 field 查询 MultiFieldQueryParser multiFieldQueryParser = new MultiFieldQueryParser(new String[]&#123;"title", "content"&#125;, analyzer); Query query = multiFieldQueryParser.parse(keyword); // 搜索前 10 个匹配度最高的文档 TopDocs topDocs = indexSearcher.search(query, 10); // 组装查询结果 List&lt;HtmlBean&gt; htmlBeanList = new ArrayList&lt;&gt;(); for (ScoreDoc scoreDoc : topDocs.scoreDocs) &#123; int docId = scoreDoc.doc; Document document = indexReader.document(docId); HtmlBean htmlBean = new HtmlBean(); htmlBean.setTitle(document.get("title")); htmlBean.setContent(document.get("content")); htmlBean.setUrl(document.get("url")); htmlBeanList.add(htmlBean); &#125; return htmlBeanList; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return null;&#125; 3. 使用结果]]></content>
      <categories>
        <category>Luence</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene(一) —— 快速入门]]></title>
    <url>%2Fblog%2F2018%2F05%2F05%2FLucene-%E4%B8%80-%E2%80%94%E2%80%94-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1. 搜索引擎组件1.1 索引组件为了快速搜索大量的文本，必须针对文本建立索引，将文本内容转换成能够进行快速搜索的格式。 这个过程就叫做索引操作(indexing)，输出就是索引(index) 1.1.1 获取内容使用网络爬虫或者蜘蛛程序来搜索和界定需要索引的内容。 1.1.2 建立文档获取原始内容之后，就需要对内容进行索引，首先必须将内容转换成文档，以供搜索引擎使用。 文档主要包括几个带值的域，比如标题、正文、摘要、作者和链接(URL)。 然后需要将原始内容中的文本提取出来写入各个文档。 1.1.3 文档分析搜索引擎不能直接对文本进行索引，而必须将文本分割成一系列被称为 词汇单元 的独立原子元素。 这一步骤决定文档中的文本域如何分割成 词汇单元 系列。 Lucene 提供了大量内嵌的分析器能够轻松完成这步操作。 1.1.4 文档索引在本步骤中，文档将被加入到索引列表。 1.2 搜索组件搜索处理过程就是从索引中查找单词，从而找到包含该单词的文档。 1.2.1 建立查询搜索请求会被转换成搜索引擎使用的 查询(query) 对象格式。 查询对象可能很简单，也可能很复杂。 Lucene 提供了一个称之为 查询解析器(QueryParser) 的强大开发包，用它可以根据通用查询语法将用户输入的文本处理成查询对象。查询语句可以包含 布尔运算、短语查询或通配符查询。 1.2.2 搜索查询查询检索索引并返回与查询语句匹配的文档，结果返回时按照查询请求来排序 常见的搜索理论模型： 纯布尔模型：文档不管是否匹配查询请求，都不会被评分，匹配文档与评分不相关，一条查询仅获取所有匹配文档集合的一个子集。 向量空间模型：查询语句和文档都是高维空间的向量模型，这里每一个独立的项都是一个维度，查询语句和文档之间的相关性或相似性由各个向量之间的距离计算得到。 概率模型：采用全概率的方法来计算文档和查询语句匹配的概率。 Lucene 采用了 空间向量模型和纯布尔模型。 2. 核心技术Lucene 是一个全文搜索框架 倒排索引 压缩算法 二元搜索 2.1 倒排索引 根据属性的值来查找记录，这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性，而是由属性值来确定记录的位置，因而成为倒排索引。 单词——文档矩阵 3. Lucene 的工作方法Lucene 提供的服务实际包含两部分，一入一出： 入就是写入，将提供的源（本质上是字符串）写入索引或者将其从索引中删除； 出就是读取，向用户提供全文搜索服务，让用户可以通过关键词定位源。 写入：源字符首先经过 analyzer 处理，包括：分词，拆分成一个个单词；去除 stopword 。将源中需要的信息加入 Document 的各个 Field 中，并把需要索引的 Field 索引起来，把需要存储的 Field 存储起来。 读取：用户提供关键词，经过 analyzer 处理，对处理后的关键词搜索索引，找出对应的 Document。用户根据需要从找到的 Document 中提取出需要的 Field。 document：用户提供的源是一条条记录，它们可以是文本文件、字符串或者数据库表的一条记录等等。一条记录经过索引之后，就是以一个 Document 的形式存储在索引文件中的。用户进行搜索，也是以 Document 列表的形式返回。 field：一个 Document 可以包含多个信息域，例如一篇文章可以包括标题、正文、最后修改时间等信息域，这些信息域是通过 Field 在 Document 中存储的。Field 有两个属性可选：存储和索引。通过存储属性，可以控制是否对这个 Field 进行索引。 4. 示例代码4.1 导入依赖123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!-- lucene --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queries&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;5.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- apache-common --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-lang&lt;/groupId&gt; &lt;artifactId&gt;commons-lang&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 4.2 环境准备准备 index 和 data 两个目录，分别用于存放索引和文档 data 随便从其他项目中复制了几个 LICENSE index 保持为空，当 Lucene 运行的时候会自动进行创建 4.3 创建索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class CreateIndex &#123; /* * 索引目录 */ public static final String INDEX_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/index"; /* * 文本目录 */ public static final String DATA_DIR = "/Users/destiny/IdeaProjects/lucene-demo/src/main/resources/data"; public void createIndex() throws IOException &#123; // 目录对象，描述了索引的存放位置，需要由 Path 进行初始化 Directory directory = FSDirectory.open(Paths.get(INDEX_DIR)); // 创建分词器 Analyzer analyzer = new StandardAnalyzer(); // 由分词器对 IndexWriterConfig 进行初始化 IndexWriterConfig indexWriterConfig = new IndexWriterConfig(analyzer); indexWriterConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND); IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig); File file = new File(DATA_DIR); File[] files = file.listFiles(); if (files != null) &#123; // 读取并遍历文本路径下的所有文件，用于生成文档及其索引 for (File f : files) &#123; // 创建文档 Document document = new Document(); // 为文档设置 Field document.add(new StringField("filename", f.getName(), Field.Store.YES)); document.add(new TextField("content", FileUtils.readFileToString(f, Charset.defaultCharset()), Field.Store.YES)); document.add(new LongField("lastModify", f.lastModified(), Field.Store.YES)); // 写入索引 indexWriter.addDocument(document); &#125; &#125; indexWriter.close(); &#125; public static void main(String[] args) throws IOException &#123; CreateIndex createIndex = new CreateIndex(); createIndex.createIndex(); &#125;&#125; 运行完毕之后，发现 index 路径下多了一些文件，即为文档的索引。 4.4 查询索引12345678910111213141516171819202122232425262728public class SearchIndex &#123; public void search() throws IOException, ParseException &#123; // 打开索引所在路径 Directory directory = FSDirectory.open(Paths.get(CreateIndex.INDEX_DIR)); IndexReader indexReader = DirectoryReader.open(directory); IndexSearcher indexSearcher = new IndexSearcher(indexReader); QueryParser queryParser = new QueryParser("content", new StandardAnalyzer()); Query query = queryParser.parse("from"); // 找到符合条件的前 10 条 Document 的索引的集合 TopDocs search = indexSearcher.search(query, 10); // 遍历集合并打印文件名称 for (ScoreDoc scoreDoc : search.scoreDocs) &#123; int docId = scoreDoc.doc; Document document = indexReader.document(docId); String filename = document.get("filename"); System.out.println("filename: " + filename); &#125; &#125; public static void main(String[] args) throws IOException, ParseException &#123; SearchIndex searchIndex = new SearchIndex(); searchIndex.search(); &#125;&#125; 查询结果： 5. 理解索引过程核心类执行简单的索引过程需要用到以下几个类： IndexWriter Directory Analyzer Document Field 5.1 IndexWriterIndexWriter(写索引)是索引过程的核心组件，这个类负责创建新索引或者打开已有索引，以及向索引中添加、删除或者是更新被索引文档的信息。为开发者提供针对索引文件的写入操作，但不能用于读取或者搜索索引。IndexWriter 需要开辟一定的空间用来存储索引，该功能可以由 Directory 完成。 5.2 DirectoryDirectory 描述了 Lucene 索引存放的位置。它是一个抽象类，其实现类负责具体指定索引的存储路径。在上面的例子中，我们使用 FSDirectory.open() 方法来获取真实文件在文件系统中的存储路径，然后将她们依次传递给 IndexWriter 类的构造方法。 IndexWriter 不能直接索引文本，需要先由 Analyzer 将文本分割成独立的单词才行。 5.3 Analyzer文本文件在被索引之前，需要经过 Analyzer 处理，Analyzer 由 IndexWriter 的构造方法来指定，负责从被索引文本文件中提取词汇单元，并剔除剩下的无用信息。如果被索引的内容不是纯文本文件，那就需要先将其转换成文本文档。 Analyzer 是一个抽象类，其实现类中： 有的用于跳过停用词（指一些常用且不能帮助区分文档的词，如a、an、the、in 和 on 等） 有的用于把词汇转换成小写，以使得搜索过程不区分大小写 等等 分析器的分析对象为文档。 5.4 DocumentDocument 代表一些 域(Field) 的集合，可以将 Document 理解为虚拟文档，如 Web页面、邮件信息等。文档的域代表文档或者文档相关的一些元数据。 Lucene 只处理文本和数字，Lucene 的内核本身只处理 java.lang.String 和 java.io.Reader 对象和本地数字类型 Document 对象的结构比较简单，为一个多个 Field 对象的容器， Field 是指包含能被索引的文本内容的类。 5.5 Field索引中，每个文档都包含一个或者多个不同命名的域，这些域包含在 Field 类中。 每个域都有一个域名和对应的值，以及一组选项来精确控制 Lucene 索引操作各个域值。 6. 理解搜索过程核心类核心类： IndexSearcher Term Query TermQuery TocDocs 6.1 IndexSearcher用于搜索 IndexWriter 所创建的索引，可以将它看做一个以只读方式打开索引的类。 它需要利用 Directory 实例来掌握前期创建的索引，然后才能提供大量的搜索方法，最简单的搜索方法是将单个 Query 对象和 int topN 所谓该方法的参数，返回一个 TopDocs 对象。 6.2 TermTerm 是搜索功能的基本单元，与 Field 对象类似，Term 对象包含一对字符串元素：域名和单词，注意 Term 对象还与索引操作有关。 6.3 QueryLucene 含有许多具体的 Query 子类 6.4 TermQuery是 Lucene 提供的最基本的查询类型，也是简单的查询类型之一，它用来匹配指定域中包含特定值的文档。 6.5 TopDocsTopDocs 类是一个简单的容器指针，指针一般指向前 N 个排名的搜索结果，搜索结果即匹配查询条件的文档。TopDocs 会记录前 N 个结果中每个结果的 int docID 和浮点型分数。]]></content>
      <categories>
        <category>Luence</category>
      </categories>
      <tags>
        <tag>Luence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[quartz 入门]]></title>
    <url>%2Fblog%2F2018%2F04%2F25%2Fquartz-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1. 任务调度概述各种企业应用几乎都会碰到任务调度的需求。 在特定的时间点执行指定的操作。 任务调度本身涉及多线程并发、运行时间规则指定和解析、运行现场保持和恢复、线程池维护等诸多方面的问题。 2. Quartz Quartz允许开发人员灵活地定义触发器的调度时间，并可对触发器和任务进行关联映射； Quartz提供了调度运行环境的持久化和保存； Quartz还提供了组件式的侦听器、插件、线程池等功能。 2.1 Quartz基础结构Quartz对任务调度领域的问题进行了高度的抽象，提出了调度器、任务、触发器这3个核心的概念。 2.1.1 Job是一个接口，只有一个方法void execute(JobExecutionContext context)，开发者通过实现该接口来定义需要执行的任务，JobExecutionContext 类提供了调度上下文的各种信息。Job 运行时的信息保存在 JobDataMap 实例中。 2.1.2 JobDetailQuartz 在每次执行 Job 的时候，都重新创建一个 Job 实例，所以它不是直接接收一个 Job 实例，而是接收一个 Job 实现类，以便运行时通过 newInstance() 反射调用机制实例化 Job。因此需要通过一个类来描述 Job 的实现类及其他相关信息，如 Job 名称、描述、关联监听器等信息，而 JobDetail 承担了这一角色。通过该类的构造函数 JobDetail(java.lang.String name, java.lang.String group, java.lang.Class jobClass)，可以更具体地了解它的功能。该构造函数要求指定 Job 的实现类，以及任务在 Schedule 中的组名和 Job 名称。 2.1.3 Trigger描述触发 Job 执行的时间触发规则。主要有 SimpleTrigger 和 CronTrigger 这两个子类。当仅需要触发一次或者以固定间隔周期性执行的时候， SimpleTrigger 是最佳选择；而 CronTrigger 则可以通过 Cron 表达式定义出各种复杂的调度方案，如每天早上 9:00 执行，每周一、周三下午 5:00 执行等。 2.1.4 Calendarorg.quartz.Calendar 和 java.util.Calendar 不同，它是一些日历特定时间点的集合。一个 Trigger 可以和多个 Calendar 关联，以便排除或包含某些时间点。假设安排每周一早晨 10:00 执行任务，但是如果遇到法定节假日不执行任务，这时就需要在 Trigger 触发机制的基础上使用 Calendar 进行定点排除。针对不同的时间段类型，如 AnnualCalendar、MonthlyCalendar、WeeklyCalendar 分别针对每年、每月和每周进行定义。 2.1.5 Scheduler代表一个 Quartz 的独立运行容器，Trigger 和 JobDetail 可以注册到 Scheduler 中，二者在 Scheduler 中拥有各自的组及名称。组及名称是 Scheduler 查找定位容器中某个对象的依据， Trigger 的组及明恒的组合必须唯一， JobDetail 的组及名称的组合也必须唯一（但可以和 Trigger 的组及名称相同，因为二者处在不同的容器中）。Scheduler 定义了多个接口方法，允许外部通过组及名称访问和控制容器中的 Trigger 和 JobDetail。Scheduler 可以将 Trigger 绑定到某一个 JobDetail 中，这样当 Trigger 被触发时，对应的 Job 就会被执行。一个 Job 可以对应多个 Trigger，但一个 Trigger 只能对应一个 Job。可以通过 SchedulerFactory 创建一个 Scheduler 实例。Scheduler 拥有一个 SchedulerContext，保存着 Scheduler 上下文信息，可以对照 ServletContext 来理解 SchedulerContext。 Job 和 Trigger 都可以访问 SchedulerContext 内的信息。SchedulerContext 内部通过一个 Map，以键值对的方式维护这些上下文数据。SchedulerContext 为保存和获取数据提供了多个 put() 和 getXxx() 方法。可以通过 Scheduler#getContext() 方法获取 SchedulerContext 实例。 2.1.6 ThreadPoolSchedule 使用一个线程池作为任务运行的基础设施，任务通过共享线程池中的线程来提高效率。 Job 有一个 StatefulJob 子接口，代表有状态的任务。该接口是一个没有方法的标签接口，其目的是让 Quartz 知道任务类型，以便采取不同的措施。无状态任务在执行时拥有自己的 JobDataMap 复制，对 JobDataMap 的更改不会影响下次执行。而有状态任务共享同一个 JobDataMap 实例，每次任务执行时对 JobDataMap 所做的更改会保存下来。后面的执行可以看到更改。 因此，无状态任务可以并发执行，而有状态任务的 StatefulJob 不能并发执行。如果上一次的 StatefulJob 还没有执行完成，则下次的任务将阻塞等待。有状态任务比无状态任务需要考虑更多的因素，所以尽量避免使用无状态任务。 如果 Quartz 使用了数据库持久化任务调度信息，则无状态的 JobDataMap 仅会在 Scheduler 注册的任务时保存一次，而有状态任务对应的 JobDataMap 在每次执行任务后都会进行保存。 Trigger 自身也可以拥有一个 JobDataMap，其关联的 JobDataMap 可以通过 JobExecutionContext#getTrigger().getJobDataMap() 方法获取。不管是有状态还是无状态的任务，在任务执行期间对 Trigger 的 JobDataMap 所做的更改都不会进行持久化。 Quartz 拥有完善的事件和监听体系，大部分组件都拥有事件，如任务执行前事件、执行后事件、触发器触发前事件、触发器触发后事件、调度器开始事件、调度器关闭事件等。可以注册相应的监听器处理感兴趣的事件。 2.2 SimpleTriggerSimpleTrigger 有多个重载的构造函数，用于在不同场合下构造出对应的实例。 SimpleTrigger(String name, String group)：指定所属组和名称； SimpleTrigger(String name, String group, Date startTime)：指定触发的开始时间； SimpleTrigger(String name, String group, Date startTime, Date endTime, int repeatCount, long repeatInterval)：指定开始时间、结束时间、重复执行次数、时间间隔； SimpleTrigger(String name, String group, String jobName, String jobGroup, Date startTime, Date endTime, int repeatCount, long repeatInterval)：最复杂的一个构造函数，通过 jobName 和 jobGroup，使该 Trigger 和 Scheduler 中的某个任务关联起来。 2.2.1 代码实例 2.2.1.1 SimpleJob123456public class SimpleJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(jobExecutionContext.getTrigger().getName() + " triggered. time is:" + System.currentTimeMillis()); &#125;&#125; 2.2.1.2 SimpleTriggerRunner12345678910111213141516171819202122232425262728293031public class SimpleTriggerRunner &#123; public static void main(String[] args) &#123; try &#123; // 创建一个 JobDetail 实例，指定 SimpleJob JobDetail jobDetail = JobBuilder.newJob(SimpleJob.class) .withIdentity("jName", "jGroup") .build(); // 通过 SimpleTrigger 定义调度规则：【立即启动】、【每2秒运行一次】、【用运行10次】 SimpleTrigger simpleTrigger = TriggerBuilder.newTrigger() .withIdentity("tName", "tGroup") .startNow() .withSchedule( SimpleScheduleBuilder.simpleSchedule() .withIntervalInSeconds(2) // 调度间隔 .withRepeatCount(10) // 调度次数 ).build(); // 通过 SchedulerFactory 获取一个调度器实例 SchedulerFactory factory = new StdSchedulerFactory(); Scheduler scheduler = factory.getScheduler(); scheduler.scheduleJob(jobDetail, simpleTrigger); scheduler.start(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.2.1.3 运行结果tName1 triggered. time is:1524563336613 tName1 triggered. time is:1524563338522 tName1 triggered. time is:1524563340522 tName1 triggered. time is:1524563342524 tName1 triggered. time is:1524563344523 tName1 triggered. time is:1524563346523 tName1 triggered. time is:1524563348523 tName1 triggered. time is:1524563350524 tName1 triggered. time is:1524563352524 tName1 triggered. time is:1524563354524 tName1 triggered. time is:1524563356523 2.3 使用 CronTriggerCronTrigger 能够提供比 SimpleTrigger 更有实际意义的调度方案，调度规则基于 Cron表达式。 CronTrigger 支持日历相关的周期性时间间隔（比如每月第一个周一执行），而不是简单的周期时间间隔。 2.3.1 Cron 表达式Quartz 使用类似 Linux 下的 Cron 表达式定义时间规则。Cron 表达式由 6 或 7 个空格分割的时间字段组成。 位置 时间域名 允许值 允许的特殊字符 1 秒 [0, 60) ,-*/ 2 分钟 [0, 60) ,-*/ 3 小时 [1, 24) ,-*/ 4 日期 [1, 32) ,-*?/LWC 5 月份 [1, 13) ,-*/ 6 星期 [1, 8) ,-*/LC?# 7 年（可选） 空值 或 [1970, 2100) ,-*/ 特殊字符： 特殊字符 作用 * 表示对应时间域的每一个时刻，如 * 在分钟时段就表示每分钟 ? 只能在日期和星期中使用，占位符，无意义 - 表达范围，如在小时中使用 10-12，表示从 10 点到 12 点 , 列表纸，如在星期中使用 MON,WED,FRI，表示周一、周三、周五 / x/y 表示等步长序列，x 为起始值，y 为增量步长，如在分钟中使用 0/15，表示0、15、30、45秒 L 只能在日期和星期中使用，代表 Last 的意思，日期中表示当月最后一天，星期表示周六 W 只能出现在日期中，是对前导日期的修饰，表示里该日期最近的工作日 LW 只能出现在日期中，表示当月最后一个工作日 # 只能在星期字段中使用，表示当月的某个工作日，6#3表示当月第三个周五，4#5 表示当月第五个周三，如果不存在则不触发 C 只能在日期和星期中使用，Calendar，表示计划所关联的日期。5C 在日期中相当于 5日之后的那一天，1C 在星期中相当于 周天后的那一天 示例 表达式 说明 0 0 12 * * ? 每天 12:00 运行 0 15 10 ? * * 每天 10:15 运行 0 15 10 * * ? 每天 10:15 运行 0 15 10 * * ? * 每天 10:15 运行 0 15 10 * * ? 2008 在 2008 年的每天 10:15 运行 0 * 14 * * ? 每天 14 点到 15 点每分钟运行一次，开始于 14:00，结束于 14:59 0 0/5 14 * * ? 每天 14 点到 15 点每 5 分钟运行一次，开始于 14:00，结束语 14:55 0 0/5 14,18 * * ? 每天 14 点到 15 点每 5 分钟运行一次，此外每天 18 点到 19 点每 5 分钟也运行一次 0 10,44 14 ? 3 WED 3 月的每周三的 14:10 到 14:44，每分钟运行一次 0 15 10 ? * MON-FRI 每个工作日的 10:15 运行一次 0 15 10 15 * ? 每月 15 日的 10:15 运行一次 0 15 10 L * ? 每月最后一天的 10:15 运行一次 0 15 10 ? * 6L 每月的最后一个周五的 10:15 运行一次 0 15 10 ? * 6L 2014-2016 2014、2015、2016 年每个月的最后一个周五的 10:15 运行 0 15 10 ? * 6#3 每月第三个周五的 10: 15 运行 2.3.2 示例123456789101112131415161718192021222324public class CronTriggerRunner &#123; public static void main(String[] args) &#123; try &#123; JobDetail jobDetail = new JobDetail("jName1", "jGroup1", SimpleJob.class); // 创建 CronTrigger 指定组及名称 CronTrigger cronTrigger = new CronTrigger("tName1", "tGroup1"); // 新建并设置 Cron 表达式：从每分钟的 0 秒开始，每隔5秒触发一次 CronExpression cronExpression = new CronExpression("0/5 * * * * ?"); cronTrigger.setCronExpression(cronExpression); SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); scheduler.scheduleJob(jobDetail, cronTrigger); scheduler.start(); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.3 运行结果tName1 triggered. time is:1524645830011 tName1 triggered. time is:1524645835006 tName1 triggered. time is:1524645840006 tName1 triggered. time is:1524645845002 tName1 triggered. time is:1524645850003 tName1 triggered. time is:1524645855004 tName1 triggered. time is:1524645860003 tName1 triggered. time is:1524645865003 tName1 triggered. time is:1524645870005 tName1 triggered. time is:1524645875006 tName1 triggered. time is:1524645880000 tName1 triggered. time is:1524645885000 tName1 triggered. time is:1524645890007 tName1 triggered. time is:1524645895005 tName1 triggered. time is:1524645900005 由于打印的时间是以毫秒作为单位的，因此可以看毫秒数的倒数第4位，都是以 5 作为步长的。 2.4 Calendar在实际任务调度中，不可能一成不变地按照某个特定周期调度任务，必须考虑到现实生活中日历上的特殊日期。 下面的例子中，该任务每小时运行一次，并将 五一劳动节 和 国庆节 排除在外 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142public class CalendarExample &#123; public static void main(String[] args) throws SchedulerException &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); // 法定节日是以年作为周期的，所以使用 AnnualCalendar AnnualCalendar holidays = new AnnualCalendar(); // 五一劳动节 Calendar laborDay = new GregorianCalendar(); laborDay.add(Calendar.MONTH, 5); laborDay.add(Calendar.DATE, 1); // 国庆节 Calendar nationalDay = new GregorianCalendar(); nationalDay.add(Calendar.MONTH, 10); nationalDay.add(Calendar.DATE, 1); ArrayList&lt;Calendar&gt; calendarList = new ArrayList&lt;&gt;(); calendarList.add(laborDay); calendarList.add(nationalDay); // 排除这两个日期 holidays.setDaysExcluded(calendarList); // 向 Scheduler 注册日历 scheduler.addCalendar("holidays", holidays, false, false); // 4月1日上午10点 Date runDate = TriggerUtils.getDateOf(0, 0, 10, 1, 4); JobDetail jobDetail = new JobDetail("jName1", "jGroup1", SimpleJob.class); SimpleTrigger trigger = new SimpleTrigger( "tName1", "tGroup1", runDate, null, SimpleTrigger.REPEAT_INDEFINITELY, 60L * 60L * 1000L); // 让 Trigger 应用指定的日历规则 trigger.setCalendarName("holidays"); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); &#125; &#125; 2.5 任务调度信息存储在默认情况下，Quartz 将任务调度的运行信息保存在内存中。这种方法提供了最佳的性能，但缺乏持久性。 如果需要持久化任务调度信息，则 Quartz 允许用户通过调整其属性文件，将这些信息保存到数据库中。 2.5.1 通过配置文件调整任务调度信息Quartz JAR 文件的 org.quartz 包含了一个 quartz.properties 属性配置文件，并提供了默认属性。可以通过在类路径下新建一个 quartz.properties 文件来覆盖默认配置。 # 集群的配置，这里不使用集群 org.quartz.scheduler.instanceName = DefaultQuartzScheduler org.quartz.scheduler.rmi.export= false org.quartz.scheduler.warpJobExecutionInUserTransaction = false # 配置调度器的线程池 org.quartz.threadPool.class = org.quartz.simple.SimpleThreadPool org.quartz.threadPool.threadCount = 10 org.quartz.threadPool.threadPriority = 5 org.quartz.threadPool.threadInheritContextClassLoaderOfInitializingThread # 配置任务调度现场数据保存机制 org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore 如果任务数目很大，则可以通过增大线程池获得更好的性能。 默认情况下，Quartz 采用 org.quartz.simpl.RAMJobStore 保存任务的现场数据，而通过以下设置可以将任务调度现场数据保存到数据库中 org.quartz.jobStore.class = org.quratz.impl.jdbcjobstore.JobStoreTX # 数据库表前缀 org.quartz.jobStore.tablePrefix = QRTZ_ # 数据源名称 org.quartz.jobStore.dataSource = qzDS # 定义数据源的具体属性 org.quartz.dataSource.qzDS.driver = com.mysql.jdbc.Driver org.quartz.dataSource.qzDS.URL = jdbc:mysql://localhost:3306/quartz org.quartz.dataSource.qzDS.user = root org.quartz.dataSource.qzDS.password = 123456 org.quartz.dataSource.qzDS.maxConnections = 10 要将任务调度数据保存到数据库中，就必须使用 org.quratz.impl.jdbcjobstore.JobStoreTX，并提供相应的数据库配置信息。 用户必须事先在相应的数据库中创建 Quartz 的数据表，在 Quartz 的完整发布包的 docs/dbTables 目录下拥有对应不同数据库的 SQL 脚本。 选择自己使用的数据库对应的脚本执行即可。 执行结果： 2.5.2 查询数据库中的运行信息首先，引入依赖：1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.45&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 任务的现场保存对于上层的 Quartz 来说是完全透明的。使用该配置文件后将之前的代码重新运行，就能在数据库中看到对应的数据。 当调度程序中途停止之后，任务调度的现场数据将记录在数据库表中，在系统重启时就可以在此基础上继续任务的调度。 1234567891011121314151617181920212223242526public class JDBCJobStoreRunner &#123; public static void main(String[] args) &#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); // 获取调度器中所有的触发组 String[] triggerGroups = scheduler.getTriggerGroupNames(); // 重新恢复在 tGroup1 组中名为 tName1 的触发器的运行 for (int i = 0; i &lt; triggerGroups.length; ++ i) &#123; String[] triggerNames = scheduler.getTriggerNames(triggerGroups[i]); for (int j = 0; j &lt; triggerNames.length; ++ j) &#123; Trigger trigger = scheduler.getTrigger(triggerGroups[i], triggerNames[j]); if (trigger instanceof SimpleTrigger &amp;&amp; trigger.getFullName().equals("tGroup1.tName1")) &#123; // 恢复运行 scheduler.rescheduleJob(triggerNames[j], triggerGroups[i], trigger); &#125; &#125; &#125; scheduler.start(); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 如果调度程序执行后非正常退出，就可以通过 JDBCJobStoreRunner 根据记录在数据库中的现场数据恢复任务的调度。Scheduler 中的所有 Trigger 及 JobDetail 的运行信息都会保存在数据库中，这里仅恢复 tGroup1 组中名为 tName1 的触发器。触发器采用 GROUP.TRIGGER_NAME 的全名格式，通过 Scheduler#reschduleJob(String triggerName, String groupName, Trigger trigger) 方法即可重新调度关联某个 Trigger 任务。 2.5.3 不同时期 QRTZ_SIMPLE_TRIGGERS 表的数据 执行 代码 中的 SimpleTriggerRunner 一段时间后退出 quartz 数据库状态如下 这时 QRTZ_SIMPLE_TRIGGERS 表中的数据如下 REPEAT_COUNT: 触发器器需要执行的总次数 REPEAT_INTERVAL: 调度间隔(单位：毫秒) TIMES_TRIGGERED: 触发器已经调度的次数 1234567891011121314151617181920212223242526public class JDBCJobStoreRunner &#123; public static void main(String[] args) &#123; try &#123; SchedulerFactory schedulerFactory = new StdSchedulerFactory(); Scheduler scheduler = schedulerFactory.getScheduler(); JobKey jobKey = new JobKey("jName", "jGroup"); List&lt;? extends Trigger&gt; triggers = scheduler.getTriggersOfJob(jobKey); // SELECT TRIGGER_NAME, TRIGGER_GROUP FROM &#123;QRTZ_&#125;TRIGGERS WHERE SCHED_NAME = &#123;DefaultQuartzScheduler&#125; AND JOB_NAME = ? AND JOB_GROUP = ? // 其中 &#123;QRTZ_&#125; 和 &#123;DefaultQuartzScheduler&#125; 均来自 quartz.properties 的配置 // 重新恢复在jGroup1组中，名为job1_1的 job的触发器运行 if(triggers.size() &gt; 0)&#123; for (Trigger tg : triggers) &#123; // 根据类型判断 if ((tg instanceof CronTrigger) || (tg instanceof SimpleTrigger)) &#123; // 恢复job运行 scheduler.resumeJob(jobKey); &#125; &#125; scheduler.start(); &#125; &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 此时原先被中断的任务已经恢复。 可以看到，将剩余12次全部执行完成。 再次查看 QRTZ_SIMPLE_TRIGGER 表，发现触发器已经完成调度并被清除。 3. 集成 SpringSpring 为创建 Quartz 的 Scheduler、Trigger、JobDetail 提供了便利的 FactoryBean 类，以便能够在 Spring 容器中享受注入的好处。 Spring 提供了两方面的支持： 为 Quartz 的主要组件提供了更具 Bean 风格的扩展类 提供创造 Scheduler 的BeanFactory 类，方便在 Spring 环境下创建对应的组件对象，并结合 Spring 容器生命周期执行启动和停止的动作。 3.1 创建 JobDetail由于 JobDetail 使用带参构造函数，不方便通过 Spring 配置，因此 Spring 通过扩展 JobDetail 提供了更具 Bean 风格的 JobDetailFactoryBean，此外，Spring 还提供了 MethodInvokingJobDetailFactoryBean，用于将 Spring 容器中 Bean 的方法包装成 Quartz 任务，使开发者不必为 Job 创建对应的类。 3.1.1 JobDetailFactoryBean12345678910111213141516171819@Configuration@ComponentScan(basePackages = &#123;"example5"&#125;)public class QuartzConf &#123; @Bean public JobDetailFactoryBean jobDetailFactoryBean() &#123; JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); jobDetailFactoryBean.setJobClass(SimpleJob.class); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("size", 10); jobDetailFactoryBean.setJobDataAsMap(map); jobDetailFactoryBean.setApplicationContextJobDataKey("applicationContext"); return jobDetailFactoryBean; &#125;&#125; JobDetailFactoryBean 封装了 SimpleJob 任务类，并为 Job 对应的 JobDataMap 设置了一个 key 为 size，value 为 10的数据。此外，通过指定 ApplicationContextJobDataKey，让 Job 的JobDataMap 持有 Spring ApplicationContext 的引用。 jobClass：实现 Job 接口的任务类； beanName：默认为 bean 的id，显示指定 Bean 名称，对应任务的名称； jobDataAsMap：类型为 Map，为任务所对应的 JobDataMap 提供值。提供这个数据是因为用户无法在 Spring 配置文件中为 JobDataMap 类型的属性提供信息； applicationContextJobDataKey：用户可以将 Spring ApplicationContext 的引用保存到 JobDataMap 中，以便在 Job 的代码中访问 ApplicaitonContext。为了达到这个目的，用户需要指定一个 key 对应这个 ApplicationContext，如果不设置就不会将 ApplicationContext 放入 JobDataMap中； jobListenerNames：类型为 String[]，指定注册在 Scheduler 中的 JobListener 名称。 3.2 创建 TriggerSpring 按照相似的思路分为 SimpleTrigger 和 CronTrigger 提供了更具 Bean 风格的 SimpleTriggerFactoryBean 和 CronTriggerFactoryBean 的扩展类， 3.2.1 SimpleTriggerFactoryBean1234567891011121314@Bean(name = "simpleTrigger")public SimpleTriggerFactoryBean simpleTriggerFactoryBean() &#123; SimpleTriggerFactoryBean simpleTriggerFactoryBean = new SimpleTriggerFactoryBean(); simpleTriggerFactoryBean.setJobDetail(jobDetailFactoryBean().getObject()); simpleTriggerFactoryBean.setStartDelay(1000); simpleTriggerFactoryBean.setRepeatInterval(2000); simpleTriggerFactoryBean.setRepeatCount(20); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("count", 10); simpleTriggerFactoryBean.setJobDataAsMap(map); return simpleTriggerFactoryBean;&#125; 定义了一个 Trigger，该 Trigger 和 JobDetail 相关联，延迟 1 秒后启动，时间间隔为 2 秒，重复执行 20 次。 Trigger 中设置的 JobDataMap 在执行任务时必须通过以下方式获取12345public class SimpleJob implements StatefulJob &#123; public void execute(JobExecutionContext context) throws JobExecutionException &#123; Map dataMap = context.getTrigger().getJobDataMap(); &#125;&#125; 3.2.2 CronTriggerFactoryBean1234567@Bean(name = "cronTriggerFactoryBean")public CronTriggerFactoryBean cronTriggerFactoryBean() &#123; CronTriggerFactoryBean cronTriggerFactoryBean = new CronTriggerFactoryBean(); cronTriggerFactoryBean.setJobDetail(jobDetailFactoryBean().getObject()); cronTriggerFactoryBean.setCronExpression("0/5 * * * * ?"); return cronTriggerFactoryBean;&#125; 3.3 SchedulerQuartz 的 SchedulerFactory 是标准的工厂类，不太适合在 Spring 环境下使用。此外，为了保证 Scheduler 能够感知到 Spring 的生命周期，Spring 提供了 SchedulerFactory。 12345678910111213@Beanpublic SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 注册一个或多个 Trigger schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean().getObject()); // 以 Map 类型设置 SchedulerContext Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeout", 30); schedulerFactoryBean.setSchedulerContextAsMap(map); // 显示指定 Quartz 配置文件的路径 schedulerFactoryBean.setConfigLocation(new ClassPathResource("quartz.properties")); return schedulerFactoryBean;&#125; triggers：属性为 trigger[]，可以注册多个 Trigger schedulerContextAsMap：Scheduler拥有类似 ServletContext 的 SchedulerContext，允许用户以 Map 的形式设置 SchedulerContext 的参数值 configLocation：指定配置文件路径 calendars：类型为 Map，通过该属性向 Scheduler 注册 JobDetail jobDetails：类型为 JobDetail[]，通过该属性向 Scheduler 注册 JobDetail autoStartup：SchedulerFactoryBean 初始化之后是否立即启动，默认为 true startupDelay：SchedulerFactoryBean 启动后的延迟时间，默认为 0 SchedulerFactoryBean 的一项重要功能是允许用户将 Quartz 配置文件中的信息转移到 Spring 配置文件中 12345678910111213141516171819@Beanpublic SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 注册一个或多个 Trigger schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean().getObject()); // 以 Map 类型设置 SchedulerContext Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("timeout", 30); schedulerFactoryBean.setSchedulerContextAsMap(map); // 显示指定 Quartz 配置文件的路径 schedulerFactoryBean.setConfigLocation(new FileSystemResource("classpath:quartz.properties")); //------------------ 集成 Quartz 配置文件 ------------------// Properties properties = new Properties(); properties.setProperty("org.quartz.threadPool.class", "org.quartz.simpl.SimpleThreadPool"); properties.setProperty("org.quartz.threadPool.threadCount", "10"); schedulerFactoryBean.setQuartzProperties(properties); return schedulerFactoryBean;&#125; 3.4 测试代码此处有一个坑，就说从 Spring 容器中根据 beanName 获取的 schedulerFactoryBean 其实是 org.quartz.impl.StdScheduler 对象，如果使用 org.springframework.scheduling.quartz.SchedulerFactoryBean 会抛出以下异常 从 Spring 容器中直接获取 Scheduler 即可。1234567891011public class SimpleTriggerRunner &#123; public static void main(String[] args) throws SchedulerException &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(QuartzConf.class); // 此处一定要取 Scheduler 而不是 SchedulerFactoryBean，因为它是一个工厂bean，得到的不是它本身，而是它负责创建的 org.quartz.impl.StdScheduler 对象 Scheduler scheduler = context.getBean("schedulerFactoryBean", Scheduler.class); scheduler.start(); &#125;&#125; 4. 附录4.1 tables_mysql_innodb.sql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151-- In your Quartz properties file, you'll need to set -- org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate-- By: Ron Cordell - roncordell-- I didn't see this anywhere, so I thought I'd post it here. This is the script from Quartz to create the tables in a MySQL database, modified to use INNODB instead of MYISAM.DROP TABLE IF EXISTS QRTZ_JOB_LISTENERS;DROP TABLE IF EXISTS QRTZ_TRIGGER_LISTENERS;DROP TABLE IF EXISTS QRTZ_FIRED_TRIGGERS;DROP TABLE IF EXISTS QRTZ_PAUSED_TRIGGER_GRPS;DROP TABLE IF EXISTS QRTZ_SCHEDULER_STATE;DROP TABLE IF EXISTS QRTZ_LOCKS;DROP TABLE IF EXISTS QRTZ_SIMPLE_TRIGGERS;DROP TABLE IF EXISTS QRTZ_CRON_TRIGGERS;DROP TABLE IF EXISTS QRTZ_BLOB_TRIGGERS;DROP TABLE IF EXISTS QRTZ_TRIGGERS;DROP TABLE IF EXISTS QRTZ_JOB_DETAILS;DROP TABLE IF EXISTS QRTZ_CALENDARS;CREATE TABLE QRTZ_JOB_DETAILS(JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,DESCRIPTION VARCHAR(250) NULL,JOB_CLASS_NAME VARCHAR(250) NOT NULL,IS_DURABLE VARCHAR(1) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,IS_STATEFUL VARCHAR(1) NOT NULL,REQUESTS_RECOVERY VARCHAR(1) NOT NULL,JOB_DATA BLOB NULL,PRIMARY KEY (JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_JOB_LISTENERS (JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,JOB_LISTENER VARCHAR(200) NOT NULL,PRIMARY KEY (JOB_NAME,JOB_GROUP,JOB_LISTENER),INDEX (JOB_NAME, JOB_GROUP),FOREIGN KEY (JOB_NAME,JOB_GROUP)REFERENCES QRTZ_JOB_DETAILS(JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,DESCRIPTION VARCHAR(250) NULL,NEXT_FIRE_TIME BIGINT(13) NULL,PREV_FIRE_TIME BIGINT(13) NULL,PRIORITY INTEGER NULL,TRIGGER_STATE VARCHAR(16) NOT NULL,TRIGGER_TYPE VARCHAR(8) NOT NULL,START_TIME BIGINT(13) NOT NULL,END_TIME BIGINT(13) NULL,CALENDAR_NAME VARCHAR(200) NULL,MISFIRE_INSTR SMALLINT(2) NULL,JOB_DATA BLOB NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (JOB_NAME, JOB_GROUP),FOREIGN KEY (JOB_NAME,JOB_GROUP)REFERENCES QRTZ_JOB_DETAILS(JOB_NAME,JOB_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_SIMPLE_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,REPEAT_COUNT BIGINT(7) NOT NULL,REPEAT_INTERVAL BIGINT(12) NOT NULL,TIMES_TRIGGERED BIGINT(10) NOT NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_CRON_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,CRON_EXPRESSION VARCHAR(120) NOT NULL,TIME_ZONE_ID VARCHAR(80),PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_BLOB_TRIGGERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,BLOB_DATA BLOB NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_TRIGGER_LISTENERS (TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,TRIGGER_LISTENER VARCHAR(200) NOT NULL,PRIMARY KEY (TRIGGER_NAME,TRIGGER_GROUP,TRIGGER_LISTENER),INDEX (TRIGGER_NAME, TRIGGER_GROUP),FOREIGN KEY (TRIGGER_NAME,TRIGGER_GROUP)REFERENCES QRTZ_TRIGGERS(TRIGGER_NAME,TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_CALENDARS (CALENDAR_NAME VARCHAR(200) NOT NULL,CALENDAR BLOB NOT NULL,PRIMARY KEY (CALENDAR_NAME))TYPE=InnoDB;CREATE TABLE QRTZ_PAUSED_TRIGGER_GRPS (TRIGGER_GROUP VARCHAR(200) NOT NULL,PRIMARY KEY (TRIGGER_GROUP))TYPE=InnoDB;CREATE TABLE QRTZ_FIRED_TRIGGERS (ENTRY_ID VARCHAR(95) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,IS_VOLATILE VARCHAR(1) NOT NULL,INSTANCE_NAME VARCHAR(200) NOT NULL,FIRED_TIME BIGINT(13) NOT NULL,PRIORITY INTEGER NOT NULL,STATE VARCHAR(16) NOT NULL,JOB_NAME VARCHAR(200) NULL,JOB_GROUP VARCHAR(200) NULL,IS_STATEFUL VARCHAR(1) NULL,REQUESTS_RECOVERY VARCHAR(1) NULL,PRIMARY KEY (ENTRY_ID))TYPE=InnoDB;CREATE TABLE QRTZ_SCHEDULER_STATE (INSTANCE_NAME VARCHAR(200) NOT NULL,LAST_CHECKIN_TIME BIGINT(13) NOT NULL,CHECKIN_INTERVAL BIGINT(13) NOT NULL,PRIMARY KEY (INSTANCE_NAME))TYPE=InnoDB;CREATE TABLE QRTZ_LOCKS (LOCK_NAME VARCHAR(40) NOT NULL,PRIMARY KEY (LOCK_NAME))TYPE=InnoDB;INSERT INTO QRTZ_LOCKS values('TRIGGER_ACCESS');INSERT INTO QRTZ_LOCKS values('JOB_ACCESS');INSERT INTO QRTZ_LOCKS values('CALENDAR_ACCESS');INSERT INTO QRTZ_LOCKS values('STATE_ACCESS');INSERT INTO QRTZ_LOCKS values('MISFIRE_ACCESS');commit;]]></content>
      <categories>
        <category>quartz</category>
      </categories>
      <tags>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java文件下载]]></title>
    <url>%2Fblog%2F2018%2F04%2F16%2FJava%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[今天在开发中遇到了一个需求： 在服务端保存一个Excel模板，用户通过浏览器传递不同的参数，解析参数并写入模板返回给用户以供下载。 需求本身很简单，但在开发的过程中踩了几个坑，所以记录下来。 1. 文件下载的原理 通过 HttpServletResponse.setContentType() 方法设置 Content-Type 字段的值，设置为 application/octet-stream 或 application/x-msdownload ，决定客户端服务器以那种方式来接受返回的信息 1response.setContentType("application/vnd.ms-excel"); 通过 HttpServletResponse.setHeader() 方法设置 Content-Disposition 头的值为 attachment;filename=文件名 ，浏览器通过附件的形式来获取到用户上传的文件 1response.addHeader("Content-Disposition", "attachment; filename=" + fileName); 读取下载文件，通过 HttpServletResponse.getOutputStream() 方法返回 ServletOutputStream 对象来向客户端写入附件文件的内容 1234567891011try (OutputStream out = response.getOutputStream(); BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file)); BufferedOutputStream bos = new BufferedOutputStream(out)) &#123; byte[] buff = new byte[2048]; int bytesRead; while (-1 != (bytesRead = bis.read(buff, 0, buff.length))) &#123; bos.write(buff, 0, bytesRead); &#125;&#125; catch (IOException e) &#123; logger.error(e.getMessage());&#125; 2. Http 报头 Content-disposition 的作用Content-Disposition 属性是作为对下载文件的一个标识字段。 在 rfc2616 章节19.5 Additional Features中 Content-Disposition 属性有两种类型：inline 和 attachment inline ：将文件内容直接显示在页面 attachment：弹出对话框让用户下载 2.1 inlineinline 用于直接在页面中展示该文件，常用与图片等 示例： 12345File file = new File("rfc1806.txt");String filename = file.getName();response.setHeader("Content-Type","text/plain");response.addHeader("Content-Disposition","inline;filename=" + new String(filename.getBytes(),"utf-8"));response.addHeader("Content-Length","" + file.length()); 2.2 attachmentattachment 用于通知浏览器弹出对话框以供用户下载。 示例： 12345File file = new File("rfc1806.txt");String filename = file.getName();response.setHeader("Content-Type","text/plain");response.addHeader("Content-Disposition","attachment; filename=" + new String(filename.getBytes(),"utf-8"));response.addHeader("Content-Length","" + file.length()); 3. filename 属性中文乱码如果在设置 filename 的时候直接使用中文，则会出现如下情况: 在代码中直接使用中文进行设置 相应的 HTTP Response 浏览器的弹窗 首先，产生乱码的根本问题是在 HTTP 协议中，HTTP Header要求其内容必须为 ISO-8859-1 编码。 所以，在开发中尽量使用如下方式： 1response.setHeader("Content-disposition", "attachment; filename=" + new String("中文文件名".getBytes("utf-8"), "ISO8859-1")); 得到文件名的字节数组，将字节数组转换成 IOS-8859-1 格式编码的字符串。 而不能通过如下方式： 1"中文文件名".getBytes("ISO8859-1"); 因为 IOS-8859-1 的编码表中没有汉字字符，因此无法通过以上的方式对中文字符串进行编码。 以先通过 &quot;中文文件名&quot;.getBytes(&quot;utf-8&quot;) 获取其 byte[]字节，让其按照字节来编码，即在使用 new String(&quot;中文文件名&quot;.getBytes(&quot;utf-8&quot;), &quot;ISO8859-1&quot;) 将其重新组成一个字符串，传送给浏览器。 4. 演示4.1 代码及资源路径 4.2 HTTP Response 详情 4.3 浏览器能够正确识别]]></content>
      <categories>
        <category>踩坑总结</category>
      </categories>
      <tags>
        <tag>踩坑总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)In Search of an Understandable Consensus Algorithm —— Raft算法]]></title>
    <url>%2Fblog%2F2018%2F04%2F15%2F%E7%BF%BB%E8%AF%91-In-Search-of-an-Understandable-Consensus-Algorithm-%E2%80%94%E2%80%94-Raft%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本篇博客为著名的 RAFT 一致性算法论文的中文翻译，论文名为《In search of an Understandable Consensus Algorithm (Extended Version)》(寻找一种易于理解的一致性算法) Raft 是一种用来管理日志复制的一致性算法。它和 Paxos 的性能和功能是一样的，但是它和 Paxos 的结构不一样；这使得 Raft 更容易理解并且更易于建立实际的系统。为了提高理解性，Raft 将一致性算法分为了几个部分，例如领导选取（leader selection），日志复制（log replication）和安全性（safety），同时它使用了更强的一致性来减少了必须需要考虑的状态。从用户学习的结果来看，Raft 比 Paxos 更容易学会。Raft 还包括了一种新的机制来使得动态改变集群成员，它使用重叠大多数（overlapping majorities）来保证安全。 1. 引言一致性算法允许一组机器像一个整体一样工作，即使其中的一些机器出了错误也能正常工作。正因为此，他们扮演着建立大规模可靠的软件系统的关键角色。在过去的十年中 Paxos 一直都主导着有关一致性算法的讨论：大多数一致性算法的实现都基于它或者受它影响，并且 Paxos 也成为了教学生关于一致性知识的主要工具。 不幸的是，尽管在降低它的复杂性方面做了许多努力，Paxos 依旧很难理解。并且，Paxos 需要经过复杂的修改才能应用于实际中。这些导致了系统构构建者和学生都十分头疼。 在被 Paxos 折磨之后，我们开始寻找一种在系统构建和教学上更好的新的一致性算法。我们的首要目标是让它易于理解：我们能不能定义一种面向实际系统的一致性算法并且比 Paxos 更容易学习呢？并且，我们希望这种算法能凭直觉就能明白，这对于一个系统构建者来说是十分必要的。对于一个算法，不仅仅是让它工作起来很重要，知道它是如何工作的更重要。 我们工作的结果是一种新的一致性算法，叫做 Raft。在设计 Raft 的过程中我们应用了许多专门的技巧来提升理解性，包括算法分解（分为领导选取（leader selection），日志复制（log replication）和安全性（safety）） 和 减少状态（state space reduction）（相对于 Paxos，Raft 减少了非确定性的程度和服务器互相不一致的方式）。在两所学校的43个学生的研究中发现，Raft 比 Paxos 要更容易理解：在学习了两种算法之后，其中的33个学生回答 Raft 的问题要比回答 Paxos 的问题要好。 在许多方面，Raft与现有的协商一致意见相似(最值得注意的是，Oki和Liskov的Viewstamped复制)，但它有几个新的特点: 强领导者（Strong Leader） : Raft使用一种比其他共识算法更强的领导方式。例如，日志条目只从Leader流向其他服务器。这样就简化了复制日志的管理，使Raft更容易理解。 领导选取（Leader Selection）: Raft 使用随机定时器选举领导人。这只增加了对任何协商一致算法所需的心跳的一小部分机制，同时快速地解决冲突。 成员变化（Membership Change）: Raft 为了调整集群中成员关系使用了新的联合一致性（joint consensus）的方法，这种方法中大多数不同配置的机器在转换关系的时候会交迭（overlap）。这使得在配置改变的时候，集群能够继续操作。 我们认为，Raft 在教学方面和实际实现方面比 Paxos 和其他算法更出众。 它比其他算法更简单、更容易理解； 它能满足一个实际系统的需求； 它拥有许多开源的实现并且被许多公司所使用； 它的安全特性已经被证明； 并且它的效率和其他算法相比也具有竞争力。 这篇论文剩下的部分会讲如下内容： 复制状态机（replicated state machine）问题（第2节）; 讨论 Paxos 的优缺点（第3节）; 讨论我们用的为了达到提升理解性的方法（第4节）; 陈述 Raft 一致性算法（第5~8节）; 评价 Raft 算法（第9节）; 对相关工作的讨论（第10节）。 2. 复制状态机（Replicated State Machine）复制状态机在分布式领域是一个常用且重要的技术。 通过复制服务副本，并和副本一起来协调客户端的交互，来实现容错服务。 这个方法同样提供了一个框架，来理解和设计复制管理协议。 一致性算法是在复制状态机的背景下提出来的。在这个方法中，在一组服务器的状态机产生同样的状态的副本因此即使有一些服务器崩溃了这组服务器也还能继续执行。复制状态机在分布式系统中被用于解决许多有关容错的问题。例如，GFS，HDFS还有 RAMCloud 这些大规模的系统都是用一个单独的集群领导者，使用一个单独的复制状态机来进行领导选取和存储配置信息来应对领导者的崩溃。使用复制状态机的例子有 Chubby 和 ZooKeeper。 复制状态机的架构。一致性算法管理来自客户端状态命令的复制日志。状态机处理的日志中的命令的顺序都是一致的，因此会得到相同的执行结果。 复制状态机是通过复制日志来实现的。每一台服务器保存着一份日志，日志中包含一系列的命令，状态机会按顺序执行这些命令。因为每一台计算机的状态机都是确定的，所以每个状态机的状态都是相同的，执行的命令是相同的，最后的执行结果也就是一样的了。 如何保证复制日志一致就是一致性算法的工作了。在一台服务器上，一致性模块接受客户端的命令并且把命令加入到它的日志中。它和其他服务器上的一致性模块进行通信来确保每一个日志最终包含相同序列的请求，即使有一些服务器宕机了。一旦这些命令被正确的复制了，每一个服务器的状态机都会按同样的顺序去执行它们，然后将结果返回给客户端。最终，这些服务器看起来就像一台可靠的状态机。 应用于实际系统的一致性算法一般有以下特性： 确保安全性（从来不会返回一个错误的结果），即使在所有的非拜占庭（Non-Byzantine）情况下，包括网络延迟、分区、丢包、冗余和乱序的情况下。 高可用性，只要集群中的大部分机器都能运行，可以互相通信并且可以和客户端通信，这个集群就可用。因此，一般来说，一个拥有 5 台机器的集群可以容忍其中的 2 台的失败（fail）。服务器停止工作了我们就认为它失败（fail）了，没准一会当它们拥有稳定的存储时就能从中恢复过来，重新加入到集群中。 不依赖时序保证一致性，时钟错误和极端情况下的消息延迟在最坏的情况下才会引起可用性问题。 通常情况下，一条命令能够尽可能快的在大多数节点对一轮远程调用作出相应时完成，一少部分慢的机器不会影响系统的整体性能。 3. Paxos算法的不足在过去的10年中，Leslie Lamport 的 Paxos 算法几乎已经成为了一致性算法的代名词：它是授课中最常见的算法，同时也是许多一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，例如一个单一复制日志条目（single replicated log entry）。我们把这个子集叫做单一决策 Paxos（single-decree Paxos）。之后 Paxos通过组合多个这种协议来完成一系列的决策，例如一个日志（multi-Paxos）。Paxos 确保安全性和活跃性（liveness），并且它支持集群成员的变更。它的正确性已经被证明，通常情况下也很高效。 不幸的是，Paxos 有两个致命的缺点。 Paxos 太难以理解。它的完整的解释晦涩难懂；很少有人能完全理解，只有少数人成功的读懂了它。并且大家做了许多努力来用一些简单的术语来描述它。尽管这些解释都关注于单一决策子集问题，但仍具有挑战性。在 NSDI 2012 会议上的一次非正式调查显示，我们发现大家对 Paxos 都感到不满意，其中甚至包括一些有经验的研究员。我们自己也曾深陷其中，我们在读过几篇简化它的文章并且设计了我们自己的算法之后才完全理解了 Paxos，而整个过程花费了将近一年的时间。我们假定 Paxos 的晦涩来源于它将单决策子集作为它的基础。单决策（Single-decree）Paxos 是晦涩且微妙的：它被划分为两个没有简单直观解释的阶段，并且难以独立理解。正因为如此，它不能很直观的让我们知道为什么单一决策协议能够工作。为多决策 Paxos 设计的规则又添加了额外的复杂性和精巧性。我们相信多决策问题能够分解为其它更直观的方式。 它难以在实际环境中实现。其中一个原因是，对于多决策 Paxos （multi-Paxos） ，大家还没有一个一致同意的算法。Lamport 的描述大部分都是有关于单决策 Paxos （single-decree Paxos）；他仅仅描述了实现多决策的可能的方法，缺少许多细节。有许多实现 Paxos 和优化 Paxos 的尝试，但是他们都和 Lamport 的描述有些出入。例如，Chubby 实现的是一个类似 Paxos 的算法，但是在许多情况下的细节没有公开。 另外，Paxos 的结构也是不容易在一个实际系统中进行实现的，这是单决策问题分解带来的又一个问题。例如，从许多日志条目中选出条目然后把它们融合到一个序列化的日志中并没有带来什么好处，它仅仅增加了复杂性。围绕着日志来设计一个系统是更简单、更高效的：新日志按照严格的顺序添加到日志中去。另一个问题是，Paxos 使用对等的点对点的实现作为它的核心（尽管它最终提出了一种弱领导者的形式来优化性能）。这种方法在只有一个决策被制定的情况下才显得有效，但是很少有现实中的系统使用它。如果要做许多的决策，选择一个领导人，由领带人来协调是更简单有效的方法。 因此，在实际的系统应用中和 Paxos 算法都相差很大。所有开始于 Paxos 的实现都会遇到很多问题，然后由此衍生出了许多与 Paxos 有很大不同的架构。这是既费时又容易出错的，并且理解 Paxos 的难度又非常大。Paxos 算法在它正确性的理论证明上是很好的，但是在实现上的价值就远远不足了。来自 Chubby 的实现的一条评论就能够说明： There are signiﬁcant gaps between the description of the Paxos algorithm and the needs of a real-world system... the ﬁnal system will be based on an unproven protocol 翻译：Paxos 算法的描述与实际实现之间存在巨大的鸿沟... 最终的系统往往建立在一个没有被证明的算法之上。 正因为存在这些问题，我们认为 Paxos 不仅对于系统的构建者来说不友好，同时也不利于教学。鉴于一致性算法对于大规模软件系统的重要性，我们决定试着来设计一种另外的比 Paxos 更好的一致性算法。Raft 就是这样的一个算法。 4. 易于理解的设计设计 Raft 的目标有如下几个： 它必须提供一个完整的、实际的基础来进行系统构建，为的是减少开发者的工作； 它必须在所有情况下都能保证安全可用； 它对于常规操作必须高效； 最重要的目标是：易于理解，它必须使得大多数人能够很容易的理解； 另外，它必须能让开发者有一个直观的认识，这样才能使系统构建者们去对它进行扩展。 在设计 Raft 的过程中，我们不得不在许多种方法中做出选择。当面临这种情况时，我们通常会权衡可理解性：每种方法的可理解性是如何的？（例如，它的状态空间有多复杂？它是不是有很细微的含义？）它的可读性如何？读者能不能轻易地理解这个方法和它的含义？ 我们意识到对这种可理解性的分析具有高度的主观性；尽管如此，我们使用了两种适用的方式。 第一种是众所周知的问题分解：我们尽可能将问题分解成为若干个可解决的、可被理解的小问题。例如，在 Raft 中，我们把问题分解成为了领导选取（leader election）、日志复制（log replication）、安全（safety）和成员变化（membership changes）。 我们采用的第二个方法是通过减少需要考虑的状态的数量将状态空间简化，这能够使得整个系统更加一致并且尽可能消除不确定性。特别地，日志之间不允许出现空洞，并且 Raft 限制了限制了日志不一致的可能性。尽管在大多数情况下，我们都都在试图消除不确定性，但是有时候有些情况下，不确定性使得算法更易理解。尤其是，随机化方法使得不确定性增加，但是它减少了状态空间。我们使用随机化来简化了 Raft 中的领导选取算法。 5. Raft 一致性算法Raft是一种用于管理第2节中描述的表单的复制日志的算法。表2总结了压缩格式的算法，表3列出了算法的关键属性;这些数字的组成部分是分段讨论的。 状态 表-2-1 在所有服务器上持久存在的 名称 描述 currentTerm 服务器最后知道的任期号（从0开始递增） votedFor 当前任期内收到选票的 候选人 id（如果没有就为null） log[] 日志条目；，诶个条目包含状态机的要执行命令和从 `领导者 出收到的任期号 在所有服务器上不稳定存在的 名称 描述 commitIndex 已知的被提交的最大日志条目的索引值（从0开始递增） lastApplied 被状态机执行的额最大日志条目的索引值（从0开始递增） 在领导人服务器上不稳定存在的（在选举之后初始化的） 名称 描述 nextIndex[] 对于每个服务器，记录需要发给它的下一个日志条目的索引（初始化为Leader上一条日志索引+1） natchIndex[] 对于每一个服务器，记录已经复制到该拂去其的日志的最高索引值（从0开始递增） 附加日志远程调用（AppendEntries RPC）由领导人来调用复制日志 表-2-2 参数 描述 term 领导人的任期号 leaderId 领导人的id，为了其他服务器能重定向到Leader prevLogIndex 最新日志之前的日志的索引值 prevLogTerm 最新日志之前的日志的领导人任期号 entries[] 要存储的日志条目（表示heartbeat时为空，有时会为了效率发送多条） leaderCommit 领导人提交的日志条目索引值 返回值 描述 term 当前的任期号，用于 Leader 更新自己的任期号 success 如果其他服务器包含能够匹配上 prevLogIndex 和 prevLogTerm 的日志时为真 Follower需要实现： 如果 term &lt; currentTerm 返回false 如果在 prevLogIndex 处的日志的任期号与 prevLogTerm 不匹配时，返回false 如果一条已经存在的日志与新的冲突（index 相同但任期号 term 不同），则删除已经存在的日志和它之后的所有日志 添加任何在以后日志中不存在的条目 如果 leaderCommit &gt; commitIndex，将 commitIndex 设置为 leaderCommit 和最新日志条目索引号中较小的一个 投票请求RPC（RequestVote RPC）由候选人发起收集选票 表-2-3 参数 描述 term 领导人的任期号 candidateId 请求投票的候选人id lastLogIndex 候选人最新日志条目的索引值 lastLogTerm 候选人最新日志条目对应的任期号 返回值 描述 term 当前的任期号，用于 候选人 更新自己的任期号 voteGranted 如果候选人收到选票为true 接受者需要实现 如果 term &lt; currentTerm 返回false 如果 votedFor 为空或者与 candidateId 相同，并且候选人的日志和自己的日志一样新，则给候选人投票。 服务器需要遵守的规则所有服务器 如果 commitIndex &gt; lastApplied，lastApplied 自增，将 log[lastApplied] 应用到状态机； 如果RPC的请求或者响应中包含一个 Term &gt; currentTerm，则 currentTerm 赋值为 Term，并切换状态为Follower； Follower 响应来自候选人和领导人的RPC请求 如果在超过选取 Leader 时间之前没有收到来自领导人的 AppendEntries RPC 或者没有收到候选人的投票请求，则自己转换状态为候选人 Candidate 转变为 Candidate 之后开始选举 currentTerm 自增 给自己投票 重置选举计时器 向其他服务器发送 RequestVote RPC 如果收到了来自大多数服务器的投票，则成为领导人 如果收到了来自新 Leader 的 AppendEntries RPC(heartbeat)，则成为 Follower 如果选举超时，开始新一轮选举 Leader 一旦成为领导人：想起他所有服务器发送空的 AppendEntries PRC(heartbeat)；在空闲时间重复发送以防止选举超时 如果收到来自客户端的请求，向本地日子增加条目，在该条目应用到状态机后响应客户端 对于一个 Followed 来说，如果上一次收到的日志索引大于将要收到的日志索引(nextIndex)：通过 AppendEntries RPC 将 nextIndex 之后的所有日志条目发送出去 如果发送成功：将该 Follower 的 nextIndex 和 matchIndex 更新 如果由于日志不一致导致 AppendEntries RPC 失败：nextIndex 递减并且重新发送 如果存在一个满足 N &gt; commitIndex 和 matchIndex[i] &gt;= N 并且 log[N].term == currentTerm的 N，则将 commitIndex 赋值为N Raft 一致性算法的总结（不包括成员变化和日志压缩） 表-3 Raft 算法保证这些特性任何时刻都能成立 性质 描述 选举安全原则(Election Safety) 一个任期 (Term) 内最多允许有一个 Leader 被选上 领导者只增加原则(Leader Append-Only) Leader 永远不会覆盖或删除自己的日志，只会增加条目 日志匹配原则(Log Matching) 如果两个日志在相同的索引位置上的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置的条目完全相同。 领导者完全原则(Leader Completeness) 如果一个日志条目在一个给定任期内被提交，那么这个条目一定会出现在所有任期更大的 Leader 中 状态机安全原则(State Machine Safely) 如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目 Raft 通过首先选出一个领导人来实现一致性，然后给予领导人完全管理复制日志（replicated log）的责任。领导人接收来自客户端的日志条目，并把它们复制到其他的服务器上，领带人还要告诉服务器们什么时候将日志条目应用到它们的状态机是安全的。通过选出领导人能够简化复制日志的管理工作。例如，领导人能够决定将新的日志条目放到哪，而并不需要和其他的服务器商议，数据流被简化成从领导人流向其他服务器。如果领导人宕机或者和其他服务器失去连接，就可以选取下一个领导人。 通过选出 Leader 的方法，Raft 将共识问题分解为三个相对独立的子问题，这些子问题在下面的子部分中讨论: Leader 选举: 当现有 Leader 失败时，必须选出新的 Leader。 日志复制（Log replication）： 领导人必须从客户端接收日志然后复制到集群中的其他服务器，并且强制要求其他服务器的日志保持和自己相同 安全性（Safety）： Raft 的关键的安全特性是 表-3 中提到的状态机安全原则（State Machine Safety）:如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目。5.4节阐述了 Raft 是如何保证这条原则的，解决方案涉及到一个对于选举机制另外的限制，这一部分会在 5.2节 中说明。 在说明了一致性算法之后，本章会讨论有关可用性（availability）的问题和系统中时序（timing）的问题。 5.1. Raft基础一个 Raft 集群包括若干服务器；对于一个典型的 5 服务器集群，该集群能够容忍 2 台机器不能正常工作，而整个系统保持正常。在任意的时间，每一个服务器一定会处于以下三种状态中的一个：领导人、候选人、追随者。在正常情况下，只有一个服务器是领导人，剩下的服务器是追随者。追随者们是被动的：他们不会发送任何请求，只是响应来自领导人和候选人的请求。领导人来处理所有来自客户端的请求（如果一个客户端与追随者进行通信，追随者会将信息发送给领导人）。候选人是用来选取一个新的领导人的，这一部分会在 5.2节 进行阐释。图-4 阐述了这些状态，和它们之间的转换；它们的转换会在下边进行讨论。 服务器的状态。追随者只响应其他服务器的请求。如果追随者没有收到任何消息，它会成为一个候选人并且开始一次选举。收到大多数服务器投票的候选人会成为新的领导人。领导人在它们宕机之前会一直保持领导人的状态。 时间被分为一个个的任期（term），每一个任期的开始都是领导人选举。在成功选举之后，一个领导人会在任期内管理整个集群。如果选举失败，该任期就会因为没有领带人而结束。这个转变会在不同的时间的不同服务器上观察到。 如 图-5 所示，Raft 算法将时间划分成为任意不同长度的 任期（term）。任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），就像 5.2 节 所描述的那样，一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最少要有一个领导人。 不同的服务器可能会在任期内观察到多次不同的状态转换，在某些情况下，一台服务器可能看不到一次选举或者一个完整的任期。任期在 Raft 中充当逻辑时钟的角色，并且它们允许服务器检测过期的信息，比如过时的领导人。每一台服务器都存储着一个当前任期的数字，这个数字会单调的增加。当服务器之间进行通信时，会互相交换当前任期号；如果一台服务器的当前任期号比其它服务器的小，则更新为较大的任期号。如果一个候选人或者领导人意识到它的任期号过时了，它会立刻转换为追随者状态。如果一台服务器收到的请求的任期号是过时的，那么它会拒绝此次请求。 Raft 中的服务器通过远程过程调用（RPC）来通信，基本的 Raft 一致性算法仅需要 2 种 RPC。RequestVote RPC 是候选人在选举过程中触发的（5.2节），AppendEntries RPC 是领导人触发的，为的是复制日志条目和提供一种 心跳（heartbeat） 机制（5.3节）。第7章加入了第三种 RPC 来在各个服务器之间传输 快照（snapshot）。如果服务器没有及时收到 RPC 的响应，它们会重试，并且它们能够并行的发出 RPC 来获得最好的性能。 5.2. 领导人选举Raft 使用一种 心跳机制（heartbeat） 来触发领导人的选取。当服务器启动时，它们会初始化为追随者。一太服务器会一直保持追随者的状态只要它们能够收到来自领导人或者候选人的有效 RPC。领导人会向所有追随者周期性发送 心跳（heartbeat，不带有任何日志条目的 AppendEntries RPC） 来保证它们的领导人地位。如果一个追随者在一个周期内没有收到心跳信息，就叫做 选举超时（election timeout） ,然后它就会假定没有可用的领导人并且开始一次选举来选出一个新的领导人。 为了开始选举，一个追随者会自增它的当前任期并且转换状态为候选人。然后，它会给自己投票并且给集群中的其他服务器发送 RequestVote RPC 。一个候选人会一直处于该状态，直到下列三种情形之一发生： 它赢得了选举； 另一台服务器赢得了选举； 一段时间后没有任何一台服务器赢得了选举 一个候选人如果在一个任期内收到了来自集群中大多数服务器的投票就会赢得选举。在一个任期内，一台服务器最多能给一个候选人投票，按照 先到先服务原则（first-come-first-served） （注意：在 5.4节 针对投票添加了一个额外的限制）。大多数原则使得在一个任期内最多有一个候选人能赢得选举 （表-3 中提到的选举安全原则） 。一旦有一个候选人赢得了选举，它就会成为 领导人 。然后它会像其他服务器发送心跳信息来建立自己的领导地位并且组织新的选举。 当一个 候选人 等待别人的选票时，它有可能会收到来自其他服务器发来的声明其为领导人的 AppendEntries RPC 。如果这个领导人的 任期（包含在它的 RPC 中） 比当前候选人的当前任期要大，则候选人认为该领导人合法，并且转换自己的状态为 追随者 。如果在这个 RPC 中的任期小于候选人的当前任期，则候选人会拒绝此次 RPC， 继续保持候选人 状态。 第三种情形是一个 候选人 既没有赢得选举也没有输掉选举：如果许多追随者在同一时刻都成为了候选人，选票会被分散，可能没有候选人能获得大多数的选票。当这种情形发生时，每一个候选人都会超时，并且通过自增任期号和发起另一轮 RequestVote RPC 来开始新的选举。然而，如果没有其它手段来分配选票的话，这种情形可能会无限的重复下去。 Raft 使用 随机的选举超时时间 来确保第三种情形很少发生，并且能够快速解决。为了防止在一开始是选票就被瓜分，选举超时时间是在一个固定的间隔内随机选出来的（例如，150~300ms）。这种机制使得在大多数情况下只有一个服务器会率先超时，它会在其它服务器超时之前赢得选举并且向其它服务器发送心跳信息。同样的机制被用于选票一开始被瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，在超时进行下一次选举之前一直等待。这能够减小在新的选举中一开始选票就被瓜分的可能性。9.3节 展示了这种方法能够快速的选出一个领导人。 选举是一个理解性引导我们设计替代算法的一个例子。最开始时，我们计划使用一种排名系统：给每一个候选人分配一个唯一的排名，用于在竞争的候选人之中选择领导人。如果一个候选人发现了另一个比它排名高的候选人，那么它会回到追随者的状态，这样排名高的候选人会很容易地赢得选举。但是我们发现这种方法在可用性方面有一点问题（一个低排名的服务器在高排名的服务器宕机后，需要等待超时才能再次成为候选人，但是如果它这么做的太快，它能重置选举领带人的过程）。我们对这个算法做了多次调整，但是每次调整后都会出现一些新的问题。最终我们认为随机重试的方法是更明确并且更易于理解的。 5.3.日志复制一旦选出了领导人，它就开始接收客户端的请求。每一个客户端请求都包含一条需要被 复制状态机（replicated state machine） 执行的命令。领导人把这条命令作为新的日志条目加入到它的日志中去，然后并行的向其他服务器发起 AppendEntries RPC ，要求其它服务器复制这个条目。当这个条目被安全的复制之后（下面的部分会详细阐述），领导人会将这个条目应用到它的状态机中并且会向客户端返回执行结果。如果追随者崩溃了或者运行缓慢或者是网络丢包了，领导人会无限的重试 AppendEntries RPC （甚至在它向客户端响应之后）知道所有的追随者最终存储了所有的日志条目。 图-6：日志由有序编号的日志条目组成。每个日志条目包含它被创建时的任期号（每个方块中的数字），并且包含用于状态机执行的命令。如果一个条目能够被状态机安全执行，就被认为可以提交了。 日志就像 图-6 所示那样组织的。每个日志条目存储着一条被状态机执行的命令和当这条日志条目被领导人接收时的任期号。日志条目中的任期号用来检测在不同服务器上日志的不一致性，并且能确保 图-3 中的一些特性。每个日志条目也包含一个整数索引来表示它在日志中的位置。 领导人 决定什么时候将日志条目应用到状态机是安全的；这种条目被称为 可被提交（commited） 。 Raft 保证 可被提交（commited）的日志条目 是持久化的并且最终会被所有可用的状态机执行。一旦被领导人创建的条目已经复制到了大多数的服务器上，这个条目就称为可被提交的（例如，图-6中的7号条目）。领导人日志中之前的条目都是可被提交的（commited），包括由之前的领导人创建的条目。5.4节将会讨论当领导人更替之后这条规则的应用问题的细节，并且也讨论了这种提交方式是安全的。领导人跟踪记录它所知道的被提交条目的最大索引值，并且这个索引值会包含在之后的 AppendEntries RPC 中（包括心跳 heartbeat 中），为的是让其他服务器都知道这条条目已经提交。一旦一个追随者知道了一个日志条目已经被提交，它会将该条目应用至本地的状态机（按照日志顺序）。 我们设计了 Raft 日志机制来保证不同服务器上日志的一致性。这样做不仅简化了系统的行为使得它更可预测，并且也是保证安全性不可或缺的一部分。Raft 保证以下特性，并且也保证了 表-3 中的日志匹配原则 （Log Matching Property） : 如果在不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果在不同日志中的两个条目有着相同的索引和任期号，则它们之间的所有条目都是完全一样的。 第一条特性源于 领导人 在一个任期里在给定的一个日志索引位置最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，领导人会把新日志条目紧接着之前的条目的索引位置和任期号都包含在里面。如果追随者没有在它的日志中找到相同索引和任期号的日志，它就会拒绝新的日志条目。这个一致性检查就像一个归纳步骤：一开始空的日志的状态一定是满足日志匹配原则的，一致性检查保证了当日志添加时的日志匹配原则。因此，只要 AppendEntries 返回成功的时候，领导人就知道追随者们的日志和它的是一致的了。 图-7：当最上边的领导人掌权之后，追随者日志可能有以下情况（a~f）。一个格子表示一个日志条目；格子中的数字是它的任期。一个追随者可能会丢失一些条目（a, b）；可能多出来一些未提交的条目（c, d）；或者两种情况都有（e, f）。例如，场景 f 在如下情况下就会发生：如果一台服务器在任期2时是领导人并且往它的日志中添加了一些条目，然后在将它们提交之前就宕机了，之后它很快重启了，成为了任期3的领导人，又往它的日志中添加了一些条目，然后在任期2和任期3中的条目提交之前它又宕机了并且几个任期内都一直处于宕机状态。 在一般情况下， 领导人 和 追随者们 的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而， 领导人 的崩溃会导致日志不一致（旧的领导人可能没有完全复制完日志中的所有条目）。这些不一致会导致一系列领导人和追随者崩溃。 图-7 阐述了一些 追随者 可能和 新的领导人 日志不同的情况。一个 追随者 可能会丢失掉领导人上的一些条目，也有可能包含一些 领导人 没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。 在 Raft 算法中， 领导人 通过 强制追随者们复制它的日志 来处理日志的不一致。这就意味着，在追随者上的冲突日志会被领导者的日志覆盖。5.4节会说明当添加了一个额外的限制之后这是安全的。 为了使得追随者的日志同自己的一致， 领导人 需要找到追随者同它的日志一致的地方，然后删除追随者在该位置之后的条目，然后将自己在该位置之后的条目发送给追随者。这些操作都在 AppendEntries RPC 进行一致性检查时完成。领导人给每一个追随者维护了一个 nextIndex ，它表示领导人将要发送给该追随者的下一条日志条目的索引。当一个领导人开始掌权时，它会将 nextIndex 初始化为 它的最新的日志条目索引数+1（图-7 中的 11） 。如果一个追随者的日志和领导者的不一致，AppendEntries 一致性检查会在下一次 AppendEntries RPC 时返回失败。在失败之后，领导人会将 nextIndex 递减然后重试 AppendEntries RPC 。最终 nextIndex 会达到一个领导人和追随者日志一致的地方。这时，AppendEntries 会返回成功，追随者中冲突的日志条目都被移除了，并且添加所缺少的上了领导人的日志条目。一旦 AppendEntries 返回成功，追随者和领导人的日志就一致了，这样的状态会保持到该任期结束。 如果需要的话，算法还可以进行优化来减少 AppendEntries RPC 失败的次数。例如，当拒绝了一个 AppendEntries 请求，追随者可以记录下冲突日志条目的任期号和自己存储那个任期的最早的索引。通过这些信息，领导人能够直接递减nextIndex跨过那个任期内所有的冲突条目；这样的话，一个冲突的任期需要一次 AppendEntries RPC，而不是每一个冲突条目需要一次 AppendEntries RPC。在实践中，我们怀疑这种优化是否是必要的，因为 AppendEntries 一致性检查很少失败并且也不太可能出现大量的日志条目不一致的情况。 通过这种机制，一个领导人在掌权时不需要采取另外特殊的方式来恢复日志的一致性。它只需要使用一些常规的操作，通过响应 AppendEntries 一致性检查的失败能使得日志自动的趋于一致。一个领导人从来不会覆盖或者删除自己的日志（表-3 中的领导人只增加原则）。 这个日志复制机制展示了在第2章中阐述的所希望的一致性特性：Raft 能够接受，复制并且应用新的日志条目只要大部分的服务器是正常的。在通常情况下，一条新的日志条目可以在一轮 RPC 内完成在集群的大多数服务器上的复制；并且一个速度很慢的追随者并不会影响整体的性能。]]></content>
      <categories>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>文献翻译</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft协议(1)——一致性原理分析]]></title>
    <url>%2Fblog%2F2018%2F04%2F14%2FRaft%E5%8D%8F%E8%AE%AE-1-%E2%80%94%E2%80%94%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[概述在一个由 Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人） 就像一个民主社会，领袖由民众投票选出。刚开始没有领袖，所有集群中的参与者都是群众，那么首先开启一轮大选，在大选期间所有群众都能参与竞选，这时所有群众的角色就变成了候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除领袖的候选人又变回群众角色服从领袖领导。这里提到一个概念「任期」，用术语 Term 表达。关于 Raft 协议的核心概念和术语就这么多而且和现实民主制度非常匹配，所以很容易理解。三类角色的变迁图如下，结合后面的选举过程来看很容易理解。 Raft 集群中节点状态转化 Leader 选举过程在极简的思维下，一个最小的 Raft 民主集群需要三个参与者（如下图：A、B、C），这样才可能投出多数票。初始状态 ABC 都是 Follower，然后发起选举这时有三种可能情形发生。下图中前二种都能选出 Leader，第三种则表明本轮投票无效（Split Votes），每方都投给了自己，结果没有任何一方获得多数票。之后每个参与方随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机 timeout，最先从 timeout 中恢复发起投票的一方向还在 timeout 中的另外两方请求投票，这时它们就只能投给对方了，很快达成一致。 选出 Leader 后，Leader 通过定期向所有 Follower 发送心跳信息维持其统治。若 Follower 一段时间未收到 Leader 的心跳则认为 Leader 可能已经挂了再次发起选主过程。 Leader 节点对一致性的影响Raft 协议强依赖 Leader 节点的可用性来确保集群数据的一致性。数据的流向只能从 Leader 节点向 Follower 节点转移。当 Client 向集群 Leader 节点提交数据后，Leader 节点接收到的数据处于未提交状态（Uncommitted），接着 Leader 节点会并发向所有 Follower 节点复制数据并等待接收响应，确保至少集群中超过半数节点已接收到数据后再向 Client 确认数据已接收。一旦向 Client 发出数据接收 Ack 响应后，表明此时数据状态进入已提交（Committed），Leader 节点再向 Follower 节点发通知告知该数据状态已提交。 在这个过程中，主节点可能在任意阶段挂掉，看下 Raft 协议如何针对不同阶段保障数据一致性的。 数据到达 Leader 节点前这个阶段 Leader 挂掉不影响一致性，不多说。 数据到达 Leader 节点，但未复制到 Follower 节点这个阶段 Leader 挂掉，数据属于未提交状态，Client 不会收到 Ack 会认为超时失败可安全发起重试。Follower 节点上没有该数据，重新选主后 Client 重试重新提交可成功。原来的 Leader 节点恢复后作为 Follower 加入集群重新从当前任期的新 Leader 处同步数据，强制保持和 Leader 数据一致。 数据到达 Leader 节点，成功复制到 Follower 所有节点，但还未向 Leader响应这个阶段 Leader 挂掉，虽然数据在 Follower 节点处于未提交状态（Uncommitted）但保持一致，重新选出 Leader 后可完成数据提交，此时 Client 由于不知到底提交成功没有，可重试提交。针对这种情况 Raft 要求 RPC 请求实现幂等性，也就是要实现内部去重机制。 数据到达 Leader 节点，成功复制到 Follower 部分节点，但还未向 Leader 响应接受这个阶段 Leader 挂掉，数据在 Follower 节点处于未提交状态（Uncommitted）且不一致，Raft 协议要求投票只能投给拥有最新数据的节点。所以拥有最新数据的节点会被选为 Leader 再强制同步数据到 Follower，数据不会丢失并最终一致。 数据到达 Leader 节点，成功复制到 Follower 所有或多数节点，数据在所有节点都处于已提交状态，但还未响应 Client这个阶段 Leader 挂掉，Cluster 内部数据其实已经是一致的，Client 重复重试基于幂等策略对一致性无影响。 网络分区导致的脑裂情况，出现双 Leader网络分区将原先的 Leader 节点和 Follower 节点分隔开，Follower 收不到 Leader 的心跳将发起选举产生新的 Leader。这时就产生了双 Leader，原先的 Leader 独自在一个区，向它提交数据不可能复制到多数节点所以永远提交不成功。向新的 Leader 提交数据可以提交成功，网络恢复后旧的 Leader 发现集群中有更新任期（Term）的新 Leader 则自动降级为 Follower 并从新 Leader 处同步数据达成集群数据一致。 算法以正确性、高效性、简洁性作为主要设计目标。虽然这些都是很有价值的目标，但这些目标都不会达成直到开发者写出一个可用的实现。所以我们相信可理解性同样重要。]]></content>
      <categories>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
        <tag>一致性算法</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ-(5)——ActiveMQ结合Spring开发]]></title>
    <url>%2Fblog%2F2018%2F04%2F14%2FActiveMQ-5-%E2%80%94%E2%80%94ActiveMQ%E7%BB%93%E5%90%88Spring%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[步骤依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; 在Spring中配置jmsTemplate12345678910111213141516171819202122&lt;!--JMS连接池工厂--&gt;&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://localhost:61616"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"/&gt;&lt;/bean&gt;&lt;!--目的地--&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg index="0" value="spring-queue"/&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="defaultDestination" ref="destination"/&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"/&gt; &lt;/property&gt;&lt;/bean&gt; 如果是topic 添加topic的配置 修改jmsTemplate配置中的defaultDestination 12345678910111213141516171819202122&lt;!--JMS连接池工厂--&gt;&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://localhost:61616"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"/&gt;&lt;/bean&gt;&lt;!--目的地--&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg index="0" value="spring-topic"/&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="defaultDestination" ref="destination"/&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"/&gt; &lt;/property&gt;&lt;/bean&gt; 如果在Spring中配置消费者的话，就不需要启动消费者相当于注册了一个默认消息监听器 当JMS Provider接受到消息之后就会触发listener的onMessage()方法 1234567&lt;bean id="jmsContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="jmsFactory"/&gt; &lt;property name="destination" ref="destination"/&gt; &lt;property name="messageListener" ref="messageListener"/&gt;&lt;/bean&gt;&lt;bean id="messageListener"class="org.destiny.activemq.spring.MyMessageListener"/&gt; 12345678910111213package org.destiny.activemq.spring;public class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println("receive: " + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 最佳实践 Camel框架支持大量的企业集成模式，可以大大简化集成组件间的大量服务和复杂的消息流。而Spring更注重简单性。 Spring消息发送的核心架构是JmsTemplate，隔离了像打开、关闭Session和Producer等操作。因此应用开发人员仅仅需要关注实际的业务逻辑。但JmsTemplate损害了ActiveMQ的PooledConnectionFactory对Session和消息Producer的缓存机制带来的性能提升。 新的Spring中，可以设置org.springframework.jms.connection.CachingConnectionFactory的sessionCacheSize，或者直接使用ActiveMQ的PooledConnectionFactory。 不建议使用JmsTemplate的receive()，因为JmsTemplate上的所有调用都是同步的，这意味着调用的线程会阻塞，直到方法返回，性能影响较大。 尽量使用DefaultMessageListenerContainer，它允许异步接受消息并缓存session和消息Consuer。]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(4)——Broker的启动方式]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2FActiveMQ-4-%E2%80%94%E2%80%94Broker%E7%9A%84%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Broker：相当于一个ActiveMQ服务器实例。 命令行启动参数示例 activemq start：默认使用acitvemq.xml来启动 activemq start xbean:file:../conf/activemq.xml：使用指定的配置文件来启动。 用ActiveMQ来构建Java应用用ActiveMQ Broker作为独立的消息服务器来构建JAVA应用。ActiveMQ也支持在VM中通信基于嵌入式的Broker，能够无缝集成其他Java应用。 嵌入式BrokerBrokerService启动Broker1234567public static void main(String[] args) throws Exception &#123; // 开启ActiveMQ Broker BrokerService brokerService = new BrokerService(); brokerService.setUseJmx(true); brokerService.addConnector("tcp://localhost:61616"); brokerService.start();&#125; BrokerFactory启动Broker1234567public static void main(String[] args) throws Exception &#123; // 开启ActiveMQ Broker String uri = "properties:broker.properties"; BrokerService brokerService = BrokerFactory.createBroker(new URI(uri)); brokerService.addConnector("tcp://localhost:61616"); brokerService.start();&#125; 配置文件broker.properties123useJmx=truepersistent=falsebrokerName=Cheese 利用Spring集成Broker123456789&lt;bean id="broker" class="org.apache.activemq.broker.BrokerService" init-method="start" destroy-method="stop"&gt; &lt;property name="brokerName" value="myBroker"/&gt; &lt;property name="persistent" value="false"/&gt; &lt;property name="transportConnectorURIs"&gt; &lt;list&gt; &lt;value&gt;tcp://localhost:61616&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 启动多个Broker如果需要启动多个Broker，那么需要为每个Broker设置一个名字12]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(3)——JMS可靠性机制]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2FActiveMQ-3-%E2%80%94%E2%80%94JMS%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[消息接受确认JMS消息只有在被确认之后，才认为已经被成功地消费了。消费的成功通常包含三个阶段：客户端接受消息、客户端处理消息和消息被确认。在事务性会话中，当一个事务被提交的时候，确认自动发生。在非事务性会话中，消息何时被确认取决于创建会话时的应答模式。该参数有三个可选方案： Session.AUTO_ACKNOWLEDGE当客户成功的从receive()方法返回的时候，或者从MessageListener.onMessage()方法成功返回的时候，会话自动确认客户端收到的消息。 Session.CLIENT_ACKNOWLEDGE客户端通过调用消息的acknowledge()方法确认消息。在这种模式中，确认是在会话层上进行，确认一个被消费的消息将自动确认所有已被会话消费的消息。 1Session session = connection.createSession(false, Session.CLIENT_ACKNOWLEDGE); Session.DUPS_ACKNOWLEDGE只是会话迟钝的确认消息的提交。如果JMS Provider失败，那么可能会导致一些重复的消息。如果是重复的消息，那么JMS Provider必须把消息头的JMSRedelivered字段设置为true 消息的持久性，JMS支持两种消息提交模式PERSISTENTJMS Provider永久保存消息，以保证消息不会因为JMS Provider的失败而丢失。 NON_PERSISTENT不要求JMS Provider持久保存消息 消息的临时目的地可以通过Session的createTemporaryQueue()和createTemporaryTopic()方法来创建临时目的地。他们的存在时间只限于创建他们的连接所保持的时间，只有创建该临时目的地的连接上的消息消费者才能够从临时目的地中提取消息。 本地事务在一个JMS客户端，可以使用本地事务来组合消息的发送和签收。Session接口提供了commit()和rollback()方法。 事务提交意味着生产的所有消息被发送，消费的所有消息被确认。 事务回滚意味着生产的所有消息被销毁，消费的所有消息被恢复并重新提交，除非他们已过期。 PTP模型该模型定义了客户端如何向队列发送消息，从队列接受消息。 PTP模型是基于队列的，生产者发消息到队列，消费者从队列接受消息，队列使得消息的异步传输成为可能。 特点 Session在关闭时，如果有消息已经被接受，但还没有确认，那么当消费者下次连接到相同的队列时，这些消息还会被再次接受。 如果用户在receive()方法中设定了消息选择条件，那么不符合条件的消息会留在队列中。 队列可以长久地保存消息直到消费者收到消息，消费者不需要因为担心消息丢失而时刻与队列保持激活的连接状态。 Pub/Sub模型该模型定义了如何向一个内容节点发布和订阅消息。 主题可以被认为是消息的传输中介，发布者发布消息到主题，订阅者从主题订阅消息，二者相互独立，不需要接触。 特点 消息订阅分为非持久订阅和持久订阅 非持久订阅时，只有当客户端处于激活状态才能收到某个主题的消息；离线时发布到主题的消息将会丢失。 持久订阅时，客户端向JMS Provider注册一个自己身份的ID，当客户端处于离线状态时，Provider会为这个ID保存所有发送到主题的消息。 如果用户在receive()方法中设定了消息选择条件，那么不符合条件的消息不会被接收。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(2)——JMS规范]]></title>
    <url>%2Fblog%2F2018%2F04%2F11%2FActiveMQ-2-%E2%80%94%E2%80%94JMS%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[定义JMS(Java Message Service)，Java消息服务 JMS定义了Java访问消息中间件的接口，并没有给予实现。 实现JMS接口的消息中间件成为JMSProvider，如ActiveMQ。 JMS规范 JMS message：JMS的消息，由三部分组成：消息头、消息属性、消息体 JMS Producer：消息生产者，创建和发送消息 JMS Consumer：消息消费者，接受和处理消息，消息的消费可以采用以下两种方式之一： 同步消费：通过调用消费者的receive方法从目的地中显示提取消息，receive方法可以一直阻塞到消息到达 异步消费：客户可以为消费者注册一个Listener，以定义在消息到达时所采取的动作。 JMS domains：消息传递域，JMS定义了两周消息传递域： 点对点：每个消息只能有一个消费者，生产者和消费者没有时间上的相关性，无论消费者在生产者发送消息的时候是否处于运行状态，都可以提取消息； 发布订阅：每个消息可以被多个消费者消费，生产者和消费者有时间上的相关性，订阅一个主题的消费者只能消费它订阅之后发布的消息 ConnectionFactory：连接工厂，用来创建连接对象，已连接到JMS的Provider JMS Connection：封装了客户与JMS提供者之间的一个虚拟连接 JMS Session：是生产和消费消息的一个单线程上下文 会话用于创建消息生产者、消费者和消息等。会话提供了一个事务性的上下文，在这个上下文中，一组发送和接受被组合到了一个原子操作中。 Destination：消息发送到的目的地。 Acknowledge：签收。消费者收到消息后，需要告诉JMS Provider消息已被消费。 Transaction：事务 JMS Client：用来收发消息的Java应用 JMS Message结构组成 消息头 属性 消息体 消息头消息头包含识别信息和路由信息 JMSDestination：消息发送的目的地，主要是指Queue或Topic。 JMSDeliveryMode：传送模式，持久或非持久。 持久消息应该会且只会被发送一次，JMS提供者出现故障，消息也不会丢失，会在服务器恢复之后再次传递。 非持久的消息最多会被发送一次，这意味着服务器出现故障，该消息会永远丢失。 JMSExpiration：消息过期时间，为0表示永不过期。 JMSPriority：消息优先级，数字越大，级别越高，加急消息要先于普通消息。 JMSMessageId：唯一标识。 JMSCorrelationID：用来连接到另一个消息，典型应用是在回复消息中关联到原消息。 JMSReplyTo：提供本消息回复消息的目的地址，由开发者提供 JMSType：消息的类型识别符 JMSRedelivered：如果一个客户端收到了一个设置了JMSRedelivered属性的消息，则表示客户端可能收到过该消息，但没有签收。 消息体 TextMessage：文本消息 MapMessage：映射消息 BytesMessage：二进制消息 StreamMessage：流式消息 ObjectMessage：对象消息 属性应用程序设置和添加的属性1message.setStringProperty("username", username); JMS定义的属性12// 返回所有连接支持的JMSX属性的名字connection.getMetaData().getJMSXPropertyNames(); JMS供应商特定的属性JMS定义的属性 JMSXUserID：发送消息的用户标识 JMSXAppID：发送消息的应用标识 JMSXDeliveryCount：转发消息重试次数 JMSXGroupID：消息所在的消息组的标识 JMSXGroupSeq：组内消息的序号]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ(1)——概览&入门]]></title>
    <url>%2Fblog%2F2018%2F04%2F09%2FActiveMQ-1-%E2%80%94%E2%80%94%E6%A6%82%E8%A7%88-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[概览ActiveMQ简介 什么是ActiveMQ ActiveMQ的作用 ActiveMQ的特点 消息中间件的功能、特点、应用场景等 ActiveMQ安装和基本使用通过源码安装、基本的配置实例、启动、测试运行、关闭等 JMS基本概念、消息结构、可靠性机制、PTP、Pub/Sub、API结构、JMS应用开发的基本步骤、持久和非持久的Topic 同ActiveMQ构建应用 多种启动Broker的方法 单独应用的开发 结合Spring开发 ActiveMQ的Transport多种运输协议的功能、配置和使用 ActiveMQ的消息存储队列和Topic、KahaDB、AMQ、JDBC、MMS等 ActiveMQ的Network 在一台服务器上启动多个Broker 静态网络连接的功能、配置 “丢失”消息的处理 容错或可负载均衡的连接 动态网络连接等 ActiveMQ集群 队列消费者集群 Broker的集群 MasterSlave等 Destination高级特性 通配符 组合队列 配置启动的Destination 删除不活动的Destination 虚拟Destination 镜像队列 Message Dispatch高级特性 消息游标 异步发送 分发策略 优化批量控制 Message高级特性 消息属性 Advisory Message 延迟和定时消息投递 Blob消息 消息转换 Consumer高级特性 消息异步分发 消息优先级 管理持久化消息 消息分组 消息重抵策略 杂项 监控和管理 集成ActiveMQ和Tomcat ActiveMQ优化ActiveMQ简介介绍ActiveMQ是Apache推出的一款开源的、完全支持JMS和J2EE规范的JMSProvider实现的消息中间件(Message Oriented Middleware, MOM)。 作用用来帮助实现高可用、高性能、可伸缩、易用和安全的企业级面向消息服务的系统。 ActiveMQ安装和基本使用下载并安装服务端 从http://activemq.apache.org/download.html下载最新的ActiveMQ 直接解压1$ tar -zxvf apache-activemq-5.9.0-bin.tar.gz activemq 启动运行 普通启动 1234$ pwd/usr/local/activemq/bin$ ./activemq start 启动并指定日志文件 1$ ./activemq start &gt; /tmp/activemqlog 检查是否已经启动ActiveMQ默认采用61616端口提供JMS服务，使用8061端口提供管理控制台服务，执行以下命令以便检验是否已经成功启动ActiveMQ服务： 查看61616端口是否已经打开： netstat -an | grep 61616 查看控制台输出或者日志文件 直接访问ActiveMQ的管理页面：http://localhost:8161/admin，默认的用户名和密码是admin/admin 关闭ActiveMQ1$ ./activemq stop 基本的消息发送配置MAVEN所需的依赖12345678910&lt;dependency&gt; &lt;gruopId&gt;org.apache.activemq&lt;/gruopId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;gruopId&gt;org.apache.xbean&lt;/gruopId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; 消息生产者123456789101112131415161718192021222324252627public static void main(String[] args) throws JMSException, InterruptedException &#123; // 创建连接工厂，连接工程负责与ActiveMQ服务端建立连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616"); // 由连接工厂创建连接 Connection connection = connectionFactory.createConnection(); // 启动连接 connection.start(); // 通过连接创建会话 Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); // 通过会话创建目的地，名称表示对列名 Destination destination = session.createQueue("my-queue"); // 通过 session 创建生产者 MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; 100; ++i) &#123; TextMessage message = session.createTextMessage("message -- " + i); Thread.sleep(100); // 通过消息生产者发出消息 producer.send(message); System.out.println("创建成功"); &#125; session.commit(); session.close(); connection.close();&#125; 运行结果： 消息消费者123456789101112131415161718192021222324public static void main(String[] args) throws JMSException, InterruptedException &#123; // 创建连接工厂，连接工厂负责与ActiveMQ服务端建立连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://localhost:61616"); // 由连接工厂创建连接 Connection connection = connectionFactory.createConnection(); // 启动连接 connection.start(); // 通过连接创建会话 Session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); // 通过会话创建目的地，名称表示对列名 Destination destination = session.createQueue("my-queue"); // 通过 session 创建生产者 MessageConsumer consumer = session.createConsumer(destination); for (int i = 0; i &lt; 100; ++i) &#123; TextMessage message = (TextMessage) consumer.receive(); session.commit(); System.out.println("收到消息: " + message.getText()); &#125; session.close(); connection.close();&#125; 运行结果： JMS模型]]></content>
      <categories>
        <category>ActiveMQ</category>
      </categories>
      <tags>
        <tag>ActiveMQ</tag>
        <tag>JMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[盘点实际项目中常用的加密算法及使用场景]]></title>
    <url>%2Fblog%2F2018%2F04%2F08%2F%E7%9B%98%E7%82%B9%E5%AE%9E%E9%99%85%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[MD5定义MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4。 特点 压缩性：任意长度的数据，算出的MD5值长度都是固定的。 容易计算：从原数据计算出MD5值很容易。 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 MD5的作用是让大容量信息在用数字签名软件签署私人密钥前被”压缩”成一种保密的格式（就是把一个任意长度的字节串变换成一定长的十六进制数字串）。除了MD5以外，其中比较有名的还有sha-1、RIPEMD以及Haval等。 应用场景一致性验证MD5的典型应用是对一段信息（Message）产生信息摘要（Message-Digest），以防止被篡改。MD5就可以为任何文件（不管其大小、格式、数量）产生一个同样独一无二的“数字指纹”，如果任何人对文件做了任何改动，其MD5值也就是对应的“数字指纹”都会发生变化。 数字签名MD5的典型应用是对一段Message(字节串)产生fingerprint(指纹），以防止被“篡改”。举个例子，你将一段话写在一个叫 readme.txt文件中，并对这个readme.txt产生一个MD5的值并记录在案，然后你可以传播这个文件给别人，别人如果修改了文件中的任何内容，你对这个文件重新计算MD5时就会发现（两个MD5值不相同）。如果再有一个第三方的认证机构，用MD5还可以防止文件作者的“抵赖”，这就是所谓的数字签名应用。 安全访问认证MD5还广泛用于操作系统的登陆认证上，如Unix、各类BSD系统登录密码、数字签名等诸多方面。如在Unix系统中用户的密码是以MD5（或其它类似的算法）经Hash运算后存储在文件系统中。当用户登录的时候，系统把用户输入的密码进行MD5 Hash运算，然后再去和保存在文件系统中的MD5值进行比较，进而确定输入的密码是否正确。通过这样的步骤，系统在并不知道用户密码的明码的情况下就可以确定用户登录系统的合法性。这可以避免用户的密码被具有系统管理员权限的用户知道。 缺点与不足2014年中国山东大学的王小云教授公布破译了MD5、HAVAL-128、 MD4和RIPEMD算法的报告。通过加速的杂凑与冲撞方法破译了MD5算法。 实践 RSA定义RSA为公钥加密体制 乙方生成两把秘钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 甲方获取乙方的公钥，然后用它对信息加密。 乙方得到加密后的信息，用私钥解密。 特点便于理解，使用广泛RSA算法是第一个能同时用于加密和数字签名的算法，也易于理解和操作。RSA是被研究得最广泛的公钥算法，从提出到现今的三十多年里，经历了各种攻击的考验，逐渐为人们接受，普遍认为是目前最优秀的公钥方案之一。 缺点与不足：加密和解密花费时间长、速度慢，只适合对少量数据进行加密为提高保密强度，RSA密钥至少为500位长，一般推荐使用1024位。这就使加密的计算量很大。为减少计算量，在传送信息时，常采用传统加密方法与公开密钥加密方法相结合的方式，即信息采用改进的DES或IDEA对话密钥加密，然后使用RSA密钥加密对话密钥和信息摘要。对方收到信息后，用不同的密钥解密并可核对信息摘要。 实践ssh口令登录1234567sequenceDiagram客户端-&gt;&gt;服务端: 口令登录服务端-&gt;&gt;客户端: 发送1024为公钥指纹客户端-&gt;&gt;服务端: 指纹保存在$HOME/.ssh/known_hosts，接受远程主机秘钥服务端-&gt;&gt;客户端: 请求输入密码客户端-&gt;&gt;服务端: 输入密码服务端-&gt;&gt;客户端: 接受或拒绝链接 ssh公钥登录12345sequenceDiagram客户端-&gt;&gt;服务端: 登录请求服务端-&gt;&gt;客户端: 发送随机字符串客户端-&gt;&gt;服务端: 发送加密后的随机字符串服务端-&gt;&gt;客户端: 接受或拒绝链接 客户端事先把自己的公钥保存在服务端的指定目录: $HOME/.ssh/authorized_keys 客户端生成秘钥: ssh-keygen，运行结束后，在$HOME/.ssh/目录下，会新生成两个文件: id_rsa.pub和id_rsa。前者是公钥，后者是私钥。 将公钥发送给远程主机: ssh-copy-id user@host]]></content>
      <categories>
        <category>加密</category>
      </categories>
      <tags>
        <tag>开发</tag>
        <tag>算法</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（二）Nginx实现动静分离]]></title>
    <url>%2Fblog%2F2018%2F04%2F03%2F%EF%BC%88%E4%BA%8C%EF%BC%89Nginx%E5%AE%9E%E7%8E%B0%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[概念在反向代理时，如果是静态资源，就直接从Nginx发布的路径中去读取，而不需要从后台服务器获取。 但这种情况下需要保证后端跟前端的程序保持一致，可以使用Rsync做服务端自动同步或者使用NFS、MFS分布式共享存储。 概念图 原理Nginx可以拦截请求 因此可以利用这一特性，将拦截到的静态请求进行重定向。 12345678910111213141516171819202122232425server &#123; listen 80; server_name destiny; access_log logs/host.access.log main; index index.html index.htm index.jsp; root /usr/local/tomcat-9.0.0-RC5-1/webapps/ROOT/; # 不区分大小写的正则匹配 location ~* .*\.(jpg|jepg|fig|png|wsf|ico)$ &#123; if(-f $request_filename) &#123; # expires 15d; break; &#125; &#125; # 不区分大小写的正则匹配 locatin ~* .*\.(html|htm|js|css)$ &#123; # expires 1d; &#125; location / &#123; proxy_pass http://10.211.55.5 &#125;&#125; 在前两个location中，没有配置后端服务器的路径Nginx就会默认去寻找root的资源 Nginx会以root为根路径，将请求的路径拼在其后去查找，如果能访问到，Nginx就可以直接将该文件返回。 如果能够查询到响应的文件，就会直接返回。 指令index(默认主页设置模块)如果URL中没有指定文件，则设置一个默认主页。 可以指定多个文件，如果第一个文件没有找到，将会查找后面指定的文件 index index.html index.htm index.jsp root请求到达后的文件根目录 123location /i/ &#123; root /spool/w3;&#125; 如果请求/i/top.gif文件，Nginx将转到/spool/w3/i/top.gif文件 在请求中root会添加这个location到它的值后面，即”/i/top.gif”并不会请求”/spool/w3/top.gif”文件，如果要实现上述类似于apache alias的功能，可以使用alias指令。 简单来说，root是拼接，alias是替换。 实现当访问静态资源的请求进入(假设为http://10.211.55.4:80/static/person.jpg)时，会被配置文件中的第一个location拦截 location会将root中配置的路径和访问路径拼接在一起，新的路径为/usr/local/tomcat-9.0.0-RC5-1/webapps/ROOT/static/person.jpg，在Nginx的路径中进行查找。 初始情况，不加Nginx的情况下启动Tomcat 访问10.211.55.4:8080即可访问Tomcat主页。 查看logs/localhost_access_log.2018-04-03.txt可以看到访问日志 此时可以看到，请求了多个静态文件。 加入Nginx将包含上图中文件的路径/usr/local/apache-tomcat-7.0.73/webapps/ROOT/配置进Nginx配置文件中的root属性。 并配置location用于拦截jpg/jepg/fig/png/wsf/ico后缀的文件。 然后sbin/nginx -s reload重启Nginx 效果展示分别重启Tomcat和Nginx后，再访问10.211.55.4(Nginx自动监听80端口并转发至8080) 删除浏览器缓存 此时再查看日志，已经请求中已经不再对静态资源进行请求]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从头搭建github博客]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2F%E4%BB%8E%E5%A4%B4%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[安装Node.js并配置Node.js环境成功界面如下： 安装git并配置git环境 注册Github并新建项目首页 新建仓库页参考其他博客的时候，很多博客中都提到 项目名必须是 github账户名.github.io 但经本人测试其实项目名称可以任意选取，如本人的仓库名就是blog，而非destinywang.github.io 设置进入项目的setting选项卡中 下拉到Github Pages，此时该项目已经被部署，可以通过提供的外网链接去访问。 安装HexoHexo中文网站 Hexo是个快捷，简介且高效的博客框架 让上百个页面在几秒内完成渲染 Hexo支持Github Flavored Markdown的所有功能 在合适的位置创建文件夹 以上操作需要在空文件夹中进行 123$ npm install hexo -g # 安装Hexo$ hexo -v # 检查Hexo是否安装成功$ hexo init # 初始化文件夹 Hexo init npm install此命令用于安装所需要的组件 hexo g首次体验Hexo hexo s此命令会在本地开启Hexo的服务器 可以在发布到github之前先在本地进行调试 然后再浏览器中输入localhost:4000/blog/如果出现如下界面就成功了 将Hexo和Github page联系起来设置本地git如果是第一次使用git的话需要设置name和email 1234$ ssh-keygen -t rsa -C &quot;your email&quot; # 生成秘钥，路径在~/.ssh下，windows用户的路径为C:\Users\Administrator\.ssh$ eval &quot;$(ssh-agent -s)&quot; # 添加秘钥到ssh-agent$ ssh-add ~/.ssh/id_rsa # 添加生成的SSH key到ssh-agent 登录github，进行设置 进入用户的setting页面 在SSH and GPG keys选项卡中添加一个ssh key，并将id_rsa.pub(公钥)的内容复制上去 配置Deployment为了保证Hexo能够正确的通过Git进行add、commit、pull、push等操作需要将本地及远程的git仓库信息进行配置 当前站点文件夹的状态： 修改_config.yml文件，将deployment部分相关的内容进行替换 type: 部署类型 repository: 远程仓库路径，即github中的仓库路径 branch: 分支名 新建一篇博客在终端中执行命令hexo new post 博客名 会在source/_posts路径下生成对应的博客文件test.md 安装hexo-deployer-git扩展文件1$ npm install hexo-deployer-git --save 编辑文章1$ vim source/_posts/test.md 打开test.md文件，按照正常的Markdown文件编辑即可 部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475$ hexo d -gINFO Start processingINFO Files loaded in 640 msINFO Generated: tags/index.htmlINFO Generated: about/index.htmlINFO Generated: 2018/04/01/jvm/index.htmlINFO Generated: 2018/04/01/test/index.htmlINFO Generated: 2018/04/01/hello-world-1/index.htmlINFO Generated: archives/index.htmlINFO Generated: tags/jvm/index.htmlINFO Generated: archives/2018/index.htmlINFO Generated: archives/2018/04/index.htmlINFO Generated: tags/java基础/index.htmlINFO Generated: index.htmlINFO Generated: 2018/04/01/hello-world/index.htmlINFO Generated: 2018/04/01/一-Nginx基本知识/index.htmlINFO Generated: tags/Nginx/index.htmlINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/avatar.gifINFO Generated: images/apple-touch-icon-next.pngINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/algolia_logo.svgINFO Generated: images/cc-by-nc.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/cc-by-sa.svgINFO Generated: images/cc-by.svgINFO Generated: images/cc-zero.svgINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/favicon-32x32-next.pngINFO Generated: images/loading.gifINFO Generated: images/logo.svgINFO Generated: images/placeholder.gifINFO Generated: images/quote-r.svgINFO Generated: images/searchicon.pngINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: images/quote-l.svgINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: images/blog-logo.jpegINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: css/main.cssINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: js/src/affix.jsINFO Generated: js/src/exturl.jsINFO Generated: js/src/algolia-search.jsINFO Generated: js/src/bootstrap.jsINFO Generated: js/src/love.jsINFO Generated: js/src/js.cookie.jsINFO Generated: js/src/post-details.jsINFO Generated: js/src/motion.jsINFO Generated: js/src/scrollspy.jsINFO Generated: js/src/scroll-cookie.jsINFO Generated: lib/font-awesome/bower.jsonINFO Generated: js/src/utils.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.min.jsINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/velocity/velocity.min.jsINFO Generated: js/src/schemes/pisces.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.pack.jsINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: lib/jquery/index.jsINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: lib/velocity/velocity.jsINFO 61 files generated in 1.13 sINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...[master 966acc9] Site updated: 2018-04-01 21:18:16 1 file changed, 1 insertion(+), 1 deletion(-)To github.com:DestinyWang/blog.git + fa066f8...966acc9 HEAD -&gt; master (forced update)Branch &apos;master&apos; set up to track remote branch &apos;master&apos; from &apos;git@github.com:DestinyWang/blog.git&apos;.INFO Deploy done: git 至此，博客已经部署成功，可以去http://用户名.github.io查看。 安装Next1$ git clone https://github.com/iissnan/hexo-theme-next themes/next 下载到站点文件夹路径下的themes/next 启用Next主体在站点目录中，打开配置文件_config.yml，修改theme: next123$ pwd~/blog$ vim _config.yml 主题设定在next主题目录下的_config.yml，修改scheme: Pisces 123$ pwd~/blog$ vim themes/next/_config.yml 语言设定Hexo提供了多种语言支持，包括简体中文zh-Hans在站点根目录下修改配置文件_config.yml中的language为zh-Hans 123$ pwd~/blog$ vim _config.yml 修改菜单栏在主题目录下修改配置文件_config.yml中的menu 123$ pwd~/blog$ vim themes/next/_config.yml 设置菜单项图标对应字段是menu_icons同样在主题目录下的_config.yml中修改 格式为item name: icon name，其中item name 与所配置的菜单名字对应，icon name是Font Awesome图标的名字。而 enable可用于控制是否显示图标，你可以设置成 false 来去掉图标。 123$ pwd~/blog$ vim themes/next/_config.yml 设置侧栏位置修改主题目录下sidebar的position值 123$ pwd~/blog$ vim themes/next/_config.yml 设置头像在站点根目录下载配置文件中新增avatar，值设置为头像的链接地址。地址可以是网络地址，也可以是本地地址（放置在source/images/目录下） 设置文章代码主题在主题目录下修改配置文件_config.yml，字段highlight_theme，默认值为nomal。可以设置为night 123$ pwd~/blog$ vim themes/next/_config.yml 添加分类在站点路径下新建页面categories 123456$ pwd~/blog$ hexo new page categories# 在 source/categories 目录中修改index.mdvim source/categories/index.md 12# 在主题的 _config.yml 中取消注释:$ vim _config.yml 在要分类的文章中加入 category 属性: 添加标签页面标签是对博客分类的方式比如一个系列的博客都是将神经网络，那么就可以给每篇博客加上神经网络的tag 1234567$ pwd~/blog$ hexo new page tagsINFO Created: ~/blog/source/tags/index.md# 在新建的index.md中添加type: &quot;tags&quot;vim source/tags/index.md 后面只需要在博客的开头中添加tags: [A, B, C]即可 成功后，标签部分的导航栏为 Aboute Me1234567$ pwd~/blog$ hexo new page aboutINFO Created: ~/blog/source/about/index.md# 在新建的index.md中添加如下内容vim source/about/index.md 成功后效果如下所示： 添加github导航条从这里选择主题 然后将代码复制到themes/next/layout/_layout.swig 123$ pwd~/blog$ vim themes/next/layout/_layout.swig 成功后的效果如下： 修改内容区域宽度默认情况Next 对内容的宽度的设定如下： 700px，当屏幕宽度 &lt; 1600px 900px，当屏幕宽度 &gt;= 1600px 移动设备下，宽度自适应 非Pisces Scheme主题修改1$ vim source/css_variables/custom.styl 修改内容： 12345// 修改成你期望的宽度$content-desktop = 700px// 当视窗超过 1600px 后的宽度$content-desktop-large = 900px Pisces Scheme主题修改1$ vim themes\next\source\css\_schemes\Picses\_layout.styl 修改内容： 123.header &#123;width: 1150px;&#125;.container .main-inner &#123;width: 1150px;&#125;.content-wrap &#123;width: calc(100% - 260px);&#125; 设置首页不显示全文(只显示预览)打开主题路径下的_config.yml1$ vim themes/next/_config.yml 修改auto_excerpt12345# Automatically Excerpt. Not recommand.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150 将enable属性改为true 修改code代码块自定义样式1$ vim themes/next/source/css/_custom/custom.styl 取消文章目录对标题的自动编号 nexT对 markdown 语法的标题 # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 会默认进行标号分配，这样有可能会打乱文章原有标题 取消方式： 修改主题配置文件 1$ vim theme/next/_config 将 number 设为 false 结束至此，博客基本设置OK但还有很多地方可以继续挖掘 后续会持续更新]]></content>
      <tags>
        <tag>github博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（一）Nginx基本知识]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2F%EF%BC%88%E4%B8%80%EF%BC%89Nginx%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[简介Nginx是一款轻量级的Web服务器，也是一款轻量级的反向代理服务器 用途 直接支持Rails和PHP程序 作为HTTP反向代理服务器 作为负载均衡服务器 作为邮件代理服务器 帮助实现动静分离 特点高稳定、高性能、资源占用少、功能丰富、模块化结构、支持热部署 安装Nginx 依赖gcc openssl-devel pcre-devel zlib zlib-devel 1yum install gcc openssl-devel pcre-devel zlib zlib-devel 安装 $ ./configure --prefix=/usr/local/nginx --withhttp_stub_status_module $ make $ make install 常见的Nginx安装配置选项 Nginx基本运行// 测试配置文件 $ sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful // 启动 $ sbin/nginx // 停止 $ sbin/nginx -s stop $ sbin/nginx -s quit // 重启 $ sbin/nginx -s reload // 查看进程 ps -ef | grep nginx Nginx的基本配置默认启动Nginx的时候，使用的配置文件是conf/nginx.conf文件 也可以在启动Nginx的时候，通过-c来指定要去读的配置文件 常见的配置文件 文件名 用途 nginx.conf 应用程序的基本配置文件 mime.types MIME类型关联的扩展文件 fastcgi.conf 与fastcgi相关的配置，与PHP相关 proxy.conf 与proxy相关的配置（反向代理） sites.conf 配置Nginx提供的网站，包括虚拟主机 nginx.cong1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950user root;worker_processes 1;error_log logs/error.log crit;pid logs/nginx.pid; # nginx 进程号文件路径events &#123; # 事件模块 use epoll; # 文件的模型 worker_connections 24; # 每个worker的connections&#125;http &#123; # web反向代理 include mime.type; # 引入mime.type include proxy.conf; # 引入proxy.conf defualt_type application/octet-stream; # mine.type 的缺省类型 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; # 日志格式，远程地址 - 远程用户 时间 等 &apos;$status $body_bytes_sent &quot;$http_referer&quot;&apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; access_log logs/access.log main; # 使用为main的格式 upstream test.com &#123; # 负载均衡模块 server 127.0.0.1:8080 weight = 5; &#125; server &#123; lisent 80; server_name detiny; access_log logs/host.access.log main; index index.html index.htm index.jsp; root /Users/destiny/Download/apache-tomcat-9.0.1/webapps/ROOT/; location ~* .*\.(jpg|jepg|gif|png|wsf|ico)$ &#123; # 如果是图片，就去root路径查询 if(-f $request_filename) &#123; break; &#125; &#125; location / proxy_pass http://destiny.com; &#125; &#125;&#125; Nginx的进程结构启动Nginx的时候，会启动一个Master进程，这个进程不处理客户端的任何请求，主要用来产生worker进程 而每个worker进程用来处理一个Request Niginx 模块分为：核心模块、时间模块、标准HTTP模块、可选HTTP模块、邮件模块、第三方模块和补丁等。 基本模块Nginx默认的功能模块，它们提供的指令，允许使用定义Nginx基本功能的变量，在编译的时候不能被禁用，包括: 核心模块：基本功能和指令，如进程管理和安全 事件模块：在Nginx内配置网络使用的能力 配置模块：提供包含机制 常用模块Nginx常用的核心模块指令 error_log include pid user worker_cpu_affinity worker_processes error_log语法： error_log file [ debug|info|notice|warn|error|crit ] Nginx支持将不同的虚拟主机的日志记录在不同的路径 12345678910111213http &#123; error_log logs/http_error.log error; server &#123; server_name one; access_log logs/one_access.log; error_log logs/one_error.log error; &#125; server &#123; server_name two; access_log logs/two_access.log; error_log logs/two_error.log error; &#125;&#125; include从外部引入文件，支持文件通配符 pid指定pid文件，可以使用kill命令 user为了提高安全性，指定允许操作Nginx的用户 语法：user user [group] worker_cpu_affinity指定工作进程指定到某个CPU上 // 指定每个进程绑定一个CPU worker_processes 4; worker_cpu_affinity 0001 0010 0100 1000; // 指定第一个进程到CPU0/CPU2，第二个进程到CPU1/CPU3 worker_processes 2; worker_cpu_affinity 0101 1010; worker_processes一个工作进程为一个单线程的进程 如果Nginx工作在一些CPU密集型的环境中，并且你的机器拥有2块以上的CPU，则可以将worker_processes的数目设置为CPU核数。 如果你的机器运行在需要处理大量静态文件的环境，并且文件的大小总和超出了可用的内存，那么可以增加worker_processes的以便充分利用磁盘带宽。 日志模块控制Nginx如何记录请求日志 12345log_format gzip $remote_addr - $remote_user [$time_local] &quot;$request&quot;&apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot;&apos; &apos;&quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&apos;; access_log /spool/logs/nginx-access.log gzip buffer=32k; access_log语法：access_log path [format [buffer=size | off]] 默认值：access_log log/access.log combined 使用字段：http、server、location 注意： Nginx指定的用户必须有创建日志的权限 log_format语法：log_format name format [format ...] 默认值：log_format combined &quot;...&quot; 使用字段：http、server 变量名 含义 $body_bytes_sent 减去应答头后传送给客户端的字节数 $bytes_sent 传送给客户端的字节数 $connection 连接数 $msec 正在写入日志条目的当前时间 $pipe 如果请求为管道的 request_length 请求主体的长度 $request_time 从一个请求发出到Nginx工作的时间 $status 应答的状态 $time_local 写入普通日志格式的当地时间 事件模块 use connection use语法：use [ kqueue | rtsig | epoll | /dev/poll | select | poll | eventport] connections语法：worker_connections 最大连接数 = worker_processes * worker_connections // 反向代理环境下 最大连接数 = worker_processes * worker_connections / 4 原因：浏览器默认打开两个连接到服务器，Nginx使用来自相同地址池的fds与前后端相连接 HTTP模块基本配置Nginx的HTTP配置主要包括三个区块，结构如下 alias语法：alias file-path | directory-path; 使用字段：location alias是替换路径，而root是追加路径，将location后的路径追到root之后 12345location /i/ &#123; alias /spool/w3/images/&#125;请求 /i/top.gif 将返回这个文件 &quot;/spool/w3/images/top.gif&quot;。 error_page语法：error_page code [ code ... ] [ = | = answer-code ] uri | @named_location 使用字段：http、server、location、location中的if字段 这个参数可以为错误代码指定相应的错误页面 1234error_page 4040 /404.html;error_page 502 503 504 /50x.html;error_page 403 http://example.com/forbidden.html;error_page 404 = @fetch; 同样，你也可以将原有响应代码修改为另一个响应代码 12error_page 404 = 200 /empty.gif;error_page 404 = 403 /forbindden.gif; internal语法：internal 使用字段：location internal指定某个location只能被内部的请求调用，外部的调用会返回404. location区段通过指定模式来与客户端请求的URI相匹配 location [=|~|~*|^~|@] pattern { # ... } 没有修饰符，表示必须以指定的模式开始123456server &#123; server_name destiny.com; location /abc &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 http://destiny.com/abc/ http://destiny.com/abcde =，表示必须与指定的模式精准匹配123456server &#123; server_name destiny.com; location = /abc &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) 不能匹配 http://destiny.com/abc/ http://destiny.com/abcde ~，表示指定的正则表达式要区分大小写 ~表示按照正则表达式的语法与pattern进行匹配 123456server &#123; server_name destiny.com; location ~ ^/abc$ &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) 不能匹配 http://destiny.com/ABC/ http://destiny.com/abc/ http://destiny.com/abcde ~*，表示正则表达式不区分大小写123456server &#123; server_name destiny.com; location ~* ^/abc$ &#123; # ... &#125;&#125; 可以匹配： http://destiny.com/abc http://destiny.com/abc?age=24 (参数不参与匹配) http://destiny.com/ABC/ 不能匹配 http://destiny.com/abc/ http://destiny.com/abcde ^~，表示正则表达式不区分大小写 类似于无修饰符的行为，也是以指定模式开始，但如果模式匹配，那么久停止搜索其他模式了。 @，定义命名location区段，这些区段客户端不能访问，只可以由内部产生的请求来访问多个location的优先级问题 带有=的精准匹配 没有修饰符的精准匹配 正则表达式按照定义顺序 ^~的开头匹配 ~或~* 修饰符 没有修饰符的，如果指定字符串与URI开头匹配 Http反向代理模块 Nginx通常被用作后端服务器的反向代理，这样就可以很方便的实现动静分离，以及负载均衡，从而大大提高服务器的处理能力。 Http Proxy模块，功能很多，最常用的是proxy_pass 如果要使用proxy_cache的话，需要集成第三方的ngx_cache_purge模块，用来清除指定的URL缓存。 反向代理 普通的正向代理，为客户端提供代理服务 123456graph TDA[客户端]--&gt;|发出请求|B&#123;代理&#125;B --&gt; |代理访问并返回响应|AB --&gt; |代理访问|C[服务器A]B --&gt; |代理访问|D[服务器B]B --&gt; |代理访问|E[服务器C] 反向代理，为服务端提供代理服务 123456graph TDA[客户端A]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;B[客户端B]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;C[客户端C]--&gt;|先访问反向代理服务器|D&#123;代理服务器&#125;D --&gt; |代理客户端访问|E[服务器]E --&gt; |返回请求|D Http代理模块这个模块可以转发请求到其他的服务器 location / { proxy_pass http://localhost:8080; # 转发指令，把当前的指令转发到指定路径 proxy_set_header X-Real-IP $remote_addr; # 设置http请求头 } proxy_buffer_size设置从被代理服务器(真实服务器)读取的第一部分应答的缓冲区大小 语法：proxy_buffer_size the_size通常情况下这部分应答中包含一个小的应答头 proxy_buffering为后端服务器启用响应缓冲 如果启用缓冲，Nginx假设被代理服务器能够非常快的传递响应，并将其放入缓冲区 如果禁用缓冲，从后端传来的应答将立即被传送到客户端 语法：proxy_buffering on|off proxy_pass设置被代理服务器的地址和被映射的URL 地址可以使用主机名或IP+端口号的形式]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2018%2F04%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
