<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://destinywang.github.io/blog/"/>
  <updated>2020-04-06T05:54:11.135Z</updated>
  <id>https://destinywang.github.io/blog/</id>
  
  <author>
    <name>destiny</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ElasticSearch 原理与实践</title>
    <link href="https://destinywang.github.io/blog/2020/04/06/ElasticSearch-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    <id>https://destinywang.github.io/blog/2020/04/06/ElasticSearch-原理与实践/</id>
    <published>2020-04-06T05:54:11.000Z</published>
    <updated>2020-04-06T05:54:11.135Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>OAuth2 授权认证中文架构和实践</title>
    <link href="https://destinywang.github.io/blog/2020/04/05/OAuth2-%E6%8E%88%E6%9D%83%E8%AE%A4%E8%AF%81%E4%B8%AD%E6%96%87%E6%9E%B6%E6%9E%84%E5%92%8C%E5%AE%9E%E8%B7%B5/"/>
    <id>https://destinywang.github.io/blog/2020/04/05/OAuth2-授权认证中文架构和实践/</id>
    <published>2020-04-05T03:07:15.000Z</published>
    <updated>2020-04-06T05:53:32.153Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-微服务安全要解决的问题"><a href="#1-微服务安全要解决的问题" class="headerlink" title="1. 微服务安全要解决的问题"></a>1. 微服务安全要解决的问题</h1><p>OAuth2 最初是为了解决开放系统间授权的问题而诞生的</p><p><img src="https://user-images.githubusercontent.com/17758731/78466023-5ca97880-772f-11ea-8c36-5f939f0a335d.png" alt="image"></p><blockquote><p>假设用户有一部分资源放在云存储服务上, 这是用户需要通过客户应用完成对云存储上受保护资源的访问, 此时就需要云存储服务向客户应用授权.</p></blockquote><p>有如下几种方法:</p><table><thead><tr><th>方法名</th><th>描述</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>用户名密码复制</td><td>复制资源拥有者的用户名密码, 将它们传递到受保护的资源</td><td>实现简单, 适用于公司内部应用</td><td>如果开放应用不受信, 对用户安全风险较大, 可能导致严重信息泄露</td></tr><tr><td>万能钥匙</td><td>客户应用和受保护资源间商定一个通用的 develop key</td><td>适用于有合作的公司或部门</td><td>对于不受信的第三方应用不安全, develop key 容易泄露</td></tr><tr><td>特殊令牌</td><td>使用特殊的密码或令牌, 仅能访问受保护的资源</td><td>能较好的保护用户信息不被泄露</td><td>如何产生, 保护及吊销令牌实现复杂</td></tr></tbody></table><pre><code>在传统应用的 web 安全领域中, 比较常见的方案就是通过过滤器拦截应用的请求, 先判断是否完成登录授权, 如果没有就跳转到登录界面, 登录后给客户端种下对应的 cookie, 登录用户携带 cookie 匹配到 session 后验证身份, 再完成后续操作.</code></pre><p><img src="https://user-images.githubusercontent.com/17758731/78468845-fbdd6880-774d-11ea-8ce9-48b47b915a0c.png" alt="image"></p><p><a href="https://insights.thoughtworks.cn/traditional-web-app-authentication/" target="_blank" rel="noopener">传统 web 应用中的身份验证技术</a></p><p>传统的认证方案在微服务架构中, 面临以下问题:</p><ol><li>服务拆分粒度较小, 服务和服务之间如何鉴权?</li><li>服务的应用形态多种多样, 如浏览器, 客户端以及其他应用, 如何处理多样的登录问题?</li></ol><p>OAuth2 解决问题域和场景:</p><ul><li>开放系统间授权<ul><li>社交联合登录</li><li>开放 API 平台</li></ul></li><li>现代微服务安全<ul><li>单页浏览器 App</li><li>无线原生 App</li><li>服务器端 WebApp</li><li>微服务和 API 间调用</li></ul></li><li>企业内部应用认证授权</li></ul><h1 id="2-OAuth2-的定义和原理"><a href="#2-OAuth2-的定义和原理" class="headerlink" title="2. OAuth2 的定义和原理"></a>2. OAuth2 的定义和原理</h1><p>对保存用户资源的服务来说, 一般会通过颁发令牌的方式向第三方应用授权及验证身份</p><p><img src="https://user-images.githubusercontent.com/17758731/78469238-e702d400-7751-11ea-9286-9fcab89b1ed9.png" alt="image"></p><p>OAuth2 定义:</p><ol><li>用于 REST/APIs 的代理授权框架</li><li>基于令牌 Token 的授权, 在无需暴露用户密码的前提下, 使应用能够获取对用户数据的有限访问权限</li><li>解耦认证和授权</li><li>事实上的标准安全框架, 支持多种用例场景:<ol><li>服务器端 WebApp</li><li>浏览器单页 SPA</li><li>无线/原生 APP</li><li>服务器对服务器之间</li></ol></li></ol><p>OAuth 术语:</p><ul><li>客户应用: 通常是一个 Web 应用或无线应用, 它需要访问用户的受保护资源</li><li>资源服务器: 是一个 Web 站点或者 Web Service API, 用户的受保护数据保存于此</li><li>在客户应用成功认证并获得授权之后, 向客户应用颁发访问令牌 Access Token</li><li>资源拥有者: 资源的拥有人, 想要分享某些资源给第三方应用</li><li>客户凭证: 客户的 <code>clientId</code> 和密码, 用于认证客户</li><li>令牌: 授权服务器在接收到用户请求后, 颁发的访问令牌</li><li>作用域: 用户请求访问令牌时, 由资源所有者额外指定的细分权限</li></ul><h1 id="3-OAuth2授权模式"><a href="#3-OAuth2授权模式" class="headerlink" title="3. OAuth2授权模式"></a>3. OAuth2授权模式</h1><h2 id="3-1-授权码模式"><a href="#3-1-授权码模式" class="headerlink" title="3.1 授权码模式"></a>3.1 授权码模式</h2><p><img src="https://user-images.githubusercontent.com/17758731/78469625-9db48380-7755-11ea-8728-c99afdf51345.png" alt="image"></p><ul><li>通过前端渠道获取授权码</li><li>通过后端渠道, 客户使用 authorization code 去交换 access token 和 可选的 refresh token</li><li>假定资源拥有者和客户在不同设备上</li><li>最安全的流程, 因为令牌不会经过 user-agent</li></ul><h2 id="3-2-简化模式"><a href="#3-2-简化模式" class="headerlink" title="3.2 简化模式"></a>3.2 简化模式</h2><p><img src="https://user-images.githubusercontent.com/17758731/78470732-1ae3f680-775e-11ea-9611-cf66b7cd8d54.png" alt="image"></p><ul><li>适用于公开的浏览器单页应用</li><li>AccessToken 直接从授权服务器返回</li><li>不支持 refresh tokens</li><li>假定资源所有者和公开客户应用在同一个设备上</li><li>最容易受安全攻击</li></ul><h2 id="3-3-刷新令牌"><a href="#3-3-刷新令牌" class="headerlink" title="3.3 刷新令牌"></a>3.3 刷新令牌</h2><p>简化令牌的获取, 通过 Refresh Token 快速重新获取令牌</p><p><img src="https://user-images.githubusercontent.com/17758731/78470913-9db98100-775f-11ea-9002-ae4aa70e84b0.png" alt="image"></p><h2 id="3-4-授权类型选型"><a href="#3-4-授权类型选型" class="headerlink" title="3.4 授权类型选型"></a>3.4 授权类型选型</h2><p><img src="https://user-images.githubusercontent.com/17758731/78471132-63e97a00-7761-11ea-9b09-ea48fae9e9e3.png" alt="image"></p><h1 id="4-Spring-Security-OAuth2-架构简介"><a href="#4-Spring-Security-OAuth2-架构简介" class="headerlink" title="4. Spring Security OAuth2 架构简介"></a>4. Spring Security OAuth2 架构简介</h1><p>授权服务器的基本功能: </p><p><img src="https://user-images.githubusercontent.com/17758731/78471359-5634f400-7763-11ea-93db-900a863b45cd.png" alt="image"></p><ol><li>客户端首先需要完成授权, 授权通过后获取 token</li><li>拿到 token 后, 服务可以通过 Introspect 进行校验</li><li>校验过程中如果 token 过期, 可以获取新的 token.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-微服务安全要解决的问题&quot;&gt;&lt;a href=&quot;#1-微服务安全要解决的问题&quot; class=&quot;headerlink&quot; title=&quot;1. 微服务安全要解决的问题&quot;&gt;&lt;/a&gt;1. 微服务安全要解决的问题&lt;/h1&gt;&lt;p&gt;OAuth2 最初是为了解决开放系统间授权的问题
      
    
    </summary>
    
      <category term="微服务" scheme="https://destinywang.github.io/blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="授权" scheme="https://destinywang.github.io/blog/tags/%E6%8E%88%E6%9D%83/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 Casbin</title>
    <link href="https://destinywang.github.io/blog/2020/04/04/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Casbin/"/>
    <id>https://destinywang.github.io/blog/2020/04/04/深入理解-Casbin/</id>
    <published>2020-04-04T03:41:26.000Z</published>
    <updated>2020-04-05T03:03:47.033Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1. 基础知识"></a>1. 基础知识</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><p>Casbin 是一个强大高效的开源访问控制框架, 支持多种访问控制模型.</p><p>Casbin 能做什么:</p><ol><li>支持自定义请求的格式, 默认的请求格式为 <code>{subject, object, action}</code>.</li><li>具有访问控制模型 model 和策略 policy 两个核心概念.</li><li>支持 RBAC 中的多层角色继承, 不止主体可以有角色, 资源也可以有角色.</li><li>支持超级用户, 如 <code>root</code> 或 <code>admin</code>, 超级用户可以不受授权策略的约束访问任意资源.</li><li>支持多种内置的操作符, 如 <code>keyMatch</code>, 方便对路径式的资源进行管理, 如 <code>/foo/bar</code> 可以映射到 <code>/foo*</code>.</li></ol><p>Casbin 不能做的:</p><ol><li>身份认证 <code>authentication</code>(验证用户名,密码), casbin 只负责访问控制, 应该有其他专门的组件负责身份认证, 然后由 casbin 进行访问控制, 二者是相互配合的关系.</li><li>管理用户列表或角色列表, casbin 认为应该有项目自身来维护用户和用户列表, 用户通常由他们的密码, 但 casbin 解决的核心问题应该是存储 RBAC 方案中用户和角色之间的映射关系.</li></ol><p>安装方式:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">go</span> get github.com/casbin/casbin/v2</span><br></pre></td></tr></table></figure><h2 id="1-2-简单使用"><a href="#1-2-简单使用" class="headerlink" title="1.2 简单使用"></a>1.2 简单使用</h2><p>开发过程分为如下几部:</p><ol><li>编写访问控制文件(model)</li><li>编写策略文件(policy)</li><li>通过 casbin 提供的 API 完成对应的鉴权</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">enforcer, err := casbin.NewEnforcer(<span class="string">"conf/model.conf"</span>, <span class="string">"conf/policy.csv"</span>) <span class="comment">// Casbin 决策器需要有模型文件和策略文件作为参数</span></span><br><span class="line">assert.Nil(t, err)</span><br><span class="line">sub := <span class="string">"alice"</span> <span class="comment">// 需要访问资源的用户</span></span><br><span class="line">obj := <span class="string">"data1"</span> <span class="comment">// 将要被访问的资源</span></span><br><span class="line">act := <span class="string">"read"</span>  <span class="comment">// 该用户访问资源的具体操作</span></span><br><span class="line">ok, err := enforcer.Enforce(sub, obj, act)</span><br><span class="line">assert.Nil(t, err)</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line">t.Logf(<span class="string">"%s has %s on %s"</span>, sub, act, obj)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.Logf(<span class="string">"%s dosen't has %s on %s"</span>, sub, act, obj)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行结果:</p><pre><code>=== RUN   TestDemo1TestDemo1: demos_test.go:24: alice has read on data1--- PASS: TestDemo1 (0.00s)PASS</code></pre><h2 id="1-3-工作原理"><a href="#1-3-工作原理" class="headerlink" title="1.3 工作原理"></a>1.3 工作原理</h2><p>在 Casbin 中, 访问控制模型被抽象为 PERM(Policy, Effect, Request, Matcher) 的一个文件, 因此, 切换或升级项目的授权机制时, 只需修改该文件, 开发者可以通过组合可用的模型来指定自己的访问规则:</p><p>Casbin 中最基本最简单的访问控制模型(model)是 ACL, ACL 中 model 的 CONF 为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Request definition</span><br><span class="line">[request_definition]</span><br><span class="line">r = sub, obj, act</span><br><span class="line"></span><br><span class="line"># Policy definition</span><br><span class="line">[policy_definition]</span><br><span class="line">p = sub, obj, act</span><br><span class="line"></span><br><span class="line"># Policy effect</span><br><span class="line">[policy_effect]</span><br><span class="line">e = some(where (p.eft == allow))</span><br><span class="line"></span><br><span class="line"># Matchers</span><br><span class="line">[matchers]</span><br><span class="line">m = r.sub == p.sub &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act</span><br></pre></td></tr></table></figure><p>ACL model 的实例 policy:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p, alice, data1, read</span><br><span class="line">p, bob, data2, write</span><br></pre></td></tr></table></figure><p>含义:</p><ul><li><code>alice</code> 对 <code>data1</code> 有 <code>read</code> 权限</li><li><code>bob</code> 对 <code>data2</code> 有 <code>write</code> 权限</li></ul><h1 id="2-Model-访问控制模型"><a href="#2-Model-访问控制模型" class="headerlink" title="2. Model(访问控制模型)"></a>2. Model(访问控制模型)</h1><h2 id="2-1-Model-语法"><a href="#2-1-Model-语法" class="headerlink" title="2.1 Model 语法"></a>2.1 Model 语法</h2><ul><li>model 配置文件至少应该包含四部分:<ul><li><code>[request_defintion]</code></li><li><code>[policy_destintion]</code></li><li><code>[policy_effect]</code></li><li><code>[mathers]</code></li></ul></li><li>如果 model 使用 RBAC, 还需要添加 <code>[role_defition]</code> 部分</li><li>Model CONF 文件可以包含注释</li></ul><h3 id="2-1-1-Request-定义"><a href="#2-1-1-Request-定义" class="headerlink" title="2.1.1 Request 定义"></a>2.1.1 Request 定义</h3><p><code>[request_defintion]</code> 部分用于 request 的定义, 它明确了 <code>func NewEnforcer(params ...interface{}) (*Enforcer, error) {}</code> 方法的参数列表定义</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[request_definition]</span><br><span class="line">r = sub, obj, act</span><br></pre></td></tr></table></figure><p><code>sub, obj, act</code> 表示经典三元组: 访问实体, 访问资源和访问方法. 如果不需要指定特定特定资源, 可以定义成 <code>r = sub, obj</code>, 或者如果有两个访问实体, 可以定义成 <code>sub1, sub2, obj, act</code>.</p><h3 id="2-1-2-Policy-定义"><a href="#2-1-2-Policy-定义" class="headerlink" title="2.1.2 Policy 定义"></a>2.1.2 Policy 定义</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[policy_definition]</span><br><span class="line">p = sub, obj, act</span><br><span class="line">p2 = sub, act</span><br></pre></td></tr></table></figure><p>对 policy 规则的具体描述:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p, alice, data1, read</span><br><span class="line">p2, bob, write-all-objects</span><br></pre></td></tr></table></figure><p><code>[policy_definition]</code> 部分是对策略的定义, 每条规则通常是以行如 p, p2 的 <code>policy type</code> 开头, 如果存在多个 policy 定义, casbin 会根据前文提到的 <code>policy type</code> 与具体的某条规则匹配, 上面的 policy 绑定关系将会在 matcher 中使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(alice, data1, read) -&gt; (p.sub, p.obj, p.act)</span><br><span class="line">(bob, write-all-objects) -&gt; (p2.sub, p2.act)</span><br></pre></td></tr></table></figure><h3 id="2-1-3-Policy-Effect-定义"><a href="#2-1-3-Policy-Effect-定义" class="headerlink" title="2.1.3 Policy Effect 定义"></a>2.1.3 Policy Effect 定义</h3><p><code>[policy_effect]</code> 部分是对policy生效范围的定义, 原语定义了当多个 policy rule 同时匹配访问请求 request 时, 该如何对多个决策结果进行集成以实现统一决策. 以下示例展示了一个只有一条规则生效，其余都被拒绝的情况:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[policy_effect]</span><br><span class="line">e = some(where (p.eft == allow))</span><br></pre></td></tr></table></figure><blockquote><p>表示如果存在任意一个决策结果为 allow 的匹配规则, 则最终决策结果为 allow, 其中 p.eft 表示决策规则的决策解雇, 可以为 allow 或者 deny, 当不指定规则的决策结果时, 取默认值 allow, 通常情况下, policy 的 p.eft 默认为 allow</p></blockquote><h3 id="2-1-4-Matchers"><a href="#2-1-4-Matchers" class="headerlink" title="2.1.4 Matchers"></a>2.1.4 Matchers</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[matchers]</span><br><span class="line">m = r.sub == p.sub &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act</span><br></pre></td></tr></table></figure><p><code>[matchers]</code> 原语定义了策略规则如何与访问请求进行匹配的匹配器, 其本质上是布尔表达式, 可以理解为 Request, Policy 等原语定义了关于策略和请求的变量, 然后将这些变量代入Matcher原语中求值, 从而进行策略决策.</p><p>可以在 matcher 中定义函数, 可以是内置函数或自定义函数:</p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>keyMatch(arg1,arg2)</td><td>arg1 是一个 URL 路径, 如 <code>/alice_data/resource1</code>, arg2 可以是 URL 路径或者一个模式, 如 <code>/alice_data/</code>, 返回 arg1 是否与 arg2 匹配</td></tr><tr><td>keyMatch2(arg1,arg2)</td><td>arg1 是一个 URL 路径, 例如 <code>/alice_data/resource1</code>, arg2 可以是 URL 路径或者是一个 <code>:</code> 模式，例如 <code>/alice_data/:resource</code>. 此函数返回 arg1 是否与 arg2 匹配</td></tr></tbody></table><p>regexMatch(arg1, arg2) | arg1 可以是任何字符串. arg2 是一个正则表达式. 它返回 arg1 是否匹配 arg2.|<br>ipMatch(arg1, arg2) | arg1 是一个 IP 地址, 如 <code>192.168.2.123</code>. arg2 可以是 IP 地址或 CIDR, 如 <code>192.168.2. 0/24</code>. 它返回 arg1 是否匹配 arg2.</p><blockquote><p>添加自定义函数</p></blockquote><p>准备好一个有多个参数以及一个 bool 类型返回值的函数, 然后用 <code>interface{}</code> 类型包装该函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MyFunc</span><span class="params">(key1, key2 <span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">    <span class="comment">/// ~</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MyFuncAdaptor</span><span class="params">(args ...<span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line">    key1 := args[<span class="number">0</span>].(<span class="keyword">string</span>)</span><br><span class="line">    key2 := args[<span class="number">1</span>].(<span class="keyword">string</span>)</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">bool</span>)(MyFunc(key1, key2)), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后注册到 Casbin enforcer 中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e.AddFunction(<span class="string">"my_func"</span>, MyFuncAdaptor)</span><br></pre></td></tr></table></figure><p>然后就可以在 model 中使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[matchers]</span><br><span class="line">m = r.sub == p.sub &amp;&amp; my_func(r.obj, p.obj) &amp;&amp; r.act == p.act</span><br></pre></td></tr></table></figure><h3 id="2-1-5-Role-定义"><a href="#2-1-5-Role-定义" class="headerlink" title="2.1.5 Role 定义"></a>2.1.5 Role 定义</h3><p><code>[role_defintion]</code> 定义了 RBAC 中的角色继承关系, Casbin 支持 RBAC 系统的多个实例, 用户可以有角色和继承关系, 资源也可以有角色和继承关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[role_definition]</span><br><span class="line">g = _, _</span><br><span class="line">g2 = _, _</span><br></pre></td></tr></table></figure><p>g1 是一个 RBAC 体系, g2 是另一个 RBAC 体系, <code>,</code> 表示角色继承关系的前项和后项, 前项继承后项的角色的权限, 如果需要进行角色和用户的绑定, 直接使用 g 即可, 如果需要标识角色与用户和资源的绑定关系时, 可以使用 g 和 g2, 在 Casbin 中, 我们以 policy 表示实际的用户角色映射关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p, data2_admin, data2, read</span><br><span class="line">g, alice, data2_admin</span><br></pre></td></tr></table></figure><p>上述策略规则表示 <code>alice</code> 继承或具有角色 <code>data2_admin</code>, 这里的 <code>alice</code> 可以为具体的某个用户, 某种资源抑或某个角色, 在 Casbin 中它将会被当作字符串(string)来对待.</p><p>在 matcher 中, 应该用如下方式校验角色:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[matchers]</span><br><span class="line">m = g(r.sub, p.sub) &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act</span><br></pre></td></tr></table></figure><ol><li>Casbin 只存储用户角色的映射关系;</li><li>Casbin 不验证用户是否为有效用户, 或者角色是否为有效角色. 这应该由身份验证来处理.</li><li>RBAC 系统中的用户名称和角色名称不应相同, 因为Casbin将用户名和角色识别为字符串, 所以当前语境下Casbin无法得出这个字面量到底指代用户 alice 还是角色 alice. 这时, 使用明确的 role_alice, 问题便可迎刃而解;</li><li>假设 A 具有角色 B, B 具有角色 C, 并且 A 有角色 C. 这种传递性在当前版本会造成死循环.</li></ol><p>域租户的角色定义</p><p>在 Casbin 中的 RBAC 角色可以是全局或是基于特定域的, 特定域的角色意味着当用户处于不同的租户时, 用户所关联的角色也不尽相同, 租户角色定义类似如下写法, 第三个 <code>_</code> 表示域的概念</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[role_definition]</span><br><span class="line">g = _, _, _</span><br></pre></td></tr></table></figure><p>对应的策略规则实例如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p, admin, tenant1, data1, read</span><br><span class="line">p, admin, tenant2, data2, read</span><br><span class="line"></span><br><span class="line">g, alice, admin, tenant1</span><br><span class="line">g, alice, user, tenant2</span><br></pre></td></tr></table></figure><p>接下来在matcher中, 应该像下面的例子一样检查角色信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[matchers]</span><br><span class="line">m = g(r.sub, p.sub, r.dom) &amp;&amp; r.dom == p.dom &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act</span><br></pre></td></tr></table></figure><h2 id="2-2"><a href="#2-2" class="headerlink" title="2.2"></a>2.2</h2><h1 id="3-存储"><a href="#3-存储" class="headerlink" title="3. 存储"></a>3. 存储</h1><h2 id="3-1-Model-存储"><a href="#3-1-Model-存储" class="headerlink" title="3.1 Model 存储"></a>3.1 Model 存储</h2><h3 id="3-1-1-从-CONF-文件中加载-model"><a href="#3-1-1-从-CONF-文件中加载-model" class="headerlink" title="3.1.1 从 CONF 文件中加载 model"></a>3.1.1 从 CONF 文件中加载 model</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Casbin 决策器需要有模型文件和策略文件作为参数</span></span><br><span class="line">enforcer, err := casbin.NewEnforcer(<span class="string">"conf/model.conf"</span>, <span class="string">"conf/policy.csv"</span>)</span><br></pre></td></tr></table></figure><h3 id="3-1-2-从代码加载-model"><a href="#3-1-2-从代码加载-model" class="headerlink" title="3.1.2 从代码加载 model"></a>3.1.2 从代码加载 model</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用 Go 代码初始化 model</span></span><br><span class="line">m := casbin.NewModel()</span><br><span class="line">m.AddDef(<span class="string">"r"</span>, <span class="string">"r"</span>, <span class="string">"sub, obj, act"</span>)</span><br><span class="line">m.AddDef(<span class="string">"p"</span>, <span class="string">"p"</span>, <span class="string">"sub, obj, act"</span>)</span><br><span class="line">m.AddDef(<span class="string">"g"</span>, <span class="string">"g"</span>, <span class="string">"_, _"</span>)</span><br><span class="line">m.AddDef(<span class="string">"e"</span>, <span class="string">"e"</span>, <span class="string">"some(where (p.eft == allow))"</span>)</span><br><span class="line">m.AddDef(<span class="string">"m"</span>, <span class="string">"m"</span>, <span class="string">"g(r.sub, p.sub) &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act"</span>)</span><br><span class="line"><span class="comment">// 从 .CSV 文件 adapter 中加载 policy 规则。</span></span><br><span class="line"><span class="comment">// 使用自己的 adapter 替换</span></span><br><span class="line">a := persist.NewFileAdapter(<span class="string">"examples/rbac_policy.csv"</span>)</span><br><span class="line"><span class="comment">// 创建一个 enforcer。</span></span><br><span class="line">e := casbin.NewEnforcer(m, a)</span><br></pre></td></tr></table></figure><h3 id="3-1-3-从字符串加载-model"><a href="#3-1-3-从字符串加载-model" class="headerlink" title="3.1.3 从字符串加载 model"></a>3.1.3 从字符串加载 model</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用字符串初始化 model</span></span><br><span class="line">text :=</span><br><span class="line"><span class="string">`</span></span><br><span class="line"><span class="string">[request_definition]</span></span><br><span class="line"><span class="string">r = sub, obj, act</span></span><br><span class="line"><span class="string">[policy_definition]</span></span><br><span class="line"><span class="string">p = sub, obj, act</span></span><br><span class="line"><span class="string">[role_definition]</span></span><br><span class="line"><span class="string">g = _, _</span></span><br><span class="line"><span class="string">[policy_effect]</span></span><br><span class="line"><span class="string">e = some(where (p.eft == allow))</span></span><br><span class="line"><span class="string">[matchers]</span></span><br><span class="line"><span class="string">m = g(r.sub, p.sub) &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act</span></span><br><span class="line"><span class="string">`</span></span><br><span class="line">m := NewModel(text)</span><br><span class="line"><span class="comment">// 从 .CSV 文件 adapter 中加载 policy 规则。</span></span><br><span class="line"><span class="comment">// 使用自己的 adapter 替换。</span></span><br><span class="line">a := persist.NewFileAdapter(<span class="string">"examples/rbac_policy.csv"</span>)</span><br><span class="line"><span class="comment">// 创建一个 enforcer。</span></span><br><span class="line">e := casbin.NewEnforcer(m, a)</span><br></pre></td></tr></table></figure><h2 id="3-2-Policy-存储"><a href="#3-2-Policy-存储" class="headerlink" title="3.2 Policy 存储"></a>3.2 Policy 存储</h2><h3 id="3-2-1-File-Adapter-内置"><a href="#3-2-1-File-Adapter-内置" class="headerlink" title="3.2.1 File Adapter(内置)"></a>3.2.1 File Adapter(内置)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">e := casbin.NewEnforcer(<span class="string">"examples/basic_model.conf"</span>, <span class="string">"examples/basic_policy.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line">a := fileadapter.NewAdapter(<span class="string">"examples/basic_policy.csv"</span>)</span><br><span class="line">e := casbin.NewEnforcer(<span class="string">"examples/basic_model.conf"</span>, a)</span><br></pre></td></tr></table></figure><h3 id="3-2-2-MySQL-Adapter"><a href="#3-2-2-MySQL-Adapter" class="headerlink" title="3.2.2 MySQL Adapter"></a>3.2.2 MySQL Adapter</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a := mysqladapter.NewAdapter(<span class="string">"mysql"</span>, <span class="string">"root:@tcp(127.0.0.1:3306)/"</span>)</span><br><span class="line">e := casbin.NewEnforcer(<span class="string">"examples/basic_model.conf"</span>, a)</span><br></pre></td></tr></table></figure><h3 id="3-2-3-自建-Adapter"><a href="#3-2-3-自建-Adapter" class="headerlink" title="3.2.3 自建 Adapter"></a>3.2.3 自建 Adapter</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a := yourpackage.NewAdapter(params)</span><br><span class="line">e := casbin.NewEnforcer(<span class="string">"examples/basic_model.conf"</span>, a)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-基础知识&quot;&gt;&lt;a href=&quot;#1-基础知识&quot; class=&quot;headerlink&quot; title=&quot;1. 基础知识&quot;&gt;&lt;/a&gt;1. 基础知识&lt;/h1&gt;&lt;h2 id=&quot;1-1-概述&quot;&gt;&lt;a href=&quot;#1-1-概述&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>领域驱动设计</title>
    <link href="https://destinywang.github.io/blog/2020/03/12/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"/>
    <id>https://destinywang.github.io/blog/2020/03/12/领域驱动设计/</id>
    <published>2020-03-12T11:12:48.000Z</published>
    <updated>2020-04-05T03:03:45.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>DDD 是一种处理高度复杂领域的设计思想, 试图分离技术实现的复杂性, 并围绕业务概念构建领域模型来控制业务的复杂性, 以解决软件难以理解和演进的问题. DDD 是一种架构的设计方法论, 通过边界划分将复杂业务领域简单化, 找出领域和应用边界.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h1&gt;&lt;p&gt;DDD 是一种处理高度复杂领域的设计思想, 试图分离技术实现的复杂性, 并围绕业务概念构建领域模型来控制业务的复杂性, 
      
    
    </summary>
    
      <category term="架构设计" scheme="https://destinywang.github.io/blog/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="领域驱动设计" scheme="https://destinywang.github.io/blog/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 nginx</title>
    <link href="https://destinywang.github.io/blog/2019/11/17/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-nginx/"/>
    <id>https://destinywang.github.io/blog/2019/11/17/深入理解-nginx/</id>
    <published>2019-11-17T14:37:24.000Z</published>
    <updated>2020-04-05T03:03:52.200Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Nginx-简介"><a href="#1-Nginx-简介" class="headerlink" title="1. Nginx 简介"></a>1. Nginx 简介</h2><h3 id="1-1-Nginx-的三个主要应用场景"><a href="#1-1-Nginx-的三个主要应用场景" class="headerlink" title="1.1 Nginx 的三个主要应用场景"></a>1.1 Nginx 的三个主要应用场景</h3><ol><li>静态资源服务: 通过本地文件系统提供服务</li><li>反向代理服务: 缓存, 负载均衡</li><li>API 服务: OpenResty</li></ol><p><img src="https://user-images.githubusercontent.com/17758731/69009167-cd711380-098d-11ea-8c78-2a5c8d1a713b.png" alt="image"></p><p>用户请求会首先经过 Nginx, 再导应用服务(如 Tomcat, Apache 等), 应用服务根据自身逻辑再去访问存储服务(如 MySQL, Redis, Elasticsearch 等), 通过这样的方式对外部提供最基础的服务.</p><p>这样的一个典型架构模式中, Nginx 往往处于企业内网的边缘节点, 随着网络链路的增长, 用户的请求时延会不断变长, 如果我们能够把所有用户在一段时间内看起来不变的动态内容缓存在 Nginx 上, 由 Nginx 直接向用户提供反馈, 这样时延就会相应得到降低, 因此反向代理会衍生出另一个功能: 缓存加速, 这样能够加速我们的访问. 很多时候当我们在访问 css, JavaScript 以及小图片的时候, 这样的资源没有必要通过应用服务器来返回, 只需要通过本地文件查询系统上放置的静态资源, 由 Nginx 提供访问即可.</p><p>此外由于应用服务普遍运行效率较低, QPS 受限, 因此通常会将多个应用服务组成集群, 向用户提供高性能, 高可用, 可扩展的服务, 此时就需要可以提供反向代理功能的 Nginx 来将动态请求传导给应用服务器. 当多个应用服务器构成集群之后, 就需要能够支持服务的弹性伸缩, 如节点的新增和下线, 因此反向代理服务器必须具备负载均衡功能.</p><p>最后, 由于应用服务的性能存在瓶颈, 但数据库由于使用场景简单, 并发性能较高, 因此性能高于应用服务, 所以 Nginx 可以直接访问数据库, Redis, 利用 Nginx 自身强大的性能实现如 Web 防火墙等功能直接提供给用户, 这要求 API 服务有强大的业务处理功能. 因此向 OpenResty, 以及 Nginx 集成 JavaScript, 利用 JS, LUA 提供完整的 API 服务.</p><h3 id="1-2-Nginx-的优点"><a href="#1-2-Nginx-的优点" class="headerlink" title="1.2 Nginx 的优点"></a>1.2 Nginx 的优点</h3><ol><li>高并发, 高性能: 同时具备高并发和高性能, 高并发往往需要为每个连接分配的资源尽可能少, 高性能需要好的设计, Nginx 在 32 核 64G 内存的服务器上可以达到千万级的并发连接, 对于简单的请求可以达到百万级.</li><li>可扩展性好: 可扩展性主要体现在 Nginx 的模块化设计, 稳定的模块化设计使得第三方模块生态圈非常丰富.</li><li>高可靠性: Nginx 可以在服务器上持续不间断的运行数年. 由于 Nginx 往往出现在企业内网的边缘节点, 直接面向用户, 因此可靠性非常重要, 是企业能够向用户提供 4 个 9 甚至更高可靠性的保障.</li><li>热部署: Nginx 可以在不停止服务的情况下升级重启. 服务器可能同时存在百万级的并发连接, 如果简单 kill 掉进程会导致操作系统向所有正在连接状态的 TCP 客户端发送一个 TCP 中的终端响应. 而热部署可以保证 Nginx 重启的同事连接不会中断.</li><li>BSD 许可证: Nginx 不只是开源免费, 而且可以在有定制需要的场景下修改 Nginx 源代码, 并且运行在商业场景下, 这是合法的.</li></ol><h3 id="1-3-Nginx-的组成"><a href="#1-3-Nginx-的组成" class="headerlink" title="1.3 Nginx 的组成"></a>1.3 Nginx 的组成</h3><ol><li>二进制可执行文件: 由各模块源码编译出的一个文件, 由官方模块以及自定义的第三方模块共同组成.</li><li>Nginx.conf 文件: 控制 Nginx 的行为.</li><li>access.log 访问日志: 记录每一条 HTTP 请求信息.</li><li>error.log 错误日志: 用于定位问题.</li></ol><h3 id="1-4-编译-Nginx"><a href="#1-4-编译-Nginx" class="headerlink" title="1.4 编译 Nginx"></a>1.4 编译 Nginx</h3><p>安装 Nginx 的步骤:</p><ol><li>下载 Nginx: 可以从官网下载压缩包, 或者通过 <code>yum</code>, <code>apt-get</code> 等命令完成;</li><li>执行 <code>configure</code> 文件, 会生成很多中间文件;</li><li>执行编译</li><li>安装</li></ol><h4 id="1-4-1-下载"><a href="#1-4-1-下载" class="headerlink" title="1.4.1 下载"></a>1.4.1 下载</h4><p>可以直接在 <a href="http://nginx.org/en/download.html" target="_blank" rel="noopener">http://nginx.org/en/download.html</a> 页面选择合适的版本并下载</p><p><img src="https://user-images.githubusercontent.com/17758731/69018029-4bacd480-09e5-11ea-97cd-dc1a361bb794.png" alt="image"></p><p>Nginx 目录下个各个文件目录的主要功能:</p><table><thead><tr><th style="text-align:center">目录名</th><th>功能</th></tr></thead><tbody><tr><td style="text-align:center">auto</td><td>用辅助 configure 脚本执行时去判定 Nginx 需要支持的模块, 已经当前操作系统特性等</td></tr><tr><td style="text-align:center">conf</td><td>示例文件的集合, 为了方便运维配置, 可以把示例文件拷贝到安装目录</td></tr><tr><td style="text-align:center">contrib</td><td>提供了两个 peal 脚本和 vim 工具, 由于 vim 默认不支持 Nginx 语法高亮, 我们可以将 contrib/vim 下的所有文件拷贝到本地 vim 配置中 <code>cp -r contrib/vim/* ~/.vim/</code>, 此时 vim 就支持 Nginx 配置文件的语法高亮了 <img src="https://user-images.githubusercontent.com/17758731/69018388-27ea8e00-09e7-11ea-8bde-77bb8c66c3d8.png" alt="image"></td></tr><tr><td style="text-align:center">html</td><td>提供了两个 HTML 文件, 一个是发现 50X 错误时, 可以默认重定向到该页面, 另一个是默认的欢迎界面</td></tr><tr><td style="text-align:center">man</td><td>Linux 对 Nginx 的帮助文件</td></tr><tr><td style="text-align:center">src</td><td>Nginx 的源代码目录</td></tr><tr><td style="text-align:center">CHANGES</td><td>记录了当前 Nginx 版本新增的 feature 以及 bugfix</td></tr><tr><td style="text-align:center">CHANGES.ru</td><td>俄语版 CHANGES文件</td></tr><tr><td style="text-align:center">configure</td><td>用来生成中间文件的脚本, 是执行编译前的一个必备动作</td></tr></tbody></table><h4 id="1-4-2-configure-命令"><a href="#1-4-2-configure-命令" class="headerlink" title="1.4.2 configure 命令"></a>1.4.2 configure 命令</h4><p>configure 命令的参数主要分为几个部分:</p><ol><li>Nginx 运行中辅助文件路径:</li></ol><table><thead><tr><th style="text-align:center">参数名</th><th>功能</th></tr></thead><tbody><tr><td style="text-align:center"><code>--modules-path=$PATH</code></td><td>nginx 引用动态模块的路径</td></tr><tr><td style="text-align:center"><code>--lock-path=$PATH</code></td><td>设置 nginx.lock 文件的路径</td></tr><tr><td style="text-align:center"><code>--prefix=$PATH</code></td><td>指定编译输出的路径, 其他路径都会使用该前缀路径</td></tr></tbody></table><ol start="2"><li>确定使用/启用模块(前缀通常是 <code>--with/--without</code>)</li></ol><p>以 <code>--with</code> 前缀开始的模块名意味着 Nginx 默认不会编译进来, 而以 <code>--without</code> 前缀开始的模块名意味着 Nginx 默认会编译进来.</p><ol start="3"><li>指定 Nginx 中需要的特殊参数</li></ol><table><thead><tr><th style="text-align:center">参数名</th><th>功能</th></tr></thead><tbody><tr><td style="text-align:center"><code>--with-debug</code></td><td>编译时打印 debug 参数</td></tr></tbody></table><p>执行完 configure 命令后, Nginx 安装路径下会自动创建一个目录 <code>objs</code>, 其中有一个 <code>ngx_modules.c</code>, 该文件决定后面的编译会引入哪些模块.</p><p><img src="https://user-images.githubusercontent.com/17758731/69063029-c104bd80-0a56-11ea-9059-fa4439c01898.png" alt="image"></p><p>所有被编译的模块会在该文件中被声明为一个 <code>ngx_module_t</code> 类型的数组.</p><p>依次进行 <code>make</code> 和 <code>make install</code> 即可.</p><h3 id="1-5-Nginx-配置语法"><a href="#1-5-Nginx-配置语法" class="headerlink" title="1.5 Nginx 配置语法"></a>1.5 Nginx 配置语法</h3><ol><li>配置文件由指令与指令块构成;</li><li>每条指令以 <code>;</code> 分号结尾, 指令与参数间以空格符号分割;</li><li>指令块以 <code>{}</code> 大括号将多条指令组织在一起;</li><li><code>include</code> 语句允许组合多个配置文件以提升可维护性;</li><li>使用 <code>#</code> 符号添加注释, 提高可读性;</li><li>使用 <code>$</code> 符号使用变量;</li><li>部分指令的参数支持正则表达式;</li></ol><p>如:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">inclue</span>      mime.types;</span><br><span class="line">    <span class="attribute">upstream</span> thwp &#123;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">127.0.0.1:8000</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span> <span class="number">443</span> http2;</span><br><span class="line">        <span class="comment"># Nginx 配置语法</span></span><br><span class="line">        <span class="attribute">limit_req_zone</span> <span class="variable">$binary_remote_addr</span> zone=one:<span class="number">10m</span> rate=1r/s;</span><br><span class="line">        <span class="attribute">location</span> <span class="regexp">~* \.(gif|jpg|jpeg)$</span> &#123;</span><br><span class="line">            <span class="attribute">proxy_cache</span> my_cache;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">3m</span>; <span class="attribute">proxy_cache_key</span> <span class="variable">$host</span><span class="variable">$uri</span><span class="variable">$is_args</span><span class="variable">$args</span>;</span><br><span class="line">            <span class="attribute">proxy_cache_valid</span> <span class="number">200</span> <span class="number">304</span> <span class="number">302</span> <span class="number">1d</span>;</span><br><span class="line">            <span class="attribute">proxy_pass</span> http://thwp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置块的主要内容:</p><ol><li>http: 包含的所有的指令都由 http 模块去解析</li><li>upstream: 表示上游服务, 当 Nginx 需要与 Tomcat 等服务交互时, 需要定义 upstream</li><li>server: 定义的一组域名</li><li>location: 一组 url 表达式</li></ol><h4 id="1-5-1-配置参数-时间单位"><a href="#1-5-1-配置参数-时间单位" class="headerlink" title="1.5.1 配置参数: 时间单位"></a>1.5.1 配置参数: 时间单位</h4><table><thead><tr><th style="text-align:center">配置单位</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">ms</td><td style="text-align:center">毫秒</td></tr><tr><td style="text-align:center">s</td><td style="text-align:center">秒</td></tr><tr><td style="text-align:center">m</td><td style="text-align:center">分</td></tr><tr><td style="text-align:center">h</td><td style="text-align:center">小时</td></tr><tr><td style="text-align:center">d</td><td style="text-align:center">天</td></tr><tr><td style="text-align:center">w</td><td style="text-align:center">周</td></tr><tr><td style="text-align:center">m</td><td style="text-align:center">月, 30 天</td></tr><tr><td style="text-align:center">y</td><td style="text-align:center">年, 365 天</td></tr></tbody></table><h4 id="1-5-2-配置参数-空间单位"><a href="#1-5-2-配置参数-空间单位" class="headerlink" title="1.5.2 配置参数: 空间单位"></a>1.5.2 配置参数: 空间单位</h4><table><thead><tr><th style="text-align:center">配置单位</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">字节</td></tr><tr><td style="text-align:center">k/K</td><td style="text-align:center">kb</td></tr><tr><td style="text-align:center">m/M</td><td style="text-align:center">MB</td></tr><tr><td style="text-align:center">g/G</td><td style="text-align:center">GB</td></tr></tbody></table><h3 id="1-6-Nginx-命令行"><a href="#1-6-Nginx-命令行" class="headerlink" title="1.6 Nginx 命令行"></a>1.6 Nginx 命令行</h3><p>命令行规则:</p><ol><li>格式: nginx + 命令 + 参数, 如 <code>nginx -s reload</code></li><li>帮助: <code>-?</code> 或 <code>-h</code></li><li>使用指定配置文件: <code>-c</code></li><li>指定配置指令: <code>-g</code></li><li>指定运行目录: <code>-p</code></li><li>发送信号: <code>-s</code><ol><li>立刻停止服务: stop</li><li>优雅的停止服务: quit</li><li>重新加载配置文件: reload</li><li>重新开始记录日志文件: reopen</li></ol></li><li>测试配置文件是否有语法错误: <code>-t</code> 或 <code>-T</code></li><li>打印 Nginx 版本信息, 编译信息等: <code>-v</code> 或 <code>-V</code></li></ol><h4 id="1-6-1-重载配置文件"><a href="#1-6-1-重载配置文件" class="headerlink" title="1.6.1 重载配置文件"></a>1.6.1 重载配置文件</h4><p>重载配置文件指的是在 Nginx 不重启的前提下修改配置文件. 在修改了配置文件后, 可以直接执行下面命令, 让 Nginx 进程再不停止的情况下重新加载配置文件.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nginx -s reload</span><br></pre></td></tr></table></figure><h4 id="1-6-2-热部署"><a href="#1-6-2-热部署" class="headerlink" title="1.6.2 热部署"></a>1.6.2 热部署</h4><p>热部署指的是在 Nginx 不重启的前提下更新 Nginx 版本, 此时只需要更换 Nginx 的二进制文件(/sbin/nginx)即可, 将新版本的 nginx 二进制文件放入 sbin 路径下</p><p><img src="https://user-images.githubusercontent.com/17758731/69107614-eb816580-0aac-11ea-993c-354a17eb4db8.png" alt="image"></p><h4 id="1-6-3-日志切割"><a href="#1-6-3-日志切割" class="headerlink" title="1.6.3 日志切割"></a>1.6.3 日志切割</h4><p>当 Nginx 运行一段时间后, 日志量会比较大, 此时可以通过日志切割, 将一段时间范围之外的日志切割出去, 保持当前文件日志量不会太大, 此外, 该过程依然需要保持 Nginx 处于运行状态.</p><p><img src="https://user-images.githubusercontent.com/17758731/69108643-436d9b80-0ab0-11ea-840b-fa35634f73f6.png" alt="image"></p><p>上图的方式就完成了一次日志切割, 利用 <code>nginx -s reopen</code> 实现, 但实际场景中, 我们更多是希望能够每天或者每周自动执行一次日志切割, 这样可以写成一个 bash 脚本, 先复制当前日志文件, 再执行 reopen, 再将该脚本放在 crontab 中定时执行.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">LOGS_PATH=/Users/destiny/dev/nginx/logs/<span class="built_in">history</span></span><br><span class="line">CUR_LOGS_PATH=/Users/destiny/dev/nginx/logs</span><br><span class="line">YESTERDAY=$(date -d <span class="string">"yesterday"</span> +%Y-%m-%d)</span><br><span class="line">mv <span class="variable">$&#123;CUR_LOGS_PATH&#125;</span>/access.log <span class="variable">$&#123;LOGS_PATH&#125;</span>/access_<span class="variable">$&#123;YESTERDAY&#125;</span>.<span class="built_in">log</span></span><br><span class="line">mv <span class="variable">$&#123;CUR_LOGS_PATH&#125;</span>/error.log <span class="variable">$&#123;LOGS_PATH&#125;</span>/error<span class="variable">$&#123;YESTERDAY&#125;</span>.<span class="built_in">log</span></span><br><span class="line"><span class="comment"># 向 Nginx 主进程发送 USR1 信号, USR1 信号是重新打开日志文件, 等同于 reopen</span></span><br><span class="line"><span class="built_in">kill</span> -USR1 $(cat /Users/destiny/dev/nginx/logs/nginx.pid)</span><br></pre></td></tr></table></figure><h3 id="1-7-Nginx-作为静态资源服务器的典型场景"><a href="#1-7-Nginx-作为静态资源服务器的典型场景" class="headerlink" title="1.7 Nginx 作为静态资源服务器的典型场景"></a>1.7 Nginx 作为静态资源服务器的典型场景</h3><h4 id="1-7-1-展示静态页面"><a href="#1-7-1-展示静态页面" class="headerlink" title="1.7.1 展示静态页面"></a>1.7.1 展示静态页面</h4><p>使用 Hadoop 的 HTML 格式文档用来展示, 目录结构如下:</p><p><img src="https://user-images.githubusercontent.com/17758731/69154134-66cd3080-0b1a-11ea-9fa8-def4c162b512.png" alt="image"></p><p>将该路径复制到 Nginx 的安装路径下</p><p><img src="https://user-images.githubusercontent.com/17758731/69154346-cdeae500-0b1a-11ea-8a5c-0b48336e1f00.png" alt="image"></p><p>可以看到此时 Nginx 安装文件下新增了一个 <code>hadoop</code> 文件.</p><p>修改 Nginx 配置文件, <code>conf/nginx.conf</code>:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#user  nobody;</span></span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">#error_log  logs/error.log;</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log  notice;</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log  info;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#pid        logs/nginx.pid;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">include</span>       mime.types;</span><br><span class="line">    <span class="attribute">default_type</span>  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">sendfile</span>        <span class="literal">on</span>;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#keepalive_timeout  0;</span></span><br><span class="line">    <span class="attribute">keepalive_timeout</span>  <span class="number">65</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gzip  on;</span></span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="comment"># 配置监听的端口</span></span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">8000</span>;</span><br><span class="line">        <span class="attribute">server_name</span>  localhost;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#access_log  logs/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拦截所有的 URL, 都去访问 Nginx 安装路径下的 hadoop/ 路径</span></span><br><span class="line">        <span class="comment"># URL 的后缀需要与文件后缀一一对应</span></span><br><span class="line">        <span class="comment"># localhost:8000/abc.html =&gt; hadoop/abc.html</span></span><br><span class="line">        <span class="attribute">location</span> / &#123;</span><br><span class="line">            <span class="attribute">alias</span> hadoop/;</span><br><span class="line">            <span class="comment"># root   html;</span></span><br><span class="line">            <span class="comment"># index  index.html index.htm;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重启 Nginx 就可以看到效果:</p><p><img src="https://user-images.githubusercontent.com/17758731/69155207-3e463600-0b1c-11ea-8dc4-a649886b801f.png" alt="image"></p><p>此时我们已经完成了 Nginx 最基础的功能之一, 构建静态 web 站点.</p><h4 id="1-7-2-压缩响应"><a href="#1-7-2-压缩响应" class="headerlink" title="1.7.2 压缩响应"></a>1.7.2 压缩响应</h4><p><img src="https://user-images.githubusercontent.com/17758731/69155384-92511a80-0b1c-11ea-8102-6c5b2c0ff529.png" alt="image"></p><p>在上面的请求中, 我们可以看到 <code>hadoop-project-dist/hadoop-common/CLIMiniCluster.html</code> 请求的大小为 23.1KB, 这与实际的文件大小一致, Nginx 提供了GZIP 压缩的功能, 通常文本文件经过 GZIP 压缩后的大小会有大幅的降低, 因此我们可以通过配置开启 GZIP 压缩功能:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启 gzip</span></span><br><span class="line">    <span class="attribute">gzip</span>  <span class="literal">on</span>;</span><br><span class="line">    <span class="comment"># 设置允许压缩的最小长度, 超过大小的文件才会开启压缩功能</span></span><br><span class="line">    <span class="attribute">gzip_min_length</span> <span class="number">1</span>;</span><br><span class="line">    <span class="comment"># 压缩级别</span></span><br><span class="line">    <span class="attribute">gzip_comp_level</span> <span class="number">2</span>;</span><br><span class="line">    <span class="comment"># 只针对列出类型的文件进行压缩</span></span><br><span class="line">    <span class="attribute">gzip_types</span> text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;</span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时重启 Nginx 后强制刷新页面可以看到文件大小已经大幅降低, 并且响应头中也带上了 <code>Content-Encoding: gzip</code> 标识, 说明经过了压缩.</p><p><img src="https://user-images.githubusercontent.com/17758731/69156437-5d45c780-0b1e-11ea-8163-ca7f04cfe52f.png" alt="image"></p><h4 id="1-7-3-目录浏览"><a href="#1-7-3-目录浏览" class="headerlink" title="1.7.3 目录浏览"></a>1.7.3 目录浏览</h4><p>Nginx 中 <code>auto_index</code> 模块可以提供这样的功能:</p><blockquote><p>当我们访问以 <code>/</code> 结尾的 URL 时, 把目录中的文件结构返回</p></blockquote><p>配置方法也很简单, 在 location 模块中加入启动 autoindex 即可.</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> / &#123;</span><br><span class="line">    <span class="attribute">alias</span> hadoop/;</span><br><span class="line">    <span class="attribute">autoindex</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-7-4-响应限流"><a href="#1-7-4-响应限流" class="headerlink" title="1.7.4 响应限流"></a>1.7.4 响应限流</h4><p>由于公网带宽比较有限, 当有大量用户访问大文件时, 请求之间会形成争抢关系, 可能会为了当用户访问大文件时限制其速度, 以期望能够分离出足够的带宽以供用户访问小文件. 此时可以通过 set 命令以及内置的变量完成该功能</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> / &#123;</span><br><span class="line">    <span class="attribute">alias</span> hadoop/;</span><br><span class="line">    <span class="attribute">autoindex</span> <span class="literal">on</span>;</span><br><span class="line">    <span class="comment"># 限制 Nginx 向客户浏览器发送响应的速度, 每秒最多传输 1k 字节</span></span><br><span class="line">    <span class="attribute">set</span> <span class="variable">$limit_rate</span> <span class="number">1k</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改配置文件后重启 Nginx</p><p><img src="https://user-images.githubusercontent.com/17758731/69158562-9b90b600-0b21-11ea-9856-339e826d4fd5.png" alt="image"></p><p>再强制刷新页面后可以看到, 此时响应速度维持在 1k/s 的速度. <code>hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html</code> 文件大小为 13KB, 请求用时 13s.</p><h4 id="1-7-5-访问日志-access-log"><a href="#1-7-5-访问日志-access-log" class="headerlink" title="1.7.5 访问日志(access.log)"></a>1.7.5 访问日志(access.log)</h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">include</span>       mime.types;</span><br><span class="line">    <span class="attribute">default_type</span>  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 日志格式</span></span><br><span class="line">    <span class="attribute">log_format</span>  main  <span class="string">'<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] "<span class="variable">$request</span>" '</span></span><br><span class="line">                      <span class="string">'<span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> "<span class="variable">$http_referer</span>" '</span></span><br><span class="line">                      <span class="string">'"<span class="variable">$http_user_agent</span>" "<span class="variable">$http_x_forwarded_for</span>"'</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 日志路径, 对所在模块生效, 第一个参数是日志路径, 第二个是采用的日志格式</span></span><br><span class="line">    <span class="attribute">access_log</span>  logs/access.log  main;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后面日志就会按照 main 所规定的格式打印, 此外还有很多不同的参数支持自定义配置, 如 <code>http-core-module</code> 下的 <code>$content_length</code> 等.</p><h3 id="1-8-Nginx-作为具备缓存功能的反向代理服务器应用场景"><a href="#1-8-Nginx-作为具备缓存功能的反向代理服务器应用场景" class="headerlink" title="1.8 Nginx 作为具备缓存功能的反向代理服务器应用场景"></a>1.8 Nginx 作为具备缓存功能的反向代理服务器应用场景</h3><h4 id="1-8-1-反向代理功能"><a href="#1-8-1-反向代理功能" class="headerlink" title="1.8.1 反向代理功能"></a>1.8.1 反向代理功能</h4><p>以上个例子的 Hadoop 文档服务器作为上游服务器, 我们搭建一个用户实现反向代理的 Nginx 服务器, 可以支持反向代理以及缓存.</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#user  nobody;</span></span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># upstream 定义一批上游服务器</span></span><br><span class="line">    <span class="attribute">upstream</span> local &#123;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">127.0.0.1:8000</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">9000</span>;</span><br><span class="line">        <span class="comment"># 反向代理服务器的域名</span></span><br><span class="line">        <span class="attribute">server_name</span>  localhost;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#access_log  logs/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">        <span class="attribute">location</span> / &#123;</span><br><span class="line">            <span class="comment"># 将 HTTP 请求添加自定义的 header 发送给上游</span></span><br><span class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将 location 匹配到的请求代理到下面的路径</span></span><br><span class="line">            <span class="attribute">proxy_pass</span> http://local;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</span><br><span class="line">        <span class="attribute">location</span> = /50x.html &#123;</span><br><span class="line">            <span class="attribute">root</span>   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的配置中, 我们对作为反向代理的 Nginx 服务器开启了 <code>upstream</code> 配置, 表示上游服务, Nginx 就会将匹配的请求转发到该配置块内部的 server 中, 如果 server 包含多个节点, 我们可以配置分发的策略, 包括 hash, 轮询等. <code>upstream</code> 配置块定义的一批服务器, 可以以一个统一的名字命名, 上例中起名为 <code>local</code>.</p><p><code>location</code> 配置块中通过 <code>proxy_pass</code> 配置, 将匹配的所有请求代理到 <code>local</code> 的所有上游服务中.</p><p>此时通过 <a href="http://localhost:9000" target="_blank" rel="noopener">http://localhost:9000</a> 就可以通过代理服务器访问到 Hadoop 的文档.</p><h4 id="1-8-2-缓存"><a href="#1-8-2-缓存" class="headerlink" title="1.8.2 缓存"></a>1.8.2 缓存</h4><p>在 web 开发中, 通常只有不同用户展示内容不同的动态内容才需要请求应用服务器, 对于一段时间内不会发生变化的内容, 为了减轻上游服务器的压力, 我们可以让 Nginx 把上游服务器返回的内容缓存一段时间. 由于一般情况下, Nginx 的性能远高于普通应用服务器, 因此对于小站点会有较大的性能提升.</p><p>Nginx 缓存的使用方式:</p><ol><li>在 HTTP 配置块中声明缓存配置</li><li>在需要开启缓存的 location 配置块中启用</li></ol><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#user  nobody;</span></span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置缓存文件路径, 文件的命名方式, 文件的 key(关键字需要放在共享内存中)</span></span><br><span class="line">    <span class="attribute">proxy_cache_path</span> /tmp/nginxcache levels=<span class="number">1</span>:<span class="number">2</span> keys_zone=my_cache:<span class="number">10m</span> max_size=<span class="number">10g</span> inactive=<span class="number">60m</span> use_temp_path=<span class="literal">off</span>;</span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">9000</span>;</span><br><span class="line">        <span class="attribute">server_name</span>  localhost;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#access_log  logs/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">        <span class="attribute">location</span> / &#123;</span><br><span class="line">            <span class="comment"># 将 HTTP 请求添加自定义的 header 发送给上游</span></span><br><span class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 指定使用上面声明的共享内存 my_cache</span></span><br><span class="line">            <span class="attribute">proxy_cache</span> my_cache;</span><br><span class="line">            <span class="comment"># 在共享内存中设置的 key, 由于同一个 uri 不同用户的返回可能不同, 此时需要将参数也作为 key</span></span><br><span class="line">            <span class="attribute">proxy_cache_key</span> <span class="variable">$host</span><span class="variable">$uri</span><span class="variable">$is_args</span><span class="variable">$args</span>;</span><br><span class="line">            <span class="comment"># 对于哪些响应开启缓存</span></span><br><span class="line">            <span class="attribute">proxy_cache_valid</span> <span class="number">200</span> <span class="number">304</span> <span class="number">302</span> <span class="number">1d</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将 location 匹配到的请求代理到下面的路径</span></span><br><span class="line">            <span class="attribute">proxy_pass</span> http://local;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</span><br><span class="line">        <span class="attribute">location</span> = /50x.html &#123;</span><br><span class="line">            <span class="attribute">root</span>   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该配置生效后, 当 Nginx 反向代理服务器拥有缓存时, 即使停掉应用服务器依然可以正常提供服务.</p><h3 id="1-9-access-日志"><a href="#1-9-access-日志" class="headerlink" title="1.9 access 日志"></a>1.9 access 日志</h3><p>access 日志记录了 Nginx 运行时的访问信息, 我们可以通过 access 日志来分析定位问题以及用户的运营数据, 但大部分都是离线场景, 在线实时分析相对比较困难, 而 GoAccess 可以通过图形化的方式, 通过 websocket 协议实时把 access 日志的内容展示出来, 方便我们分析问题.</p><p>原生的 access 日志内容:</p><pre><code>127.0.0.1 - - [21/Nov/2019:23:04:13 +0800] &quot;GET /css/print.css HTTP/1.0&quot; 200 215 &quot;http://127.0.0.1:9000/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:04:13 +0800] &quot;GET /images/breadcrumbs.jpg HTTP/1.0&quot; 200 349 &quot;http://127.0.0.1:9000/css/maven-theme.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:04:13 +0800] &quot;GET /images/external.png HTTP/1.0&quot; 200 230 &quot;http://127.0.0.1:9000/css/maven-theme.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:04:13 +0800] &quot;GET /images/h5.jpg HTTP/1.0&quot; 200 357 &quot;http://127.0.0.1:9000/css/maven-theme.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET / HTTP/1.0&quot; 200 20536 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /css/maven-base.css HTTP/1.0&quot; 200 2310 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /css/maven-theme.css HTTP/1.0&quot; 200 4624 &quot;http://127.0.0.1:9000/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /css/site.css HTTP/1.0&quot; 200 936 &quot;http://127.0.0.1:9000/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /images/logos/maven-feather.png HTTP/1.0&quot; 200 3330 &quot;http://127.0.0.1:9000/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /css/print.css HTTP/1.0&quot; 200 215 &quot;http://127.0.0.1:9000/&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /images/breadcrumbs.jpg HTTP/1.0&quot; 200 349 &quot;http://127.0.0.1:9000/css/maven-theme.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /images/external.png HTTP/1.0&quot; 200 230 &quot;http://127.0.0.1:9000/css/maven-theme.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;127.0.0.1 - - [21/Nov/2019:23:28:32 +0800] &quot;GET /images/h5.jpg HTTP/1.0&quot; 200 357 &quot;http://127.0.0.1:9000/css/maven-theme.css&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36&quot;</code></pre><p><a href="https://goaccess.io/" target="_blank" rel="noopener">GoAccess官网</a></p><p><img src="https://goaccess.io/images/goaccess-dashboard.png?20190828082924" alt="image"></p><p>GoAccess 以一种友好的图形化方式展示, 当我们使用 Nginx 配置中默认的日志格式时, 可以支持使用 <code>goaccess access.log -o report.html --log-format=COMBINED</code> 命令解析, <code>-o</code> 参数会指定生成一个报表 html, <code>--log-format=COMBINED</code> 指定了解析日志的默认格式, 当我们的 access log 格式发生改变的时候, 需要更换解析格式.</p><p>效果展示:</p><ul><li><p>命令行<br><img src="https://user-images.githubusercontent.com/17758731/69478057-d0a24e80-0e28-11ea-88c8-de6a57d575a8.png" alt="image"></p></li><li><p>网页版<br><img src="https://user-images.githubusercontent.com/17758731/69478068-edd71d00-0e28-11ea-9c1c-496be9894f99.png" alt="image"></p></li></ul><h3 id="1-10-SSL-协议"><a href="#1-10-SSL-协议" class="headerlink" title="1.10 SSL 协议"></a>1.10 SSL 协议</h3><p>大部分站点都通过使用 HTTPS 协议保证网络安全.</p><p>SSL 协议(Secure Sockets Layer), 现在更多使用 TLS(Transport Layer Security), SSL 协议是由网井公司在 1995 年推出的, 1999 年 RETF 把 SSL 更名为 TLS1.0.</p><p><img src="https://user-images.githubusercontent.com/17758731/69473898-a8006180-0df4-11ea-8060-7cab57aefdd7.png" alt="image"></p><p>在七层模型中, HTTP 处在应用层, SSL 协议处在表示层, 通过握手, 交换秘钥, 告警和对称加密的方式, 使 HTTP 层在没有感知的情况下做到数据加密.</p><p>当我们抓包时可以看到类似下图的密码配置</p><p><img src="https://user-images.githubusercontent.com/17758731/69473978-85bb1380-0df5-11ea-9122-86811e3eb0fb.png" alt="image"></p><table><thead><tr><th>TLS</th><th>_</th><th>ECDHC</th><th>_</th><th>RSA</th><th>_</th><th>WITH</th><th>_</th><th>AES</th><th>_</th><th>128</th><th>_</th><th>GCM</th><th>_</th><th>SHA256</th></tr></thead><tbody><tr><td></td><td></td><td>秘钥交换</td><td></td><td>身份验证</td><td></td><td></td><td></td><td>算法</td><td></td><td>强度</td><td></td><td>模式</td><td></td><td>MAC 或 PRF</td></tr><tr><td></td><td></td><td>椭圆曲线加密算法, 为了解决浏览器和服务器之间如何各自独立生成相同的秘钥</td><td></td><td>身份验证算法 RSA</td><td></td><td></td><td></td><td>对称加密算法名</td><td></td><td>对称加密算法加密强度</td><td></td><td>对称加密算法分组模式</td><td></td><td>摘要算法, 用来将不定长度的字符串生成定长摘要.</td></tr></tbody></table><h4 id="1-10-1-对称加密"><a href="#1-10-1-对称加密" class="headerlink" title="1.10.1 对称加密"></a>1.10.1 对称加密</h4><p>在对称加密的场景中, A 和 B 共同持有同一把秘钥, A 可以把明文通过秘钥加密生成密文, 而 B拿到密文后可以通过同一个秘钥解密出明文. 除此之外的其他人如果没有秘钥, 即使知道了对称加密的具体算法也无法解密.</p><p>具体的工作原理可以以对称加密的典型算法 <code>RC4</code> 来理解:</p><pre><code>假设我们有秘钥序列 1010, 明文内容是 0110, 通过秘钥的加密过程其实就是二者做异或操作:1010 ^ 0110 = 1100 此时就通过秘钥将原文加密, 生成密文由于异或具有对称的特性, 密文与秘钥做同样的异或操作就可以还原出明文:1100 ^ 0110 = 1010</code></pre><p>由于以上原理, 对称加密的性能较好, 基本上遍历一次就可以完成加密/解密</p><h4 id="1-10-2-非对称加密"><a href="#1-10-2-非对称加密" class="headerlink" title="1.10.2 非对称加密"></a>1.10.2 非对称加密</h4><p>相比对称加密, 非对称加密的性能就会差很多:</p><ol><li>根据数学原理, 首先会生成一对秘钥, 我们称其中一个为公钥, 另一个为私钥, 其特点是同一份明文文档, 如果用公钥加密, 只有用与其一起生成的私钥才能解密, 反之亦然.</li><li>假设 A 生成了一对公钥和私钥, 并将其公钥发布出去, 此时 B 想和 A 通信, 就需要先将自己的明文用 A 发布的公钥加密, A 接收到之后, 再用自己的私钥解密即可.</li><li>此外公钥和私钥还可以用来做身份严重, 假设有一段信息, A 用自己的私钥完成加密, 将密文发给 B, 只要 B 拿到 A 的公钥, 且可以成功解开这段密文, 就证明这段密文确实是 A 发出的.</li></ol><h4 id="1-10-3-SSL-证书的公信力如何保证"><a href="#1-10-3-SSL-证书的公信力如何保证" class="headerlink" title="1.10.3 SSL 证书的公信力如何保证"></a>1.10.3 SSL 证书的公信力如何保证</h4><p>使用公钥私钥进行加密通信的前提条件是首先需要确定消息的发送发身份, 才能使用发送者提供的公钥进行解密, 在多方通信的场景中为了解决这个问题必须有一个工信机构, 即 CA.</p><ol><li>向登记机构申请证书, 需要等级申请人身份</li><li>登记机构通过 CSR发给 CA, CA 通过之后会生成一对公钥和私钥给订阅人, 其中公钥在 CA 自身保存.</li><li>登记人获得公钥和私钥之后, 将其部署到自己的 web 服务器上.</li><li>当浏览器访问 HTTP 站点的时候, 首先会请求证书, web 服务器会将公钥证书发给浏览器, 浏览器会去验证证书是否合法</li><li>CA 会把过期的证书放在 CRL 或 OCSP 服务器上.</li></ol><p>证书的类型:</p><ol><li>域名验证(domain validated, DV) 证书, 验证域名的归属是否正确;</li><li>组织验证(origanization validated, OV)证书, 申请证书时验证企业名称, 申请较慢, 价格较高.</li><li>扩展验证(extended vaiidation, EV)证书, 会把申请证书时填写的地址名称显示出来.</li></ol><p>证书链:</p><p>目前所有站点的主证书都是由 3 个证书构成:</p><ol><li>根证书</li><li>二级证书</li><li>主证书</li></ol><p>根证书的验证非常谨慎, 操作系统每年只会更新一次根证书库, 因此新的根证书 CA 机构很难快速加入到操作系统认可的证书库. 大部分浏览器使用操作系统的证书库. Nginx 在向浏览器发送证书的时候, 只发送二级证书和主证书, 浏览器会验证二级证书的签发机构根证书是否有效.</p><h4 id="1-10-4-TLS-的通信过程"><a href="#1-10-4-TLS-的通信过程" class="headerlink" title="1.10.4 TLS 的通信过程"></a>1.10.4 TLS 的通信过程</h4><p>通信过程需要完成的任务:</p><ol><li>验证身份</li><li>达成安全套件共识</li><li>传递秘钥</li><li>加密通信</li></ol><p>具体通信步骤:</p><ol><li>由浏览器向服务器发送 client hello 消息, 不同的浏览器所支持的安全套件和加速算法都是不同的.</li><li>服务端维护一套自己支持的加密算法列表以及优先选择的加密算法套件. 发送给客户端. 发送最终选择的安全套件.</li><li>Nginx 将自己的公钥证书(包含证书链)发送给浏览器.</li><li>发送 <code>Server Hello Done</code>.</li><li>客户端根据椭圆曲线的公共参数生成自己的私钥, 再把公钥发送给服务器.</li><li>此时 Nginx 有自己的私钥, 并把公钥发送给客户端, 可以根据自己的私钥和客户端的公钥共同生成双发加密的秘钥; 客户端根据服务器发来的公钥和自己生成的私钥也可以生成秘钥, 服务器和客户端分别生成的秘钥是相同的.</li></ol><p>TLS 的工作:</p><ol><li>交换秘钥</li><li>加密数据</li></ol><p>Nginx 优化方式:</p><h4 id="1-10-5-OpenResty"><a href="#1-10-5-OpenResty" class="headerlink" title="1.10.5 OpenResty"></a>1.10.5 OpenResty</h4><h2 id="2-Nginx-架构基础"><a href="#2-Nginx-架构基础" class="headerlink" title="2. Nginx 架构基础"></a>2. Nginx 架构基础</h2><h3 id="2-1-Nginx-请求处理流程"><a href="#2-1-Nginx-请求处理流程" class="headerlink" title="2.1 Nginx 请求处理流程"></a>2.1 Nginx 请求处理流程</h3><p><img src="https://user-images.githubusercontent.com/17758731/69478508-4826ac80-0e2e-11ea-8fe2-e405105bbff5.png" alt="image"></p><ol><li>大致有三种流量会被 Nginx 接收;</li><li>Nginx 有三个主要的状态机, 分别是 处理 TCP/UDP 的传输层状态机, 处理应用层的 HTTP 状态机, 处理邮件的 Mail 状态机. 被称为状态机是因为Nginx 是通过非阻塞事件驱动处理引擎(epoll), 一旦使用异步处理引擎, 通常都需要通过状态机来把请求正确的识别和处理;</li><li>通过解析如果发现请求需要访问静态资源, 就会走磁盘缓存;</li><li>如果发现请求走反向代理, 反向代理的内容可以做磁盘缓存;</li><li>在处理静态资源的时候, 如果内存不足以完全缓存所有资源的时候, <code>sendfile</code> 和 AIO 会退化成阻塞的磁盘调用, 因此需要线程池来处理;</li><li>对于每一个完成的请求, 需要记录 access 日志和 error 日志;</li><li>Nginx 更多是作为负载均衡/反向代理服务器使用, 因此需要把请求通过协议级传输都上游服务器.</li></ol><h3 id="2-2-Nginx-进程结构"><a href="#2-2-Nginx-进程结构" class="headerlink" title="2.2 Nginx 进程结构"></a>2.2 Nginx 进程结构</h3><ul><li>单进程结构: 不适用于生产环境, 一般仅用于开发调试</li><li>多进程结构: 更加健壮, 使用多核计算机.</li></ul><p>Nginx 进程主要分为如下几个部分:</p><ul><li><p>master, 用来完成 worker 进程的管理, 通常第三方模块不会再此加入自己的代码</p><ul><li>Cache 相关进程: 在多个 worker 进程共享, 此外还要被 CacheManager 和 CacheLoader 进程使用.<ul><li>CacheManager: 开启动态代理时后端发来的动态请求做缓存所使用.</li><li>CacheLoader:</li></ul></li><li>Worker 进程(多个): 处理外部请求, Nginx 采用事件驱动模型, 希望每个 worker 从头到尾占用一颗 CPU, 因此不只要把 worker 进程数与 CPU 核数配置相同, 还需要把每个 Worker 进程与 CPU 核心绑定在一起, 这样可以更好的使用每颗 CPU 核心上的 CPU 缓存.</li></ul></li><li><p>master/workfer 间通过信号通信;</p></li><li>worker 进程间的通信采用共享内存解决.</li></ul><blockquote><p>Nginx 采用多进程而非多线程结构的原因:<br>主要还是考虑到了不同模块之间的隔离, 由于Nginx 需要保证高可靠性, 如果采用多线程模式, 由于线程之间共享同一段地址空间, 如果当某个第三方模块引发了地址空间的段错误, 出现地址越界时, 会导致 Nginx 进程下的全部线程都挂掉; 而如果采用了多进程则不会出现这样的问题.</p></blockquote><p><img src="https://user-images.githubusercontent.com/17758731/69479146-2a107a80-0e35-11ea-8c83-4e740e310101.png" alt="image"></p><p>当我们执行了 <code>nginx -s reload</code> 时, 可以看到 master 进程重新启动了 3 个 worker 进程.</p><p>当我们向 worker 进程发送退出信号时, 该进程退出时会自动向父进程(master)发送一个 <code>SIGCHLD</code> 信号, 这样 master 进程就知道该 worker 进程退出, 会重新再启动一个 worker 进程.</p><p><img src="https://user-images.githubusercontent.com/17758731/69479275-54af0300-0e36-11ea-9f06-9152c0e99435.png" alt="image"></p><h3 id="2-3-使用信号管理-Nginx-进程"><a href="#2-3-使用信号管理-Nginx-进程" class="headerlink" title="2.3 使用信号管理 Nginx 进程"></a>2.3 使用信号管理 Nginx 进程</h3><p>首先列出 Nginx 各个进程可接收的信号:</p><ul><li>master 进程:<ul><li>监控 worker 进程:<ul><li>CHLD: linux 操作系统中规定当子进程退出后, 需要向父进程发送 <code>CHLD</code> 信号</li></ul></li><li>通过接收信号来管理 worker 进程<ul><li>TERM, INT: 立刻停止 Nginx 进程</li><li>QUIT: 优雅停止 Nginx(保证当前连接都完成)</li><li>HUP: 重载配置文件</li><li>USR1: 重新打开日志文件, 用于日志切割</li><li>USR2: 热部署使用</li><li>WINCH</li></ul></li></ul></li><li>worker 进程: (不推荐直接对 worker 进程发送信号, 最好可以向 master 发送信号, 由 master 完成对 worker 的控制)<ul><li>TERM, INT</li><li>QUIT</li><li>USR1</li><li>WINCH</li></ul></li><li>Nginx 命令行: Nginx 在 <code>logs/nginx.pid</code> 文件中记录了当前 master 进程, 下面几个命令的执行方式就是从上面文件中找到 master 的 pid, 向该 pid 发送同样的信号<ul><li>reload: HUP</li><li>reopen: USR1</li><li>stop: TERM</li><li>quit: QUIT</li></ul></li></ul><h3 id="2-4-reload-重载配置文件的实现方式"><a href="#2-4-reload-重载配置文件的实现方式" class="headerlink" title="2.4 reload 重载配置文件的实现方式"></a>2.4 reload 重载配置文件的实现方式</h3><p>reload 命令可以在 Nginx 继续对外提供服务的同时重新加载配置文件:</p><ol><li>向 master 进程发送 HUP 信号(reload 命令触发)</li><li>master 进程校验配置语法是否正确</li><li>master 进程打开新的监听端口</li><li>master 进程用新配置启动新的 worker 子进程</li><li>master 进程向老 worker 子进程发送 <code>QUIT</code> 信号</li><li>老 worker 进程关闭监听句柄, 处理完当前连接后结束进程</li></ol><p>因此, 如果老的 worker 进程由于存在大量连接, 短时间内无法关闭, 在刚执行完 <code>nginx -s reload</code> 时会出现 worker 进程数量增加的情况.</p><h3 id="2-5-热升级的完整流程"><a href="#2-5-热升级的完整流程" class="headerlink" title="2.5 热升级的完整流程"></a>2.5 热升级的完整流程</h3><ol><li>将旧的 nginx 二进制文件替换成新的 nginx 二进制文件(注意备份)</li><li>向旧 master 进程发送 <code>USR2</code> 信号</li><li>旧 master 进程修改 pid 文件名, 加后缀 <code>.oldbin</code></li><li>旧 master 进程用新 Nginx 文件启动新 master 进程(新 master 进程是老 master 的子进程)</li><li>向老 master 进程发送 <code>QUIT</code> 信号, 关闭老 master 进程</li><li>如果需要回滚, 向老 master 发送 <code>HUP</code>, 向新 master 发送 <code>QUIT</code></li></ol><p>所谓优雅的关闭 Nginx, 主要是针对 worker 进程而言, 因为只有 worker 负责处理请求. 所谓优雅关闭就是让 Nginx 的 worker 进程可以识别出当前哪些连接不再处理请求再去关闭. </p><ol><li>设置定时器: worker_shutdown_timeout</li><li>关闭监听句柄</li><li>关闭空闲连接</li><li>在循环中等待全部连接关闭</li><li>退出进程</li></ol><h2 id="2-6-Nginx-网络事件"><a href="#2-6-Nginx-网络事件" class="headerlink" title="2.6 Nginx 网络事件"></a>2.6 Nginx 网络事件</h2><p><img src="https://user-images.githubusercontent.com/17758731/69479916-be7edb00-0e3d-11ea-8148-d70007c14a25.png" alt="image"></p><p>当主机 A 向主机 B 发送 HTTP 请求的时候:</p><ol><li>应用层发送一个 GET 请求</li><li>传输层记录通信双方的端口</li><li>网络层记录双方的公网 IP</li><li>到达链路层后经过以太网, 到达路由器, 路由器记录所在运营商的公网 ip.</li><li>再经过广域网到达主机 B 所在的路由器中</li><li>再经过链路层, 网络层, 传输层, 此时操作系统会将数据流交给对应端口的进程.</li></ol><p>TCP 报文内容:</p><p><img src="https://user-images.githubusercontent.com/17758731/69479903-a6a75700-0e3d-11ea-80a4-191211392ade.png" alt="image"></p><p>TCP 协议会将以此网络传输视上层报文大小, 拆分为多个小的报文, TCP 层会考虑中间每个环节中最大的 MTU 值, 该值被称为 MSS, 因此每收到一个 MSS 大小的报文时, 都是一个网络事件.</p><p><img src="https://user-images.githubusercontent.com/17758731/69480188-1fa7ae00-0e40-11ea-93d1-65d2db8d155e.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-Nginx-简介&quot;&gt;&lt;a href=&quot;#1-Nginx-简介&quot; class=&quot;headerlink&quot; title=&quot;1. Nginx 简介&quot;&gt;&lt;/a&gt;1. Nginx 简介&lt;/h2&gt;&lt;h3 id=&quot;1-1-Nginx-的三个主要应用场景&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="Nginx" scheme="https://destinywang.github.io/blog/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://destinywang.github.io/blog/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>cronexpr 源码解析</title>
    <link href="https://destinywang.github.io/blog/2019/09/14/cronexpr-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>https://destinywang.github.io/blog/2019/09/14/cronexpr-源码解析/</id>
    <published>2019-09-14T07:40:26.000Z</published>
    <updated>2020-04-04T03:38:05.979Z</updated>
    
    <content type="html"><![CDATA[<p>cronexpr (地址 <a href="https://github.com/gorhill/cronexpr" target="_blank" rel="noopener">https://github.com/gorhill/cronexpr</a>) 是一个 github 上 star 数较高的 crontab 表达式解析库, 主要功能是解析 crontab 表达式并能够求出未来 N 次的触发时间.</p><p>一个典型的使用方式如下:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestParse1</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">now := time.Now()</span><br><span class="line">expr, err := Parse(<span class="string">"0 5/7 10 20-25 2-10/2 5#2 */10"</span>)</span><br><span class="line">assert.Nil(t, err)</span><br><span class="line">t.Logf(<span class="string">"expr=[%+v]"</span>, expr)</span><br><span class="line">next := expr.NextN(now, <span class="number">4</span>)</span><br><span class="line">assert.True(t, <span class="built_in">len</span>(next) &gt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> _, nextTime := <span class="keyword">range</span> next &#123;</span><br><span class="line">t.Logf(<span class="string">"next=[%s]"</span>, nextTime.String())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果为:</p><pre><code>cronexpr_test.go:350: expr=[&amp;{expression:0 5/7 10 20-25 2-10/2 5#2 */10 secondList:[0] minuteList:[5 12 19 26 33 40 47 54] hourList:[10] daysOfMonth:map[25:true 20:true 21:true 22:true 23:true 24:true] workdaysOfMonth:map[] lastDayOfMonth:false lastWorkdayOfMonth:false daysOfMonthRestricted:true actualDaysOfMonthList:[] monthList:[2 4 6 8 10] daysOfWeek:map[] specificWeekDaysOfWeek:map[12:true] lastWeekDaysOfWeek:map[] daysOfWeekRestricted:true yearList:[1970 1980 1990 2000 2010 2020 2030 2040 2050 2060 2070 2080 2090]}]cronexpr_test.go:354: next=[2020-02-14 10:05:00 +0800 CST]cronexpr_test.go:354: next=[2020-02-14 10:12:00 +0800 CST]cronexpr_test.go:354: next=[2020-02-14 10:19:00 +0800 CST]cronexpr_test.go:354: next=[2020-02-14 10:26:00 +0800 CST]</code></pre><p>可以看到 cronexpr 的核心接口主要有两个:</p><ul><li>Parse(string) (*Expression, error) 用于解析指定的 cron 表达式, 将 cron 解析为包含各个子项(second, minute, hour, day, month, week, year) 可以触发的列表</li><li>(*Expression) NextN(time.Time, unint) []time.Time: 用于根据指定时间计算未来 n 次触发时间.</li></ul><p>下面我们就分别从源码分析一下这两个核心的接口</p><h1 id="1-cronexpr-Parse-string-Expression-error"><a href="#1-cronexpr-Parse-string-Expression-error" class="headerlink" title="1. cronexpr.Parse(string) (*Expression, error)"></a>1. cronexpr.Parse(string) (*Expression, error)</h1><p><img src="https://github.com/DestinyWang/crontab/blob/master/master/main/webroot/images/cron.Parse(" alt="image">.png?raw=true)</p><p>先列出该方法主要功能的思维导图, 前面说过这个方法会解析 crontab 表达式, 并最终构造 <code>Expression</code> 对象, 那么我们首先就需要了解 Expression 对象的结构, 在上文的单元测试中, 我打印了 <code>&quot;0 5/7 10 20-25 2-10/2 5#2 */10&quot;</code> 所构造的 Expression 对象, 首先我们先看看这个 crontab 表达式的语义:</p><table><thead><tr><th></th><th>秒</th><th>分</th><th>时</th><th>天</th><th>月</th><th>周</th><th>年</th></tr></thead><tbody><tr><td>表达式</td><td>0</td><td>5/7</td><td>10</td><td>20-25</td><td>2</td><td>5#2</td><td>*/10</td></tr><tr><td>语义</td><td>每分钟的第 0 秒</td><td>每小时从第 5 分钟开始, 每隔 7 分钟</td><td>每天的 10 时</td><td>每月从 20~25 日</td><td>每年 2~10 月中所有偶数月</td><td>每个月的第 2 个周 5</td><td>1970 ~2099 年的每个 10 年</td></tr></tbody></table><p>此时我们看一下 Expression 对象的值:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">expr := &amp;Expression&#123;</span><br><span class="line">expression: <span class="string">"0 5/7 10 20-25 2-10/2 5#2 */10"</span>,     <span class="comment">// cron 表达式</span></span><br><span class="line">secondList: []<span class="keyword">int</span>&#123;<span class="number">0</span>&#125;,                             <span class="comment">// 可触发的秒数</span></span><br><span class="line">minuteList: []<span class="keyword">int</span>&#123;<span class="number">5</span>, <span class="number">12</span>, <span class="number">19</span>, <span class="number">26</span>, <span class="number">33</span>, <span class="number">40</span>, <span class="number">47</span>, <span class="number">54</span>&#125;, <span class="comment">// 可触发的分钟数</span></span><br><span class="line">hourList:   []<span class="keyword">int</span>&#123;<span class="number">10</span>&#125;,                            <span class="comment">// 可触发的小时数</span></span><br><span class="line">daysOfMonth: <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>&#123; <span class="comment">// 可触发的日期</span></span><br><span class="line"><span class="number">20</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="number">21</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="number">22</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="number">23</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="number">24</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="number">25</span>: <span class="literal">true</span>,</span><br><span class="line">&#125;,</span><br><span class="line">workdaysOfMonth:       <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>&#123;&#125;, <span class="comment">// 该月的工作日, 用于</span></span><br><span class="line">lastDayOfMonth:        <span class="literal">false</span>,          <span class="comment">// 是否包含当月最后一天</span></span><br><span class="line">lastWorkdayOfMonth:    <span class="literal">false</span>,          <span class="comment">// 是否包含当月最后一个工作日</span></span><br><span class="line">daysOfMonthRestricted: <span class="literal">false</span>,          <span class="comment">//</span></span><br><span class="line">actualDaysOfMonthList: []<span class="keyword">int</span>&#123;&#125;,</span><br><span class="line">monthList:             []<span class="keyword">int</span>&#123;<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>&#125;, <span class="comment">// 可触发的月份</span></span><br><span class="line">daysOfWeek:            <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>&#123;&#125;,        <span class="comment">// 可触发的星期</span></span><br><span class="line">specificWeekDaysOfWeek: <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>&#123;</span><br><span class="line"><span class="number">12</span>: <span class="literal">true</span>,</span><br><span class="line">&#125;,</span><br><span class="line">lastWeekDaysOfWeek:   <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">bool</span>&#123;&#125;,</span><br><span class="line">daysOfWeekRestricted: <span class="literal">true</span>,</span><br><span class="line">yearList:             []<span class="keyword">int</span>&#123;<span class="number">1970</span>, <span class="number">1980</span>, <span class="number">1990</span>, <span class="number">2000</span>, <span class="number">2010</span>, <span class="number">2020</span>, <span class="number">2030</span>, <span class="number">2040</span>, <span class="number">2050</span>, <span class="number">2060</span>, <span class="number">2070</span>, <span class="number">2080</span>, <span class="number">2090</span>&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;cronexpr (地址 &lt;a href=&quot;https://github.com/gorhill/cronexpr&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/gorhill/cronexpr&lt;/a&gt;) 是一个 gi
      
    
    </summary>
    
      <category term="go" scheme="https://destinywang.github.io/blog/categories/go/"/>
    
      <category term="源码解析" scheme="https://destinywang.github.io/blog/categories/go/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="cron" scheme="https://destinywang.github.io/blog/tags/cron/"/>
    
  </entry>
  
  <entry>
    <title>在系统中如何正确处理时区</title>
    <link href="https://destinywang.github.io/blog/2019/09/13/%E5%9C%A8%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%A4%84%E7%90%86%E6%97%B6%E5%8C%BA/"/>
    <id>https://destinywang.github.io/blog/2019/09/13/在系统中如何正确处理时区/</id>
    <published>2019-09-13T12:20:50.000Z</published>
    <updated>2019-09-13T15:28:27.868Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>前段时间开维护了一个简单的定时/延迟任务调度系统, 在保存定时任务的时候, 需要考虑时区问题, 因为不同时区的 <code>早上 10:00</code> 并不是同一个时间点</p></blockquote><h1 id="1-什么是时区"><a href="#1-什么是时区" class="headerlink" title="1. 什么是时区"></a>1. 什么是时区</h1><p>为了照顾到各地区的使用方便, 又使其他地方的人容易将本地的时间换算到别的地方时间上去. 有关国际会议决定将地球表面按经线从东到西, 划成一个个区域, 并且规定相邻区域的时间相差1小时, 在同一区域内的东端和西端的人看到太阳升起的时间最多相差不过 1 小时, 当人们跨过一个区域, 就将自己的时钟校正 1 小时(向西减 1 小时, 向东加 1 小时), 跨过几个区域就加或减几小时. 这样使用起来就很方便.</p><p>现今全球共分为 24 个时区. 实际上, 常常 1 个国家或 1 个省份同时跨着 2 个或更多时区, 为了照顾到行政上的方便, 常将1个国家或1个省份划在一起. 所以时区并不严格按南北直线来划分, 而是按自然条件来划分, 例如, 中国幅员宽广, 差不多跨5个时区, 但为了使用方便简单, 实际上在只用东八时区的标准时即北京时间为准.</p><p><img src="https://user-images.githubusercontent.com/17758731/64865301-94ee4a00-d66b-11e9-8333-754607404140.png" alt="image"></p><p>在中国地区, 普遍采用东八区, 所谓东八区的意思就是相比格林尼治时间快了八个小时, 对我国人民来说在早上 <code>8:10</code>, 那么同一时刻格林尼治天文台所在的时区时间是凌晨 <code>0:10</code>, 但是这里需要注意的是, 时间是相同的, 这是在同一刻发生的事情, 不同的只是时间的表示方式. 时区通过将绝对时间进行一定的偏移, 从而让全球人民的常识性作息习惯基本一致, 比如通过时区的概念, 能够让全球所有时区都保持在上午 <code>12:00</code> 左右吃午餐.</p><p>因此其实我们日常生活中的时间是由两部分组成: <code>时区时间+时区偏移量</code>, 例如 <code>北京时间 2019-09-13 21:24:15</code>, 表示方式其实是这样:</p><pre><code>&quot;2019-09-13 21:24:15 +8:00&quot; // 东八区&quot;2019-09-13 14:24:15 +1:00&quot; // 东一区</code></pre><h1 id="2-时间在计算机中的表示"><a href="#2-时间在计算机中的表示" class="headerlink" title="2. 时间在计算机中的表示"></a>2. 时间在计算机中的表示</h1><p>上面说过, 在日常生活中, 我们引入时区的概念是为了维持全球相对统一的常识和作息习惯. 但是其缺点在于不同时区进行转化时比较麻烦, 需要将原时间先转换成格林尼治时间, 再转成目标时区时间, 这一点在计算机的存储中更为突出.</p><p>因此我们引入了绝对时间的概念, 绝对时间从一个标准时间点 <code>&quot;1970-01-01 00:00:00 +0:00&quot;</code> 开始到现在的秒数, 使用整型来表示. 不再使用年月日时分秒所表示的相对时间.</p><p>同一时刻在全球任何一个时区所生成的绝对的时间都是相同的, 因为计算机内部有一个计时电路, 通常是一个经过精密加工的石英晶体, 在其张力限度内以一定的频率振荡, 有两个寄存器与每个石英晶体相关联, 一个计数器和保持寄存器, 石英晶体每次振荡似的计数器减 1, 当技术器为 0 时产生一个中断信号, 并重置计数器. 通过中断信号来完成计时.</p><p>因此, 我们需要做的事情就是把生成的绝对时间持久化, 当业务读取的时候根据不同的时区再进行相应的转换, 最终变为符合用户时区的字符串.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestTime</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">now := time.Now()</span><br><span class="line">t.Logf(<span class="string">"now=[%d]"</span>, now.Unix())</span><br><span class="line">t.Logf(<span class="string">"format=[%s]"</span>, now.String())</span><br><span class="line">name, offset := now.Zone()</span><br><span class="line">t.Logf(<span class="string">"ZoneName=[%s], offset=[%d]s"</span>, name, offset)</span><br><span class="line"></span><br><span class="line">now = time.Now().In(time.FixedZone(<span class="string">"GMT"</span>, <span class="number">0</span>))</span><br><span class="line">t.Logf(<span class="string">"now=[%d]"</span>, now.Unix())</span><br><span class="line">t.Logf(<span class="string">"format=[%s]"</span>, now.String())</span><br><span class="line">name, offset = now.Zone()</span><br><span class="line">t.Logf(<span class="string">"ZoneName=[%s], offset=[%d]s"</span>, name, offset)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果如下:</p><pre><code>cronexpr_test.go:379: now=[1568383281]cronexpr_test.go:380: format=[2019-09-13 22:01:21.245361 +0800 CST m=+0.001606362]cronexpr_test.go:382: ZoneName=[CST], offset=[28800]scronexpr_test.go:385: now=[1568383281]cronexpr_test.go:386: format=[2019-09-13 14:01:21.245528 +0000 GMT]cronexpr_test.go:388: ZoneName=[GMT], offset=[0]s</code></pre><p>可以看到实例代码中获取了两次时间, 第一次是以当前系统时间获取(+8:00), 第二次是以格林尼治时间获取(+0:00)<br>两次获取的绝对时间是相同的, 只是在系列化成字符串时, 根据各自不同的时区执行了偏移.</p><p>通过这样的方式可以从根本上避免时区带来的问题, 不同的数据库系统处理时区的方式存在差异, 一次使用 <code>DateTime</code> 之类的类型存储时间, 这样对时区的处理就依赖于数据库自身. 保险起见还是更推荐使用简单的 <code>bigint</code> 来存储绝对时间, 这样带来的好处也是巨大的, 例如可以将时间范围的计算转变成长整型的比较, 并且屏蔽了时区所带来的影响.</p><h1 id="3-不同时区的-crontab-表达式如何处理"><a href="#3-不同时区的-crontab-表达式如何处理" class="headerlink" title="3. 不同时区的 crontab 表达式如何处理"></a>3. 不同时区的 crontab 表达式如何处理</h1><p>在文章的开头我提到过, 这一问题的产生是由于用户可能在不同时区提交 crontab 表达式, 我们存储时间虽然使用绝对时间, 但是 crontab 本身就是一个用来匹配年月日的工具, 必然要涉及到时区问题.</p><blockquote><p>假设 0 时区的用户提交了一个 crontab 表达式 <code>0 */6 * * *</code>, 意为每个格林尼治时间的早 <code>10:00</code> 触发任务, 而服务器所在时区为东八区 CST, 如果直接将这个 crontab 表达式解析, 其语义会变成每个北京时间的早 <code>10:00</code> 触发任务, 可以看到, 直接使用会丢失时区信息.</p></blockquote><p>因此方案也显而易见, 提交 crontab 任务的时候, 需要提供时区信息, 在解析 crontab 表达式的时候, 此时解析的 cron 表达式中的小时信息都是基于服务器时区<code>(触发的小时为 [0, 6, 12, 18])</code> 都是基于服务器时区, 需要将其转换为调用方所在时区的触发时间<code>([4, 10, 16, 20])</code>.</p><p>由于 crontab 表达式的格式比较多, 类似 <em>, 5, </em>/8, 5-10, 5-10/2, 都可以表示小时, 难以直接对 cron 表达式做处理, 比较好的方式是通过 cron 表达式解析的结果, 对其触发的 <code>hourList</code> 值做替换.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;前段时间开维护了一个简单的定时/延迟任务调度系统, 在保存定时任务的时候, 需要考虑时区问题, 因为不同时区的 &lt;code&gt;早上 10:00&lt;/code&gt; 并不是同一个时间点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1-什么是时区&quot;&gt;&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Viper: Go 配置管理利器</title>
    <link href="https://destinywang.github.io/blog/2019/09/07/Viper-Go-%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%E5%88%A9%E5%99%A8/"/>
    <id>https://destinywang.github.io/blog/2019/09/07/Viper-Go-配置管理利器/</id>
    <published>2019-09-07T08:35:20.000Z</published>
    <updated>2019-09-14T07:40:06.458Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Viper-简介"><a href="#1-Viper-简介" class="headerlink" title="1. Viper 简介"></a>1. Viper 简介</h1><h2 id="1-1-什么是-Viper"><a href="#1-1-什么是-Viper" class="headerlink" title="1.1. 什么是 Viper"></a>1.1. 什么是 Viper</h2><p>Viper 是 Go 工程的完整配置解决方案, 能够在工程中处理所有类型的需求和格式, Viper 可以支持:</p><ul><li>设置默认值</li><li>JSON, TOML, YAML, HCL, envfile 和 Java properties 配置文件的读取</li><li>实时查看并重新读取配置文件(可选)</li><li>环境变量的读取</li><li>远程配置系统(etcd 和 Consul) 的读取和变更查看</li><li>命令行标志的读取</li><li>buffer 的读取</li><li>设置显示值</li></ul><p>Viper 可以被看做一个你所有工程配置需求的注册表.</p><h2 id="1-2-为什么使用要使用-Viper"><a href="#1-2-为什么使用要使用-Viper" class="headerlink" title="1.2. 为什么使用要使用 Viper"></a>1.2. 为什么使用要使用 Viper</h2><p>在构建现代应用时, 你一定不想关心配置文件的格式, 你应该把精力放在构建出色的软件系统, Viper 就是为此而生的.</p><p>Viper 可以为你完成如下工作:</p><ul><li>从 JSON, TOML, YAML, HCL, envfile 或 Java properties 格式中找到, 加载并解析配置文件;</li><li>提供为不同配置项设置默认值的机制;</li><li>提供在命令行中指定配置项来覆盖的机制;</li><li>提供别名系统来重命名配置, 而不用破坏现有代码;</li><li>当用户提供了与默认值相同的命令行或配置文件时了, 可以很容易地区分它们.</li></ul><p>Viper 使用如下优先级顺序, 每一项都会比后面优先级更高:</p><ol><li>通过显示调用去设置</li><li>命令行参数</li><li>环境变量</li><li>配置文件</li><li>k/v 存储系统</li><li>默认值</li></ol><p>Viper 配置项的 key 大小写不敏感.</p><h2 id="1-3-向-Viper-设置值"><a href="#1-3-向-Viper-设置值" class="headerlink" title="1.3. 向 Viper 设置值"></a>1.3. 向 Viper 设置值</h2><h3 id="1-3-1-设置默认值"><a href="#1-3-1-设置默认值" class="headerlink" title="1.3.1 设置默认值"></a>1.3.1 设置默认值</h3><p>一个好的配置系统是需要支持默认值的. 默认值对于 key 来说不是必须的, 但如果配置文件, 环境变量, 远程配置系统, 命令行, Set 函数都没有指定时, 默认值将会起作用.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">viper.SetDefault(<span class="string">"ContentDir"</span>, <span class="string">"content"</span>)</span><br><span class="line">viper.SetDefault(<span class="string">"LayoutDir"</span>, <span class="string">"layouts"</span>)</span><br><span class="line">viper.SetDefault(<span class="string">"Taxonomies"</span>, <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;<span class="string">"tag"</span>: <span class="string">"tags"</span>, <span class="string">"category"</span>: <span class="string">"categories"</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="1-3-2-读取"><a href="#1-3-2-读取" class="headerlink" title="1.3.2 读取"></a>1.3.2 读取</h3><p>Viper 可以搜索多个路径, 但当前一个 Viper 实例只支持单个配置文件. Viper 不会设置配置项的默认搜索路径, 需要应用程序指定.</p><p>下面是一些关于 Viper 如何搜索并读取配置文件的例子. 没有任何路径是必须的, 但至少应该提供一个需要配置文件的路径.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">viper.SetConfigName(<span class="string">"config"</span>) <span class="comment">// 配置文件名称, 不需要扩展名, viper 会自动识别</span></span><br><span class="line">viper.AddConfigPath(<span class="string">"etc/appname/"</span>) <span class="comment">// 查找配置文件的路径</span></span><br><span class="line">viper.AddConfigPath(<span class="string">"$Home/.appname"</span>) <span class="comment">// 可以多次添加查找路径</span></span><br><span class="line">viper.AddCOnfigPath(<span class="string">"."</span>) <span class="comment">// 添加当前路径</span></span><br><span class="line">err := viper.ReadInConfig() <span class="comment">// 查找并读取配置文件</span></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(fmt.Errorf(<span class="string">"fatal error config file: %s\n"</span>, err))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你也可以像这样处理一些特定的错误场景:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> err := viper.ReadInConfig(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> _, ok := err.(viper.ConfigFileNotFoundError); ok &#123;</span><br><span class="line">        <span class="comment">// 配置文件找不到</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 配置文件可以找到但发生了其他错误</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 后续逻辑</span></span><br></pre></td></tr></table></figure><h3 id="1-3-3-写入"><a href="#1-3-3-写入" class="headerlink" title="1.3.3 写入"></a>1.3.3 写入</h3><h3 id="1-3-4-监视并重新读取配置文件"><a href="#1-3-4-监视并重新读取配置文件" class="headerlink" title="1.3.4 监视并重新读取配置文件"></a>1.3.4 监视并重新读取配置文件</h3><p>Viper 支持让你的应用在运行中实时读取配置文件.</p><p>需要重启服务才能使新配置生效的日子一去不复返了, Viper 支持的应用可以在运行时读取文件, 并且可以快速感知.</p><p>只需要将 <code>watchConfig</code> 告诉 Viper 实例, 也可以选在在每次发生改变时为 Viper 提供一个运行函数.</p><p>确保在调用 watchConfig 之前已经添加所有的 configPath.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">viper.WatchConfig()</span><br><span class="line">viper.OnConfigChange(<span class="function"><span class="keyword">func</span><span class="params">(e fsnotify.Event)</span>)</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"Config file changed: "</span>, e.Name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-3-5-从-io-Reader-读取配置文件"><a href="#1-3-5-从-io-Reader-读取配置文件" class="headerlink" title="1.3.5 从 io.Reader 读取配置文件"></a>1.3.5 从 io.Reader 读取配置文件</h3><p>Viper 预先定义了多个配置源, 包括文件, 环境变量, 命令行参数和远程 k/v 存储, 但你不必受它们的约束, 你依然可以实现你自己所必须的配置源并提供给 Viper.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestReadFromIOReader</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">viper.SetConfigType(<span class="string">"yaml"</span>)</span><br><span class="line"><span class="keyword">var</span> yamlExample = []<span class="keyword">byte</span>(<span class="string">`</span></span><br><span class="line"><span class="string">Hacker: true</span></span><br><span class="line"><span class="string">name: steve</span></span><br><span class="line"><span class="string">hobbies:</span></span><br><span class="line"><span class="string">- skateboarding</span></span><br><span class="line"><span class="string">- snowboarding</span></span><br><span class="line"><span class="string">- go</span></span><br><span class="line"><span class="string">clothing:</span></span><br><span class="line"><span class="string">  jacket: leather</span></span><br><span class="line"><span class="string">  trousers: denim</span></span><br><span class="line"><span class="string">age: 35</span></span><br><span class="line"><span class="string">eyes : brown</span></span><br><span class="line"><span class="string">beard: true</span></span><br><span class="line"><span class="string">`</span>)</span><br><span class="line">viper.ReadConfig(bytes.NewBuffer(yamlExample))</span><br><span class="line">name := viper.Get(<span class="string">"name"</span>) <span class="comment">// this would be "steve"</span></span><br><span class="line">fmt.Printf(<span class="string">"type of name: %T\n"</span>, name)</span><br><span class="line">fmt.Printf(<span class="string">"value of name: %s"</span>, name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到输出结果:</p><pre><code>type of name: stringvalue of name: steve</code></pre><h3 id="1-3-6-使用环境变量"><a href="#1-3-6-使用环境变量" class="headerlink" title="1.3.6 使用环境变量"></a>1.3.6 使用环境变量</h3><p>Viper 对环境变量提供了完整的支持, 有以下五种方式使用 ENV:</p><ul><li>AutomaticEnv()</li><li>BindEnv(string…): error</li><li>SetEnvPrefix(string)</li><li>SetEnvKeyReplacer(string…) *strings.Replacer</li><li>AllowEmptyEnv(bool)</li></ul><p>在使用环境变量的时候, 需要认识到 Viper 会将 ENV 变量视为区分大小写.</p><h4 id="1-3-6-1-SetEnvPrefix"><a href="#1-3-6-1-SetEnvPrefix" class="headerlink" title="1.3.6.1 SetEnvPrefix"></a>1.3.6.1 SetEnvPrefix</h4><p>Viper 提供了确保 ENV 变量唯一的机制. 通过使用 SetEnvPrefix, 你可以让 Viper 在读取环境变量时使用前缀, <code>BindEnv</code> 和 <code>AutomaticEnv</code> 都会使用这个前缀.</p><h4 id="1-3-6-2-BindEnv"><a href="#1-3-6-2-BindEnv" class="headerlink" title="1.3.6.2 BindEnv"></a>1.3.6.2 BindEnv</h4><p><code>BindEnv</code> 接收一个或两个参数, 第一个参数是 key 名, 第二个参数是环境变量名称. 环境变量的名称是大小写敏感的, 如果环境变玲名称没有提供, 那么 Viper 将自动假定环境变量匹配以下格式: <code>前缀 + &quot;_&quot; + key 名称大写</code>, 当你显式的提供了环境变量名称(即第二个参数)时, 就不会自动添加前缀. 例如, 如果第二个参数名是 <code>id</code>, Viper 就会查找环境变量 <code>ID</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestEnv</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">viper.SetEnvPrefix(<span class="string">"spf"</span>)</span><br><span class="line">viper.BindEnv(<span class="string">"id"</span>)</span><br><span class="line"></span><br><span class="line">os.Setenv(<span class="string">"SPF_ID"</span>, <span class="string">"13"</span>)</span><br><span class="line">id := viper.Get(<span class="string">"id"</span>)</span><br><span class="line">assert.Equal(t, id, <span class="string">"13"</span>)</span><br><span class="line"></span><br><span class="line">viper.BindEnv(<span class="string">"id"</span>, <span class="string">"myspf"</span>)</span><br><span class="line">os.Setenv(<span class="string">"myspf"</span>, <span class="string">"15"</span>)</span><br><span class="line">id = viper.Get(<span class="string">"id"</span>)</span><br><span class="line">assert.Equal(t, <span class="string">"15"</span>, id)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>BinEnv 会将环境变量与 Viper 维护的某个变量绑定, 如果只传一个参数, 这个参数将作为 key 名, 去匹配名称为 <code>大写(前缀_key)</code> 的环境变量. 如果传入两个参数, 第二个参数将直接作为读取的环境变量, 其值将到第一个参数上</p><h4 id="1-3-6-3-AutomaticEnv"><a href="#1-3-6-3-AutomaticEnv" class="headerlink" title="1.3.6.3 AutomaticEnv"></a>1.3.6.3 AutomaticEnv</h4><p><code>AutomaticEnv</code> 是一个强大的助手, 尤其是当与 <code>SetEnvPrefix</code> 组合使用时. 当被调用时, Viper 会在任何使用 <code>viper.Get</code> 的时候检查环境变量. 检查的逻辑是如下规则: 它将如果设置了 <code>EnvPrefix</code> 检查环境变量的名称是否与加上前缀的大写 key 相匹配</p><h4 id="1-3-6-4-SetEnvKeyReplacer"><a href="#1-3-6-4-SetEnvKeyReplacer" class="headerlink" title="1.3.6.4 SetEnvKeyReplacer"></a>1.3.6.4 SetEnvKeyReplacer</h4><p><code>SetEnvKeyReplacer</code> 允许你使用 <code>strings.Replacer</code>, 以在一定程度上重写环境变量的 key. 如果默希望在 <code>Get()</code> 调用中使用 <code>-</code> 或某些东西, 但希望环境变量使用 <code>_</code> 分隔符, 那么这是非常有用的. 使用它的一个例子可以在 <code>viper_test.go</code> 中找到.</p><h3 id="1-3-7-使用命令行变量"><a href="#1-3-7-使用命令行变量" class="headerlink" title="1.3.7 使用命令行变量"></a>1.3.7 使用命令行变量</h3><p>就像 <code>BindEnv</code>, 在调用绑定方法时, 不会设置该值, 这意味着可以尽早绑定, 甚至可以在 <code>init()</code> 的时候就绑定.</p><p>对于单个标识, <code>BindPFlag</code> 方法提供此功能:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">serverCmd.Flags().Int(<span class="string">"port"</span>, <span class="number">1138</span>, <span class="string">"Port to run Application server on"</span>)</span><br><span class="line">viper.BindPFlag(<span class="string">"port"</span>, serverCmd.Flags().Lookup(<span class="string">"port"</span>))</span><br></pre></td></tr></table></figure><p>还可以绑定一组现有的 pflag</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pflag.Int(<span class="string">"flagname"</span>, <span class="number">1234</span>, <span class="string">"help message for flagname"</span>)</span><br><span class="line"> </span><br><span class="line">pflag.Parse()</span><br><span class="line">viper.BindPFlags(pflag.CommandLine)</span><br><span class="line"> </span><br><span class="line">i := viper.GetInt(<span class="string">"flagname"</span>)</span><br></pre></td></tr></table></figure><h1 id="2-部分源码解析"><a href="#2-部分源码解析" class="headerlink" title="2. 部分源码解析"></a>2. 部分源码解析</h1><p>以一个简单的测试用例来作为源码分析的入口:</p><blockquote><p>viper_test.go<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestFlag</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">os.Setenv(<span class="string">"env"</span>, <span class="string">"test"</span>) <span class="comment">// 设置环境变量</span></span><br><span class="line"><span class="comment">// 设置默认值</span></span><br><span class="line">viper.SetDefault(<span class="string">"Best Friend"</span>, <span class="string">"Cream"</span>)</span><br><span class="line"><span class="comment">// 绑定变量, 将环境变量 env 绑定到 viper 维护的配置 env 上</span></span><br><span class="line">viper.BindEnv(<span class="string">"env"</span>, <span class="string">"env"</span>)</span><br><span class="line">env := viper.Get(<span class="string">"env"</span>)</span><br><span class="line">assert.NotNil(t, env)</span><br><span class="line"><span class="comment">// 按照配置读取不同文件, 此时需要读取 test-conf 文件</span></span><br><span class="line">viper.SetConfigName(fmt.Sprintf(<span class="string">"%s-conf"</span>, env))</span><br><span class="line"><span class="comment">// 路径为 ./conf</span></span><br><span class="line">viper.AddConfigPath(<span class="string">"conf"</span>)</span><br><span class="line"><span class="comment">// 类型为 yaml</span></span><br><span class="line">viper.SetConfigType(<span class="string">"yaml"</span>)</span><br><span class="line"><span class="comment">// viper 读取配置文件</span></span><br><span class="line">err := viper.ReadInConfig()</span><br><span class="line">assert.Nil(t, err)</span><br><span class="line"><span class="comment">// 取出 Color</span></span><br><span class="line">color := viper.Get(<span class="string">"Color"</span>)</span><br><span class="line">assert.Equal(t, <span class="string">"yellow"</span>, color)</span><br><span class="line"><span class="comment">// 取出 Age</span></span><br><span class="line">age := viper.Get(<span class="string">"Age"</span>)</span><br><span class="line">assert.Equal(t, <span class="number">1</span>, age)</span><br><span class="line"><span class="comment">// 取出 Hobby</span></span><br><span class="line">hobby := viper.Get(<span class="string">"Hobby"</span>)</span><br><span class="line">assert.Equal(t, <span class="number">2</span>, <span class="built_in">len</span>(hobby.([]<span class="keyword">interface</span>&#123;&#125;)))</span><br><span class="line"><span class="comment">// 取出 Best Friend</span></span><br><span class="line">bestFriend := viper.Get(<span class="string">"Best Friend"</span>)</span><br><span class="line">assert.Equal(t, <span class="string">"Cream"</span>, bestFriend)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><p>在测试文件路径下, 还有 conf/test-conf.yaml 文件内容如下:</p><p>目录结构如下:</p><p><img src="https://user-images.githubusercontent.com/17758731/64476222-e2c40780-d1be-11e9-921d-b21bd736e7d7.png" alt="image"></p><p>内容是我的爱猫王蛋黄 :)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Color:</span> <span class="string">"yellow"</span></span><br><span class="line"><span class="attr">Name:</span> <span class="string">"DanHuang"</span></span><br><span class="line"><span class="attr">Age:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">Hobby:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"Eat"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"Sleep"</span></span><br></pre></td></tr></table></figure><h2 id="2-1-Viper-对象"><a href="#2-1-Viper-对象" class="headerlink" title="2.1 Viper 对象"></a>2.1 Viper 对象</h2><p>viper 包所有暴露出的函数在内部都是 viper 对象的方法, 这些方法都是对 viper 实例对象的操作, 因此我们先看看 viper 对象的底层结构:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Viper <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 分隔键列表的分隔符, 用于一次性访问嵌套值</span></span><br><span class="line">keyDelim <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 查找配置文件的路径集合</span></span><br><span class="line">configPaths []<span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 从中读取配置的文件系统</span></span><br><span class="line">fs afero.Fs</span><br><span class="line"></span><br><span class="line"><span class="comment">// 远程提供者的集合, 用于搜索配置</span></span><br><span class="line">remoteProviders []*defaultRemoteProvider</span><br><span class="line"></span><br><span class="line"><span class="comment">// 要在路径中查找的文件名称</span></span><br><span class="line">configName        <span class="keyword">string</span></span><br><span class="line">configFile        <span class="keyword">string</span></span><br><span class="line">configType        <span class="keyword">string</span></span><br><span class="line">configPermissions os.FileMode</span><br><span class="line">envPrefix         <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line">automaticEnvApplied <span class="keyword">bool</span></span><br><span class="line">envKeyReplacer      *strings.Replacer</span><br><span class="line">allowEmptyEnv       <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">config         <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">override       <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">defaults       <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">kvstore        <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">pflags         <span class="keyword">map</span>[<span class="keyword">string</span>]FlagValue</span><br><span class="line">env            <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">aliases        <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">typeByDefValue <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 在对象上存储读取属性, 这样我们就可以按顺序用注释进行回写</span></span><br><span class="line"><span class="comment">// 只有在读取的配置是属性文件时才会使用</span></span><br><span class="line">properties *properties.Properties</span><br><span class="line"></span><br><span class="line">onConfigChange <span class="function"><span class="keyword">func</span><span class="params">(fsnotify.Event)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="2-2-viper-SetDefault"><a href="#2-2-viper-SetDefault" class="headerlink" title="2.2 viper.SetDefault"></a>2.2 viper.SetDefault</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 为这个 key 提供默认值, 对 key 的大小写不敏感, 仅当用户没有通过命令行, 配置或环境变量提供值时才会被使用</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">SetDefault</span><span class="params">(key <span class="keyword">string</span>, value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123; v.SetDefault(key, value) &#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Viper)</span> <span class="title">SetDefault</span><span class="params">(key <span class="keyword">string</span>, value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line"><span class="comment">// 如果传入alias，则设置适当的缺省值</span></span><br><span class="line">key = v.realKey(strings.ToLower(key))</span><br><span class="line">value = toCaseInsensitiveValue(value)</span><br><span class="line"></span><br><span class="line">path := strings.Split(key, v.keyDelim)</span><br><span class="line">lastKey := strings.ToLower(path[<span class="built_in">len</span>(path)<span class="number">-1</span>])</span><br><span class="line">deepestMap := deepSearch(v.defaults, path[<span class="number">0</span>:<span class="built_in">len</span>(path)<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">// set innermost value</span></span><br><span class="line">deepestMap[lastKey] = value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要工作:</p><ol><li><a href="#221">如果传入的 key 是别名, 遍历所有别名, 直到找到真正的 key (#2.2.1)</a></li><li><a href="#222">面对复杂的 value 类型, 将其所有 key 转变为小写 (#2.2.2)</a></li><li>通过 <code>&quot;.&quot;</code> 将 key 分割, 如 <code>spring.datasource.password</code></li><li>将 path 分割的最后一个字符串转为小写</li><li>用分割后的所有前缀搜索 defaults map, 如果不存在就创建</li><li>用分割后的最后一个字符创和传入的值做键值对放入 defaults 中</li></ol><p>面对复杂的默认值配置, 最终保存的结构类似如下形式:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">defaults := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="string">"server"</span>: <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="string">"port"</span>: <span class="number">8080</span>,</span><br><span class="line"><span class="string">"servlet"</span>: <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="string">"context-path"</span>: <span class="string">"/"</span>,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"spring"</span>: <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="string">"datasource"</span>: <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="string">"username"</span>: <span class="string">"root"</span>,</span><br><span class="line"><span class="string">"password"</span>: <span class="number">123456</span>,</span><br><span class="line"><span class="string">"url"</span>: <span class="string">"jdbc:mysql://localhost:3306/test"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"com.alibaba.druid.pool.DruidDataSource"</span>,</span><br><span class="line"><span class="string">"driver-class-name"</span>: <span class="string">"com.mysql.cj.jdbc.Driver"</span>,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-1-v-Viper-realKey"><a href="#2-2-1-v-Viper-realKey" class="headerlink" title="2.2.1 (v *Viper) realKey"></a><span id="221">2.2.1</span> (v *Viper) realKey</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Viper)</span> <span class="title">realKey</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">newkey, exists := v.aliases[key]</span><br><span class="line"><span class="keyword">if</span> exists &#123;</span><br><span class="line">jww.DEBUG.Println(<span class="string">"Alias"</span>, key, <span class="string">"to"</span>, newkey)</span><br><span class="line"><span class="keyword">return</span> v.realKey(newkey)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于 viper 存在别名系统, 别名系统是一个递归的结构, 如 B 是 A 的别名, C 是 B 的别名, D 是 C 的别名, viper 自身使用一个 <code>aliases map[string]string</code> 来存储别名信息, 因此上例中的情况会有如下存储结构:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">aliases = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span> &#123;</span><br><span class="line"><span class="string">"B"</span>: <span class="string">"A"</span>,</span><br><span class="line"><span class="string">"C"</span>: <span class="string">"B"</span>,</span><br><span class="line"><span class="string">"D"</span>: <span class="string">"C"</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果给该方法输入 D, debug 输出的结果就是:</p><pre><code>DEBUG Alias D to CDEBUG Alias C to BDEBUG Alias B to A</code></pre><p>最终返回 A.</p><p>用户在设置默认值的时候有可能传入一个别名, 由于不知道别名的指向是否是另一个别名, 因此需要通过递归的方式找到不存在为止.</p><p>因此不断的通过当前的 key 取出 value 作为 newKey, 如果 newKey 已经存在, 就需要拿着 newKey 再去取值, 直到某一次通过 newKey 取不出值, 就说明当前的 newKey 是真正的 key.</p><h3 id="2-2-2-toCaseInsensitiveValue"><a href="#2-2-2-toCaseInsensitiveValue" class="headerlink" title="2.2.2 toCaseInsensitiveValue"></a><span id="222">2.2.2</span> toCaseInsensitiveValue</h3><p>判断 value 的类型:</p><ul><li>如果是 map 类型, 将它 key 的类型全部转换为 string</li><li>转成 map[string]interface{} 之后, 做一份拷贝并将 value</li><li>如果不是 map 类型, 直接返回</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">toCaseInsensitiveValue</span><span class="params">(value <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">switch</span> v := value.(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]<span class="keyword">interface</span>&#123;&#125;:</span><br><span class="line">value = copyAndInsensitiviseMap(cast.ToStringMap(v))</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;:</span><br><span class="line">value = copyAndInsensitiviseMap(v)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-2-1-copyAndInsensitiviseMap"><a href="#2-2-2-1-copyAndInsensitiviseMap" class="headerlink" title="2.2.2.1 copyAndInsensitiviseMap"></a>2.2.2.1 copyAndInsensitiviseMap</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">copyAndInsensitiviseMap</span><span class="params">(m <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">map</span>[<span class="title">string</span>]<span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">nm := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key, val := <span class="keyword">range</span> m &#123;</span><br><span class="line">lkey := strings.ToLower(key)</span><br><span class="line"><span class="keyword">switch</span> v := val.(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]<span class="keyword">interface</span>&#123;&#125;:</span><br><span class="line">nm[lkey] = copyAndInsensitiviseMap(cast.ToStringMap(v))</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;:</span><br><span class="line">nm[lkey] = copyAndInsensitiviseMap(v)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">nm[lkey] = v</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> nm</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>创建一个新 map</li><li>通过遍历当前 <code>map[string]interface{}</code> 的所有键值对</li><li>将 key 改为小写</li><li>如果 value 类型是 <code>map[interface{}]interface{}</code>, 转成 <code>map[string]interface{}</code> 后递归调用当前函数</li><li>如果 value 类型是 <code>map[string]interface{}</code>, 递归调用当前函数</li><li>如果类型不再是 map, 就将当前 kv 设置进拷贝 map</li><li>返回拷贝 map</li></ul><p>对 map 进行特殊处理的原因是在配置文件系统中, 配置文件类似树形结构, 每个配置项都有值或者子配置, 如:</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  servlet:</span></span><br><span class="line"><span class="attr">    context-path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line"><span class="attr">  datasource:</span></span><br><span class="line"><span class="attr">    username:</span> <span class="string">root</span></span><br><span class="line"><span class="attr">    password:</span> <span class="number">123456</span></span><br><span class="line"><span class="attr">    url:</span> <span class="attr">jdbc:mysql://localhost:3306/test</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">com.alibaba.druid.pool.DruidDataSource</span></span><br><span class="line"><span class="attr">    driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br></pre></td></tr></table></figure><p>只有 map 用来表示递归的内容 <code>map[interface{}]interface{}</code> 意味着 map 中的每个元素可能是一个新的 map, 这个方法就是为了将上述结构复制为 <code>map[string]interface{}</code> 并遍历整个 map, 将所有的 key 转换成小写.</p><h3 id="2-2-3-deepSearch"><a href="#2-2-3-deepSearch" class="headerlink" title="2.2.3 deepSearch"></a>2.2.3 deepSearch</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">deepSearch</span><span class="params">(m <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;, path []<span class="keyword">string</span>)</span> <span class="title">map</span>[<span class="title">string</span>]<span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">for</span> _, k := <span class="keyword">range</span> path &#123;</span><br><span class="line">m2, ok := m[k]</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="comment">// intermediate key does not exist</span></span><br><span class="line"><span class="comment">// =&gt; create it and continue from there</span></span><br><span class="line">m3 := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">m[k] = m3</span><br><span class="line">m = m3</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">m3, ok := m2.(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="comment">// intermediate key is a value</span></span><br><span class="line"><span class="comment">// =&gt; replace with a new map</span></span><br><span class="line">m3 = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">m[k] = m3</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// continue search from here</span></span><br><span class="line">m = m3</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> m</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要功能:</p><ol><li>传入 <code>defaults(map[string]interface{})</code> 和 <code>path, 分割后的所有前缀(除去最后一个元素)</code></li><li>遍历 path 的每一个元素:<ol><li>如果当前元素不存在与 defaults:<ol><li>创建新 map m3</li><li>将 k, m3 赋值给当前 m</li><li>再将m 指向该空 map, 用于下一个 key 的赋值</li><li>直接开心新一轮循环</li></ol></li><li>判断当前 value 是否为 <code>map[string]interface{}</code><ol><li>如果不是, 将空 map 赋给当前 map 的 key</li></ol></li></ol></li></ol><h2 id="2-3-BindEnv"><a href="#2-3-BindEnv" class="headerlink" title="2.3 BindEnv"></a>2.3 BindEnv</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BindEnv</span><span class="params">(input ...<span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123; <span class="keyword">return</span> v.BindEnv(input...) &#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Viper)</span> <span class="title">BindEnv</span><span class="params">(input ...<span class="keyword">string</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> key, envkey <span class="keyword">string</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(input) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> fmt.Errorf(<span class="string">"BindEnv missing key to bind to"</span>)</span><br><span class="line">&#125;</span><br><span class="line">key = strings.ToLower(input[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(input) == <span class="number">1</span> &#123;</span><br><span class="line">envkey = v.mergeWithEnvPrefix(key)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">envkey = input[<span class="number">1</span>]</span><br><span class="line">&#125;</span><br><span class="line">v.env[key] = envkey</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>接收一个可变长度参数</li><li>变量名称是第一个参数, 环境变量名称是第二个参数</li><li>如果没指定第二个参数, 就会通过 <code>环境变量前缀大写 + _ + 变量名称大写</code> 的形式指定</li><li>以环境变量名为 key, viper 变量名为 value 放入 env 的 map 中</li></ol><h2 id="2-4-Get"><a href="#2-4-Get" class="headerlink" title="2.4 Get"></a>2.4 Get</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Get</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">interface</span></span>&#123;&#125; &#123; <span class="keyword">return</span> v.Get(key) &#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Viper)</span> <span class="title">Get</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">lcaseKey := strings.ToLower(key)</span><br><span class="line">val := v.find(lcaseKey)</span><br><span class="line"><span class="keyword">if</span> val == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> v.typeByDefValue &#123;</span><br><span class="line"><span class="comment">// TODO(bep) this branch isn't covered by a single test.</span></span><br><span class="line">valType := val</span><br><span class="line">path := strings.Split(lcaseKey, v.keyDelim)</span><br><span class="line">defVal := v.searchMap(v.defaults, path)</span><br><span class="line"><span class="keyword">if</span> defVal != <span class="literal">nil</span> &#123;</span><br><span class="line">valType = defVal</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> valType.(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">bool</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToBool(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">string</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToString(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">int32</span>, <span class="keyword">int16</span>, <span class="keyword">int8</span>, <span class="keyword">int</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToInt(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">uint</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToUint(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">uint32</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToUint32(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">uint64</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToUint64(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">int64</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToInt64(val)</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">float64</span>, <span class="keyword">float32</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToFloat64(val)</span><br><span class="line"><span class="keyword">case</span> time.Time:</span><br><span class="line"><span class="keyword">return</span> cast.ToTime(val)</span><br><span class="line"><span class="keyword">case</span> time.Duration:</span><br><span class="line"><span class="keyword">return</span> cast.ToDuration(val)</span><br><span class="line"><span class="keyword">case</span> []<span class="keyword">string</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToStringSlice(val)</span><br><span class="line"><span class="keyword">case</span> []<span class="keyword">int</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToIntSlice(val)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>将传入 key 转为小写</li><li><a href="#241">查找 key 对应的 value</a></li><li>如果为空返回</li><li>如果开启了 typeByDefValue, 需要根据不同类型依次完成转换</li></ol><h3 id="2-4-1-find"><a href="#2-4-1-find" class="headerlink" title=" 2.4.1  find"></a><span id="241"> 2.4.1 </span> find</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Viper)</span> <span class="title">find</span><span class="params">(lcaseKey <span class="keyword">string</span>)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">val    <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">exists <span class="keyword">bool</span></span><br><span class="line">path   = strings.Split(lcaseKey, v.keyDelim)</span><br><span class="line">nested = <span class="built_in">len</span>(path) &gt; <span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// compute the path through the nested maps to the nested value</span></span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInDeepMap(path, castMapStringToMapInterface(v.aliases)) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// if the requested key is an alias, then return the proper key</span></span><br><span class="line">lcaseKey = v.realKey(lcaseKey)</span><br><span class="line">path = strings.Split(lcaseKey, v.keyDelim)</span><br><span class="line">nested = <span class="built_in">len</span>(path) &gt; <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Set() override first</span></span><br><span class="line">val = v.searchMap(v.override, path)</span><br><span class="line"><span class="keyword">if</span> val != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInDeepMap(path, v.override) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PFlag override next</span></span><br><span class="line">flag, exists := v.pflags[lcaseKey]</span><br><span class="line"><span class="keyword">if</span> exists &amp;&amp; flag.HasChanged() &#123;</span><br><span class="line"><span class="keyword">switch</span> flag.ValueType() &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"int"</span>, <span class="string">"int8"</span>, <span class="string">"int16"</span>, <span class="string">"int32"</span>, <span class="string">"int64"</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToInt(flag.ValueString())</span><br><span class="line"><span class="keyword">case</span> <span class="string">"bool"</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToBool(flag.ValueString())</span><br><span class="line"><span class="keyword">case</span> <span class="string">"stringSlice"</span>:</span><br><span class="line">s := strings.TrimPrefix(flag.ValueString(), <span class="string">"["</span>)</span><br><span class="line">s = strings.TrimSuffix(s, <span class="string">"]"</span>)</span><br><span class="line">res, _ := readAsCSV(s)</span><br><span class="line"><span class="keyword">return</span> res</span><br><span class="line"><span class="keyword">case</span> <span class="string">"intSlice"</span>:</span><br><span class="line">s := strings.TrimPrefix(flag.ValueString(), <span class="string">"["</span>)</span><br><span class="line">s = strings.TrimSuffix(s, <span class="string">"]"</span>)</span><br><span class="line">res, _ := readAsCSV(s)</span><br><span class="line"><span class="keyword">return</span> cast.ToIntSlice(res)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> flag.ValueString()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInFlatMap(path, v.pflags) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Env override next</span></span><br><span class="line"><span class="keyword">if</span> v.automaticEnvApplied &#123;</span><br><span class="line"><span class="comment">// even if it hasn't been registered, if automaticEnv is used,</span></span><br><span class="line"><span class="comment">// check any Get request</span></span><br><span class="line"><span class="keyword">if</span> val, ok := v.getEnv(v.mergeWithEnvPrefix(lcaseKey)); ok &#123;</span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInAutoEnv(path) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">envkey, exists := v.env[lcaseKey]</span><br><span class="line"><span class="keyword">if</span> exists &#123;</span><br><span class="line"><span class="keyword">if</span> val, ok := v.getEnv(envkey); ok &#123;</span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInFlatMap(path, v.env) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Config file next</span></span><br><span class="line">val = v.searchMapWithPathPrefixes(v.config, path)</span><br><span class="line"><span class="keyword">if</span> val != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInDeepMap(path, v.config) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// K/V store next</span></span><br><span class="line">val = v.searchMap(v.kvstore, path)</span><br><span class="line"><span class="keyword">if</span> val != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInDeepMap(path, v.kvstore) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Default next</span></span><br><span class="line">val = v.searchMap(v.defaults, path)</span><br><span class="line"><span class="keyword">if</span> val != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> nested &amp;&amp; v.isPathShadowedInDeepMap(path, v.defaults) != <span class="string">""</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// last chance: if no other value is returned and a flag does exist for the value,</span></span><br><span class="line"><span class="comment">// get the flag's value even if the flag's value has not changed</span></span><br><span class="line"><span class="keyword">if</span> flag, exists := v.pflags[lcaseKey]; exists &#123;</span><br><span class="line"><span class="keyword">switch</span> flag.ValueType() &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"int"</span>, <span class="string">"int8"</span>, <span class="string">"int16"</span>, <span class="string">"int32"</span>, <span class="string">"int64"</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToInt(flag.ValueString())</span><br><span class="line"><span class="keyword">case</span> <span class="string">"bool"</span>:</span><br><span class="line"><span class="keyword">return</span> cast.ToBool(flag.ValueString())</span><br><span class="line"><span class="keyword">case</span> <span class="string">"stringSlice"</span>:</span><br><span class="line">s := strings.TrimPrefix(flag.ValueString(), <span class="string">"["</span>)</span><br><span class="line">s = strings.TrimSuffix(s, <span class="string">"]"</span>)</span><br><span class="line">res, _ := readAsCSV(s)</span><br><span class="line"><span class="keyword">return</span> res</span><br><span class="line"><span class="keyword">case</span> <span class="string">"intSlice"</span>:</span><br><span class="line">s := strings.TrimPrefix(flag.ValueString(), <span class="string">"["</span>)</span><br><span class="line">s = strings.TrimSuffix(s, <span class="string">"]"</span>)</span><br><span class="line">res, _ := readAsCSV(s)</span><br><span class="line"><span class="keyword">return</span> cast.ToIntSlice(res)</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> flag.ValueString()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// last item, no need to check shadowing</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>给定一个 key, 找出它的 value. 将按照以下顺序检查:<br>命令行标识, 环境变量, 配置文件, kv存储, 默认值.</p><p>Viper 将首先检查是否存在别名。</p><ol><li>[如果存在嵌套, 通过嵌套 map 得到嵌套的值的路径]</li></ol><h4 id="2-4-1-1"><a href="#2-4-1-1" class="headerlink" title="2.4.1.1"></a>2.4.1.1</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Viper-简介&quot;&gt;&lt;a href=&quot;#1-Viper-简介&quot; class=&quot;headerlink&quot; title=&quot;1. Viper 简介&quot;&gt;&lt;/a&gt;1. Viper 简介&lt;/h1&gt;&lt;h2 id=&quot;1-1-什么是-Viper&quot;&gt;&lt;a href=&quot;#1-1-什么
      
    
    </summary>
    
      <category term="Go" scheme="https://destinywang.github.io/blog/categories/Go/"/>
    
      <category term="源码" scheme="https://destinywang.github.io/blog/categories/Go/%E6%BA%90%E7%A0%81/"/>
    
    
      <category term="Viper" scheme="https://destinywang.github.io/blog/tags/Viper/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 Git</title>
    <link href="https://destinywang.github.io/blog/2019/09/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Git/"/>
    <id>https://destinywang.github.io/blog/2019/09/02/深入理解-Git/</id>
    <published>2019-09-02T09:18:11.000Z</published>
    <updated>2019-09-02T13:17:24.649Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Git-数据结构"><a href="#1-Git-数据结构" class="headerlink" title="1. Git 数据结构"></a>1. Git 数据结构</h1><p>当通过 git init 初始化一个 git 项目时, 当前路径上回自动创建一个 <code>.git</code> 文件夹用来保存所有 git 需要用到的数据.</p><p>我们先来简单介绍一下 <code>.git</code> 中的主要内容:</p><h2 id="1-1-HEAD"><a href="#1-1-HEAD" class="headerlink" title="1.1 HEAD"></a>1.1 HEAD</h2><p><img src="https://user-images.githubusercontent.com/17758731/64104177-57094000-cda6-11e9-8f19-e6c37ce646ac.png" alt="image"></p><ul><li>HEAD 是一个文本文件, 保存当前工作区中的当前分支, <code>ref: refs/heads/master</code> 就是代表当前正在工作的分支是 master, 切换分支时 head 的内容会发生改变</li></ul><h2 id="1-2-config"><a href="#1-2-config" class="headerlink" title="1.2 config"></a>1.2 config</h2><p>主要用于记录当前 git 仓库的配置信息, 假设通过 local 设置了其他的用户名和邮箱, 会在此处保存.</p><p><img src="https://user-images.githubusercontent.com/17758731/64104562-06461700-cda7-11e9-8110-3aa3df5ffac3.png" alt="image"></p><h2 id="1-3-refs"><a href="#1-3-refs" class="headerlink" title="1.3 refs"></a>1.3 refs</h2><p>HEAD 中的指向是一个 refs 下的文件</p><p><img src="https://user-images.githubusercontent.com/17758731/64105627-2c6cb680-cda9-11e9-8074-329b428f8a8b.png" alt="image"></p><p>refs 下包含如下几个内容:</p><ul><li>heads: 对应分支, 是一个独立的开发空间, 不同分支间的工作互不影响. 当彼此间需要集成的时候可以进行合并. HEAD 文件的内容是整个仓库当前工作在哪个分支上, 所以内容是一个引用, 指向 <code>refs/head/</code> 下的某个值, 而此处可以看到, master 内是一个 40 位的 16 进制数字(<code>42ba8f37d95fb8847e8b5639d67ad7aff7bfe0d1</code>)</li></ul><p>我们可以使用 git 内置的命令查看这串数字的类型, 发现这是一个 commit 对象, 也就是说 heads 中保存了当前项目的所有分支, 每个分支都指向了一个 commit 对象:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git cat-file -t 42ba8f37d95fb8847e8b5639d67ad7aff7bfe0d1</span><br><span class="line">commit</span><br></pre></td></tr></table></figure><ul><li>tags: 标签, 当项目开发到一定程度, 是一个关键的里程碑, 或支持了某关键特性, 就可以对特定的 commit 打上一个 tag 做标识.</li></ul><h2 id="1-4-objects"><a href="#1-4-objects" class="headerlink" title="1.4 objects"></a>1.4 objects</h2><p>objects 是 git 中非常重要的路径, 保存了 git 核心数据结构: commit 信息</p><p><img src="https://user-images.githubusercontent.com/17758731/64106125-25927380-cdaa-11e9-8a3f-2131d855bb06.png" alt="image"></p><p>objects 下内容主要分为三部分:</p><ul><li>两位 16 进制数字开头的文件夹, 内部包含一个或多个 38 为 16 进制数字组成的文件名<code>(b98a673367b325d7de6151286d7ceb4aa6c9d3)</code>, 其实 git 内部主要使用 40 位的 16 进制数字, 需要将该名称与文件夹名组合起来, 如上图中我们查看的是 <code>01</code> 下的文件:</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git cat-file -t 01b98a673367b325d7de6151286d7ceb4aa6c9d3</span><br><span class="line">tree</span><br></pre></td></tr></table></figure><p>类型为 tree, 此时我们可以再看看它的内容:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git cat-file -p 01b98a673367b325d7de6151286d7ceb4aa6c9d3</span><br><span class="line">100644 blob 85aa2fa76396d11d0e3cfc3aa8d31d0d9fdb8da5SparseArray.md</span><br><span class="line">100644 blob 109f7918011338d8f409e965400f4ac2a99088ebsparse-array.go</span><br><span class="line">100644 blob b56a4561bf11b3fe2dfe7014b01eafc175b6b99bsparse-array_test.go</span><br></pre></td></tr></table></figure><p>可以看到这棵树中包含三个元素, blob 表示类型是文件, 而每个文件也包含一个 40 位的 hash 值, 我们再继续通过 hash 值查看其中一个元素的类型和内容:</p><p><img src="https://user-images.githubusercontent.com/17758731/64107005-072d7780-cdac-11e9-9d89-bd80161b05b6.png" alt="image"></p><p>类型是一个文件, 而内容就是一段简单的 go 代码</p><ul><li>info:</li><li>pack: git 会做自我梳理, 如果某个类型 1 的文件过于松散, 会对它进行打包, 并将打包后的文件放在 pack 中.</li></ul><p>commit, tree, blob 就是 git 数据结构中最为核心的三个元素.</p><h2 id="1-5-commit-tree-blob-三者间的关系"><a href="#1-5-commit-tree-blob-三者间的关系" class="headerlink" title="1.5 commit, tree, blob 三者间的关系"></a>1.5 commit, tree, blob 三者间的关系</h2><p><img src="https://user-images.githubusercontent.com/17758731/64113249-567ba400-cdbc-11e9-8afc-4d923c72c966.png" alt="image"></p><ul><li>每次执行 <code>git commit</code>, 都会创建一个 commit 对象, 每个 commit 对象除了保存前一个 commit 的地址以外, 还会对应唯一的 tree, 由于文件系统是树形结构, 这个 tree 代表了该 commit 的视图, 视图存放了当前 commit 对应本项目仓库的所有文件和文件夹的快照, 每个 commit 对象再不借助其他 commit 的情况下就可以复原出整个项目.</li><li>tree: 用来表示当前 commit 视图中的一个文件夹</li><li>blob: 直接与文件内容关联, 在 git 仓库中, 只要文件内容一致, 就是一个 blob</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Git-数据结构&quot;&gt;&lt;a href=&quot;#1-Git-数据结构&quot; class=&quot;headerlink&quot; title=&quot;1. Git 数据结构&quot;&gt;&lt;/a&gt;1. Git 数据结构&lt;/h1&gt;&lt;p&gt;当通过 git init 初始化一个 git 项目时, 当前路径上回自动
      
    
    </summary>
    
      <category term="Git" scheme="https://destinywang.github.io/blog/categories/Git/"/>
    
    
      <category term="Git" scheme="https://destinywang.github.io/blog/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 MySQL 原理</title>
    <link href="https://destinywang.github.io/blog/2019/08/13/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-MySQL-%E5%8E%9F%E7%90%86/"/>
    <id>https://destinywang.github.io/blog/2019/08/13/深入理解-MySQL-原理/</id>
    <published>2019-08-13T14:20:12.000Z</published>
    <updated>2019-09-07T08:32:02.403Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-MySQL-体系架构"><a href="#1-MySQL-体系架构" class="headerlink" title="1. MySQL 体系架构"></a>1. MySQL 体系架构</h1><p>MySQL 的架构整体上可以分为服务层和引擎层:</p><ul><li>Server 层涵盖了 MySQL 大多数核心服务, 包括请求的接收, 以及绝大多数内置函数(如 DATE()等)</li><li>Engine 层负责数据的读写</li></ul><p><img src="https://user-images.githubusercontent.com/17758731/62950141-13ac5900-be1a-11e9-9497-d217c977a872.png" alt="image"></p><h2 id="1-1-连接器"><a href="#1-1-连接器" class="headerlink" title="1.1 连接器"></a>1.1 连接器</h2><pre><code>负责建立与客户端建立连接, 获取权限, 维持和管理连接</code></pre><p>通过 TCP 连接, 验证用户身份, 当连接到达时获取用户当前所有权限, 而权限的获取是一次性的, 也就是说即使登录后对该用户的权限做了修改, 也无法立即生效, 需要等到用户下一次登录 MySQL 才能体现.</p><p>常用的登录命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ mysql -h<span class="variable">$IP</span> -P<span class="variable">$PORT</span> -u<span class="variable">$USER</span> -p</span><br><span class="line">Enter password: <span class="comment"># 此时再输入密码</span></span><br></pre></td></tr></table></figure><p>然后再输入密码, 虽然 -p 后可以直接跟密码, 但此时界面不会对密码进行隐藏, 为了安全起见还是建议使用前者</p><p>在登录之后, 可以通过 <code>show processlist</code> 命令查询当前所有生效的连接, 下图是我通过两个终端分别登录本机的 MySQL, 并使用第二个连接执行该命令的结果</p><p><img src="https://user-images.githubusercontent.com/17758731/62951975-7b17d800-be1d-11e9-92c6-1c2db4c906f7.png" alt="image"></p><p>登录成功后, 如果没有后续的操作, 连接会处于 <code>Sleep</code> 状态, 如上图中 Id 为 3 的连接, 表示系统中存在的一个空闲连接. 而 Id 为 4 的连接此时由于正在执行 <code>show processlist</code> 命令, 因此 Command 列值为 <code>Query</code></p><p>MySQL 连接默认的超时时间为 8 小时, 意味着该连接如果 8 小时内没有进行任何的操作, 就会被系统逐出. 超时失效后的连接如果试图再执行任何操作, 都会被告知 <code>Lost connection to MySQL server during query</code></p><h2 id="1-2-查询缓存"><a href="#1-2-查询缓存" class="headerlink" title="1.2 查询缓存"></a>1.2 查询缓存</h2><p>MySQL 所有的查询请求都会先从查询缓存中查找, 其内容可以看做一个一个典型的映射关系</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;SQL 语句, 结果集&gt;</span><br></pre></td></tr></table></figure><p>如果查询语句命中缓存就不会执行后面的操作</p><p>虽然看起来很美好, 但 MySQL 为此做了相对复杂的缓存一致性的维护, 对表的任何写操作都会导致使用该表所对应的缓存全部失效.</p><p>为什么需要全部失效呢? 因为 MySQL 对于范围查询的侦测基本上无能为力, 假设我们有如下语句:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>, score <span class="keyword">FROM</span> student <span class="keyword">WHERE</span> score &gt; <span class="number">90</span>;</span><br></pre></td></tr></table></figure><p>这样一个典型的区间查询, 假设有如下操作:</p><ol><li>插入一条 score 为 92 的字段;</li><li>假设有一个 name 为 Bob 的记录, score 为 80, 现在将其修改为 91;</li></ol><p>执行这样的操作时, MySQL 难以实现也没有必要去完成对缓存细粒度的更新, 因此任何写操作都会导致该表的全部缓存失效.</p><p>这样的机制就带来了一个问题: 对于写操作比较频繁的表, 对应缓存失效非常频繁, 导致白白浪费内存和 CPU. 因此可以在配置中禁用缓存模块, 甚至在 MySQL8.0 之后, 官方已经彻底将缓存模块删除.</p><h2 id="1-3-分析器"><a href="#1-3-分析器" class="headerlink" title="1.3 分析器"></a>1.3 分析器</h2><p>分析器是执行 SQL 的第一步</p><h3 id="1-3-1-词法分析"><a href="#1-3-1-词法分析" class="headerlink" title="1.3.1 词法分析"></a>1.3.1 词法分析</h3><p>解析字符串中每个单词的含义, 建立连接后, 客户端都是已一条字符串格式的 SQL 语句与 MySQL 进行交互, 假设客户端传入了如下一条 SQL 语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>, <span class="keyword">name</span>, gender, score <span class="keyword">FROM</span> student <span class="keyword">WHERE</span> grade = <span class="number">4</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> score <span class="keyword">LIMIT</span> <span class="number">0</span>, <span class="number">100</span>;</span><br></pre></td></tr></table></figure><p>在进行词法分析的时候, 会进行如下操作:</p><ol><li>从 <code>SELECT</code> 判断出这是一条查询语句</li><li>从 <code>id, name, gender, score</code> 识别为列名</li><li>从 <code>student</code> 识别出表名  </li><li>…</li></ol><p>分析的的输出是一棵语法树, 语法树的节点主要分为以下两种类型:</p><ol><li>单个元素, 例如关键字, 表名, 运算符等</li><li>子语句, 例如子查询, 而每个子语句也有一棵语法树用来表示自身的所有单个元素和子语句</li></ol><h3 id="1-3-2-语法分析"><a href="#1-3-2-语法分析" class="headerlink" title="1.3.2 语法分析"></a>1.3.2 语法分析</h3><p>根据词法分析的结果和语法规则判断输入的 SQL 语句是否满足 MySQL 语法</p><h3 id="1-3-3-语义分析"><a href="#1-3-3-语义分析" class="headerlink" title="1.3.3 语义分析"></a>1.3.3 语义分析</h3><h2 id="1-4-优化器"><a href="#1-4-优化器" class="headerlink" title="1.4 优化器"></a>1.4 优化器</h2><p>经过分析器, MySQL 已经理解了 SQL 语句要做什么, 现在需要进行优化操作</p><ol><li>根据规则(扫描行数/是否排序等)决定使用哪条索引</li><li>进行多表关联的时候, 决定表的连接顺序</li></ol><p>最终确定执行方案</p><h2 id="1-5-执行器"><a href="#1-5-执行器" class="headerlink" title="1.5 执行器"></a>1.5 执行器</h2><p>先判断用户对表有没有相应的执行权限, 如果有权限, 根据表所属的引擎调用不同接口. 至于为什么在此处才查询是否有权限, 是因为有时候 SQL 语句需要操作的表不只是 SQL 语句中使用的, 例如当有触发器需要执行时, 涉及的表就没有 体现在 SQL 语句中. 查询语句会优先执行 <code>获取满足条件的第一行</code> 接口, 然后再循环调用 <code>查询满足条件的下一行</code> 接口</p><h1 id="2-MySQL-日志系统"><a href="#2-MySQL-日志系统" class="headerlink" title="2. MySQL 日志系统"></a>2. MySQL 日志系统</h1><p>这里主要介绍两种日志, 慢查询日志和二进制日志(BinLog)</p><p>RedoLog(重做日志) 和 UndoLog(回滚日志)属于 InnoDB 提供的特性, 而非 MySQL 提供, 对二者的介绍会放在事务的实现一章.</p><h2 id="2-1-慢查询日志"><a href="#2-1-慢查询日志" class="headerlink" title="2.1 慢查询日志"></a>2.1 慢查询日志</h2><h2 id="2-2-BinLog"><a href="#2-2-BinLog" class="headerlink" title="2.2 BinLog"></a>2.2 BinLog</h2><p>BinLog 记录了对 MySQL 数据库执行更改的所有操作, BinLog 功能会将所有事务的操作通过日志的形式追加到磁盘中持久化, 不存在被自动覆盖的情况.</p><p>BinLog 是 MySQL server 层的概念, 与存储引擎无关, 但大部分支持事务的存储引擎都实现了 BinLog 的整合, 例如 InnoDB 中 BinLog 的持久化是事务中的一个步骤, InnoDB 会等待 MySQL 返回 BinLog 持久化的结果, 再决定自身是提交还是回滚, 因此对 InnoDB 来说, 任何提交的事务必然存在 BinLog.</p><h3 id="2-2-1-BinLog-内容"><a href="#2-2-1-BinLog-内容" class="headerlink" title="2.2.1 BinLog 内容"></a>2.2.1 BinLog 内容</h3><p>BinLog 有两种形式:</p><table><thead><tr><th>形式</th><th>描述</th></tr></thead><tbody><tr><td>STATEMENT</td><td>BinLog 记录的是执行的 SQL 语句本身, 优点是节省空间, 缺点是有些特定的函数在不同情况下得到的结果不同</td></tr><tr><td>ROW</td><td>BinLog 记录的是记录的修改情况, 假设一条 SQL 语句修改了 100 条语句, 该模式下 BinLog 会记录这 100 条语句的被修改情况, 缺点是浪费空间, 优点是记录的更为准确, 也不会出现 STATEMENT 模式的问题</td></tr><tr><td>MIXED</td><td>是以上两种模式的混合, 一般的语句修改使用 STATEMENT 保存, 而如果存在某些 STATEMENT 无法完成主从复制的操作, 则采用 ROW 格式保存.</td></tr></tbody></table><p>假设有如下表:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`t`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`a`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`t_modified`</span> <span class="keyword">timestamp</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="string">`idx_a`</span> (<span class="string">`a`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="string">`idx_t_modified`</span>(<span class="string">`t_modified`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span>;</span><br></pre></td></tr></table></figure><p>当我们执行:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> t <span class="keyword">where</span> a &gt;= <span class="number">4</span> <span class="keyword">and</span> t_modified &lt;= <span class="string">'2019-09-04'</span> <span class="keyword">limit</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>如果 BinLog 格式为 statement, BinLog 中记录的就是 SQL 语句的原文, 但这样一条看似没有问题的 BinLog 如果用来复现数据, MySQL 会抛出一条警告, 因为这条 delete 语句带 limit, 贸然执行可能会带来数据不一致的场景:</p><ul><li>如果 delete 语句使用的是索引 idx_a, 那么会根据 idx_a 找到第一个满足条件的行</li><li>如果 delete 语句使用的索引是 idx_t_midified, 那么会根据 idx_t_midified 删除第一个满足条件的行.</li></ul><p>如果 BinLog 格式为 row, 此时的 BinLog 原文中不会存在 SQL 语句原文, 而是替换成了两个 event:</p><ul><li>Table_map event: 标识后面的操作是基于哪张表;</li><li>Delete_rows event: 用于定义删除行为.</li></ul><p>此时 BinLog 中记录的是真实被删除记录的主键, 当然不会出现主备删除不同行的问题.</p><p>此外, statement 模式下对一些函数做了处理, 例如 NOW(), 不会出现在主库从库分别记录当前时间的情况, 原理是在BinLog 生成时, 多记了一条命令: <code>SET TIMESTAMP=1567611268</code>, 通过这条命令, 让 MySQL 显式确保主备数据的一致性.</p><h3 id="2-2-2-BinLog-功能"><a href="#2-2-2-BinLog-功能" class="headerlink" title="2.2.2 BinLog 功能"></a>2.2.2 BinLog 功能</h3><p>总的来说, BinLog 具有以下功能:</p><ol><li>恢复数据, 数据库存在误操作的可能, 假设某个时间被删库跑路应该如何防范?<br>比较常见的方式是采用定级备份 + BinLog 恢复. 定时备份可以选择每日或者每周进行一次, BinLog 会一直追加. 假设数据库在 <code>t1</code> 时刻被删库跑路, 而距离 <code>t1</code> 最近的一次全量备份发生在 <code>t0</code>, 那么首先需要将 <code>t0</code> 时刻的副本覆盖, 然后就可以通过全量执行 <code>t0</code> ~ <code>t1</code> 期间的全量 BinLog 来将数据库恢复到 <code>t1</code> 时刻的状态.</li><li>主备复制, 目前数据库集群在主备模式下, 一般都使用 BinLog 来实现主从复制. 每个备库会定时从主库进行 BinLog 的同步去执行. 每个备库都维护了自身的同步进度, 同步时会根据自己当前额进度去获取其后的 BinLog.</li><li>业务需求, 业务系统间有时会通过监听 BinLog 的方式去实现通信. 如某个系统本身逻辑比较复杂, 但只需要关心其写入 DB 的数据情况, 此时就可以通过监听该系统所用数据库的 BinLog 即可. 常见的工具有 <code>Cannal</code>, <code>Maxwell</code> 等.</li></ol><p>BinLog 的日志文件格式为二进制, 其产生的二进制文件不能通过 vim, cat, tail 等命令直接查看, 需要使用 MySQL 提供的专用查看工具 <code>mysqlbinlog</code> 进行查看.</p><p>BinLog 的写入机制</p><blockquote><p>事务执行过程中, 先把日志写到 BinLog Cache, 事务提交的时候再把 BinLog Cache 写入到 BinLog 文件中.</p></blockquote><p>一个事务的 BinLog 不能被拆开, 再大的事务也要确保一次性写入. MySQL 给每个线程分配了一块 BinLog Cache 的内存, 如果超过了这个大小就需要暂存到磁盘, 事务提交的时候执行器把 BinLog Cache 里完整事务写入到 BinLog 中, 并清空 BinLog Cache.</p><p><img src="https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png" alt="image"></p><p>每个线程都有自己的 BinLog Cache, 但是共用一份 BinLog 文件.</p><ul><li>write 操作指的是将日志写入文件系统的 Page cache, 并没有落盘, 速度较快;</li><li>fsync 会落盘</li></ul><p>wirte 和 fsync 的时机由 <code>sync_binlog</code> 控制:</p><ul><li>sync_binlog = 0, 每次提交只 write, 不 fsync</li><li>sync_binlog = 1, 每次提交既 write, 又 fsync</li><li>sync_binlog = N(N &gt; 1), 每次提交都 write, 累计 N 个后再 fsync</li></ul><p>实际业务场景中, 考虑到丢失日志量的可控性, 通常会设置为 100~1000 之间, 但这样的话如果 MySQL 宕机重启, 会丢失最新一部分事务的 BinLog 日志.</p><h1 id="3-MySQL-索引"><a href="#3-MySQL-索引" class="headerlink" title="3. MySQL 索引"></a>3. MySQL 索引</h1><h2 id="3-1-索引概述"><a href="#3-1-索引概述" class="headerlink" title="3.1 索引概述"></a>3.1 索引概述</h2><p>常见的索引有如下几种:</p><ol><li>哈希表</li><li>搜索树</li></ol><p>哈希表示一种 以 k-v 形式存储数据的结构, 其典型的实现有 Java 中的 <code>HashMap</code> 等, 只要输入查询的 key, 就可以找到其对应的 value. 哈希表的实现方式比较简单, 根据 key 计算出一个哈希值, 然后放在数组的某个特定位置, 常见的 <code>数组+链表挂链</code> 的形式就是对哈希表的实现.</p><p>哈希表的插入和查询性能十分优秀, 通常可以认为其 get/set 方法的时间复杂度是 O(1). 对于等值查询通常是首选, 在 Redis, Memcache 中均有广泛应用. 但由于其 key 的排布无序, 虽然在 put 新元素时由于不需要考虑顺序因此非常快, 但却无法处理区间查询(大于和小于)</p><p>最典型的搜索树结构就是二叉查找树, 二叉树的特点是左子树的值小于等于双亲结点, 右子树的值大于双亲结点, 在查询的时候应用二分查找的原理能够做到理想情况下 O(log(N)) 级别的插入和查询, 并且由于其本身就是有序的, 因此天然支持区间查询.</p><p>如果能够加上自平衡的功能, 例如红黑树, 确实作为索引的性能已经比较理想, 但是这样的结论仅限于内存中的数据结构.</p><p>由于数据库系统的数据和索引需要存储在磁盘上, 而对于正常的机械磁盘来说, 一次随机读平均耗时 10ms, 其实时间主要消耗在寻到和旋转磁头的延迟上了. 而顺序读一条数据的消耗大概不到前者的 1%,  因此如果想作为一个对磁盘友好的索引结构, 不能只考虑内存中的性能, 还需要尽可能的降低随机读的频率.</p><p>那么应该如何去降低随机读的频率呢? 以红黑树为例, 假设有一千万条数据, 红黑树最少需要 24 层能够容纳得下, 那就意味着如果想根据磁盘中的红黑树找到磁盘中的数据, 就需要随机读 24 次磁盘, 这显然是不能接受的, 因此想降低随机读的频率, 首先就需要尽可能降低查询次数, 也就是降低树的深度. 在数据总量保持不变的前提下, 如果想降低树的深度, 最可行的办法就是将二叉树变为多叉树. 每个节点变成多叉树之后, 其双亲结点内部相应的需要维护一个小索引(假设是 10 叉树, 则双亲节点内部需要维护其负责的 10 个区间对应的指针), 但其实这个成本是可以忽略不计的, 因为我们一次将其从磁盘中取出, 每个节点内部的索引操作都是在内存中完成. 这样就能避免在一次查询中过多操作磁盘.</p><p>因此引出了 InnoDB 索引的实现: B+树, B+树就是为了充分利用磁盘预读功能而设计的一种数据结构:</p><blockquote><p>磁盘预读与局部性原理:<br>由于存储介质的特性, 磁盘的IO 速度远远低于主存, 因此为了提高效率, 要尽量减少磁盘 IO, 因此磁盘往往不是严格按需读取, 而是每次会预读一块数据, 即使只读一个字节, 磁盘也会从这个位置开始, 顺序向后读取一定长度(默认 4k)的数据放入内存, 这样做的理论依据是注明的局部性原理:<br>当一个数据被用到时, 其附近的数据也通常马上会被使用.</p></blockquote><p>B+ 数每个节点可以存储多个关键字, 它将节点大小设置为磁盘页的大小, 充分利用了磁盘预读的功能, 每次读取磁盘页的时候就会读取整个节点, 也正因为每个节点存储着非常多的关键字(InnoDB 每个双亲结点大概可以存储 1200 个子节点), 会使得树深度很小, 进而要执行的磁盘读取操作次数就会非常少, 更多的是在内存中对读取的数据进行查询操作, 而这部分操作的消耗往往可以忽略不计.</p><p><img src="https://user-images.githubusercontent.com/17758731/63212520-4d41d480-c138-11e9-92fc-6417e6d29717.png" alt="image"></p><h2 id="3-2-InnoDB-索引模型"><a href="#3-2-InnoDB-索引模型" class="headerlink" title="3.2 InnoDB 索引模型"></a>3.2 InnoDB 索引模型</h2><p>InnoDB 支持以下几种索引:</p><ul><li>B+ 树索引</li><li>全文索引</li><li>自适应性哈希索引</li></ul><p>B+ 树索引就是传统意义上的索引, 是目前关系型数据系统中查找数据最为常用和有效的索引. 结构类似于一棵多叉树, 根据键快速找到数据. 自适应性哈希索引, 顾名思义是由 InnoDB 根据实时的查询情况自动为表生成的索引, 不能人为干预.</p><p>B+ 数索引的本质就是 B+ 树在数据库中的实现. 在 InnoDB 中, 每个 B+ 数的双亲节点大致可以保存 1200 个子节点, 可以近似理解为 1200 叉树, 那么即使在面对亿级数据量时, 也能够做到不超过 4 层, 并且 B+ 数的第二层基本会常驻内存, 因此平均场景下, InnoDB 通过索引查询一条记录最多只需要 2~4 次磁盘 IO, 意味着查询时间大致需要 20~40ms.</p><pre><code>在 InnoDB 中, 表都是根据主键顺序以索引的形式存放的, 这种存储方式称之为索引组织表. 所有的数据都存储在主键的 B+ 树中.除了主键以外的其他索引被称为辅助索引, 叶子节点存储着索引字段和主键的映射, 在通过辅助索引查询时, 需要先从辅助索引中找到记录的主键, 再回到主索引查询对应记录.</code></pre><p>下面通过一个例子来解释一下 InnoDB 是如何通过索引快速定位数据的.</p><p>假设有以下表:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">INT</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">    k <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">16</span>),</span><br><span class="line">    <span class="keyword">index</span>(k)</span><br><span class="line">) <span class="keyword">engine</span>=<span class="keyword">InnoDB</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span>(<span class="number">10</span>, <span class="number">1</span>, <span class="string">'Alice'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span>(<span class="number">20</span>, <span class="number">2</span>, <span class="string">'Bob'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span>(<span class="number">30</span>, <span class="number">3</span>, <span class="string">'Carl'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span>(<span class="number">50</span>, <span class="number">5</span>, <span class="string">'David'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span>(<span class="number">60</span>, <span class="number">6</span>, <span class="string">'Eartha'</span>);</span><br></pre></td></tr></table></figure><p>此时表中记录为</p><table><thead><tr><th>id</th><th>k</th><th>name</th></tr></thead><tbody><tr><td>10</td><td>1</td><td>Alice</td></tr><tr><td>20</td><td>2</td><td>Bob</td></tr><tr><td>30</td><td>3</td><td>Carl</td></tr><tr><td>10</td><td>1</td><td>David</td></tr><tr><td>10</td><td>1</td><td>Eartha</td></tr><tr><td>10</td><td>1</td><td>Frank</td></tr></tbody></table><p><img src="https://user-images.githubusercontent.com/17758731/63221133-1535a280-c1c7-11e9-9a16-eb6ccbf017b9.png" alt="image"></p><ul><li>如果查询语句是 <code>SELECT * FROM t WHERE id = 10;</code>, 及主键查询, 则只需所搜主索引;</li><li>如果查询语句是 <code>SELECT * FROM t where k = 5;</code>, 即普通索引查询, 则需要先搜索 k 索引树, 得到 id 值为 50, 再去主索引中搜索一次, 这个过程被称为回表.</li></ul><h2 id="3-3-索引维护"><a href="#3-3-索引维护" class="headerlink" title="3.3 索引维护"></a>3.3 索引维护</h2><p>B+ 树是一种相对较为复杂的数据结构, 为了能够最大程度优化磁盘的读写, 引入了很多较为复杂的特性, 这里简单介绍一下 B+ 树节点的分裂与合并</p><p>B+ 树在插入和删除元素的时候, 都需要维护其有序性:</p><ul><li>以上图为例, 加入插入的新行 id 为 70, 则只需要在 R5 后追加一条记录. 如果插入的 id 值为 40, 就相对麻烦一些, 需要将 R4 后的数据在逻辑上向后挪, 并将 id 为 40 的记录插入到 R3 之后, 更糟的情况是, 如果该叶子节点已满, 就需要申请一个新的数据页, 然后挪动一部分数据过去, 这个过程称为页的分裂, 频繁的分裂会对性能造成影响</li></ul><p><img src="https://user-images.githubusercontent.com/17758731/63221460-dd7d2980-c1cb-11e9-8cd8-ed1b13b6eb0b.png" alt="image"></p><table><thead><tr><th style="text-align:center">叶子节点满</th><th style="text-align:center">双亲节点满</th><th>操作</th></tr></thead><tbody><tr><td style="text-align:center">NO</td><td style="text-align:center">NO</td><td>直接将记录插入到叶子节点</td></tr><tr><td style="text-align:center">YES</td><td style="text-align:center">NO</td><td>1. 拆分叶子节点<br>2. 将中间的节点放入双亲结点<br>3. 小于中间节点的记录放左边<br>4. 大于或等于中间节点的记录放右边</td></tr><tr><td style="text-align:center">YES</td><td style="text-align:center">YES</td><td>1. 拆分叶子节点<br> 2. 小于中间节点的记录放在左边<br> 3. 大于中间节点的记录放在右边<br> 4. 拆分双亲结点<br> 5. 小于中间节点的记录放左边<br> 6. 大于中间节点的记录放右边<br> 7. 中间节点放入上一层双亲结点</td></tr></tbody></table><blockquote><p>为什么 InnoDB 的表推荐使用自增主键<br>从上图的插入过程可以发现, 对 B+ 树来说, 效率最高的插入方式就是插入 id 最大的元素(未必需要递增, 只需要保证每次插入最大即可), 这样的插入永远是在最后一个叶子节点中向后最佳元素. 而其他情况下的插入则需考虑节点分裂. 对数据库来说, 实现 <code>永远插入最大值</code> 最简单的方式就是自增</p></blockquote><h2 id="3-4-联合索引"><a href="#3-4-联合索引" class="headerlink" title="3.4 联合索引"></a>3.4 联合索引</h2><p>联合索引指的是对表上的多个列进行索引, 联合索引的创建方法也和单个索引相同, 唯一的不同之处在于有多个索引列. 底层结构也与普通索引基本相同, 不同之处在于联合索引的叶子节点中, key 是由多个值组成的, 并且 key 之间时按照多个列从左到右的顺序排序</p><p>联合索引能够解决相对复杂的查询逻辑, 同时对多个字段进行查询, 但其使用时必须遵循最左匹配原则.</p><p><img src="https://user-images.githubusercontent.com/17758731/63221796-be34cb00-c1d0-11e9-9478-11a90c6d4682.png" alt="image"></p><p>上图是对两个 int 列进行联合索引的示意图, 可以看到, 联合索引中 key 的顺序先按照列 a 排序, 列 a 相同再按照列 b 排序, 这样类似字典序的排序方式.</p><p>由于这种特性, 如果想使用某条联合索引, 筛选条件中列的顺序必须严格符合联合索引的最左匹配, 因为如果跳过了某一列, 索引就不再有序, 假设把上图中的列 a 去掉, 列 b 的索引就变成了 <code>[10, 15, 3, 5, 5]</code> 显然无法发挥索引的功能.</p><blockquote><p>假设现在有一条 a, b, c, d 列组成的联合索引, 那么能匹配该索引的查询语句为:<br>a -&gt; b -&gt; c -&gt; d<br>a -&gt; b -&gt; c<br>a -&gt; b<br>a</p></blockquote><h2 id="3-5-覆盖索引"><a href="#3-5-覆盖索引" class="headerlink" title="3.5 覆盖索引"></a>3.5 覆盖索引</h2><p>如果一条查询语句能够从辅助索引中获得全部需要的信息, 那么就不再需要回表, 我们就将这样的索引成为覆盖索引.</p><p>对于 InnoDB 的辅助索引而言, 叶子节点的 key 为参与索引的所有字段, value 为主键信息, 假设该索引的字段为k1, k2, 那么如下查询语句都可以使用覆盖所以, 免去回表操作.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> k1 <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> k2 = ?;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>, k1 <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> k2 = ?;</span><br></pre></td></tr></table></figure><h2 id="3-6-索引的选择"><a href="#3-6-索引的选择" class="headerlink" title="3.6 索引的选择"></a>3.6 索引的选择</h2><p>由于一张表中可以存在多个索引(建议索引的数量不要超过 16 条), 但目前一条 SQL 语句只会选择一条索引去执行, 当 SQL 语句中没有明确规定走哪一条索引时, 就会由查询优化器来选择一条.</p><p>下面我们来聊一聊优化器是如何选择索引的.</p><p>查询优化器选择索引的目的, 是为了找到一个最优的方案, 最终以最小的代价去执行语句. 在绝大部分情况下, 查询优化器的行为都是符合预期的, 但既然查询优化器的行为也是由代码逻辑控制, 就可能在特定的情况下与预期不符.</p><p>先说说优化器选择的几个主要标准:</p><ol><li>扫描行数: 这是最直接的指标, 扫描行数越多就意味着访问磁盘的次数越多, 消耗的 CPU 越多;</li><li>是否需要回表</li><li>是否使用临时表;</li><li>是否排序;</li></ol><h3 id="3-6-1-扫描行数"><a href="#3-6-1-扫描行数" class="headerlink" title="3.6.1 扫描行数"></a>3.6.1 扫描行数</h3><p>首先需要明确一个概念, MySQL 在真正开始执行语句前, 无法准确知道满足条件的记录有多少条, 只能根据 <code>统计信息</code> 来估算记录数.</p><p>统计信息就是索引的区分度, 我们在建立索引时普遍会选择区分度更高, 也就是值的离散程度更高的列作为索引. 而一个索引上不同值的个数, 我们称之为 <code>基数</code>, 基数越大, 索引的区分度越高.</p><p>在 MySQL 中, 可以使用 <code>show index</code> 方法查看一个索引的基数.</p><p>而 MySQL 获取索引基数的方式是通过采样统计, 也就是说这里的 <code>cardinality</code> 列只是一个估算的值. 真正执行一遍 SQL 语句再统计虽然可以得到较为准确的值, 但是一旦表中数据过大, 这项统计工作就会变得异常耗时.</p><blockquote><p>在进行统计工作的时候, MySQL 会默认选择 N 个数据页, 统计这些页上不同的值, 得到这些页上的基数后, 得到一个平均值, 再乘以这个索引的数据页数, 就得到整条索引的基数. 而表的数据是会持续更新的, 因此索引的统计信息也不是一成不变的. 从上一次统计开始, 当整条索引上的数据行变更超过 1/M 的时候, 会自动触发重新进行一次索引统计.<br>MySQL 可以使用 <code>innodb_stats_persistent</code> 参数控制索引统计的行为  </p><ol><li>当设置为 on 的时候, 表示会将统计信息持久化存储, 此时默认 N 为 20, M 为 10.</li><li>当设置为 off 的时候, 表示统计信息只存储在内存中, 此时默认的 N 为 8, M 为 16.</li></ol></blockquote><p>我们可以看到当设置为 off 的时候, 统计采样的页数更少, 并且更新的更不活跃, 一般情况下设置为 on 会获得更好的统计效果. 但不论哪种采样方式, 与实际情况依然会存在一定偏差.</p><p>对 MySQL 的查询优化器来说, 大部分查询操作如果能通过主索引完成, 哪怕预计的扫描行数会更多, 也会优先选择主索引, 因为回表也是一种比较耗时的操作, 从辅助索引取出的没一行记录都需要再从主索引中找到整行记录在大部分情况下都会比直接走主索引更加耗时. 这一点, 在统计行数基本无误的情况下, 是没有问题的, 但假如统计行数出现了问题, 就可能会出现通过某一条辅助索引能很快定位, 优化器却选择了另一条扫描行数更多的索引.</p><p>而什么情况会导致 MySQL 对索引的采样统计出现偏差呢?</p><ol><li>最容易想到的就是索引记录进行了大量的修改, 却没有到达触发下次采样统计的行为时</li><li>在数据库短时间进行了大量的删除和插入语句时, 由于 MySQL 是使用标记删除来删除记录的,并不从索引和数据文件中真正的删除, 如果 delete 和 insert 中间的间隔相对较小,purge线程还没有来得及清理该记录. 如果主键相同的情况下, 新插入的insert会沿用之前删除的delete的记录的空间. 由于相同的近似的以及表大小,所以导致了统计信息没有变化</li></ol><p>遇到由于索引基数采样统计不准确而导致的索引选择问题, 可以通过重新统计索引信息的命令来处理:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ANALYZE</span> <span class="keyword">TABLE</span> t</span><br></pre></td></tr></table></figure><h3 id="3-6-2-是否会回表"><a href="#3-6-2-是否会回表" class="headerlink" title="3.6.2 是否会回表"></a>3.6.2 是否会回表</h3><p>回表也是一个相对耗时的操作, 对于一个满足覆盖索引的查询语句来说, 执行步骤通常是这样的:</p><ol><li>从辅助索引中找到第一条符合条件的记录, 并将其需要的字段放入结果集中</li><li>从辅助索引中找到下一条符合条件的记录, 并将其需要的字段放入结果集中</li><li>重复第 2 步, 直到辅助索引中下一条记录不再符合条件</li><li>向客户端返回</li></ol><p>而对于需要回表的查询语句, 执行步骤会变成:</p><ol><li>从辅助索引中找到第一条符合条件的记录</li><li>拿到其主键, 通过主索引找到整行记录, 并将其需要的字段防入结果集中</li><li>从辅助索引中找到吓一跳符合条件的记录</li><li>拿到其主键, 通过主索引找到整行记录, 并将其需要的字段放入结果集中</li><li>重复 3/4 步骤, 直到辅助索引中下一条记录不再符合条件</li></ol><p>不难看出, 一旦脱离覆盖索引, 最坏情况下辅助索引筛选出的每条记录都需要进行一次磁盘 IO, 这个代价是比较大的, 因此会出现如果一条查询语句同时通过主键和辅助索引筛选, 即便辅助索引扫描行数小于主键, 优化器也会选择使用主键</p><h3 id="3-6-3-是否需要排序"><a href="#3-6-3-是否需要排序" class="headerlink" title="3.6.3 是否需要排序"></a>3.6.3 是否需要排序</h3><p>排序的情况也和回表类似, 排序也是一个相对耗时的操作, 尤其是大数据量的排序, 如果无法直接在内存中完成, MySQL 会借助临时文件进行基于归并思想的外部排序. 在查询优化器的决策思路中, 也会尽量选择排序使用的索引而非前面筛选使用的索引.</p><p>假设我们的表 t 中有 a, b 两个字段, a 是主键, b 使用辅助索引, 我们向该表插入 100000 条记录, a, b 两列均从 1 开始递增, 现在执行查询语句:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> (a <span class="keyword">BETWEEN</span> <span class="number">1</span> <span class="keyword">AND</span> <span class="number">1000</span>) <span class="keyword">AND</span> (b <span class="keyword">BETWEEN</span> <span class="number">50000</span> <span class="keyword">AND</span> <span class="number">100000</span>) <span class="keyword">ORDER</span> <span class="keyword">BY</span> b <span class="keyword">limit</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p><p>正常情况下, 查询优化器会得出索引 a 的扫描行数 ≈ 1000, 索引 b 的扫描行数 ≈ 50000 的结论, 但最终会选择 b 索引, 原因就在于 <code>ORDER BY</code> 语句, 会使得查询优化器更倾向于选择能够直接排序的索引, 选择 b 的好处是从该索引上获取的数据天然有序, 不必再去进行额外的排序操作.</p><p>我们来简单解释一下 MySQL 是如何执行 ORDER BY 语句的</p><blockquote><p>当我们对一条 SQL 语句执行 Explain 时, 如果 Extra 字段值为 <code>Using filesort</code> 就表示需要排序, MySQL 会给每个线程分配一块内存(sort_buffer)用于排序.<br>正常的排序语句执行过程:  </p><ol><li>初始化 sort_buffer, 并确定需要参与的字段(MySQL 的原则是内存足够的情况下尽量将 select 的全部字段放入, 否则排序完还需要回表)</li><li>从主索引(可能需要回表)取出整行, 再去 select 的字段存入 sort_buffer 中</li><li>从主索引再取一行记录进行相同操作, 直到不满足查询条件为止.</li><li>在 sort_buffer 中对 ORDER BY 字段进行快速排序</li><li>按照结果返回给客户端  </li></ol><p>这是一条 ORDER BY 语句最理想的执行情况, sort_buffer 大小大于需要排序的总数据量, 一旦 MySQL 发现内存放不下, 就需要借助磁盘临时文件辅助排序, MySQL 需要将总数据量分为 N 份, 每一份单独排序后存在这些临时文件中, 然后把这 N 有序文件再合并成一个有序的大文件. 这个 N 与排序的总数据量和 sort_buffer 大小有关.</p><p>此外, 如果 MySQL 认为单行数据量太大, 超过 <code>max_length_for_sort_data</code> 的值, 就会换成另外一种算法, 只在 sort_buffer 中对 ORDER BY 字段 + id 进行排序, 得到结果后再进行回表.</p></blockquote><p>因此在出现可能的排序场景时, 有如下优化措施:</p><ol><li>我们大部分情况下尽量让走排序字段的索引, 这样数据就天然有序, 不需要再额外进行排序操作.</li><li>也可以利用覆盖索引的特性, 尽可能不进行额外的回表操作</li><li>只 SELECT 必要的字段, 过多的字段可能会触发 MySQL 只对 ORDER BY 字段排序, 再利用 ID 回表.</li></ol><h3 id="3-6-4-如何选择正确的索引"><a href="#3-6-4-如何选择正确的索引" class="headerlink" title="3.6.4 如何选择正确的索引"></a>3.6.4 如何选择正确的索引</h3><p>在前面我们分析了查询优化器选择索引的原理, 也分析了几个查询优化器误选索引的场景, 现在来解决不同情况下误选索引的问题</p><ol><li>由于 MySQL 索引基数采样不准确引起的, 这类问题可以通过 <code>SHOW INDEX FROM t</code> 语句确定, 再通过 <code>ANALYZE TABLE t</code> 重新触发采样解决</li><li>由于回表/排序问题导致的误选索引, 在确定该语句绝大部分情况下都会误选的前提下(因为范围查询未必总会出现上述情况), 可以通过 <code>FORCE INDEX(idx_name)</code> 来强制使用某条索引.</li><li>此外对于排序问题, 还可以将其他的索引字段也加入 <code>ORDER BY</code> 子句中, 通过这样的方式让查询优化器明白, 无论选择哪条索引都无法避免排序, 从而强迫它放弃这一筛选条件, 如上述的 SQL 语句改成 <code>SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b, a limit 1;</code> 后, 查询优化器就会根据索引的扫描行数去决定.</li></ol><h2 id="3-7-索引没有生效的场景"><a href="#3-7-索引没有生效的场景" class="headerlink" title="3.7 索引没有生效的场景"></a>3.7 索引没有生效的场景</h2><p>上一节我们讨论了 MySQL 查询优化器选错索引的原因, 这节继续讨论设置了索引但是却意外的没有生效的场景</p><h3 id="3-7-1-条件字段做函数计算"><a href="#3-7-1-条件字段做函数计算" class="headerlink" title="3.7.1 条件字段做函数计算"></a>3.7.1 条件字段做函数计算</h3><p>假设表 t 中包含一个类型为 <code>datetime</code> 类型的字段 <code>create_time</code>, 并为该字段建立索引 <code>idx_create_time</code>, 如果查询语句为:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> create_time = <span class="string">'2019-8-24'</span></span><br></pre></td></tr></table></figure><p>此时可以正常通过 <code>idx_create_time</code> 查询, 但是如果使用如下语句查询 <code>create_time</code> 字段月数为 8 的全部记录:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">MONTH</span>(create_time) = <span class="number">8</span></span><br></pre></td></tr></table></figure><p>此时 MySQL 会直接执行全表扫描.</p><p>这样的执行方式并不符合我们的预期结果, 因为月份和日期一样, 都是有序的, 但此时为什么不能通过 <code>idx_create_time</code> 进行快速查找呢, 这需要从 InnoDB 索引查询记录的方式说起:</p><p><img src="https://user-images.githubusercontent.com/17758731/63633157-05f69f00-c676-11e9-831f-a785011ae7ca.png" alt="image"></p><p>之前我们提到过, B+ 树的本质是一棵多叉树, 通过在一个节点上尽可能多放节点来降低树的深度, 且 B+树一个节点内的数据是有序的, 查找的方式是从根节点开始, 找到目标记录出现的下层指针, 直到查询到叶子节点, 这样的查询必须依赖与每层跨界点有序, 不然在遍历当前层级的时候, 记录旧可能出现在多个叶子节点, 这样 B+树的查询就会失去意义. 在上图叶子节点的绿色数据中, 我列出了每个 k 的 MONTH() 函数值, 显然并不满足同一层级跨节点有序. 因此 InnoDB 无法通过这样的一条索引去完成 MONTH() 查询.</p><p>但是优化器并不是完全放弃使用这个索引, 优化器可以选择遍历主键索引, 也可以选择遍历 <code>idx_create_time</code>, 这需要优化器按照查询计划分别计算出两种方式预计的耗时.</p><p>对于会改变有序性的函数, 优化器的决定毋庸置疑, 但对于本身就不会改变有序性的函数来说, 优化器由于场景比较复杂, 依然直接采用放弃索引的方式规避麻烦.</p><h3 id="3-7-2-隐式类型转换"><a href="#3-7-2-隐式类型转换" class="headerlink" title="3.7.2 隐式类型转换"></a>3.7.2 隐式类型转换</h3><p>假设表 t 有字段 uid, 类型为 varchar(64), 当执行如下 SQL 语句时, 会直接走全表扫描:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> uid = <span class="number">1234</span>;</span><br></pre></td></tr></table></figure><p>原因是查询语句发生了隐式的类型转换, MySQL 的类型转换规则是如果字符型和数字做比较的话, 会将字符型转换成数字.</p><p>因此上面的 SQL 语句实际被优化器转换为:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">CAST</span>(uid <span class="keyword">AS</span> signed <span class="built_in">int</span>) = <span class="number">1234</span>;</span><br></pre></td></tr></table></figure><p>隐式类型转换的问题本质上还是由于 <code>对索引字段做函数操作, 优化器会放弃走索引树的搜索功能, 触发主索引或辅助索引的全表扫描</code></p><h1 id="4-MySQL-锁"><a href="#4-MySQL-锁" class="headerlink" title="4. MySQL 锁"></a>4. MySQL 锁</h1><p>锁是一个用于管理对共享资源并发访问的数据结构.</p><p>对于写操作, InnoDB 会在行记录上加锁, 使用 lock 功能的对象是事务, 锁定的对象是数据库存储中的对象, 包括表, 页, 行. 并且一般锁会在事务 commit 或 rollback 后释放.</p><p>InnoDB 实现了两种标准的锁:</p><ol><li>共享锁(S 锁), 允许事务读一行数据, 与其他 S 锁兼容, 与 X 锁不兼容</li><li>排他锁(X 锁), 允许事务删除或更新一行数据, 与其他 S 锁或 X 锁均不兼容</li></ol><h2 id="4-1-锁的分类"><a href="#4-1-锁的分类" class="headerlink" title="4.1 锁的分类"></a>4.1 锁的分类</h2><p>根据加锁的范围, MySQL 中的锁大致可以分为全局锁, 表级锁和行级锁.</p><h3 id="4-1-1-全局锁"><a href="#4-1-1-全局锁" class="headerlink" title="4.1.1 全局锁"></a>4.1.1 全局锁</h3><p>全局锁会对整个数据库实例加锁.</p><p><code>Flush Tables With Read Lock (FTWRL)</code>, 可以让整个数据库全局加读锁, 处于只读状态, 所有更新 DDL, DML 和写事务的提交均会被阻塞.</p><p>一般用来做全库逻辑备份, 备份过程中整个库处于只读状态. 如果不加锁备份得到的库不是同一个逻辑时间点.</p><p>MySQL 自带的备份工具 <code>mysqldump</code>, 当使用 <code>-single-transaction</code> 时, 执行 dump 前会启动一个事务来获取一致性视图, MVCC 可以保证其他写操作正常.</p><h3 id="4-1-2-表级锁"><a href="#4-1-2-表级锁" class="headerlink" title="4.1.2 表级锁"></a>4.1.2 表级锁</h3><ol><li>表锁 <code>lock tables t read/write</code>, 限制接下来所有线程的读/写</li><li>元数据锁(metadata lock), 访问时会被自动加上, 保证读写操作的正确性. 防止事务 A 读期间事务 B 对表结构做修改. 普通的增删改查 DML 会对元数据加 S 锁, DDL 操作会对元数据加 X 锁.</li></ol><p>如果安全的执行 ALTER TABLE:</p><ol><li>解决长事务, 可以通过 information_schema 库的 innodb_trx 表查看执行中的事务.</li><li>读写频繁, 由于对元数据的修改会阻塞其后的所有事务, 可以给 ALTER TABLE 设定超时时间, 超时后扔拿不到锁就会直接放弃.</li></ol><h3 id="4-1-3-InnoDB-行锁的实现"><a href="#4-1-3-InnoDB-行锁的实现" class="headerlink" title="4.1.3 InnoDB 行锁的实现"></a>4.1.3 InnoDB 行锁的实现</h3><p>InnoDB 实现了 3 种行锁的算法, 分别是:</p><ol><li>记录锁: 单个记录上的锁, 总是会去锁住索引记录.</li><li>间隙锁: 锁定一个范围, 但不包含记录本身</li><li>临键锁: 实现的方式是记录锁+间隙锁, 锁定一个范围, 并且锁定记录本身.</li></ol><p>在 InnoDB 事务中, 行锁是在需要的时候才加上的, 但并不是不需要就立即释放, 需要等事务结束后再统一释放.</p><p>行锁在 InnoDB 中是基于索引实现的, 因此一旦某个加锁操作没有使用索引, 那么该锁就会退化为表锁.</p><h4 id="4-1-3-1-记录锁-Record-Locks"><a href="#4-1-3-1-记录锁-Record-Locks" class="headerlink" title="4.1.3.1 记录锁(Record Locks)"></a>4.1.3.1 记录锁(Record Locks)</h4><p>为某行记录加锁, 会封锁该行 的索引记录:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- id 列必须为主键或唯一索引</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">1</span> <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br><span class="line"><span class="keyword">UPDATE</span> t <span class="keyword">SET</span> grade = <span class="number">100</span> <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>在使用 <code>SELECT FOR UPDATE</code> 和 <code>UPDATE</code> 时, id 为 1 的记录行会被锁住, 但锁住的索引必须是主索引或者唯一索引, 否则加的锁就是临键锁, 同时, 查询语句必须为精确匹配, 不能为 <code>&lt;</code>, <code>&gt;</code> 或 <code>LIKE</code>, <code>BETWEEN</code> 等, 否则也只会加临键锁</p><h4 id="4-1-3-2-间隙锁-Gap-Locks"><a href="#4-1-3-2-间隙锁-Gap-Locks" class="headerlink" title="4.1.3.2 间隙锁(Gap Locks)"></a>4.1.3.2 间隙锁(Gap Locks)</h4><p>间隙锁作用域普通索引(非主索引或唯一索引), 间隙锁锁住的是一个区间, 而不仅仅是这个区间中的每一条记录.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> t <span class="keyword">SET</span> grade = grade + <span class="number">10</span> <span class="keyword">WHERE</span> <span class="keyword">id</span> <span class="keyword">BETWEEN</span> <span class="number">10</span> <span class="keyword">AND</span> <span class="number">15</span>;</span><br></pre></td></tr></table></figure><p>即所有在(10, 20)区间范围内的行记录都会被锁住, 即 id 为 <code>11, 12, 13, 14</code> 的记录. 但 10 和 15 两条记录不会被锁住.</p><h4 id="4-1-3-3-临键锁"><a href="#4-1-3-3-临键锁" class="headerlink" title="4.1.3.3 临键锁"></a>4.1.3.3 临键锁</h4><p>可以理解为特殊的间隙锁. 每个数据行上的普通索引列都会存在一把临键锁, 当某个事务持有该行的临键锁时, 会锁住一段 <code>左开右闭区间</code> 的数据, InnoDB 中的行锁是基于索引实现, 临键锁只与普通索引有关, 在主索引和唯一键索引上不存在临键锁.</p><p>假设有如下数据表:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">bigint</span> primary <span class="keyword">key</span>,</span><br><span class="line">    age <span class="built_in">int</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">64</span>),</span><br><span class="line">    <span class="keyword">index</span>(age),</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>内容如下:</p><table><thead><tr><th style="text-align:center">id</th><th style="text-align:center">age</th><th style="text-align:center">name</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">10</td><td style="text-align:center">Lee</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">24</td><td style="text-align:center">soraka</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">32</td><td style="text-align:center">Zed</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">45</td><td style="text-align:center">Talon</td></tr></tbody></table><p>此时, age 索引上潜在的临键锁有:</p><ul><li><code>(-∞, 10]</code></li><li><code>(10, 24]</code></li><li><code>(24, 32]</code></li><li><code>(32, 45]</code></li><li><code>(45, +∞)</code></li></ul><p>此时进行如下操作:</p><table><thead><tr><th>时刻</th><th>事务 A</th><th>事务 B</th><th>情况</th></tr></thead><tbody><tr><td>t1</td><td><code>SELECT * FROM t WHERE id BETWEEN 10 AND 24 FOR UPDATE</code></td><td>无</td><td>获得间隙锁</td></tr><tr><td>t2</td><td>无</td><td><code>INSERT INTO t(age, name) VALUES(15, &#39;Tom&#39;)</code></td><td>插入操作被阻塞</td></tr></tbody></table><p>使用这样的方式保证事务执行期间不会出现幻读.</p><h3 id="4-1-4-解决幻读"><a href="#4-1-4-解决幻读" class="headerlink" title="4.1.4 解决幻读"></a>4.1.4 解决幻读</h3><p>大部分数据库都是通过最高事务隔离级别 <code>SERIALIZABLE</code> 去解决幻读问题, 但 InnoDB 不同, 它是通过 MVCC 和临键锁, 在 <code>REPEATABLE READ</code> 隔离级别下避免幻读. 我们下面就来解释一下原因</p><blockquote><p>幻读: 在同一事务下, 连续执行两次 SQL 语句可能导致不同的结果, 第二次 SQL 语句可能会返回之前不存在的行或者没有返回之前存在的行, 即无法感知当前事务执行期间其他事务的 INSERT 或 DELETE 操作.</p></blockquote><p>假设有如下表记录:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`t`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`c`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`d`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="string">`c`</span> (<span class="string">`c`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>), (<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>),(<span class="number">15</span>,<span class="number">15</span>,<span class="number">15</span>),(<span class="number">20</span>,<span class="number">20</span>,<span class="number">20</span>),(<span class="number">25</span>,<span class="number">25</span>,<span class="number">25</span>);</span><br></pre></td></tr></table></figure><p>当我们执行如下查询语句时:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">begin</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> d=<span class="number">5</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p>InnoDB 的加锁顺序是这样的:</p><ol><li>字段 d 没有索引, 只能通过主索引全表扫描, 将主索引上全部记录加行锁</li><li>将主索引上全部 <code>间隙</code> 加锁</li></ol><table><thead><tr><th>时刻</th><th>tx-a</th><th>tx-b</th><th>tx-c</th></tr></thead><tbody><tr><td>t1</td><td><code>select * from t where d=5 for update;</code></td><td></td><td></td></tr><tr><td>t2</td><td></td><td><code>update t set d=5 where id=0;</code></td><td></td><td></td></tr><tr><td>t3</td><td><code>select * from t where d=5 for update</code></td><td></td><td></td></tr><tr><td>t4</td><td></td><td></td><td><code>update t set d=5 where id=0;</code></td></tr><tr><td>t5</td><td><code>select * from t where d=5 for update</code></td><td></td></tr></tbody></table><p>如果只对 id=5 这一行加锁, 而其他行不加锁的话, 那么在事务 a 中, 三次 select 语句执行的结果均不相同. 这种情况就被成为幻读, 一个事务在前后两次查询同一个范围时, 第二次查询到了前一次没有看到的行.</p><p>幻读带来的问题:</p><ol><li>破坏语义: T1 时刻事务 a 想做的事情是 <code>把所有 d=5 的行锁住, 不准别的事务进行读写操作</code>, 但幻读显然破坏了这样的语义</li><li>数据一致: 假设在事务 a 执行范围修改后, 提交前其他事务插入了符合 a 修改条件的记录, 并直接提交, 那么事务 a 提交后的 BinLog(STATEMENT 模式) 中涉及的修改就会包含其他事务添加的行.</li></ol><p>幻读问题的根源在于即使把所有记录都加锁, 依然无法阻止新纪录的插入, 因此为了解决幻读, InnoDB 引入了间隙锁, 用于锁住两个值之前的空隙. 例如初始化后的表 t 有 6 条记录, 就会产生 7 个间隙:</p><pre><code>(-∞, 0) (0, 5) (5, 10) (10, 15) (15, 20) (25, +∞)</code></pre><p>当执行 <code>SELECT * FROM t WHERE d=5 FOR UPDATE;</code> 时, 由于 d 字段没有索引, 不止会给已有的 6 条记录加上行锁, 还同时给 7 个间隙全部加上间隙锁, 这样就保证无法再插入新的数据.</p><p>在 InnoDB 中, 数据行是可以加锁的实体, 数据行之间的间隙也是. 但间隙锁不像行锁会分为读锁和写锁, 与间隙锁存在冲突的是 <code>向这个间隙中插入记录</code> 这个操作, 不同间隙锁之间不存在冲突关系.</p><h1 id="5-事务"><a href="#5-事务" class="headerlink" title="5. 事务"></a>5. 事务</h1><p>事务是数据库系统区别于文件系统的重要特性之一, 在文件系统中, 如果在写文件的时候进程退出, 这个文件就很有可能被损坏. 还有在顺序写入多个文件的场景, 如果执行到中间某个状态时进程退出, 就会产生复杂的中间状态.</p><p>数据库引入了事务, 就是希望能够安全的将数据库从一种一致状态转换到另一种一致的状态上来, 当数据库提交工作时, 可以确保要么所有的修改都已经成功保存, 要么所有的修改都被废弃. 而保证这些功能的关键就在于满足 ACID 特性.</p><table><thead><tr><th>概念</th><th>描述</th></tr></thead><tbody><tr><td>A(Atomicity) 原子性</td><td>原子性需要保证一系列的更新操作要么全部执行成功, 要么全部被废弃</td></tr><tr><td>C(Consisteny) 一致性</td><td>事务将数据库从一种抑制状态转变为下一种一致的状态, 在事务的开始和结束前后, 数据库的完整性约束没有被破坏</td></tr><tr><td>I(Isolation) 隔离性</td><td>隔离性保证每个读写事务的对象对其他事务的操作独享能相互分离, 即该事务提交前对其他事务都不可见</td></tr><tr><td>D(Durability) 持久性</td><td>事务一旦提交, 其结果就是持久性的, 即使发生宕机等事故, 数据库也能将数据恢复.</td></tr></tbody></table><h2 id="5-1-隔离级别"><a href="#5-1-隔离级别" class="headerlink" title="5.1 隔离级别"></a>5.1 隔离级别</h2><p>当数据库上有多个事务同时执行的时候, 可能出现脏读, 不可重复读, 幻读等问题, 为了解决这些问题, 就有了隔离级别的概念.</p><blockquote><p>在理解隔离级别的时候, 我们可以先想象机场的安检级别, 在机场中, 由于客流量较大, 并且安全问题非常重要, 因此通常会使用不同安检预案来应对不同的情况. 在常规情况下, 安检级别可能不高, 此时安检项目不多, 吞吐量较高; 但如果有国家政要等情况, 安检级别就会相对升高, 甚至当机场受到了恐怖威胁可能安检级别会更高.<br>总之安检级别越高, 相对吞吐量就会降低, 但可以保证更高的安全性.</p></blockquote><p>隔离级别也是同理, 是由 SQL92 标准定义的一套预案, 各个数据库自己来实现, 实际使用场景中, 需要由开发人员根据实际业务特点来灵活选择. 目前提供的标准事务隔离级别主要包括:</p><table><thead><tr><th style="text-align:center">隔离级别</th><th>描述</th></tr></thead><tbody><tr><td style="text-align:center">读未提交</td><td>一个事务还没有提交时, 它做的变更就能被别的事务看到</td></tr><tr><td style="text-align:center">读已提交</td><td>一个事务提交后, 它的变更才能被其他事物看到</td></tr><tr><td style="text-align:center">可重复读</td><td>一个事务执行过程中看到的数据, 总是跟这个事务在启动过程中看到的数据是一致的.</td></tr><tr><td style="text-align:center">可串行化</td><td>对于同一行记录, 写加 X 锁, 读加 S 锁, 当读写冲突的时候, 后访问的事务必须等前一个事务执行完成才能继续执行.</td></tr></tbody></table><p>读未提交的实现方式比较简单, 写操作在完成之前就能被看到说明读写可以同时对一个事务加锁, 目前绝大部分数据库的默认隔离级别都不会是读未提交, 并且在绝大多数场景中都不能使用读未提交.</p><p>目前 InnoDB 的默认隔离级别是可重复读, Oracle 的默认隔离级别是读已提交.</p><h3 id="5-1-2-事务隔离级别的实现"><a href="#5-1-2-事务隔离级别的实现" class="headerlink" title="5.1.2 事务隔离级别的实现"></a>5.1.2 事务隔离级别的实现</h3><p>在 InnoDB 中, 每条记录在更新的时候都会同时记录一条回滚操作. 记录上的最新值通过回滚操作介意得到前一个状态的值. 假设一个值从 1 被依次改为 2, 3, 4, 在回滚段中会有类似记录:</p><p><img src="https://user-images.githubusercontent.com/17758731/63634553-a9ea4580-c68a-11e9-8cbf-91a37a340f7e.png" alt="image"></p><p>当前的值为 4, 但是在查询这条记录时, 不同时刻启动的事务会有不同的 ReadView(视图), 同一条记录可以存在多个版本, 这就是数据库的多版本并发控制(Multi-Version-Concurrency-Control, MVCC), 对于在该条记录为值为 1 时启动的事务, 会使用 ReadView-A 去查询该记录, 查询的原理是通过从最新值开始, 依次向前比较直到找到提交时间早于该事物启动时间的第一条记录, 然后返回.</p><p>回滚段的删除比较特殊, 需要等到整个系统中没有比这个回滚段更早的 ReadView 时, 才可以删除, 因为 InnoDB 不能确定哪些 ReadView 会访问这条数据, 只有等真正执行的时候才知道.</p><p>在可重复读隔离级别下, 事务启动时会同时启动一份快照, 这个快照是基于整个数据库的. 但它不是真的对整个数据库做一次备份.</p><blockquote><p>InnoDB 中每个事务都有一个唯一的事务 ID, 叫做 txId, 当事务启动时统一分配并且严格递增. 每条记录也有多个版本, 每次更新都会创建一个新的版本, 并且记录修改的 txId 作为 row rx-id. 同时旧的数据版本就放在回滚段中.<br>但是记录的多个版本只是逻辑上的概念, InnoDB 并不是真的存储数据, 存储的是能够将数据恢复到上一个版本的 <code>undo log</code>.<br>对于可重复读, 一个事务启动的时候, 能够看到所以已经提交的事务结果, 也就是该事物只能看到每条记录所有已提交的 <code>row tx_id</code> 小于自己 tx_id 的版本. InnoDB 为每个事务构造了一个数组, 用来保存这个事务启动时未提交的事务 id. 对于该事物, 通过 <code>未提交事务列表中最小值</code> 和 <code>当前数据库最大事务 id + 1</code> 两个值将当前时刻的全部事务分为三部分:</p></blockquote><ol><li>已创建, 并且确定提交的事务</li><li>已创建, 但需要进一步确认是否提交的事务</li><li>还未创建的事务</li></ol><p><img src="https://user-images.githubusercontent.com/17758731/63651541-4a725f80-c788-11e9-9ac2-074d49378798.png" alt="image"></p><p>此时, 对数据库中全部记录的 row tx_id 来说, 分为四种类型:</p><ol><li>蓝色部分: 由已创建且已提交的事务生成, 可见</li><li>绿色部分:<ol><li>在当前事务 <code>未提交事务列表</code> 中, 代表由已创建但未提交的事务生成, 不可见</li><li>不在当前事务 <code>未提交事务列表</code> 中, 代表由已创建且已提交的事务生成, 可见</li></ol></li><li>黄色部分: 由未来启动的事务生成的, 不可见</li></ol><p>InnoDB 利用 redo log 实现了 MVCC, 再利用 MVCC 实现秒级创建快照的能力.</p><p>而读已提交和可重复读的实现都利用了快照, 不同之处在于:</p><ol><li>读已提交级别下, 每一条语句执行前都会重新计算出一个快照</li><li>可重复读级别下, 只在事务创建时计算一次快照, 之后事务里的其他查询都共用这一个视图.</li></ol><p>可序列化隔离级别, 不需要视图以及其他额外的特性, 每条记录都按照 S 锁和 X 锁的定义依次执行即可.</p><h2 id="5-2-事务的实现"><a href="#5-2-事务的实现" class="headerlink" title="5.2 事务的实现"></a>5.2 事务的实现</h2><p>事务的隔离性由锁来实现, 原子性和持久性由 redo log 实现, 一致性由 undo log 实现. redo log 用来恢复提交事务修改的页操作, undo log 用来将行记录回滚到某个特定版本.</p><h3 id="5-2-1-Redo-log"><a href="#5-2-1-Redo-log" class="headerlink" title="5.2.1 Redo log"></a>5.2.1 Redo log</h3><p>我们先想象一个最直接的 UPDATE 语句执行方式:</p><ol><li>根据索引从磁盘中读出记录所在的数据页</li><li>在内存中修改数据页对应的值</li><li>将数据页刷新回磁盘</li></ol><p>在不考虑性能的前提下, 这是完成一条更新操作最直观的方式.</p><p>但往往越直观的方式, 性能越差. UPDATE 操作是一个典型的随机写, 对于机械硬盘来说, 一次随机写平均花费 10ms, 并且一个事务中可能存在多条写操作, 在保证其能执行成功的同时还要保证原子性, 由此可见这并不是一个理想的方案.</p><p>InnoDB 引入了 WAL 思想, 其关键在于先写日志, 再写磁盘, 当有一条记录需要更新的时候, InnoDB 就会先把记录写到 RedoLog 中, 并更新内存, 此时更新操作就完成了. InnoDB 会在 <code>适当</code> 的时候, 将这个操作记录更新到磁盘中, 这样的更新都是在系统相对比较空闲的时候.</p><p><img src="https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png" alt="image"></p><p>这里借用极客时间的图来说明 RedoLog 的实现方式, 磁盘中的 RedoLog 是固定大小的(并不像 BinLog 可以在磁盘空间未满的情况下无限追加), 写入的方式类似环形队列, <code>write pos</code> 是当前记录的位置, 一边写一边后移, <code>checkpoint</code> 是当前需要擦除的位置, 也是往后推移并且循环, 擦除记录前要把记录更新到数据文件. 假设我们为 RedoLog 文件定义两个操作:</p><ul><li>push: 向 RedoLog 文件写入数据, 并增加 <code>write pos</code>, 当事务执行写操作触发</li><li>pop: 从 RedoLog 中删除数据, 并增加 <code>check point</code>, 当该事务的更新操作落盘时触发, 代表该条 RedoLog 不再需要.</li></ul><p>RedoLog 的写入机制:</p><blockquote><p>事务在执行的时候, 生成的 RedoLog 会先写入 RedoLog Buffer, 当事务提交时再统一持久化到磁盘.</p></blockquote><p>我们先从一条更新 SQL 语句的执行过程来体会 RedoLog 的功能.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> t <span class="keyword">SET</span> grade = grade + <span class="number">1</span> <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>执行过程如下:</p><p><img src="https://user-images.githubusercontent.com/17758731/63781356-365f6700-c91c-11e9-9bb7-6f2d7b8534f9.png" alt="image"></p><p>需要着重解释的几个点:</p><h4 id="5-2-1-1-BinLog-和-RedoLog-能否相互替代"><a href="#5-2-1-1-BinLog-和-RedoLog-能否相互替代" class="headerlink" title="5.2.1.1 BinLog 和 RedoLog 能否相互替代"></a>5.2.1.1 BinLog 和 RedoLog 能否相互替代</h4><p>答案是不能, 首先 BinLog 是 MySQL Server 层提供的功能, 旨在提供数据恢复, 集群同步等功能; RedoLog 是 InnoDB 独有的概念, 用来实现事务的原子性和持久性. 简单来说二者的设计方向不同, BinLog 在磁盘空间足够的前提下可以无限增加, 用来复现某个时间点之后的全部写操作. RedoLog 文件在磁盘中大小固定, 循环队列的结构会使得较早的日志被清理掉.</p><ul><li>BinLog 功能: 保证数据库能够从某个时间点正确恢复以及主从一直.</li><li>RedoLog 功能: 保证事务原子性和持久性, RedoLog 落盘后数据库即使宕机重启更新依然不丢.</li></ul><h4 id="5-2-1-2-为什么-RedoLog-需要先-Prepare"><a href="#5-2-1-2-为什么-RedoLog-需要先-Prepare" class="headerlink" title="5.2.1.2 为什么 RedoLog 需要先 Prepare"></a>5.2.1.2 为什么 RedoLog 需要先 Prepare</h4><p>答案是为了保证 RedoLog 和 BinLog 的一致性.</p><p>我们可以做一个假设, 如果不使用两阶段提交, 分别提交 BinLog 和 RedoLog 看看会出现什么情况.</p><table><thead><tr><th>场景</th><th>问题</th></tr></thead><tbody><tr><td>先提交 BinLog, 提交 RedoLog 前数据库宕机</td><td>此时 BinLog 落盘成功, 从库可以拉取到该 BinLog, 会将该更新在自己身上提交, 主库恢复后无法复现该事务, 此时主从不一致. 此外, 主库如果从某个时刻想通过 BinLog 恢复到当前状态, 恢复出来的时候就会多出一个事务, 该记录的值与原库值不同.</td></tr><tr><td>先提交 RedoLog, 提交 BinLog 时数据库宕机</td><td>此时 RedoLog 落盘成功, 即使数据库宕机, 主库恢复后依然可以复现. 但由于 BinLog 没有写入成功, 此时如果用这个 BinLog 来恢复临时库或者主从同步, 恢复出来的行记录就会少一条事务, 依然与原库值不同</td></tr></tbody></table><p>因此我们可以看到, RedoLog 影响宕机重启后的事务重新执行, BinLog 影响可能需要的恢复和主从同步, 要想一致就必须使用两阶段提交.</p><h4 id="5-2-1-3-两阶段提交如何保证-RedoLog-与-BinLog-一致"><a href="#5-2-1-3-两阶段提交如何保证-RedoLog-与-BinLog-一致" class="headerlink" title="5.2.1.3 两阶段提交如何保证 RedoLog 与 BinLog 一致"></a>5.2.1.3 两阶段提交如何保证 RedoLog 与 BinLog 一致</h4><p>RedoLog 的两阶段提交一共分为三步:</p><ol><li>写入 RedoLog, 处于 Prepare 状态</li><li>写入 BinLog</li><li>提交事务, 处于 commit 状态</li></ol><p>问题可能出现在步骤 1 后和步骤 2 后, 我们分情况来讨论下:</p><ol><li>写入 Prepare 状态的 RedoLog 后 MySQL 宕机: 此时 BinLog 没有写入, RedoLog 也没有提交, 此时可以当做事务提交失败.</li><li>写入 BinLog 后 MySQL 宕机: 崩溃恢复的规则如下:<ol><li>如果 RedoLog 中事务是完整的, 也就是有了 commit 标识, 则可以直接提交;</li><li>如果 RedoLog 中事务只有完整的 Prepare, 则判断对应事务的 BinLog 是否完整, BinLog 如果完整就可以提交事务, 否则回滚.</li></ol></li></ol><p>对于 MySQL 来说, 每个事务的 BinLog 都有完整的格式, 通过识别该格式就可以判断事务额 BinLog 是否完整.</p><p>此外, BinLog 和 RedoLog 都有一个共同的字段 <code>XID</code>, 在崩溃恢复的时候会按顺序扫描 RedoLog:</p><ul><li>如果碰到既有 Prepare 又有 commit 的 RedoLog, 就直接提交;</li><li>如果碰到只有 Prepare 但没有 commit 的 RedoLog, 就需要通过 TXID 去 BinLog 中查询, 再通过 BinLog 是否完整决定提交或回滚.</li></ul><h3 id="5-2-2-回滚日志-UndoLog"><a href="#5-2-2-回滚日志-UndoLog" class="headerlink" title="5.2.2 回滚日志 UndoLog"></a>5.2.2 回滚日志 UndoLog</h3><p>RedoLog 记录了事务的行为, 可以通过其对数据页进行重做. 但事务如果需要进行回滚, 就需要 UndoLog. 当事务执行失败或者显式执行 ROLLBACK 的时候, 就可以利用 UndoLog 将数据回滚到某个特定的版本.</p><p>UndoLog 存放在数据库内部的回滚段中, UndoLog 本身不是快照, 只是逻辑地将数据库恢复到原来的样子, 比如某个字段自增, UndoLog 中就会记录将该字段 -1 可以得到上一个版本</p><h3 id="5-2-3-组提交"><a href="#5-2-3-组提交" class="headerlink" title="5.2.3 组提交"></a>5.2.3 组提交</h3><p>我们通常给 <code>sync_binlog</code> 和 <code>innodb_flush_log_at_trx_commit</code> 都会设置为 1, 也就是说一个完整的事务提交前, 需要进行两次 fsync 操作, 依次是 RedoLog(prepare), 另一次是 BinLog. 然而磁盘的 fsync 性能是有限的, 甚至磁盘 fsync 的速度很大程度上限制了数据库的 TPS 上限, 为了提高磁盘 fsync 的效率, MySQL 提供了 group commit 的功能, 即一次 fsync 可以刷新确保多个事务日志被写入文件.</p><p>事务提交时, 会进行两个阶段的操作:</p><ol><li>修改内存中事务对应的信息, 并且将日志写入 RedoLog Buffer</li><li>调用 fsync 将确保日志都从 RedoLog Buffer 写入磁盘</li></ol><p>步骤 2 的耗时远大于步骤 1, 此时我们就可以当某个事务进行步骤 2 的时候, 让其他事务先执行步骤 1, 这样就可以将多个事务的重做日志通过一次 fsync 刷新到磁盘, 这样可以减轻磁盘的压力.</p><p>MySQL 甚至提供了把 RedoLog 做 fsync 时间拖到步骤 1 之后的功能:</p><ul><li>binlog_group_commit_sync_delay 参数, 表示延迟多少微秒后才调用 fsync;</li><li>binlog_group_commit_sync_no_delay_count 参数, 表示累计多少次以后才调用 fsync</li></ul><p>因此 WAL 机制主要能带来两方面提升:</p><ol><li>RedoLog 和 BinLog 都是顺序写, 速率远大于随机写.</li><li>组提交机制, 大幅降低磁盘的 IOPS 消耗.</li></ol><h1 id="6-集群与高可用"><a href="#6-集群与高可用" class="headerlink" title="6. 集群与高可用"></a>6. 集群与高可用</h1><h2 id="6-1-通过-BinLog-保证主备一致"><a href="#6-1-通过-BinLog-保证主备一致" class="headerlink" title="6.1 通过 BinLog 保证主备一致"></a>6.1 通过 BinLog 保证主备一致</h2><p>在 MySQL 的高可用场景中, 最简单和常用的就是主备复制, 客户端的读写都直接访问主库, 而备库只负责将主库的更新同步到本地执行, 当主库出现问题的时候, 可以将主库下线, 并将备库立即提升为主库.</p><p>MySQL 是通过 BinLog 的同步完成主备的数据同步功能的.</p><p>在主备同步时, 备库与主库维持了一个长连接, 主库有一个单独的线程用于处理备库的长连接, 日志的同步过程如下:</p><ol><li>备库通过 <code>change master</code> 命令指定主库的 ip, 端口, 用户名, 密码以及请求 BinLog 的文件名和日志偏移量;</li><li>备库通过 <code>start slave</code> 命令启动两个线程: 负责与主库建立连接的 <code>io_thread</code> 和 负责复现数据的 <code>sql_thread</code>;</li><li>主库建立连接后, 会按照备库传来的位置从本地读取 BinLog 发给备库;</li><li>备库拿到 BinLog 后, 写入到本地文件, 成为中转日志(relay log);</li><li>sql_thread 读取中转日志, 解析出日志中的命令并执行.</li></ol><p><img src="https://user-images.githubusercontent.com/17758731/64351234-8a5d0080-d02c-11e9-9a54-2b59ec14a68e.png" alt="image"></p><h2 id="6-2-主从延迟的来源"><a href="#6-2-主从延迟的来源" class="headerlink" title="6.2 主从延迟的来源"></a>6.2 主从延迟的来源</h2><p>在主从复制中, 主要由三步构成:</p><ol><li>主库提交事务, 写入 BinLog;</li><li>从库获得 BinLog, 放入 RelayLog;</li><li>备库执行完成.</li></ol><p>在备库上可以执行 <code>show salve status</code> 命令, 返回结果中有 <code>seconds_behind_master</code>, 用于表示当前备库延迟多少秒, MySQL 会统计BinLog 中主库记录的时间域当前系统时间的差值.</p><p>在正常情况下, BinLog 传给备库的延迟很低, 主备延迟的主要来源是备库接收完 BinLog 和提交事务的时间. 本质上说, 是从库消费中转日志(RelayLog) 的速度比主库生产 BinLog 的速度要慢.</p><p>产生这种情况的原因:</p><ol><li>很多情况下从库性能低于主库</li><li>备库除了同步数据, 还需要处理其他请求</li><li>主库频繁执行大事务</li><li>备库的并行复制能力.</li></ol><p>主备切换的时候, 正常情况下应该采用可靠性优先策略:</p><ol><li>判断从库当前的 <code>second_behind_master</code>, 如果大于某个值(如 5s), 则等待并重试, 这一步是为了尽可能在从库压力不大的时候进行.</li><li>如果小于某阈值, 把主库改成只读状态;</li><li>循环判断从库的 <code>second_behind_master</code> 直到为 0, 代表主库所有内容都已经同步到从库中;</li><li>把从库改为可写状态;</li><li>把业务请求转移到从库.</li></ol><p>这种方案下, 在步骤 3~5 期间整个数据库系统对外不可写.</p><p>MySQL 的高可用是依赖于主从延迟的, 延迟时间越小在故障转移的时候服务恢复需要的时间就越短.</p><p>在某些短暂的大事务或者备份时, 对备库延迟的影响可能会到达分钟级, 但通常备库是可以跟上进度的, 但如果备库同步的是一个持续压力较高的主库, 延迟可能达到小时级甚至永远追不上来.</p><p>究其原因就是大部分情况下从库消费中转日志的速度都会低于主库处理写操作的能力.</p><ul><li>在主库上, 影响并发度最主要的因素就是锁, InnoDB 支持行锁, 因此除了大量并发事务更新同一行的极端情况, 大部分情况下并发度都不低.</li><li>但是备库在执行的时候, 不论是单线程还是多线程, 都有一定的局限性, 导致理论上执行的速度会低于主库写操作.</li></ul><p>在 MySQL 5.6 之前, 从库采用单线程复制, 因此速度低于主库比较好理解. 但后续版本 MySQL 开始采用多线程复制之后问题依然没有得到很好的解决:</p><p><img src="https://user-images.githubusercontent.com/17758731/64469708-5cc9a180-d169-11e9-8add-a6ec8a6c8cce.png" alt="image"></p><p>中转日志中的全部记录, 首先由 <code>Coordinator</code> 读取, 然后分发给不同的 worker 负责执行.</p><blockquote><p>主库的写操作是由客户端触发的, 在从库中, 想要把主库写操作完整的复现出来, 并不能简单的让 <code>Coordinator</code> 随机分给不同 <code>Worker</code>, 这中间存在一定的限制. 比如对同一条记录的两个写操作, 如果分给了两个 Worker, 由于 CPU 的调度策略不可控, 很可能会出现第二个写早于第一个完成这样会直接导致主备不一致.<br>此外, 同一个事务分别更新了两张表, 如果放在两个 worker 中, 在其中一个 worker 完成而另一个没有完成时, 主备会出现短暂的不一致.</p></blockquote><p>因此, 多线程消费 RelayLog 的时候, 需要保证如下行为:</p><ol><li>不能出现覆盖更新, 因此对同一个行的两个事务必须由同一个 worker 顺序执行</li><li>一个事务的所有操作都需要由同一个 worker 顺序执行</li></ol><h2 id="6-3-并行复制策略"><a href="#6-3-并行复制策略" class="headerlink" title="6.3 并行复制策略"></a>6.3 并行复制策略</h2><h3 id="MySQL-5-5"><a href="#MySQL-5-5" class="headerlink" title="MySQL 5.5"></a>MySQL 5.5</h3><p>在 MySQL 5.5 的时候, 由于官方没有提供并行复制的策略, 因此 <code>《MySQL 实战 45 讲》作者林晓斌</code> 自己实现了并行复制策略: </p><h4 id="按表分发"><a href="#按表分发" class="headerlink" title="按表分发"></a>按表分发</h4><p>如果两个事务更新的是不同的表, 就可以交给不同的 worker 完成, 按表分发可以保证两个 worker 不会冲突. 但如果有跨表的事务, 还是需要放在一起</p><p><img src="https://user-images.githubusercontent.com/17758731/64469953-bfbd3780-d16d-11e9-87b3-5715034596bd.png" alt="image"></p><p>上述方案中, 在每个 worker 中维护了一个 HashTable, key 是 <code>库名.表名</code>, value 是该 worker 当前有多少个事务正在执行. 当有事务分配给该 worker 时, 涉及的表会加到 HashTable 中, 执行完成后再去掉.</p><p>每个事务在分发的时候, 跟所有的 worker 冲突关系包括三种情况:</p><ol><li>和所有的 worker 都不冲突, coordinator 会分配给最空闲的 worker;</li><li>只和一个 worker 冲突, coordinator 必须分配给该 worker;</li><li>和多个 worker 冲突, coordinator 进入等待状态, 直到和这个事务存在冲突的 worker 只剩一个, 分配给该 worker</li></ol><p>该方案在不同表之间负载均匀的场景中效果最好. 但如果出现热点表, 那么大量事务就会被集中分配给某个 worker, 退化为单线程复制.</p><h4 id="按行分发"><a href="#按行分发" class="headerlink" title="按行分发"></a>按行分发</h4><p>该方案用来解决热点表并行复制的问题: 如果两个事务没有更新相同的行, 那么在备库上可以并行执行, 按行复制的前提是 BinLog 格式为 row. (否则无法知道具体更新的行) 此时判断是否冲突的标准是是否修改了同一行记录.</p><p>此时 worker 上的 HashTable 的 key 就变成了 <code>库名+表名+主键+所有唯一键</code> 因为涉及唯一键的更新也可能存在冲突, 比如主库中 r1 让出了某个唯一键的值, r2 将唯一键更新为 r1 的值, 如果在备库中交给两个 worker 执行, 可能顺序会被打乱, 就存在问题.</p><p>按行分发的并发度更高, 但是也更消耗内存和 CPU 资源, 因为每一行记录都会作为 HashTable 的一个 key.</p><h3 id="MySQL-5-6"><a href="#MySQL-5-6" class="headerlink" title="MySQL 5.6"></a>MySQL 5.6</h3><p>MySQL 官方开始支持并行复制, 但粒度只有库, 从实现上说就是以库名作为 HashTable 的 key.</p><p>如果MySQL 实例上的各个库负载均匀就会起到一定作用.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-MySQL-体系架构&quot;&gt;&lt;a href=&quot;#1-MySQL-体系架构&quot; class=&quot;headerlink&quot; title=&quot;1. MySQL 体系架构&quot;&gt;&lt;/a&gt;1. MySQL 体系架构&lt;/h1&gt;&lt;p&gt;MySQL 的架构整体上可以分为服务层和引擎层:&lt;/p&gt;
      
    
    </summary>
    
      <category term="MySQL" scheme="https://destinywang.github.io/blog/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://destinywang.github.io/blog/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Kafka简介</title>
    <link href="https://destinywang.github.io/blog/2019/07/27/Kafka%E7%AE%80%E4%BB%8B/"/>
    <id>https://destinywang.github.io/blog/2019/07/27/Kafka简介/</id>
    <published>2019-07-27T02:03:07.000Z</published>
    <updated>2019-07-31T13:53:39.403Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>Kafka 是一种分布式, 基于发布/订阅的消息系统, 具备高性能, 高可用, 可扩展, 可持久化的特点. 在设计上具有以下特点</p><ul><li>面对海量消息时也能高效读写, 以顺序的方式读写磁盘, 从而避免随机读写的性能瓶颈, 与此同时还支持批量读写和批量压缩</li><li>支持消息分区, 在每个分区内保证顺序, 不同分区间可以并发操作</li><li>每个分区可以创建多个副本, 只有 Leader 副本负责读写, 其他副本只负责同步</li></ul><p>Kafka 典型应用场景:</p><ul><li>传统消息中间件</li><li>系统数据总线</li><li>日志收集中心</li></ul><p>接入 Kafka 能够带来的优势:</p><ul><li>解耦, 以前彼此依赖的系统只需要和 Kafka 通信</li><li>数据持久化, Kafka 把数据以消息的形式持久化到磁盘, 并能按照一定的机制清理和压缩.</li><li>扩展, Kafka 的每个 Topic 多可以分为多个 Partition, 每个 Partition 都存在多个副本以实现冗余备份. 每个 Partition 中的消息不同, 类似 DB 的水平切分</li><li>容灾, 每个 Partition 中的不同 Replica 保存的是相同的副本, 一主多从, 从副本正常情况下只与主副本同步消息, 当主副本出现故障, 则在从副本中重新选举一个主副本对外提供服务.</li><li>灵活的 Consumer, Consumer 使用从服务端 Pull 的方式拉取消息, 并且保存消费的具体位置, 当消费者宕机恢复后, 根据 Consumer 的状态重新获取需要的消息.</li><li>顺序保证, Kafka 保证一个 Partition 内消息的有序性, 但是并不保证多个 Partition 之间数据有顺序.</li></ul><h2 id="1-2-Kafka-核心概念"><a href="#1-2-Kafka-核心概念" class="headerlink" title="1.2 Kafka 核心概念"></a>1.2 Kafka 核心概念</h2><h3 id="1-2-1-Topic-amp-Partition-amp-Log"><a href="#1-2-1-Topic-amp-Partition-amp-Log" class="headerlink" title="1.2.1 Topic &amp; Partition &amp; Log"></a>1.2.1 Topic &amp; Partition &amp; Log</h3><p>Topic 是用于存储消息的逻辑概念, 可以看做消息的集合</p><p><img src="https://user-images.githubusercontent.com/17758731/61991484-39e4a180-b083-11e9-9977-25ff3a9fe8a4.png" alt="image"></p><p>每个 Topic 可以划分成一个或多个 Partition, 同一 Topic 下的不同 Partition 包含的信息是不同的, 每个消息在被添加到 Partition 时都会被分配一个 offset, 这是在此 Partition 中的唯一编号, Kafka 通过 offset 保证消息在 Partition 内的顺序</p><p><img src="https://user-images.githubusercontent.com/17758731/61991556-664ced80-b084-11e9-8a10-2ea979e3c10b.png" alt="image"></p><p>Partition 在逻辑上对应着一个 Log, 当 Producer 将消息写入 Partition 时, 实际上写入到了 Partition 对应的 Log 中. Log 是一个逻辑概念, 可以对应到磁盘的文件夹, Log 由多个 Segment 组成, 每个 Segment 对应一个日志文件和索引. 在面对海量数据时, 为避免出现超大文件, 每个日志文件的大小是由限制的, 当超出是会创建新的 Segment 继续对外服务. Kafka 采用顺序 I/O, 因此只会向最新的 Segment 追加数据. 索引采用稀疏索引的方式, 在运行时会映射到内存以提高速度.</p><h3 id="1-2-2-保留策略-amp-日志压缩"><a href="#1-2-2-保留策略-amp-日志压缩" class="headerlink" title="1.2.2 保留策略 &amp; 日志压缩"></a>1.2.2 保留策略 &amp; 日志压缩</h3><p>不论消息是否已被消费, Kafka 都会将其保存, 与此同时提供了保留策略以进行周期性的清理.</p><ol><li>根据消息保留时间, 超过 TTL 的消息就可以被删除</li><li>根据 Topic 存储数据的大小, 当 Topic 所占的日志文件大于某个阈值, 就从最旧的消息开始删除.</li></ol><p>Kafka 还提供了日志压缩的功能, 原理上和 Redis 的 AOF 日志压缩相同, Kafka 会通过后台线程定期将相同 key 的消息进行合并, 只保留最新的值</p><h3 id="1-2-3-Broker"><a href="#1-2-3-Broker" class="headerlink" title="1.2.3 Broker"></a>1.2.3 Broker</h3><p>一个单独的 Kafka server 就是一个 Broker. Broker 的主要工作就是接收生产者发送的消息, 分配 offset, 保存在日志中. 同时接收消费者, 其他 Broker 的请求, 根据请求类型就行不同的处理和响应, 一般一个 Broker 独占一个节点.</p><h3 id="1-2-4-副本"><a href="#1-2-4-副本" class="headerlink" title="1.2.4 副本"></a>1.2.4 副本</h3><p>Kafka 对消息进行冗余备份, 每个 Partition 可以有多个副本, 每个副本中包含的消息是一样的. 每个 Partition 至少有一个副本(Leader), 多的副本为 Follower.</p><ul><li>Leader: 提供读写服务</li><li>Follower: 只从 Leader 副本处把数据同步到本地并更新自己的 Log</li></ul><p><img src="https://user-images.githubusercontent.com/17758731/61991793-0b1cfa00-b088-11e9-8165-e26df6112249.png" alt="image"></p><p>一般情况下, 每个 Partition 的多个副本会被分配到不同的 Broker 上.</p><h3 id="1-2-5-ISR-集合"><a href="#1-2-5-ISR-集合" class="headerlink" title="1.2.5 ISR 集合"></a>1.2.5 ISR 集合</h3><p>ISR(In-Sync Replica) 表示目前可用, 并且消息量与 Leader 相差不多的副本集合, 是整个副本集合的一个子集, 条件:</p><ol><li>副本所在节点必须维持与 zk 的连接</li><li>副本最后一条消息的 offset 与 leader 副本的最后一条消息的 offset 之间差值不能超过指定阈值</li></ol><p>每个 Partition 的 leader 副本都会维护当前 Partition 的 ISR 集合, 并且在不断处理请求的过程中, 这个集合是在不断变化的, 有的 Follower 会因为跟不上掉队, 有的 Follower 会重新回到 ISR 集合中.</p><h3 id="1-2-6-HW-amp-LEO"><a href="#1-2-6-HW-amp-LEO" class="headerlink" title="1.2.6 HW &amp; LEO"></a>1.2.6 HW &amp; LEO</h3><p>HW(HighWatermark) 和 LEO 与上面的 ISR 集合紧密相关, HW 标记了一个特殊的 offset, 当消费者处理消息的时候, 只能拉取到 HW 之前的消息, HW 之后消息对 Consumer 来说是不可见的. HW 由 Leader 维护, 当 ISR 集合中全部的 Follower 都拉取 HW 指定消息进行同步后, Leader 会递增 HW 的值, Kafka 将 HW 之前消息的状态定义为 <code>commit</code>, 代表已 commit 的消息即使 leader 宕机也不会丢失</p><p>LEO(Log End Offset) 是所有副本都会维护的 offset 标记, 它指向追加到当前副本的最后一个消息的 offset.</p><ul><li>当 Producer 向 Leader 副本追加消息的时候 Leader 副本的 LEO 会递增</li><li>当 Follower 从 Leader 副本拉取消息成功时, Follower 副本的 LEO 就递增</li></ul><blockquote><p>以一个例子总结下 HW 和 LEO 的关系</p><ol><li>Producer 向 Partition 推送消息</li><li>Leader 将消息成功追加到 Log 中, 并递增其 LEO</li><li>Follower 成功从 Leader 同步该消息</li><li>Follower 将该消息追加到本地 Log 中, 并递增其 LEO</li><li>当 ISR 集合中所有的副本都完成了对该消息的同步, Leader 会递增 HW, 此时该消息对消费者可见</li></ol></blockquote><p>Kafka 这样设计的目的是为了权衡同步和异步复制, 如果 Follower 延迟过高, 会被踢出 ISR 集合以保证性能; 当 Leader 宕机, 会优先将 ISR 中的 Follower 副本选举为新 Leader, 新 Leader 同样包含了 HW 之前的全部消息</p><h3 id="1-2-7-Cluster-amp-Controller"><a href="#1-2-7-Cluster-amp-Controller" class="headerlink" title="1.2.7 Cluster &amp; Controller"></a>1.2.7 Cluster &amp; Controller</h3><p>多个 Broker 可以组成一个 Cluster 对外提供服务, 每个 Cluster 会选举出一个 Broker 来担任 Controller 作为集群的指挥中心, 而其他的 Broker 则听从 Controller 指挥实现相应功能. Controller 负责管理分区的状态, 管理每个分区的副本状态, 监听 zk 中数据变化等. Controller 宕机会从剩下的 Broker 中进行重新选举.</p><h3 id="1-2-8-Produce-amp-Consumer"><a href="#1-2-8-Produce-amp-Consumer" class="headerlink" title="1.2.8 Produce &amp; Consumer"></a>1.2.8 Produce &amp; Consumer</h3><ul><li>生产者主要负责生产消息, 并将消息按照一定的规则推送到 Topic 的分区中, 其中规则可以是根据消息 key 的 hash 值选择, 或者轮询</li><li>消费者主要负责拉取消息, 并对消息进行消费, 每个消费者消费到 Partition 哪个 offset 的相关信息是由自己来维护的, 不同消费者管理各自的消费位置.</li></ul><h3 id="1-2-9-Consumer-Group"><a href="#1-2-9-Consumer-Group" class="headerlink" title="1.2.9 Consumer Group"></a>1.2.9 Consumer Group</h3><p>在 Kafka 中, 多个 Consumer 可以组成一个 Group, 一个 Consumer 只能属于一个 Group. Consumer Group 保证其订阅的 Topic 的每个 Partition 只能被分配给一个 Consumer. 一个 Topic 如果同时被多个 Consumer Group 订阅, 不同 Consumer Group 之间不会干扰. 如果想要实现一个消息被多个消费者同时消费的效果, 则每个消费者需要放入单独的 Consumer Group; 如果要实现一个消息只能被一个消费者独占, 则将所有的 Consumer 放入一个 Group 中.</p><p>简单来讲, 对于同一个 Consumer Group 中, 尽管有多个消费者, 但每个消息只会被消费一次.</p><p>此外, Consumer Group 还具有水平扩展和故障转移的功能.</p><p>当我们向一个 Consumer Group 添加新的 Consumer 时, 会触发 Rebalance 重新分配分区与消费者的对应关系. 而如果有 Consumer 故障, 也会触发 Rebalance 进行重新分区.</p><p><img src="https://user-images.githubusercontent.com/17758731/61992950-af5a6d00-b097-11e9-9347-2529d7c2e685.png" alt="image"></p><ol><li>生产者根据业务逻辑产生消息</li><li>生产者根据路由规则将消息发送到指定 Partition 的 Leader 副本所在的 Broker 上</li><li>Leader 将日志追加成功后, 递增 LEO</li><li>Follower 副本从 Leader 同步到消息, 追加成功后, 递增 LEO</li><li>Leader 递增 HW, 使该消息对消费者可见</li><li>消费者加入 Consumer Group 后, 会触发 Rebalance, 将 Partition 分配给不同的消费者消费</li><li>消费者恢复其消费位置, 并向 Kafka 服务端发送拉取消息的请求</li><li>Leader 副本会验证请求的 offset 以及其他相关的信息, 最后返回消息</li></ol><h2 id="1-2-Kafka-配置文件"><a href="#1-2-Kafka-配置文件" class="headerlink" title="1.2 Kafka 配置文件"></a>1.2 Kafka 配置文件</h2><p><code>config/server.properties</code> 是 Kafka 的主要配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">############################# Server Basics #############################</span><br><span class="line"></span><br><span class="line"># 每个 Broker 在集群中的唯一标识, 即使 Broker 的 IP 地址发生了变化, broker.id 只要没变则不会影响 consumers 的消息情况</span><br><span class="line">broker.id=0</span><br><span class="line"></span><br><span class="line">############################# Socket Server Settings #############################</span><br><span class="line"></span><br><span class="line"># Kafka Server 使用的协议, 主机名及网络端口格式如下:</span><br><span class="line">#     listeners = security_protocol://host_name:port</span><br><span class="line">#   参考实例:</span><br><span class="line">#     listeners = PLAINTEXT://your.host.name:9092</span><br><span class="line">#listeners=PLAINTEXT://:9092 这是默认配置, 使用 PLAINTEXT, 端口是 9092</span><br><span class="line"></span><br><span class="line"># 接收请求的线程数</span><br><span class="line">num.network.threads=3</span><br><span class="line"></span><br><span class="line"># 执行请求的线程数</span><br><span class="line">num.io.threads=8</span><br><span class="line"></span><br><span class="line"># The send buffer (SO_SNDBUF) used by the socket server</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"></span><br><span class="line"># The receive buffer (SO_RCVBUF) used by the socket server</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"></span><br><span class="line"># The maximum size of a request that the socket server will accept (protection against OOM)</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">############################# Log Basics #############################</span><br><span class="line"></span><br><span class="line"># 用于存储 log 文件的目录, 可以将多个目录通过逗号分隔, 形成一个目录列表</span><br><span class="line">log.dirs=/tmp/kafka-logs</span><br><span class="line"></span><br><span class="line"># 每个 Topic 默认的 Partition 数</span><br><span class="line">num.partitions=1</span><br><span class="line"></span><br><span class="line"># 用来恢复 log 文件以及关闭是将 log 数刷新到磁盘的线程数量, 每个目录都对应该配置</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"></span><br><span class="line">############################# Log Flush Policy #############################</span><br><span class="line"># 每隔多少个消息触发一次 flush 操作, 将内存中的信息刷新到硬盘上</span><br><span class="line">#log.flush.interval.messages=10000</span><br><span class="line"></span><br><span class="line"># 每隔多少毫秒触发一次 flush 操作, 将内存中的信息刷新到硬盘上</span><br><span class="line">#log.flush.interval.ms=1000</span><br><span class="line"></span><br><span class="line">############################# Log Retention Policy #############################</span><br><span class="line"></span><br><span class="line"># The following configurations control the disposal of log segments. The policy can</span><br><span class="line"># be set to delete segments after a period of time, or after a given size has accumulated.</span><br><span class="line"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span><br><span class="line"># from the end of the log.</span><br><span class="line"></span><br><span class="line"># The minimum age of a log file to be eligible for deletion</span><br><span class="line">log.retention.hours=168</span><br><span class="line"></span><br><span class="line"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span><br><span class="line"># segments don&apos;t drop below log.retention.bytes.</span><br><span class="line">#log.retention.bytes=1073741824</span><br><span class="line"></span><br><span class="line"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"></span><br><span class="line"># The interval at which log segments are checked to see if they can be deleted according</span><br><span class="line"># to the retention policies</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"></span><br><span class="line">############################# Zookeeper #############################</span><br><span class="line"></span><br><span class="line"># Zookeeper connection string (see zookeeper docs for details).</span><br><span class="line"># This is a comma separated host:port pairs, each corresponding to a zk</span><br><span class="line"># server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.</span><br><span class="line"># You can also append an optional chroot string to the urls to specify the</span><br><span class="line"># root directory for all kafka znodes.</span><br><span class="line">zookeeper.connect=localhost:2181</span><br><span class="line"></span><br><span class="line"># Timeout in ms for connecting to zookeeper</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h1&gt;&lt;p&gt;Kafka 是一种分布式, 基于发布/订阅的消息系统, 具备高性能, 高可用, 可扩展, 可持久化的特点. 在设计上具有
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何高效使用Vim</title>
    <link href="https://destinywang.github.io/blog/2019/06/19/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8Vim/"/>
    <id>https://destinywang.github.io/blog/2019/06/19/如何高效使用Vim/</id>
    <published>2019-06-19T14:18:17.000Z</published>
    <updated>2019-06-22T13:25:06.074Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><h1 id="2-基本使用方式"><a href="#2-基本使用方式" class="headerlink" title="2. 基本使用方式"></a>2. 基本使用方式</h1><h2 id="2-1-vim-的模式"><a href="#2-1-vim-的模式" class="headerlink" title="2.1 vim 的模式"></a>2.1 vim 的模式</h2><p>当我们使用 <code>vim</code>, 或在后面加文件名的时候, 就可以进入 vim 的界面</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/Desktop</span><br><span class="line">$ vim demo.txt</span><br></pre></td></tr></table></figure><p>该命令就会在 ~/Desktop 路径下打开(如果有)或编辑(如果没有) <code>demo.txt</code> 文件</p><p>最初进入 vim 时是普通模式, vim 的特点之一就是可以通过不同的操作快速进入多种模式:</p><ul><li>普通模式: 进入 vim 默认的模式, 该模式有非常多的快捷键组合, 无法进行输入, 如果想编辑, 需要进入写入模式.</li><li>写入模式: 由命令模式进入, 最简单的方式通过在普通模式下输入小写 <code>i</code> 来完成(后面会介绍更多的方式), 进入写入模式后, 终端的左下角会出现 <code>-- INSERT --</code> 标志, 该模式下字母, 数字, 字符键都可以正常完成输入功能, 写入模式可以通过 <code>esc</code> 退出并回到普通模式.</li><li>命令模式: 所有的 vim 指令都需要进入由普通模式输入 <code>:</code> 进入命令模式完成, 常见的指令包括保存(w), 退出(q)等</li></ul><p>此外, 普通模式进入写入模式除了 <code>i</code> 之外, 还有其他几种方式, 不同方式之间的区别在于进入插入模式时光标的位置:</p><table><thead><tr><th style="text-align:center">输入</th><th style="text-align:center">全称</th><th style="text-align:center">光标的位置</th></tr></thead><tbody><tr><td style="text-align:center">i</td><td style="text-align:center">insert</td><td style="text-align:center">与普通模式相同</td></tr><tr><td style="text-align:center">I</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">a</td><td style="text-align:center">append</td><td style="text-align:center">普通模式光标的下一个字符</td></tr><tr><td style="text-align:center">A</td><td style="text-align:center"></td><td style="text-align:center">普通模式光标所在行的结尾</td></tr><tr><td style="text-align:center">o</td><td style="text-align:center"></td><td style="text-align:center">普通模式光标所在行的下一行开出一个新行, 并把光标移动到新行的行首</td></tr><tr><td style="text-align:center">O</td><td style="text-align:center"></td><td style="text-align:center">普通模式光标所在行的上一行开出一个新行, 并把光标移动到新行的行首</td></tr></tbody></table><h2 id="2-2-vim-光标移动"><a href="#2-2-vim-光标移动" class="headerlink" title="2.2 vim 光标移动"></a>2.2 vim 光标移动</h2><table><thead><tr><th style="text-align:center">按键</th><th style="text-align:center">操作</th></tr></thead><tbody><tr><td style="text-align:center">h</td><td style="text-align:center">光标向左</td></tr><tr><td style="text-align:center">j</td><td style="text-align:center">光标向下</td></tr><tr><td style="text-align:center">k</td><td style="text-align:center">光标向上</td></tr><tr><td style="text-align:center">l</td><td style="text-align:center">光标向右</td></tr></tbody></table><h1 id="3-vim-配置文件"><a href="#3-vim-配置文件" class="headerlink" title="3. vim 配置文件"></a>3. vim 配置文件</h1><p>vim 配置文件可以修改 vim 界面的外观, 组合按键等</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~</span><br><span class="line"><span class="comment"># 新建一个 .vim 文件夹</span></span><br><span class="line">$ mkdir .vim</span><br><span class="line">$ <span class="built_in">cd</span> .vim</span><br><span class="line"><span class="comment"># 新建一个 vimrc 文件</span></span><br><span class="line">$ vim vimrc</span><br></pre></td></tr></table></figure><p>开始进行配置:</p><pre><code>noremap 是一个更改键位的命令e.g. noremap a b当该配置生效后, 如果用户按下 a 键之后, vim 就会认为按的是 b</code></pre><p>我们需要替换的键位<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">map s &lt;nop&gt;     <span class="comment"># 禁用 s 键</span></span><br><span class="line">map S :w&lt;CR&gt;    <span class="comment"># 用 S 替换 vim 中的 `:+w+回车` 的保存功能</span></span><br><span class="line">map Q :q&lt;CR&gt;    <span class="comment"># 用 Q 替换 vim 中的 `:+q+回车` 的退出功能</span></span><br><span class="line">map R :<span class="built_in">source</span> <span class="variable">$MYVIMRC</span>&lt;CR&gt; <span class="comment"># 用 R 键替换 source 当前 vimrc 文件</span></span><br></pre></td></tr></table></figure></p><h2 id="3-1-配置-vim-的编辑器"><a href="#3-1-配置-vim-的编辑器" class="headerlink" title="3.1 配置 vim 的编辑器"></a>3.1 配置 vim 的编辑器</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">syntax on       <span class="comment"># 开启语法高亮</span></span><br><span class="line"><span class="built_in">set</span> nu          <span class="comment"># 开启行号</span></span><br></pre></td></tr></table></figure><h3 id="3-1-1-set-relativenumber-开启真实行号"><a href="#3-1-1-set-relativenumber-开启真实行号" class="headerlink" title="3.1.1 set relativenumber 开启真实行号"></a>3.1.1 set relativenumber 开启真实行号</h3><p>该配置生效之后, 行号会分两列展示, 第一列用于展示真正的行号, 第二列用于展示其他行相对当前行的距离</p><p><img src="https://user-images.githubusercontent.com/17758731/59780134-1db74d00-92ec-11e9-8132-b0faf511498b.png" alt="image"></p><h3 id="3-1-2-set-cursorline-开启当前行高亮线"><a href="#3-1-2-set-cursorline-开启当前行高亮线" class="headerlink" title="3.1.2 set cursorline 开启当前行高亮线"></a>3.1.2 set cursorline 开启当前行高亮线</h3><p><img src="https://user-images.githubusercontent.com/17758731/59780278-5a834400-92ec-11e9-9b6b-92e9657ce20d.png" alt="image"></p><h3 id="3-1-3-set-wrap-开启自动换行"><a href="#3-1-3-set-wrap-开启自动换行" class="headerlink" title="3.1.3 set wrap 开启自动换行"></a>3.1.3 set wrap 开启自动换行</h3><h3 id="3-1-4-set-showcmd-右下角显示执行的命令"><a href="#3-1-4-set-showcmd-右下角显示执行的命令" class="headerlink" title="3.1.4 set showcmd 右下角显示执行的命令"></a>3.1.4 set showcmd 右下角显示执行的命令</h3><h3 id="3-1-5-set-wildmenu-命令模式下的提示"><a href="#3-1-5-set-wildmenu-命令模式下的提示" class="headerlink" title="3.1.5 set wildmenu 命令模式下的提示"></a>3.1.5 set wildmenu 命令模式下的提示</h3><p>使用 <code>:</code> 进入命令模式, 输入 so 时, 敲 tab 会给出提示: <code>sort</code> 和 <code>source</code></p><p><img src="https://user-images.githubusercontent.com/17758731/59780689-fa40d200-92ec-11e9-96f5-da33eb7cf952.png" alt="image"></p><h2 id="3-2-vim-的编辑操作"><a href="#3-2-vim-的编辑操作" class="headerlink" title="3.2 vim 的编辑操作"></a>3.2 vim 的编辑操作</h2><p>vim 下的编辑操作通常由 <code>操作</code> 和 <code>动作</code> 组成</p><h3 id="3-2-1-常见操作"><a href="#3-2-1-常见操作" class="headerlink" title="3.2.1 常见操作"></a>3.2.1 常见操作</h3><h4 id="3-2-1-1-删除"><a href="#3-2-1-1-删除" class="headerlink" title="3.2.1.1 删除"></a>3.2.1.1 删除</h4><p>假设有如下内容, 我们需要删除中间的空格, 有如下几种方式</p><pre><code>&lt;optration&gt; &lt;motion&gt;</code></pre><p>总的来说, 编辑指令的语法类似于动宾短语, 操作一般是动词, 如复制, 删除等, 动作一般为宾语, 代表执行操作的字符.</p><p>下面来分别介绍一下常见的操作和动作</p><ol><li>在普通模式下将光标移动到空格后的 <code>&lt;</code> 然后输入 <code>x</code> 将光标的前一个字符删除.</li><li>在普通模式下输入 <code>d</code>, <code>d</code> 代表 delete, 提供了多种选项:<ol><li><code>d</code> + <code>←</code>(方向键左), 代表向左删除一个字符</li><li><code>d</code> + <code>3</code> + <code>→</code>(方向键右), 代表向右删除三个字符</li><li><code>d</code> + <code>d</code>, 代表对整行执行删除操作(实际上大多数操作都遵循双击代表针对行的规律)</li></ol></li></ol><h4 id="3-2-1-2-粘贴"><a href="#3-2-1-2-粘贴" class="headerlink" title="3.2.1.2 粘贴"></a>3.2.1.2 粘贴</h4><p><code>p</code>, 代表 paste, 可以用来粘贴被复制或剪切的字符</p><h4 id="3-2-1-4-复制"><a href="#3-2-1-4-复制" class="headerlink" title="3.2.1.4 复制"></a>3.2.1.4 复制</h4><p><code>y</code>, 代表 copy, 可以用来复制选中的字符</p><blockquote><ol><li><code>y</code> + <code>→</code>, 代表向右复制一个字符</li><li><code>y</code> + <code>3</code> + <code>→</code>, 代表向右复制三个字符</li></ol></blockquote><h4 id="3-2-1-5-改变-c"><a href="#3-2-1-5-改变-c" class="headerlink" title="3.2.1.5 改变(c)"></a>3.2.1.5 改变(c)</h4><p><code>c</code>, 代表 change, 与 <code>d</code> 操作相似, 不同的是完成了删除操作之后, 会自动进入编辑模式</p><blockquote><ol><li><code>c</code> + <code>→</code> + <code>6</code>, 代表删除光标右边的 6 个字符, 并进入编辑模式</li></ol></blockquote><h3 id="3-2-2-常见动作"><a href="#3-2-2-常见动作" class="headerlink" title="3.2.2 常见动作"></a>3.2.2 常见动作</h3><p>最常见的动作就是上下左右, 除此之外还有一些快捷动作.</p><h4 id="3-2-2-1-移动到下个单词-w"><a href="#3-2-2-1-移动到下个单词-w" class="headerlink" title="3.2.2.1 移动到下个单词(w)"></a>3.2.2.1 移动到下个单词(w)</h4><p>假设有如下字符</p><pre><code>I am Happy Today.^</code></pre><p>此时光标在 I 上, 如果在普通模式下按 <code>w</code>, 光标会移动到 <code>am</code> 的首字母 <code>a</code>, 以此类推, 每次都会让光标移动到下一个单词的首字母</p><p>假设我们想将上例中的 <code>Happy</code> 修改为 <code>excited</code>, 可以进行如下操作:</p><blockquote><p>将光标移动到 <code>Happy</code> 的首字母 h, 然后使用 <code>c</code> + <code>w</code>, 就可以将该词删除, 并且进入编辑模式, 然后输入 excited 即可.</p></blockquote><h4 id="3-2-2-2-移动到当前单词的首字母-b"><a href="#3-2-2-2-移动到当前单词的首字母-b" class="headerlink" title="3.2.2.2 移动到当前单词的首字母(b)"></a>3.2.2.2 移动到当前单词的首字母(b)</h4><p><code>b</code>, 代表 back, 可以将光标移动到当前单词的首字母位置</p><p>同样, 通过该动作就可以在 happy 的任意一个字符快速移动到首字母, 并完成删除操作</p><h4 id="3-2-2-3-范围-i"><a href="#3-2-2-3-范围-i" class="headerlink" title="3.2.2.3 范围(i)"></a>3.2.2.3 范围(i)</h4><p><code>i</code>, 代表 in, 表示选中在某个范围内的全部字符</p><blockquote><ol><li><code>c</code> + <code>i</code> + <code>w</code> 表示将当前光标所在单词范围内的全部字符替换  </li><li><code>y</code> + <code>i</code> + <code>w</code> 表示将当前光标所在单词范围内的全部字符复制</li><li><code>c</code> + <code>i</code> + <code>&quot;</code> 表示将当前光标所在引号范围的全部字符替换</li></ol></blockquote><h4 id="3-2-2-4-查找-f"><a href="#3-2-2-4-查找-f" class="headerlink" title="3.2.2.4 查找 (f)"></a>3.2.2.4 查找 (f)</h4><p><code>f</code>, 代表 find, 会将光标移动到第一个相同的字符</p><blockquote><ol><li><code>f</code> + <code>v</code>, 代表将光标向后移动到第一个 v 所在的位置s</li><li><code>d</code> + <code>f</code> + <code>:</code>, 代表 <code>删除+寻找+:</code> 从光标所在字符开始, 一直删除到其后的第一个 <code>:</code></li></ol></blockquote><h1 id="4-搜索"><a href="#4-搜索" class="headerlink" title="4 搜索"></a>4 搜索</h1><h2 id="4-1-搜索方式"><a href="#4-1-搜索方式" class="headerlink" title="4.1 搜索方式"></a>4.1 搜索方式</h2><p>vim 下的搜索主要分为两种方式:</p><ol><li>从上向下搜索(快捷键 <code>/</code>)</li><li>从下向上搜索(快捷键 <code>?</code>)</li></ol><p>两种操作的相同之处都是会以光标作为查询的起点, 向上/向下进行搜索</p><p>将搜索内容高亮的设置:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hlsearch        # 将搜索结果高亮</span><br><span class="line"><span class="keyword">set</span> incsearch       # 将搜索内容即时高亮</span><br><span class="line"><span class="keyword">set</span> ignorecase      # 忽略大小写</span><br><span class="line"><span class="keyword">set</span> smartcase       # 开启智能拼写</span><br><span class="line">exec <span class="string">"nohlsearch"</span>   # 搜索结果的高亮会在下次进入 <span class="keyword">vim</span> 是继续保留, 因此可以先执行该命令清除</span><br><span class="line"><span class="keyword">noremap</span> <span class="symbol">&lt;LEADER&gt;</span><span class="symbol">&lt;CR&gt;</span> :<span class="keyword">nohlsearch</span><span class="symbol">&lt;CR&gt;</span>    # 执行完搜索之后, 高亮会一直保留, 比较影响视线, 因此使用 `LEADER`(默认为 \ 键) + 回车执行 <span class="keyword">nohlsearch</span> 命令, 取消高亮</span><br></pre></td></tr></table></figure><p>在 vim 的搜索模式下, 模式使用 <code>n</code> 进行下一项的搜索, <code>N</code> 进行上一项的搜索, 可以配合 <code>zz</code> (将光标所在行移动到屏幕中间)</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">noremap</span> n nzz</span><br><span class="line"><span class="keyword">noremap</span> <span class="keyword">N</span> Nzz</span><br></pre></td></tr></table></figure><h1 id="5-美化-vim-界面"><a href="#5-美化-vim-界面" class="headerlink" title="5 美化 vim 界面"></a>5 美化 vim 界面</h1><h2 id="5-1-使用自带美化方案"><a href="#5-1-使用自带美化方案" class="headerlink" title="5.1 使用自带美化方案"></a>5.1 使用自带美化方案</h2><p>方式是在命令模式下输入 <code>color</code> + <code>空格</code> + <code>tab</code> 键, 接下来就会提示可以用的美化方案</p><p><img src="https://user-images.githubusercontent.com/17758731/59963846-5133ea80-952b-11e9-892f-82dcfca165ec.png" alt="image"></p><h2 id="5-2-自定义美化方案"><a href="#5-2-自定义美化方案" class="headerlink" title="5.2 自定义美化方案"></a>5.2 自定义美化方案</h2><p>但如果系统自带的美化方案不能满足需求, 就可以下载其他美化方案</p><p><a href="https://github.com/junegunn/vim-plug" target="_blank" rel="noopener">vim 插件管理</a></p><h3 id="5-2-1-下载"><a href="#5-2-1-下载" class="headerlink" title="5.2.1 下载"></a>5.2.1 下载</h3><p>使用下面的命令进行下载<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -fLo ~/.vim/<span class="built_in">autoload</span>/plug.vim --create-dirs \</span><br><span class="line">    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim</span><br></pre></td></tr></table></figure></p><h3 id="5-2-2-安装插件"><a href="#5-2-2-安装插件" class="headerlink" title="5.2.2 安装插件"></a>5.2.2 安装插件</h3><p>在 <code>~/.vimrc</code> 中, 以下文开头</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">call</span> plug#begin(<span class="string">'~/.vim/plugged'</span>)</span><br></pre></td></tr></table></figure><p>然后安装的语法格式为:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Plug <span class="string">''</span>     # 引号内为想装的插件</span><br></pre></td></tr></table></figure><p>最后使用下文结束安装</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">call</span> plug#end()</span><br></pre></td></tr></table></figure><p>将 <code>~/.vimrc</code> source 之后, <code>:</code> 进入命令模式, 输入 PlugInstall 命令开始安装指定插件</p><p><img src="https://user-images.githubusercontent.com/17758731/59964057-11bacd80-952e-11e9-98c9-93129ba662d7.png" alt="image"></p><h3 id="5-2-3-推荐的插件"><a href="#5-2-3-推荐的插件" class="headerlink" title="5.2.3 推荐的插件"></a>5.2.3 推荐的插件</h3><h4 id="5-2-3-1-vim-airline"><a href="#5-2-3-1-vim-airline" class="headerlink" title="5.2.3.1 vim-airline"></a>5.2.3.1 vim-airline</h4><p>会在 vim 底部展示状态栏</p><p><img src="https://user-images.githubusercontent.com/17758731/59964076-66f6df00-952e-11e9-82ea-553f6be1517b.png" alt="image"></p><p>包括文件路径, 编码格式以及进度条等.</p><h4 id="5-2-3-2-connorholyday-vim-snazzy"><a href="#5-2-3-2-connorholyday-vim-snazzy" class="headerlink" title="5.2.3.2 connorholyday/vim-snazzy"></a>5.2.3.2 connorholyday/vim-snazzy</h4><p>加入 <code>connorholyday/vim-snazzy</code> 并 PlugInstall 之后, 在配置文件之后再添加如下配置</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">colorscheme</span> snazzy</span><br></pre></td></tr></table></figure><p>最后 source 即可生效, 效果如图</p><p><img src="https://user-images.githubusercontent.com/17758731/59964448-644ab880-9533-11e9-8806-5ed12e3695e7.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;h1 id=&quot;2-基本使用方式&quot;&gt;&lt;a href=&quot;#2-基本使用方式&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hadoop基础</title>
    <link href="https://destinywang.github.io/blog/2019/04/21/Hadoop%E5%9F%BA%E7%A1%80/"/>
    <id>https://destinywang.github.io/blog/2019/04/21/Hadoop基础/</id>
    <published>2019-04-21T02:45:06.000Z</published>
    <updated>2019-07-27T01:55:57.663Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><h1 id="2-Hadoop-安装"><a href="#2-Hadoop-安装" class="headerlink" title="2. Hadoop 安装"></a>2. Hadoop 安装</h1><h2 id="2-1-JDK-安装配置"><a href="#2-1-JDK-安装配置" class="headerlink" title="2.1 JDK 安装配置"></a>2.1 JDK 安装配置</h2><p>可以在 Oracle 官网或者直接使用 wget 命令下载</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate --no-cookies --header <span class="string">"Cookie: oraclelicense=accept-securebackup-cookie"</span> http://download.oracle.com/otn-pub/java/jdk/8u65-b17/jdk-8u65-linux-x64.tar.gz</span><br></pre></td></tr></table></figure><p>使用 <code>tar -zxvf</code> 完成解压</p><p><img src="https://user-images.githubusercontent.com/17758731/56851599-89f87e80-6943-11e9-8b32-2453360ffef9.png" alt="image"></p><p>再将路径 (<code>/usr/soft/jdk1.8.0_65</code>) 配置到 <code>etc/enviroment</code> 路径下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 给 path 新增 JDK 的 bin 路径</span><br><span class="line">PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/soft/jdk1.8.0_65/bin&quot;</span><br><span class="line"></span><br><span class="line"># jdk 路径</span><br><span class="line">JAVA_HOME=/usr/soft/jdk1.8.0_65</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/17758731/56851719-ef993a80-6944-11e9-93ab-bc181fe1c5ee.png" alt="image"></p><p>经此验证, 已经成功安装并配置 JDK</p><h2 id="2-2-Hadoop-安装配置"><a href="#2-2-Hadoop-安装配置" class="headerlink" title="2.2 Hadoop 安装配置"></a>2.2 Hadoop 安装配置</h2><p>在 Apache 官网下载压缩包并解压:</p><p><img src="https://user-images.githubusercontent.com/17758731/56866098-2b490880-6a08-11e9-8e16-29f651ccc7a3.png" alt="image"></p><p>在 <code>/etc/enviroment</code> 文件中配置环境变量</p><pre><code>PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/soft/jdk1.8.0_65/bin:/usr/soft/hadoop-2.7.7/bin:/usr/soft/hadoop-2.7.7/sbin&quot;JAVA_HOME=/usr/soft/jdk1.8.0_65HADOOP_INSTALL=/usr/soft/hadoop-2.7.7</code></pre><p>在输入 <code>hadoop version</code> 即可看到输出:</p><pre><code>destiny@destiny-Parallels-Virtual-Platform:/etc$ hadoop versionHadoop 2.7.7Subversion Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3acCompiled by stevel on 2018-07-18T22:47ZCompiled with protoc 2.5.0From source with checksum 792e15d20b12c74bd6f19a1fb886490This command was run using /usr/soft/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jardestiny@destiny-Parallels-Virtual-Platform:/etc$ </code></pre><p><img src="https://user-images.githubusercontent.com/17758731/56866210-4c5e2900-6a09-11e9-8587-949e514572eb.png" alt="image"></p><h1 id="3-Hadoop-配置"><a href="#3-Hadoop-配置" class="headerlink" title="3. Hadoop 配置"></a>3. Hadoop 配置</h1><p>Hadoop 的配置都是 XML 文件的方式完成, 通用配置都在 <code>core-site.xml</code> 中, HDFS, MapReduce 和 YARN 都有对应的 <code>hdfs-site.xml</code>, <code>mapred-site.xml</code> 以及 <code>yarn-site.xml</code>.</p><p>Hadoop 的设计的目的在于处理海量数据, 其主要内容包括数据的存储以及运算, 存储使用 HDFS 实现, 运算使用 MapReduce 编程模型实现.</p><p>Hadoop 有三种配置方式:</p><ol><li>独立模式: 没有守护程序, 所有程序都运行在一个单独的 JVM 之上, 独立模式适合在开发期间运行 MapReduce 程序, 方便调试和测试.</li><li>伪分布式: Hadoop 守护程序运行在本地机器上, 会模拟一个小规模的集群.</li><li>完全分布式: 运行在集群的不同机器上.</li></ol><p>当需要运行某个模式的 Hadoop 时, 需要设置适当的配置, 以及启动守护进程(独立模式除外), 不同模式见的配置如下:</p><table><thead><tr><th style="text-align:center">配置文件</th><th style="text-align:center">属性</th><th style="text-align:center">独立模式值</th><th style="text-align:center">伪分布式值</th><th style="text-align:center">完全分布式值</th></tr></thead><tbody><tr><td style="text-align:center">core</td><td style="text-align:center">fs.defaultFS</td><td style="text-align:center">file:///(默认值)</td><td style="text-align:center">hdfs://localhost/</td><td style="text-align:center">hdfs://namenode</td></tr><tr><td style="text-align:center">HDFS</td><td style="text-align:center">dfs.replication</td><td style="text-align:center">N/A</td><td style="text-align:center">1</td><td style="text-align:center">3(默认值)</td></tr><tr><td style="text-align:center">MapReduce</td><td style="text-align:center">mapreduce.framework.name</td><td style="text-align:center">local(默认值)</td><td style="text-align:center">yarn</td><td style="text-align:center">yarn</td></tr><tr><td style="text-align:center">yarn</td><td style="text-align:center">yarn.resourcemanager.hostname<br>yarn.nodemanager.aux-services</td><td style="text-align:center">N/A<br>N/A</td><td style="text-align:center">localhost <br> mapreduce_shuffle</td><td style="text-align:center">resourcemanager <br> mapreduce_shuffle</td></tr></tbody></table><p>此外, Hadoop 的不同配置模式见可以共存, 只需用不同的目录存放配置文件即可, 启动的时候可以通过如下两种方式来指定配置文件:</p><ol><li>设置 <code>HADOOP_CONF_DIR</code> 环境变量</li><li>通过 <code>--config</code> 选项来指定</li></ol><h2 id="3-1-独立模式"><a href="#3-1-独立模式" class="headerlink" title="3.1 独立模式"></a>3.1 独立模式</h2><p>在独立模式下不需要进行额外的配置, 所有默认的属性都是针对独立模式的, 也没有守护程序运行, 独立模式下使用的文件系统是 <code>Local File System</code> 和 <code>Local MR job runner</code>.</p><p><img src="https://user-images.githubusercontent.com/17758731/56866418-6d277e00-6a0b-11e9-9e87-832ec82a11f6.png" alt="image"></p><p>可以看到, 独立模式下使用 <code>hadoop fs -ls</code> 显示的就是本机的根路径文件</p><h2 id="3-2-伪分布式"><a href="#3-2-伪分布式" class="headerlink" title="3.2 伪分布式"></a>3.2 伪分布式</h2><h3 id="3-2-1-配置文件"><a href="#3-2-1-配置文件" class="headerlink" title="3.2.1 配置文件"></a>3.2.1 配置文件</h3><p>在伪分布式环境下, 需要配置如下文件:</p><ol><li><p>core-site.xml(核心站点)</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>hdfs-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>mapred-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- yarn 是一个 MapReduce 框架, 2.0 版本以上开始引入 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><p>初始状态下, 这些配置文件中都是空值, 需要根据使用者的自身情况去配置以完成不同环境的搭建.</p><p><img src="https://user-images.githubusercontent.com/17758731/56905677-3cab1700-6ad3-11e9-93bf-b7274eca76ca.png" alt="image"></p><p>我们将 <code>$HADOOP_INSTALL/etc/hadoop</code> 文件夹拷贝一份, 用作伪分布式的配置</p><p><img src="https://user-images.githubusercontent.com/17758731/56906117-2baed580-6ad4-11e9-98b3-f0b1a8b24d94.png" alt="image"></p><p>然后依次将上文提到的四个配置文件修改成指定的配置方式</p><h3 id="3-2-2-配置-SSH"><a href="#3-2-2-配置-SSH" class="headerlink" title="3.2.2 配置 SSH"></a>3.2.2 配置 SSH</h3><p>在伪分布式下, 必须要启动守护进程, 启动守护进程就需要使用提供的启动脚本, Hadoop 并不严格区分伪分布式和完全分布式, 只是在目标主机上启动守护进程, 通过 SSH 命令让主机之间相互通信, 而且要启动守护进程. </p><p>伪分布式只是完全分布式的一个特例, 是一个在单个主机上运行 Hadoop 完全分布式的场景, 因此我们需要确保能够通过 SSH 命令登录本机, 而不需要通过输入密码.</p><p>在 ubuntu 上可以通过 <code>sudo apt-get install ssh</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install ssh                  <span class="comment"># 安装 ssh</span></span><br><span class="line">$ ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa  <span class="comment"># 生成公钥和私钥, -P '' 代表指定密码为空</span></span><br><span class="line">$ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys  <span class="comment"># 将公钥配置给 authorized_keys, 用来实现免密登陆</span></span><br><span class="line">$ ssh localhost                             <span class="comment"># 第一次yes</span></span><br><span class="line">$ yes</span><br><span class="line">$ ssh localhost                             <span class="comment"># 第二次不需要口令</span></span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/17758731/56973756-0f786a80-6ba0-11e9-852e-47688237b2be.png" alt="image"></p><h3 id="3-2-3-使用-HDFS"><a href="#3-2-3-使用-HDFS" class="headerlink" title="3.2.3 使用 HDFS"></a>3.2.3 使用 HDFS</h3><p>首先需要对文件系统进行格式化</p><pre><code>hdfs namenode -format</code></pre><p>然后就可以启动守护进程</p><h4 id="3-2-3-1-启动"><a href="#3-2-3-1-启动" class="headerlink" title="3.2.3.1 启动"></a>3.2.3.1 启动</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># </span></span><br><span class="line">start-dfs.sh --config <span class="variable">$HADOOP_INSTALL</span>/etc/hadoop_pseudo</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/17758731/56974348-426f2e00-6ba1-11e9-9de9-8927285be487.png" alt="image"></p><h4 id="3-2-3-2-启动-yarn"><a href="#3-2-3-2-启动-yarn" class="headerlink" title="3.2.3.2 启动 yarn"></a>3.2.3.2 启动 yarn</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># </span></span><br><span class="line">start-yarn.sh --config <span class="variable">$HADOOP_INSTALL</span>/etc/hadoop_pseudo</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/17758731/56974786-1a33ff00-6ba2-11e9-9575-a52c554de287.png" alt="image"></p><p>此时可以通过 jps 查看:</p><p><img src="https://user-images.githubusercontent.com/17758731/56975718-f83b7c00-6ba3-11e9-8880-1c968d4d8dbd.png" alt="image"></p><ul><li>其中 ResourceManager 和 NodeManager 由 Yarn 提供</li><li>NameNode, DataNode, SecondaryNameNode 由 HDFS 提供</li></ul><p>可以使用如下命令停止 Hadoop<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop-yarn.sh</span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure></p><p>通过设置环境变量, 可以不再需要借助 –config</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/soft/hadoop-2.7.7/etc/hadoop_pseudo</span><br></pre></td></tr></table></figure><p>此时再使用 <code>hadoop fs -ls /</code> 就已经没有结果显示</p><p>我们可以像使用 Linux 系统类似的命令去操作 HDFS, 下图展示一个创建文件夹的操作</p><p><img src="https://user-images.githubusercontent.com/17758731/56976335-50bf4900-6ba5-11e9-9f11-61b04f473601.png" alt="image"></p><h2 id="3-3-完全分布式"><a href="#3-3-完全分布式" class="headerlink" title="3.3 完全分布式"></a>3.3 完全分布式</h2><h3 id="3-3-1-准备工作"><a href="#3-3-1-准备工作" class="headerlink" title="3.3.1 准备工作"></a>3.3.1 准备工作</h3><ol><li><p>在 /etc/passwd 修改登录提示消息</p></li><li><p>在 /etc/hostname 中修改主机名</p></li></ol><p>可以通过软连接的方式指定 Hadoop 配置文件</p><p><img src="https://user-images.githubusercontent.com/17758731/57002668-999dee80-6bf3-11e9-8fcc-bd41e67e0788.png" alt="image"></p><p>将现在的 ubuntu 虚拟机克隆出三份, 具体配置如下:</p><p><img src="https://user-images.githubusercontent.com/17758731/57017238-d6e49980-6c50-11e9-9aeb-cc3f98d4fd16.png" alt="image"></p><ol><li>左边标出本人当前的四台节点 ip</li><li><p>将 ip 和编号分别写在当前节点(s1) 的 <code>/etc/hosts</code> 文件中:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10.211.55.33 s0</span><br><span class="line">10.211.55.34 s1</span><br><span class="line">10.211.55.35 s2</span><br><span class="line">10.211.55.36 s3</span><br></pre></td></tr></table></figure></li><li><p>此时测试, s0, s1, s2, s3 均可以被 ping 通</p></li><li>现在需要将 hosts 分别同步(覆盖)给到 s1, s2, s3 节点</li></ol><p><img src="https://user-images.githubusercontent.com/17758731/57017640-91c16700-6c52-11e9-8584-be7726f0d5cc.png" alt="image"></p><p>Hadoop 集群架构分析</p><p><img src="https://user-images.githubusercontent.com/17758731/57052874-aafefd80-6cbc-11e9-8d86-0ee8a6022d28.png" alt="image"></p><h3 id="3-3-2-集群模式配置"><a href="#3-3-2-集群模式配置" class="headerlink" title="3.3.2 集群模式配置"></a>3.3.2 集群模式配置</h3><p>预期部署的网络拓扑图: </p><p><img src="https://user-images.githubusercontent.com/17758731/57019091-021eb700-6c58-11e9-903b-4aa941551f75.png" alt="image"></p><table><thead><tr><th>节点名</th><th>功能</th></tr></thead><tbody><tr><td>s0</td><td>名称节点</td></tr><tr><td>s1</td><td>数据节点</td></tr><tr><td>s2</td><td>数据节点</td></tr><tr><td>s3</td><td>辅助名称节点</td></tr></tbody></table><blockquote><p>下面我们从 s0 开始进行配置, 在完成 s0 的配置后, Hadoop 运行时需要所有节点的配置相同, 因此类似于 hosts 文件, 我们需要将配置好的文件覆盖到其他节点.</p></blockquote><h4 id="3-3-2-1-core-site-xml"><a href="#3-3-2-1-core-site-xml" class="headerlink" title="3.3.2.1 core-site.xml"></a>3.3.2.1 core-site.xml</h4><p>core-site.xml 用来配置 NameNode 所运行的节点 ip</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://s0/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="3-3-2-2-hdfs-site-xml"><a href="#3-3-2-2-hdfs-site-xml" class="headerlink" title="3.3.2.2 hdfs-site.xml"></a>3.3.2.2 hdfs-site.xml</h4><p>hdfs-site.xml 用来配置 HDFS 的副本数量</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="3-3-2-4-yarn-site-xml"><a href="#3-3-2-4-yarn-site-xml" class="headerlink" title="3.3.2.4 yarn-site.xml"></a>3.3.2.4 yarn-site.xml</h4><p>yarn-site.xml 用来配置 yarn 的资源管理节点</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>s0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="3-3-2-5-slaves"><a href="#3-3-2-5-slaves" class="headerlink" title="3.3.2.5 slaves"></a>3.3.2.5 slaves</h4><p>通过该文件配置从节点(DataNode) 的 ip</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s1</span><br><span class="line">s2</span><br></pre></td></tr></table></figure><p>最后再将整个 <code>hadoop_cluster</code> 文件夹覆盖到其他节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r hadoop_cluster root@s1:/usr/soft/hadoop-2.7.7/etc/</span><br><span class="line">sudo scp -r hadoop_cluster root@s2:/usr/soft/hadoop-2.7.7/etc/</span><br><span class="line">sudo scp -r hadoop_cluster root@s3:/usr/soft/hadoop-2.7.7/etc/</span><br></pre></td></tr></table></figure><p>使用 <code>start-all.sh</code> 完成 hdfs 和 yarn 的启动:</p><p><img src="https://user-images.githubusercontent.com/17758731/57019992-9be76380-6c5a-11e9-8048-d55108068731.png" alt="image"></p><p>我们可以对启动日志做一个简单的解读:</p><ul><li>在 s0 节点上启动名称节点</li><li>分别在 s1 和 s2 启动数据节点</li><li>启动辅助名称节点</li><li>启动 yarn 守护进程</li><li>分别在 s1 和 s2 启动节点管理器</li></ul><p>可以看一下此时集群上所有节点的 Java 进程状态</p><p><img src="https://user-images.githubusercontent.com/17758731/57020332-8aeb2200-6c5b-11e9-8075-2ffaebfd3096.png" alt="image"></p><p>此时我们已经完成了 Hadoop 完全分布式配置.</p><h1 id="4-分布式文件系统HDFS"><a href="#4-分布式文件系统HDFS" class="headerlink" title="4. 分布式文件系统HDFS"></a>4. 分布式文件系统HDFS</h1><h2 id="4-1-概念"><a href="#4-1-概念" class="headerlink" title="4.1 概念"></a>4.1 概念</h2><ul><li>Hadoop 实现的分布式文件系统(Hadoop Distributed File System), 简称 HDFS</li><li>源自于 Google 的 GFS 论文</li><li>发表与 2003 年, HDFS 是 GFS 的克隆版</li></ul><h2 id="4-2-设计目标"><a href="#4-2-设计目标" class="headerlink" title="4.2 设计目标"></a>4.2 设计目标</h2><ul><li>非常巨大的分布式文件系统</li><li>运行在普通的廉价硬件之上</li><li>易扩展, 为用户提供性能较高的文件存储服务</li></ul><h2 id="4-3-HDFS-架构"><a href="#4-3-HDFS-架构" class="headerlink" title="4.3 HDFS 架构"></a>4.3 HDFS 架构</h2><p><img src="https://user-images.githubusercontent.com/17758731/57053421-7c832180-6cc0-11e9-9ac0-cad53ca1ae99.png" alt="image"></p><p>一个 Master(NameNode/NN), 以及多个 Slave(DataNode/DN), DataNode 用于管理数据的读写, 一个文件会被拆分成多个 block, 默认为 128M, 被存储在一系列的 DataNode(不是一个 DataNode).</p><p>NameNode 职责:</p><ol><li>负责客户端请求的响应</li><li>负责元数据(文件名称, 副本系数, block 存放的 DN)的管理</li></ol><p>DataNode 职责:</p><ol><li>存储用户文件对应的数据块</li><li>要定期向 NameNode 发送心跳信息, 汇报本身及其所有的 block 信息, 健康状况</li></ol><h2 id="4-4-HDFS-副本机制"><a href="#4-4-HDFS-副本机制" class="headerlink" title="4.4 HDFS 副本机制"></a>4.4 HDFS 副本机制</h2><p><img src="https://user-images.githubusercontent.com/17758731/58401666-055b6600-8091-11e9-93ca-204b1312832c.png" alt="image"></p><p>心跳包中包含的信息:</p><ul><li>文件名称, 副本系数, block id</li><li>e.g. 文件名 part-0, 副本系数 2, block id 为 {1, 3}</li><li>e.g. 文件名 part-1, 副本系数 3, block id 为 {2, 4, 5}</li></ul><blockquote><p>HDFS 副本存放策略: 第一个副本存放在客户端所在的节点, 另外两个副本优先存放在不同的机架上, 假设集群只有一个机架, 所有副本都会存放在同一个机架, 如果集群存在多个机架, 就随机挑选一个.</p></blockquote><h2 id="4-5-Hadoop-Shell"><a href="#4-5-Hadoop-Shell" class="headerlink" title="4.5 Hadoop Shell"></a>4.5 Hadoop Shell</h2><p>基本的命令格式:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs/hadoop fs [generic options]</span><br><span class="line">比如 ls 命令可以写成: hdfs dfs -ls / 或 hadoop fs -ls /</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">功能</th></tr></thead><tbody><tr><td style="text-align:center">ls</td><td style="text-align:center">展示文件/文件夹列表</td></tr><tr><td style="text-align:center">mkdir</td><td style="text-align:center">创建文件夹</td></tr><tr><td style="text-align:center">put</td><td style="text-align:center">上传文件</td></tr><tr><td style="text-align:center">get</td><td style="text-align:center">获取文件</td></tr><tr><td style="text-align:center">rm</td><td style="text-align:center">删除文件/文件夹</td></tr></tbody></table><h2 id="4-6-通过代码操作-API"><a href="#4-6-通过代码操作-API" class="headerlink" title="4.6 通过代码操作 API"></a>4.6 通过代码操作 API</h2><h3 id="4-6-1-测试文件的通用代码"><a href="#4-6-1-测试文件的通用代码" class="headerlink" title="4.6.1 测试文件的通用代码"></a>4.6.1 测试文件的通用代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String HDFS_PATH = <span class="string">"hdfs://10.211.55.33:8020"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对于文件系统, 所有操作的统一入库</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    FileSystem fileSystem = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    Configuration configuration = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"HDFSApp.setUp"</span>);</span><br><span class="line">        configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        fileSystem = FileSystem.get(<span class="keyword">new</span> URI(HDFS_PATH), configuration);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tearDown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        configuration = <span class="keyword">null</span>;</span><br><span class="line">        fileSystem = <span class="keyword">null</span>;</span><br><span class="line">        System.out.println(<span class="string">"HDFSApp.tearDown"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-6-2-创建路径"><a href="#4-6-2-创建路径" class="headerlink" title="4.6.2 创建路径"></a>4.6.2 创建路径</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建 HDFS 目录</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test"</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行后的结果:</p><p><img src="https://user-images.githubusercontent.com/17758731/58405892-0c877180-809b-11e9-9bed-22bb2a046cc3.png" alt="image"></p><h3 id="4-6-3-创建文件"><a href="#4-6-3-创建文件" class="headerlink" title="4.6.3 创建文件"></a>4.6.3 创建文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataOutputStream fsDataOutputStream = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/a.txt"</span>));</span><br><span class="line">    fsDataOutputStream.write(<span class="string">"hello hadoop"</span>.getBytes());</span><br><span class="line">    fsDataOutputStream.flush();</span><br><span class="line">    fsDataOutputStream.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行后的结果:</p><p><img src="https://user-images.githubusercontent.com/17758731/58406172-98999900-809b-11e9-98c9-77d5b598fe54.png" alt="image"></p><h3 id="4-6-4-查看文件内容"><a href="#4-6-4-查看文件内容" class="headerlink" title="4.6.4 查看文件内容"></a>4.6.4 查看文件内容</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查看 HDFS 文件的内容</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cat</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataInputStream fsDataInputStream = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/a.txt"</span>));</span><br><span class="line">    IOUtils.copyBytes(fsDataInputStream, System.out, <span class="number">1024</span>);</span><br><span class="line">    fsDataInputStream.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-6-5-重命名"><a href="#4-6-5-重命名" class="headerlink" title="4.6.5 重命名"></a>4.6.5 重命名</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 重命名</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rename</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> rename = fileSystem.rename(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/a.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/b.txt"</span>));</span><br><span class="line">    System.out.println(<span class="string">"rename = "</span> + rename);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行结果:</p><p><img src="https://user-images.githubusercontent.com/17758731/58406539-6b99b600-809c-11e9-8a9e-67819fc8e711.png" alt="image"></p><h3 id="4-6-6-将本地文件-copy-到-HDFS"><a href="#4-6-6-将本地文件-copy-到-HDFS" class="headerlink" title="4.6.6 将本地文件 copy 到 HDFS"></a>4.6.6 将本地文件 copy 到 HDFS</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将文件从本地 copy 到 HDFS</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">copyFromLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Path localPath = <span class="keyword">new</span> Path(<span class="string">"/Users/destiny/dev/apache-tomcat-8.5.29-src.tar.gz"</span>);</span><br><span class="line">    Path hdfsPath = <span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/"</span>);</span><br><span class="line">    fileSystem.copyFromLocalFile(localPath, hdfsPath);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行结果:</p><p><img src="https://user-images.githubusercontent.com/17758731/58406887-33df3e00-809d-11e9-9ebb-e7e94cdf83f8.png" alt="image"></p><h3 id="4-6-7-带进度条的上传"><a href="#4-6-7-带进度条的上传" class="headerlink" title="4.6.7 带进度条的上传"></a>4.6.7 带进度条的上传</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将文件从本地 copy 到 HDFS</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">copyFromLocalFileWithProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    InputStream inputStream = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"/Users/destiny/dev/hadoop-2.7.7.tar.gz"</span>)));</span><br><span class="line">    FSDataOutputStream fsDataOutputStream = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/hadoop-2.7.7.tar.gz"</span>), <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 带进度条提醒信息</span></span><br><span class="line">            System.out.print(<span class="string">"#"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    IOUtils.copyBytes(inputStream, fsDataOutputStream, <span class="number">4096</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行结果:</p><p><img src="https://user-images.githubusercontent.com/17758731/58407545-9dac1780-809e-11e9-9873-15c03f8832eb.png" alt="image"></p><h3 id="4-6-8-下载-HDFS-文件"><a href="#4-6-8-下载-HDFS-文件" class="headerlink" title="4.6.8 下载 HDFS 文件"></a>4.6.8 下载 HDFS 文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 下载 HDFS 文件到本地</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">copyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Path localPath = <span class="keyword">new</span> Path(<span class="string">"/Users/destiny/dev/"</span>);</span><br><span class="line">    Path hdfsPath = <span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/b.txt"</span>);</span><br><span class="line">    fileSystem.copyToLocalFile(hdfsPath, localPath);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-6-9-查看指定路径下的所有文件"><a href="#4-6-9-查看指定路径下的所有文件" class="headerlink" title="4.6.9 查看指定路径下的所有文件"></a>4.6.9 查看指定路径下的所有文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查看指定路径的所有文件</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFiles</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FileStatus[] fileStatuses = fileSystem.listStatus(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/"</span>));</span><br><span class="line">    <span class="keyword">for</span> (FileStatus fileStatus : fileStatuses) &#123;</span><br><span class="line">        <span class="keyword">boolean</span> directory = fileStatus.isDirectory();</span><br><span class="line">        System.out.println(<span class="string">"directory = "</span> + directory);</span><br><span class="line">        <span class="keyword">short</span> replication = fileStatus.getReplication();</span><br><span class="line">        System.out.println(<span class="string">"replication = "</span> + replication);</span><br><span class="line">        <span class="keyword">long</span> len = fileStatus.getLen();</span><br><span class="line">        System.out.println(<span class="string">"len = "</span> + len);</span><br><span class="line">        String path = fileStatus.getPath().toString();</span><br><span class="line">        System.out.println(<span class="string">"path = "</span> + path);</span><br><span class="line">        System.out.println(<span class="string">"==============================="</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行结果:</p><p><img src="https://user-images.githubusercontent.com/17758731/58408282-1495e000-80a0-11e9-9cd4-8221cd4cc79a.png" alt="image"></p><p>这里有一个小问题:</p><blockquote><p>在前面的分布式配置中, <code>hdfs-site.xml</code> 中设置的副本系数为 2, 但这里查询到的结果却为 3<br>如果是通过 HDFS shell 的方式 put 上去, 那么会采用设置的副本系数 2<br>而如果是通过 java API 上传, 那么由于本地没有设置副本系数, 因此采用的是 Hadoop 自带的副本系数</p></blockquote><h3 id="4-6-10-删除文件"><a href="#4-6-10-删除文件" class="headerlink" title="4.6.10 删除文件"></a>4.6.10 删除文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除文件(默认递归)</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">"/hdfsapi/test/"</span>), <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-7-HDFS-文件写入流程"><a href="#4-7-HDFS-文件写入流程" class="headerlink" title="4.7 HDFS 文件写入流程"></a>4.7 HDFS 文件写入流程</h2><h2 id="4-8-HDFS-文件读取刘晨"><a href="#4-8-HDFS-文件读取刘晨" class="headerlink" title="4.8 HDFS 文件读取刘晨"></a>4.8 HDFS 文件读取刘晨</h2><h1 id="5-资源调度框架-YARN"><a href="#5-资源调度框架-YARN" class="headerlink" title="5. 资源调度框架 YARN"></a>5. 资源调度框架 YARN</h1><h2 id="5-1-背景"><a href="#5-1-背景" class="headerlink" title="5.1 背景"></a>5.1 背景</h2><h3 id="5-1-1-MapReduce-1-X-存在的问题"><a href="#5-1-1-MapReduce-1-X-存在的问题" class="headerlink" title="5.1.1 MapReduce 1.X 存在的问题"></a>5.1.1 MapReduce 1.X 存在的问题</h3><blockquote><ul><li>集群由一个 JobTracker 与多个 TaskTracker 构成, 客户端提交任务的时候, 直接将作业提交给 JobTracker, 由 JobTracker 负责资源的管理与作业的调度;  </li><li>TaskTracker 定期通过心跳机制与 JobTracker 进行通信, 汇报健康状况, 资源使用情况以及任务的执行进度, 并且接收来自 JobTracker 的命令来进行任务的启动和结束</li></ul></blockquote><p><img src="https://user-images.githubusercontent.com/17758731/58748384-85773680-84aa-11e9-8233-daebe5f2ccf6.png" alt="image"></p><p>存在问题:</p><ol><li>JobTracker 存在单点故障</li><li>JobTracker 负载较大, 需要接收 TaskTracker 的心跳信息, 制约 Hadoop 集群的扩展</li><li>JobTracker 承载职责较多,  包括资源管理, 资源调度, 任务分配</li><li>仅仅支持 MapReduce 作业, Spark 以及 Storm 作业无法支持</li></ol><h3 id="5-1-2-资源利用-amp-运维成本"><a href="#5-1-2-资源利用-amp-运维成本" class="headerlink" title="5.1.2 资源利用&amp;运维成本"></a>5.1.2 资源利用&amp;运维成本</h3><p><img src="https://user-images.githubusercontent.com/17758731/58748483-1c90be00-84ac-11e9-8a8f-a1047ab1e791.png" alt="image"></p><p>由于 Hadoop 集群不支持其他形式的作业, 因此生产环境需要部署多套集群, 而不同集群在造成更多资源占用的同时, 往往存在运行时间不同, 如果能够将多个集群整合在一起, 就可以节约计算资源.</p><p>如果存在一种 <code>共享集群</code>, 能够处理不同类型的作业, 并且能够自行实现资源的合理分配, 就可以解决不同作业任务需要多套集群环境的问题.</p><p><img src="https://user-images.githubusercontent.com/17758731/58748603-f5d38700-84ad-11e9-862f-26c9e6a73f13.png" alt="image"></p><p>在 Hadoop2.0 的架构中, Hadoop 之上运行 YARN, YARN 负责集群的资源管理, 而 YARN 可以接收来自 MapReduce, HBase, Storm, Spark 等多种应用的输入. YARN 做了统一的抽象, 类似操作系统级别的通用资源调度框架, 可以让更多的计算框架运行在同一个集群中, 不同的计算框架可以共享同一个 HDFS 上的数据, 享受整体的资源调度.</p><h2 id="5-2-架构"><a href="#5-2-架构" class="headerlink" title="5.2 架构"></a>5.2 架构</h2><ul><li>Yarn(Yet Another Resource Negotiator, 另一个资源协调者的简称)</li><li>是一个通用的资源管理系统</li><li>为上层应用提供统一的资源管理和调度</li></ul><p><img src="https://user-images.githubusercontent.com/17758731/58748576-8d84a580-84ad-11e9-98db-95d5970a38d0.png" alt="image"></p><p>Yarn 架构的核心组件:</p><table><thead><tr><th style="text-align:center">角色</th><th>描述</th><th>功能</th></tr></thead><tbody><tr><td style="text-align:center">ResourceManager</td><td>整个集群同一时间提供服务的 Resource Manager 只有一个, 负责集群资源的统一管理和调度</td><td>1. 提交作业<br>2. 杀死作业<br>3. 监控 NodeManager, 一旦某个 NodeManager 挂了, 该 NameNode 上运行的任务要告诉 Application Master</td></tr><tr><td style="text-align:center">NodeManager</td><td>整个集群中有多个 NodeManager, 负责当前节点资源管理和使用</td><td>1. 定时向 ResourceManager 汇报当前节点的资源使用情况<br>2. 接受并处理 ResourceManager 的各种命令<br>3. 处理来自 Application Master 的命令<br>4. 单个节点的资源管理</td></tr><tr><td style="text-align:center">Application Master</td><td>每个应用程序对应一个 Application Master, 负责应用程序的管理</td><td>1. 为应用程序向 ResourceManager 申请资源(core, mem)<br>2. 分配给内部的 Task 处理<br> 3. 需要与 NodeManager 通信, 启动/停止 task</td></tr><tr><td style="text-align:center">Container</td><td>封装了 CPU, MEM 等资源的容器, 是一个任务运行环境的抽象</td></tr><tr><td style="text-align:center">Client</td><td>用于封装用户的操作</td><td>1. 提交作业<br> 2. 查询作业运行进度 <br> 3. 杀死作业<br></td></tr></tbody></table><h2 id="5-3-执行流程"><a href="#5-3-执行流程" class="headerlink" title="5.3 执行流程"></a>5.3 执行流程</h2><p><img src="https://user-images.githubusercontent.com/17758731/60674721-568b2080-9ead-11e9-8c35-654d3fdc8fdc.png" alt="image"></p><ol><li>用户向 YARN 提交作业</li><li>ResourceManager 为作业分配第一个 Container, 与对应的 NodeManager 通信, 要求在其上启动 Container, 用来启动应用程序</li><li>NodeManager 按照要求, 启动 Application Master</li><li>Application Master 启动后, 会首先在 ResourceManager 进行注册, 此时就可以通过 ResourceManager 查询作业的运行情况. 然后 ApplicationMaster 会将所需要的资源到 ResourceManager 上去申请</li><li>ApplicationMaster 申请到资源之后在对应的 NodeManager 上开始启动任务, 所有的任务都是以 Container 的方式运行的</li><li>NodeManager 启动对应的 Container 去执行任务.</li></ol><h2 id="5-5-提交作业到-YARN-上执行"><a href="#5-5-提交作业到-YARN-上执行" class="headerlink" title="5.5 提交作业到 YARN 上执行"></a>5.5 提交作业到 YARN 上执行</h2><h3 id="5-5-1-提交-Hadoop-包的-Example"><a href="#5-5-1-提交-Hadoop-包的-Example" class="headerlink" title="5.5.1 提交 Hadoop 包的 Example"></a>5.5.1 提交 Hadoop 包的 Example</h3><p>在 Hadoop 安装路径下的 <code>share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar</code> 文件</p><p>使用如下命令将 MapReduce 作业提交到 YARN 上去运行: </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-mapreduce-examples-2.7.7.jar pi 2 3</span><br></pre></td></tr></table></figure><h1 id="6-启动脚本分析"><a href="#6-启动脚本分析" class="headerlink" title="6. 启动脚本分析"></a>6. 启动脚本分析</h1><p>Hadoop 启动脚本位于 <code>${HADOOP_HOME}/bin</code>, <code>${HADOOP_HOME}/sbin</code> 和 <code>${HADOOP_HOME}/libexec</code> 路径下, 其中包含 *nux 的 Shell 脚本和 win 的批处理文件.</p><h2 id="6-1-start-all-sh-启动分析"><a href="#6-1-start-all-sh-启动分析" class="headerlink" title="6.1 start-all.sh 启动分析"></a>6.1 start-all.sh 启动分析</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the "License"); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start all hadoop daemons.  Run this on master node.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh"</span></span><br><span class="line"></span><br><span class="line">bin=`dirname <span class="string">"<span class="variable">$&#123;BASH_SOURCE-$0&#125;</span>"</span>`</span><br><span class="line">bin=`<span class="built_in">cd</span> <span class="string">"<span class="variable">$bin</span>"</span>; <span class="built_in">pwd</span>`</span><br><span class="line"></span><br><span class="line">DEFAULT_LIBEXEC_DIR=<span class="string">"<span class="variable">$bin</span>"</span>/../libexec</span><br><span class="line">HADOOP_LIBEXEC_DIR=<span class="variable">$&#123;HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR&#125;</span></span><br><span class="line">. <span class="variable">$HADOOP_LIBEXEC_DIR</span>/hadoop-config.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># start hdfs daemons if hdfs is present</span></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="string">"<span class="variable">$&#123;HADOOP_HDFS_HOME&#125;</span>"</span>/sbin/start-dfs.sh ]; <span class="keyword">then</span></span><br><span class="line">  <span class="string">"<span class="variable">$&#123;HADOOP_HDFS_HOME&#125;</span>"</span>/sbin/start-dfs.sh --config <span class="variable">$HADOOP_CONF_DIR</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># start yarn daemons if yarn is present</span></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="string">"<span class="variable">$&#123;HADOOP_YARN_HOME&#125;</span>"</span>/sbin/start-yarn.sh ]; <span class="keyword">then</span></span><br><span class="line">  <span class="string">"<span class="variable">$&#123;HADOOP_YARN_HOME&#125;</span>"</span>/sbin/start-yarn.sh --config <span class="variable">$HADOOP_CONF_DIR</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><ol><li>首先会通过 echo 输出一句话, 大意是该脚本已被废弃, 推荐使用 <code>start-dfs.sh</code> 和 <code>start-yarn.sh</code></li><li><code>bin=`dirname &quot;${BASH_SOURCE-$0}&quot;`</code> 提取 start-all.sh 所在的绝对路径</li><li><code>bin=`cd &quot;$bin&quot;; pwd`</code> 切换到 start-all.sh 所在的绝对路径</li><li><code>DEFAULT_LIBEXEC_DIR=&quot;$bin&quot;/../libexec</code> 获取 <code>${HADOOP_HOME}/libexec/hadoop-config.sh</code> 路径</li><li><code>HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}</code> 为 <code>HADOOP_LIBEXEC_DIR</code> 变量三元赋值: 如果 <code>HADOOP_LIBEXEC_DIR</code> 为空或者环境变量没有配置, 复制默认的绝对路径</li><li><code>. $HADOOP_LIBEXEC_DIR/hadoop-config.sh</code> 执行 <code>${HADOOP_HOME}/libexec/hadoop-config.sh</code> 脚本, 为后面执行启动各节点和启动 yarn 做预处理</li><li><code>&quot;${HADOOP_HDFS_HOME}&quot;/sbin/start-dfs.sh --config $HADOOP_CONF_DIR</code> 如果 <code>${HADOOP_HDFS_HOME}&quot;/sbin/start-dfs.sh</code> 是文件, 就通过 –config 参数启动 <code>start-dfs.sh</code> 脚本</li><li><code>&quot;${HADOOP_YARN_HOME}&quot;/sbin/start-yarn.sh --config $HADOOP_CONF_DIR</code>: 如果 <code>${HADOOP_YARN_HOME}&quot;/sbin/start-yarn.sh</code> 是文件, 就通过 –config 参数启动 <code>start-yarn.sh</code> 脚本</li></ol><h2 id="6-2-hadoop-config-sh"><a href="#6-2-hadoop-config-sh" class="headerlink" title="6.2 hadoop-config.sh"></a>6.2 hadoop-config.sh</h2><p>该脚本位于</p><h1 id="7-MapReduce"><a href="#7-MapReduce" class="headerlink" title="7. MapReduce"></a>7. MapReduce</h1><p>MapReduce 是一种并行计算编程模型, 源自于 Google 的 MapReduce 论文, 包含 Map 过程和 Reduce 过程, Map 过程对应创建 Mapper 实现类, Reduce 过程对应创建 Reducer 实现类.</p><h2 id="7-2-Map-和-Reduce-阶段"><a href="#7-2-Map-和-Reduce-阶段" class="headerlink" title="7.2 Map 和 Reduce 阶段"></a>7.2 Map 和 Reduce 阶段</h2><p>将作业拆分成 Map 阶段和 Reduce 阶段</p><ol><li>准备 Map 处理的输入数据</li><li>Mapper 处理</li><li>Shuffle: 将相同的 key 分配到同一个 Reduce 节点</li><li>Reduce 处理</li><li>输出结果</li></ol><p><img src="https://user-images.githubusercontent.com/17758731/61185171-8ba32a00-a688-11e9-895f-b9b2e2fbaf96.png" alt="image"></p><p>假设现在有两个节点</p><ol><li>使用 <code>InputFormat</code> 读取文件系统(本地, HDFS), 并拆分成多个 Split</li><li>每个 Split 由一个 <code>RecordReader</code> 负责读取, 每读一行交由一个 mapper 处理</li><li>map 产生的结果交由 <code>Partitioner</code>, 将所有的 key 按一定规则分配给同一个节点并完成排序</li><li>相同的 key 交给 <code>Reduce</code> 负责处理</li><li>处理的结果交给 <code>OutputFormat</code> 写回文件系统</li></ol><h2 id="7-3-MapReduce-编程模型"><a href="#7-3-MapReduce-编程模型" class="headerlink" title="7.3 MapReduce 编程模型"></a>7.3 MapReduce 编程模型</h2><p><img src="https://user-images.githubusercontent.com/17758731/61185527-1b4ad780-a68d-11e9-9595-f8a380a57aa7.png" alt="image"></p><h3 id="7-3-1-Split"><a href="#7-3-1-Split" class="headerlink" title="7.3.1 Split"></a>7.3.1 Split</h3><p>被 InputFormat 从文件系统中读取并分片, 并交由 MapReduce 作业来处理的数据块</p><blockquote><p>HDFS 中的 blocksize 是 HDFS 中最小的存储单元, 默认 128M<br>Split 是 MapReduce 中最小的计算单元<br>默认情况下二者是一一对应的, 也可以手工设置二者之间的关系.</p></blockquote><h3 id="7-3-2-Combiner"><a href="#7-3-2-Combiner" class="headerlink" title="7.3.2 Combiner"></a>7.3.2 Combiner</h3><h3 id="7-3-3-Partitioner"><a href="#7-3-3-Partitioner" class="headerlink" title="7.3.3 Partitioner"></a>7.3.3 Partitioner</h3><h3 id="7-4-MapReduce-1-x-架构"><a href="#7-4-MapReduce-1-x-架构" class="headerlink" title="7.4 MapReduce 1.x 架构"></a>7.4 MapReduce 1.x 架构</h3><p><img src="https://user-images.githubusercontent.com/17758731/58748384-85773680-84aa-11e9-8233-daebe5f2ccf6.png" alt="image"></p><ol><li>JobTracker(JT)<ol><li>作业的管理者</li><li>将作业分解成多个任务(MapTask &amp; ReduceTask)</li><li>将任务分派给 TaskTracker 运行</li><li>作业监控, 容错处理</li><li>在一定时间内 JobTacker 没有收到 TaskTracker 的心跳, 会重新指派到其他的 TaskTracker 去执行</li></ol></li><li>TaskTracker(TT)<ol><li>任务的执行者, 执行任务(MapTask &amp; ReduceTask)</li><li>与 JobTracker 交互: 执行/启动/停止, 发送心跳信息给 JobTracker</li></ol></li><li>MapTask<ol><li>开发的 map 任务交由 MapTask 完成</li><li>解析每条记录的数据交给自己的 Map 方法处理</li><li>将 Map 的输出结果写到本地磁盘</li></ol></li><li>ReduceTask<ol><li>将 MapTask 输出的数据进行读取</li><li>按照数据进行分组传给 Reduce 方法处理</li><li>输出结果, 写入到 HDFS</li></ol></li></ol><h3 id="7-5-MapReduce-2-x-架构"><a href="#7-5-MapReduce-2-x-架构" class="headerlink" title="7.5 MapReduce 2.x 架构"></a>7.5 MapReduce 2.x 架构</h3><h3 id="7-6-Combiner"><a href="#7-6-Combiner" class="headerlink" title="7.6 Combiner"></a>7.6 Combiner</h3><ul><li>在 Mapper Task本地的 Reduce</li><li>减少 Map Task 输出的数据量及数据网络传输量</li><li>大部分情况下逻辑和 Reduce 基本相同</li></ul><p><img src="https://user-images.githubusercontent.com/17758731/61586498-5fb40700-aba8-11e9-86ff-1309911e1010.png" alt="image"></p><h3 id="7-7-Partitioner"><a href="#7-7-Partitioner" class="headerlink" title="7.7 Partitioner"></a>7.7 Partitioner</h3><ul><li>决定 MapTask 输出的数据交由哪个 Reducer 处理</li><li>默认实现: 分发的 key 的 hash 值对 Reduce Task 个数取模</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1. 简介&quot;&gt;&lt;/a&gt;1. 简介&lt;/h1&gt;&lt;h1 id=&quot;2-Hadoop-安装&quot;&gt;&lt;a href=&quot;#2-Hadoop-安装&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="大数据" scheme="https://destinywang.github.io/blog/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hadoop" scheme="https://destinywang.github.io/blog/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://destinywang.github.io/blog/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(9)-XML解析</title>
    <link href="https://destinywang.github.io/blog/2019/04/08/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-9-XML%E8%A7%A3%E6%9E%90/"/>
    <id>https://destinywang.github.io/blog/2019/04/08/Activiti源码分析-9-XML解析/</id>
    <published>2019-04-08T14:32:21.000Z</published>
    <updated>2019-04-08T15:53:19.622Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-XML-解析"><a href="#1-XML-解析" class="headerlink" title="1. XML 解析"></a>1. XML 解析</h1><h2 id="1-1-DOM-模型"><a href="#1-1-DOM-模型" class="headerlink" title="1.1. DOM 模型"></a>1.1. DOM 模型</h2><ul><li>优点: 文档解析的时候允许客户端编辑和更新 XML 文档的内容, 并可以随机访问文档中定义的元素数据.</li><li>缺点: 文档解析的时候需要将 XML 一次性加载到内存, 进而映射成 Document 对象中的树形结构, 在解析大文件的时候内存占用大, 元素遍历查找慢, 性能容易成为瓶颈.</li></ul><h2 id="1-2-SAX-模型"><a href="#1-2-SAX-模型" class="headerlink" title="1.2. SAX 模型"></a>1.2. SAX 模型</h2><ul><li>优点: 该方式解析文档的时候, 每一次操作只会将解析的节点放置到内存中, 从头部开始, 读取一段处理一段, 内存占用小.</li><li>缺点: 解析文档的时候文档是只读的, 不能编辑, 并且文件流只能前进不能后退</li></ul><p>在 Activiti 中, 由于 XML 完全由用户的输入决定, 无法控制器大小, 因此选用 SAX 模型</p><h1 id="2-文档转换器"><a href="#2-文档转换器" class="headerlink" title="2. 文档转换器"></a>2. 文档转换器</h1><p>文档转换器可以将文档转换为 BpmnModel, 也可以将 BpmnModel 转换为文档</p><p>文档解析器: BpmnXMLConverter</p><p>解析器内部持有所有 <code>元素解析器</code></p><ul><li>元素解析器与元素之间一一对应</li><li>任务节点的元素名称是 UserTask, 因此对应的解析器为 <code>UserTaskXMLConverter</code></li><li>连线的元素名称是 SequenceFlow, 对应的解析器为 <code>SequenceFlowXMLConverter</code></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-XML-解析&quot;&gt;&lt;a href=&quot;#1-XML-解析&quot; class=&quot;headerlink&quot; title=&quot;1. XML 解析&quot;&gt;&lt;/a&gt;1. XML 解析&lt;/h1&gt;&lt;h2 id=&quot;1-1-DOM-模型&quot;&gt;&lt;a href=&quot;#1-1-DOM-模型&quot; class
      
    
    </summary>
    
      <category term="Activiti" scheme="https://destinywang.github.io/blog/categories/Activiti/"/>
    
      <category term="源码" scheme="https://destinywang.github.io/blog/categories/Activiti/%E6%BA%90%E7%A0%81/"/>
    
    
      <category term="Activiti" scheme="https://destinywang.github.io/blog/tags/Activiti/"/>
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(7)-ID生成器</title>
    <link href="https://destinywang.github.io/blog/2019/03/26/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-7-ID%E7%94%9F%E6%88%90%E5%99%A8/"/>
    <id>https://destinywang.github.io/blog/2019/03/26/Activiti源码分析-7-ID生成器/</id>
    <published>2019-03-26T14:52:05.000Z</published>
    <updated>2019-04-21T02:45:15.320Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-DbIdGenerator"><a href="#1-DbIdGenerator" class="headerlink" title="1. DbIdGenerator"></a>1. <code>DbIdGenerator</code></h1><p><img src="https://user-images.githubusercontent.com/17758731/55007318-2e706380-501a-11e9-9a32-8e98d9944b66.png" alt="image"></p><p>Activiti 默认采用数据库来实现强一致的发号器 <code>DbIdGenerator</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DbIdGenerator</span> <span class="keyword">implements</span> <span class="title">IdGenerator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">int</span> idBlockSize;</span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">long</span> nextId;</span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">long</span> lastId = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> CommandExecutor commandExecutor;</span><br><span class="line">  <span class="keyword">protected</span> CommandConfig commandConfig;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> String <span class="title">getNextId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (lastId &lt; nextId) &#123;</span><br><span class="line">      getNewBlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> _nextId = nextId++;</span><br><span class="line">    <span class="keyword">return</span> Long.toString(_nextId);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">getNewBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    IdBlock idBlock = commandExecutor.execute(commandConfig, <span class="keyword">new</span> GetNextIdBlockCmd(idBlockSize));</span><br><span class="line">    <span class="keyword">this</span>.nextId = idBlock.getNextId();</span><br><span class="line">    <span class="keyword">this</span>.lastId = idBlock.getLastId();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getIdBlockSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> idBlockSize;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setIdBlockSize</span><span class="params">(<span class="keyword">int</span> idBlockSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.idBlockSize = idBlockSize;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> CommandExecutor <span class="title">getCommandExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> commandExecutor;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCommandExecutor</span><span class="params">(CommandExecutor commandExecutor)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.commandExecutor = commandExecutor;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> CommandConfig <span class="title">getCommandConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> commandConfig;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCommandConfig</span><span class="params">(CommandConfig commandConfig)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.commandConfig = commandConfig;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>DbIdGenerator 实现了 <code>getNextId</code> 方法, 用于对应用范围内所有的实体对象分配 id, 我们就以这个方法为起点, 分析默认的发号器逻辑.</p><h2 id="1-1-DbIdGenerator-getNextId"><a href="#1-1-DbIdGenerator-getNextId" class="headerlink" title="1.1. DbIdGenerator#getNextId()"></a>1.1. DbIdGenerator#getNextId()</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> String <span class="title">getNextId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (lastId &lt; nextId) &#123;</span><br><span class="line">        getNewBlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> _nextId = nextId++;</span><br><span class="line">    <span class="keyword">return</span> Long.toString(_nextId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>比较内部持有的两个布局变量 <code>lastId</code> 和 <code>nextId</code><ol><li>如果 <code>lastId</code> 已经小于 <code>nextId</code></li><li>获取一个新的 Block</li></ol></li><li>获得当前的 <code>_nextId</code>, 并转换成字符串, 同时持有的局部变量 <code>nextId</code> 自增</li></ol><h2 id="1-2-DbIdGenerator-getNewBlock"><a href="#1-2-DbIdGenerator-getNewBlock" class="headerlink" title="1.2. DbIdGenerator#getNewBlock()"></a>1.2. DbIdGenerator#getNewBlock()</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">getNewBlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    IdBlock idBlock = commandExecutor.execute(commandConfig, <span class="keyword">new</span> GetNextIdBlockCmd(idBlockSize));</span><br><span class="line">    <span class="keyword">this</span>.nextId = idBlock.getNextId();</span><br><span class="line">    <span class="keyword">this</span>.lastId = idBlock.getLastId();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>获取一个新的 <code>IdBlock</code> 对象</li><li>分别将该对象的 <code>nextId</code> 和 <code>lastId</code> 赋值给自身持有的同名字段</li></ol><h2 id="1-3-GetNextIdBlockCmd-execute-CommandContext-commandContext"><a href="#1-3-GetNextIdBlockCmd-execute-CommandContext-commandContext" class="headerlink" title="1.3. GetNextIdBlockCmd#execute(CommandContext commandContext)"></a>1.3. GetNextIdBlockCmd#execute(CommandContext commandContext)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> IdBlock <span class="title">execute</span><span class="params">(CommandContext commandContext)</span> </span>&#123;</span><br><span class="line">    PropertyEntity property = (PropertyEntity) commandContext.getPropertyEntityManager().findById(<span class="string">"next.dbid"</span>);</span><br><span class="line">    <span class="keyword">long</span> oldValue = Long.parseLong(property.getValue());</span><br><span class="line">    <span class="keyword">long</span> newValue = oldValue + idBlockSize;</span><br><span class="line">    property.setValue(Long.toString(newValue));</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> IdBlock(oldValue, newValue - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>调用 <code>PropertyEntityManager</code>, 从 <code>ACT_GE_PROPERTY</code> 表中获取 <code>next.dbid</code> 字段的值</li><li>将旧值转换成 long 类型并增加 <code>idBlockSize</code> 长度得到新值, 其中 <code>idBlockSize</code> 通过调用链追踪到在 <code>ProcessEngineConfiguration</code> 将其设置为 2500, 并调用命令类的初始化</li><li>将新值设置进查询到的 property 对象</li><li>返回新的 <code>IdBlock</code> 对象</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-DbIdGenerator&quot;&gt;&lt;a href=&quot;#1-DbIdGenerator&quot; class=&quot;headerlink&quot; title=&quot;1. DbIdGenerator&quot;&gt;&lt;/a&gt;1. &lt;code&gt;DbIdGenerator&lt;/code&gt;&lt;/h1&gt;&lt;p&gt;&lt;im
      
    
    </summary>
    
      <category term="Activiti" scheme="https://destinywang.github.io/blog/categories/Activiti/"/>
    
      <category term="源码" scheme="https://destinywang.github.io/blog/categories/Activiti/%E6%BA%90%E7%A0%81/"/>
    
    
      <category term="Activiti" scheme="https://destinywang.github.io/blog/tags/Activiti/"/>
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(8)-发起流程实例</title>
    <link href="https://destinywang.github.io/blog/2019/03/09/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-8-%E5%8F%91%E8%B5%B7%E6%B5%81%E7%A8%8B%E5%AE%9E%E4%BE%8B/"/>
    <id>https://destinywang.github.io/blog/2019/03/09/Activiti源码分析-8-发起流程实例/</id>
    <published>2019-03-09T10:48:39.000Z</published>
    <updated>2019-03-10T05:03:49.070Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h1><h2 id="1-1-启动流程"><a href="#1-1-启动流程" class="headerlink" title="1.1. 启动流程"></a>1.1. 启动流程</h2><ol><li>操作数据库的 ACT_RU_EXECUTION 表, 如果是用户任务节点, 同时也会在 ACT_RU_TASK 表添加一条记录;</li><li></li></ol><h2 id="1-2-流程实例"><a href="#1-2-流程实例" class="headerlink" title="1.2. 流程实例"></a>1.2. 流程实例</h2><ol><li>代表流程定义的执行实例</li><li>一个流程实例包括了所有的运行节点</li><li>流程实例表示一个流程从开始到结束的最大流程分支</li><li>流程实例也被称为执行实例根节点</li></ol><p>在 Activiti 对应的接口为:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ProcessInstance</span> <span class="keyword">extends</span> <span class="title">Execution</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出 ProcessInstance 就是 Execution</p><h2 id="1-3-执行实例"><a href="#1-3-执行实例" class="headerlink" title="1.3. 执行实例"></a>1.3. 执行实例</h2><ol><li>启动流程的时候会首先创建流程实例, 然后创建执行实例</li><li>流程运转的过程中永远执行的是自己对应的执行实例</li><li>当所有的执行实例按照规则完毕之后, 对应的流程随之结束</li><li>Activiti 使用 <code>Execution</code> 对象去描述流程执行的每一个节点</li><li>流程按照流程定义的规则执行一次的过程, 就可以表示执行对象 <code>Execution</code></li><li>一个流程中, 执行对象可以存在多个, 但流程实例只能有一个</li><li>执行实例的父级 / 父级的父级为流程实例</li></ol><h2 id="1-4-概念演示"><a href="#1-4-概念演示" class="headerlink" title="1.4. 概念演示"></a>1.4. 概念演示</h2><h3 id="1-4-1-简单流程实例"><a href="#1-4-1-简单流程实例" class="headerlink" title="1.4.1. 简单流程实例"></a>1.4.1. 简单流程实例</h3><p><img src="https://user-images.githubusercontent.com/17758731/54070715-5d5aab80-429e-11e9-815e-bfc25e01843c.png" alt="image"></p><ol><li>发起流程的时候, 会先创建一个流程实例, 然后创建执行实例;</li><li>随着流程的运转, 执行实例会不断更新;</li><li>直到流程执行完毕(走到结束节点), 对应执行实例会结束, 此时流程实例也结束.</li></ol><h3 id="1-4-2-有分支的流程实例"><a href="#1-4-2-有分支的流程实例" class="headerlink" title="1.4.2. 有分支的流程实例"></a>1.4.2. 有分支的流程实例</h3><p><img src="https://user-images.githubusercontent.com/17758731/54070799-bf67e080-429f-11e9-9264-556b380bc5cc.png" alt="image"></p><ol><li>当流程进入并行网关之后, 会创建两个执行实例</li><li>当两个执行实例都结束之后, 再创建第三个执行实例</li></ol><h1 id="2-RuntimeServiceImpl-startProcessInstanceByKey-String-processDefinitionKey"><a href="#2-RuntimeServiceImpl-startProcessInstanceByKey-String-processDefinitionKey" class="headerlink" title="2. RuntimeServiceImpl#startProcessInstanceByKey(String processDefinitionKey)"></a>2. RuntimeServiceImpl#startProcessInstanceByKey(String processDefinitionKey)</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessInstance <span class="title">startProcessInstanceByKey</span><span class="params">(String processDefinitionKey)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> commandExecutor.execute(<span class="keyword">new</span> StartProcessInstanceCmd&lt;ProcessInstance&gt;(processDefinitionKey, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-1-StartProcessInstanceCmd-execution-CommandContext-commandContext"><a href="#2-1-StartProcessInstanceCmd-execution-CommandContext-commandContext" class="headerlink" title="2.1. StartProcessInstanceCmd#execution(CommandContext commandContext)"></a>2.1. StartProcessInstanceCmd#execution(CommandContext commandContext)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessInstance <span class="title">execute</span><span class="params">(CommandContext commandContext)</span> </span>&#123;</span><br><span class="line">    DeploymentManager deploymentCache = commandContext.getProcessEngineConfiguration().getDeploymentManager();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Find the process definition</span></span><br><span class="line">    ProcessDefinition processDefinition = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (processDefinitionId != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">        processDefinition = deploymentCache.findDeployedProcessDefinitionById(processDefinitionId);</span><br><span class="line">        <span class="keyword">if</span> (processDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiObjectNotFoundException(<span class="string">"No process definition found for id = '"</span> + processDefinitionId + <span class="string">"'"</span>, ProcessDefinition.class);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (processDefinitionKey != <span class="keyword">null</span> &amp;&amp; (tenantId == <span class="keyword">null</span> || ProcessEngineConfiguration.NO_TENANT_ID.equals(tenantId))) &#123;</span><br><span class="line"></span><br><span class="line">        processDefinition = deploymentCache.findDeployedLatestProcessDefinitionByKey(processDefinitionKey);</span><br><span class="line">        <span class="keyword">if</span> (processDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiObjectNotFoundException(<span class="string">"No process definition found for key '"</span> + processDefinitionKey + <span class="string">"'"</span>, ProcessDefinition.class);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (processDefinitionKey != <span class="keyword">null</span> &amp;&amp; tenantId != <span class="keyword">null</span> &amp;&amp; !ProcessEngineConfiguration.NO_TENANT_ID.equals(tenantId)) &#123;</span><br><span class="line"></span><br><span class="line">            processDefinition = deploymentCache.findDeployedLatestProcessDefinitionByKeyAndTenantId(processDefinitionKey, tenantId);</span><br><span class="line">            <span class="keyword">if</span> (processDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiObjectNotFoundException(<span class="string">"No process definition found for key '"</span> + processDefinitionKey + <span class="string">"' for tenant identifier "</span> + tenantId, ProcessDefinition.class);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiIllegalArgumentException(<span class="string">"processDefinitionKey and processDefinitionId are null"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    processInstanceHelper = commandContext.getProcessEngineConfiguration().getProcessInstanceHelper();</span><br><span class="line">    ProcessInstance processInstance = createAndStartProcessInstance(processDefinition, businessKey, processInstanceName, variables, transientVariables);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> processInstance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>初始化 processDefinition 对象, 由于 <code>startProcessInstanceByXX</code> 系列方法有多种参数, 因此一下三种条件都可以实现:<ol><li>如果 processDefinitionId 不为空, 通过该 id 查询流程定义;</li><li>如果 processDefinitionKey 不为空, 并且 <code>tenantId</code> 为空, 就通过 <code>processDefinitionKey</code> 查询最新的流程定义;</li><li>如果 processDefinitionKey 不为空, 并且 <code>tenantId</code> 也不为空, 就通过这两个参数一起查询最新的流程定义;</li></ol></li><li>获取 <code>processInstanceHelper</code> 对象</li><li>执行创建流程逻辑并返回</li></ol><h2 id="2-2-StartProcessInstanceCmd-createAndStartProcessInstance-ProcessDefinition-processDefinition-String-businessKey-String-processInstanceName-Map-lt-String-Object-gt-variables-Map-lt-String-Object-gt-transientVariables"><a href="#2-2-StartProcessInstanceCmd-createAndStartProcessInstance-ProcessDefinition-processDefinition-String-businessKey-String-processInstanceName-Map-lt-String-Object-gt-variables-Map-lt-String-Object-gt-transientVariables" class="headerlink" title="2.2. StartProcessInstanceCmd#createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String,Object&gt; variables, Map&lt;String, Object&gt; transientVariables)"></a>2.2. StartProcessInstanceCmd#createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String,Object&gt; variables, Map&lt;String, Object&gt; transientVariables)</h2><p>参数较多, 先解释下参数:</p><ul><li>processDefinition: 流程定义对象</li><li>businessKey: 业务标识</li><li>processInstanceName: 需要设置的流程名称</li><li>variables: 表单数据(会持久化到变量表中)</li><li>transientVariables: 不需要持久化的变量表</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> ProcessInstance <span class="title">createAndStartProcessInstance</span><span class="params">(ProcessDefinition processDefinition, String businessKey, String processInstanceName, </span></span></span><br><span class="line"><span class="function"><span class="params">        Map&lt;String,Object&gt; variables, Map&lt;String, Object&gt; transientVariables)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> processInstanceHelper.createAndStartProcessInstance(processDefinition, businessKey, processInstanceName, variables, transientVariables);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-3-ProcessInstanceHelper-createAndStartProcessInstance-ProcessDefinition-processDefinition-String-businessKey-String-processInstanceName-Map-lt-String-Object-gt-variables-Map-lt-String-Object-gt-transientVariables-boolean-startProcessInstance"><a href="#2-3-ProcessInstanceHelper-createAndStartProcessInstance-ProcessDefinition-processDefinition-String-businessKey-String-processInstanceName-Map-lt-String-Object-gt-variables-Map-lt-String-Object-gt-transientVariables-boolean-startProcessInstance" class="headerlink" title="2.3. ProcessInstanceHelper#createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance)"></a>2.3. ProcessInstanceHelper#createAndStartProcessInstance(ProcessDefinition processDefinition, String businessKey, String processInstanceName, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> ProcessInstance <span class="title">createAndStartProcessInstance</span><span class="params">(ProcessDefinition processDefinition,</span></span></span><br><span class="line"><span class="function"><span class="params">      String businessKey, String processInstanceName,</span></span></span><br><span class="line"><span class="function"><span class="params">      Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, <span class="keyword">boolean</span> startProcessInstance)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    CommandContext commandContext = Context.getCommandContext(); <span class="comment">// Todo: ideally, context should be passed here</span></span><br><span class="line">    <span class="keyword">if</span> (Activiti5Util.isActiviti5ProcessDefinition(commandContext, processDefinition)) &#123;</span><br><span class="line">        Activiti5CompatibilityHandler activiti5CompatibilityHandler = Activiti5Util.getActiviti5CompatibilityHandler();</span><br><span class="line">        <span class="keyword">return</span> activiti5CompatibilityHandler.startProcessInstance(processDefinition.getKey(), processDefinition.getId(),</span><br><span class="line">                variables, businessKey, processDefinition.getTenantId(), processInstanceName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Do not start process a process instance if the process definition is suspended</span></span><br><span class="line">    <span class="keyword">if</span> (ProcessDefinitionUtil.isProcessDefinitionSuspended(processDefinition.getId())) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"Cannot start process instance. Process definition "</span> + processDefinition.getName() + <span class="string">" (id = "</span> + processDefinition.getId() + <span class="string">") is suspended"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get model from cache</span></span><br><span class="line">    Process process = ProcessDefinitionUtil.getProcess(processDefinition.getId());</span><br><span class="line">    <span class="keyword">if</span> (process == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"Cannot start process instance. Process model "</span> + processDefinition.getName() + <span class="string">" (id = "</span> + processDefinition.getId() + <span class="string">") could not be found"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    FlowElement initialFlowElement = process.getInitialFlowElement();</span><br><span class="line">    <span class="keyword">if</span> (initialFlowElement == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"No start element found for process definition "</span> + processDefinition.getId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> createAndStartProcessInstanceWithInitialFlowElement(processDefinition, businessKey,</span><br><span class="line">            processInstanceName, initialFlowElement, process, variables, transientVariables, startProcessInstance);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol><li>如果流程定义是 Activiti5 风格的, 执行 Activiti5 相关的兼容代码</li><li>如果流程定义已经被挂起, 那么抛出异常</li><li>根据 processDefinitionId 获取 Process 对象, 如果失败抛出异常</li><li>获取 Process 对象的 <code>initialFlowElement</code></li><li>创建并开启流程实例, 并返回结果</li></ol><h3 id="2-3-1-ProcessDefinitionUtil-getProcess-String-processDefinitionId"><a href="#2-3-1-ProcessDefinitionUtil-getProcess-String-processDefinitionId" class="headerlink" title="2.3.1. ProcessDefinitionUtil#getProcess(String processDefinitionId)"></a>2.3.1. ProcessDefinitionUtil#getProcess(String processDefinitionId)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Process <span class="title">getProcess</span><span class="params">(String processDefinitionId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (Context.getProcessEngineConfiguration() == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> Activiti5Util.getActiviti5CompatibilityHandler().getProcessDefinitionProcessObject(processDefinitionId);</span><br><span class="line">      </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        DeploymentManager deploymentManager = Context.getProcessEngineConfiguration().getDeploymentManager();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// This will check the cache in the findDeployedProcessDefinitionById and resolveProcessDefinition method</span></span><br><span class="line">        ProcessDefinition processDefinitionEntity = deploymentManager.findDeployedProcessDefinitionById(processDefinitionId);</span><br><span class="line">        <span class="keyword">return</span> deploymentManager.resolveProcessDefinition(processDefinitionEntity).getProcess();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-2-DeploymentManager-findDeployedProcessDefinitionById-String-processDefinitionId"><a href="#2-3-2-DeploymentManager-findDeployedProcessDefinitionById-String-processDefinitionId" class="headerlink" title="2.3.2. DeploymentManager#findDeployedProcessDefinitionById(String processDefinitionId)"></a>2.3.2. DeploymentManager#findDeployedProcessDefinitionById(String processDefinitionId)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessDefinition <span class="title">findDeployedProcessDefinitionById</span><span class="params">(String processDefinitionId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (processDefinitionId == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiIllegalArgumentException(<span class="string">"Invalid process definition id : null"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// first try the cache</span></span><br><span class="line">    ProcessDefinitionCacheEntry cacheEntry = processDefinitionCache.get(processDefinitionId);</span><br><span class="line">    ProcessDefinition processDefinition = cacheEntry != <span class="keyword">null</span> ? cacheEntry.getProcessDefinition() : <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (processDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">        processDefinition = processDefinitionEntityManager.findById(processDefinitionId);</span><br><span class="line">        <span class="keyword">if</span> (processDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiObjectNotFoundException(<span class="string">"no deployed process definition found with id '"</span> + processDefinitionId + <span class="string">"'"</span>, ProcessDefinition.class);</span><br><span class="line">        &#125;</span><br><span class="line">        processDefinition = resolveProcessDefinition(processDefinition).getProcessDefinition();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> processDefinition;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>首先从缓存中查找</li><li>如果缓存没有, 继续从 DB 中查找</li><li>将 ProcessDefinition 转换为 Process 并返回</li></ol><h3 id="2-3-3-DeploymentManager-resolveProcessDefinition-ProcessDefinition-processDefinition"><a href="#2-3-3-DeploymentManager-resolveProcessDefinition-ProcessDefinition-processDefinition" class="headerlink" title="2.3.3. DeploymentManager#resolveProcessDefinition(ProcessDefinition processDefinition)"></a>2.3.3. DeploymentManager#resolveProcessDefinition(ProcessDefinition processDefinition)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessDefinitionCacheEntry <span class="title">resolveProcessDefinition</span><span class="params">(ProcessDefinition processDefinition)</span> </span>&#123;</span><br><span class="line">    String processDefinitionId = processDefinition.getId();</span><br><span class="line">    String deploymentId = processDefinition.getDeploymentId();</span><br><span class="line"></span><br><span class="line">    ProcessDefinitionCacheEntry cachedProcessDefinition = processDefinitionCache.get(processDefinitionId);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cachedProcessDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">        CommandContext commandContext = Context.getCommandContext();</span><br><span class="line">        <span class="keyword">if</span> (commandContext.getProcessEngineConfiguration().isActiviti5CompatibilityEnabled() &amp;&amp; </span><br><span class="line">            Activiti5Util.isActiviti5ProcessDefinition(Context.getCommandContext(), processDefinition)) &#123;</span><br><span class="line">        </span><br><span class="line">            <span class="keyword">return</span> Activiti5Util.getActiviti5CompatibilityHandler().resolveProcessDefinition(processDefinition);</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line">        DeploymentEntity deployment = deploymentEntityManager.findById(deploymentId);</span><br><span class="line">        deployment.setNew(<span class="keyword">false</span>);</span><br><span class="line">        deploy(deployment, <span class="keyword">null</span>);</span><br><span class="line">        cachedProcessDefinition = processDefinitionCache.get(processDefinitionId);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (cachedProcessDefinition == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"deployment '"</span> + deploymentId + <span class="string">"' didn't put process definition '"</span> + processDefinitionId + <span class="string">"' in the cache"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> cachedProcessDefinition;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>首先尝试从缓存中获取流程定义<ol><li>如果为空<ol><li>如果是 Activiti5 风格的配置</li><li>通过 Activiti5 的方式获取并返回</li></ol></li><li>尝试从 DB 中获取, 补充到缓存中</li><li>再从缓存中获取</li><li>返回</li></ol></li></ol><h2 id="2-4-ProcessInstanceHelper-createAndStartProcessInstanceWithInitialFlowElement-ProcessDefinition-processDefinition-String-businessKey-String-processInstanceName-FlowElement-initialFlowElement-Process-process-Map-lt-String-Object-gt-variables-Map-lt-String-Object-gt-transientVariables-boolean-startProcessInstance"><a href="#2-4-ProcessInstanceHelper-createAndStartProcessInstanceWithInitialFlowElement-ProcessDefinition-processDefinition-String-businessKey-String-processInstanceName-FlowElement-initialFlowElement-Process-process-Map-lt-String-Object-gt-variables-Map-lt-String-Object-gt-transientVariables-boolean-startProcessInstance" class="headerlink" title="2.4. ProcessInstanceHelper#createAndStartProcessInstanceWithInitialFlowElement(ProcessDefinition processDefinition, String businessKey, String processInstanceName, FlowElement initialFlowElement, Process process, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance)"></a>2.4. ProcessInstanceHelper#createAndStartProcessInstanceWithInitialFlowElement(ProcessDefinition processDefinition, String businessKey, String processInstanceName, FlowElement initialFlowElement, Process process, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, boolean startProcessInstance)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessInstance <span class="title">createAndStartProcessInstanceWithInitialFlowElement</span><span class="params">(ProcessDefinition processDefinition,</span></span></span><br><span class="line"><span class="function"><span class="params">        String businessKey, String processInstanceName, FlowElement initialFlowElement,</span></span></span><br><span class="line"><span class="function"><span class="params">        Process process, Map&lt;String, Object&gt; variables, Map&lt;String, Object&gt; transientVariables, <span class="keyword">boolean</span> startProcessInstance)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    CommandContext commandContext = Context.getCommandContext();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create the process instance</span></span><br><span class="line">    String initiatorVariableName = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (initialFlowElement <span class="keyword">instanceof</span> StartEvent) &#123;</span><br><span class="line">        initiatorVariableName = ((StartEvent) initialFlowElement).getInitiator();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ExecutionEntity processInstance = commandContext.getExecutionEntityManager()</span><br><span class="line">            .createProcessInstanceExecution(processDefinition, businessKey, processDefinition.getTenantId(), initiatorVariableName);</span><br><span class="line"></span><br><span class="line">    commandContext.getHistoryManager().recordProcessInstanceStart(processInstance, initialFlowElement);</span><br><span class="line"></span><br><span class="line">    processInstance.setVariables(processDataObjects(process.getDataObjects()));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set the variables passed into the start command</span></span><br><span class="line">    <span class="keyword">if</span> (variables != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (String varName : variables.keySet()) &#123;</span><br><span class="line">            processInstance.setVariable(varName, variables.get(varName));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (transientVariables != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (String varName : transientVariables.keySet()) &#123;</span><br><span class="line">        processInstance.setTransientVariable(varName, transientVariables.get(varName));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set processInstance name</span></span><br><span class="line">    <span class="keyword">if</span> (processInstanceName != <span class="keyword">null</span>) &#123;</span><br><span class="line">        processInstance.setName(processInstanceName);</span><br><span class="line">        commandContext.getHistoryManager().recordProcessInstanceNameChange(processInstance.getId(), processInstanceName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Fire events</span></span><br><span class="line">    <span class="keyword">if</span> (Context.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123;</span><br><span class="line">        Context.getProcessEngineConfiguration().getEventDispatcher()</span><br><span class="line">                .dispatchEvent(ActivitiEventBuilder.createEntityWithVariablesEvent(ActivitiEventType.ENTITY_INITIALIZED, processInstance, variables, <span class="keyword">false</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create the first execution that will visit all the process definition elements</span></span><br><span class="line">    ExecutionEntity execution = commandContext.getExecutionEntityManager().createChildExecution(processInstance);</span><br><span class="line">    execution.setCurrentFlowElement(initialFlowElement);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (startProcessInstance) &#123;</span><br><span class="line">        startProcessInstance(processInstance, commandContext, variables);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> processInstance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>创建流程实例(父级 Execution)</li><li>在历史流程表中将流程实例标记为开始</li><li>将所有 <code>DataObject</code> 转换为 Map&lt;String, Object&gt;, 并设置为流程实例的变量</li><li>将创建流程时填入的表单信息设置为变量</li><li>为流程变量设置名称</li><li>触发事件</li><li>创建第一个将访问所有流程定义元素的 <code>Execution</code></li><li>并将该 Execution 对象的当前元素设置为传入的初始化元素</li><li>如果需要立即开启<ol><li>调用开启流程实例方法</li></ol></li><li>返回该流程实例</li></ol><h3 id="2-4-1-ExecutionEntityManagerImpl-createProcessInstanceExecution-ProcessDefinition-processDefinition-String-businessKey-String-tenantId-String-initiatorVariableName"><a href="#2-4-1-ExecutionEntityManagerImpl-createProcessInstanceExecution-ProcessDefinition-processDefinition-String-businessKey-String-tenantId-String-initiatorVariableName" class="headerlink" title="2.4.1. ExecutionEntityManagerImpl#createProcessInstanceExecution(ProcessDefinition processDefinition, String businessKey, String tenantId, String initiatorVariableName)"></a>2.4.1. ExecutionEntityManagerImpl#createProcessInstanceExecution(ProcessDefinition processDefinition, String businessKey, String tenantId, String initiatorVariableName)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ExecutionEntity <span class="title">createProcessInstanceExecution</span><span class="params">(ProcessDefinition processDefinition, String businessKey, String tenantId, String initiatorVariableName)</span> </span>&#123;</span><br><span class="line">    ExecutionEntity processInstanceExecution = executionDataManager.create();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (isExecutionRelatedEntityCountEnabledGlobally()) &#123;</span><br><span class="line">        ((CountingExecutionEntity) processInstanceExecution).setCountEnabled(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    processInstanceExecution.setProcessDefinitionId(processDefinition.getId());</span><br><span class="line">    processInstanceExecution.setProcessDefinitionKey(processDefinition.getKey());</span><br><span class="line">    processInstanceExecution.setProcessDefinitionName(processDefinition.getName());</span><br><span class="line">    processInstanceExecution.setProcessDefinitionVersion(processDefinition.getVersion());</span><br><span class="line">    processInstanceExecution.setBusinessKey(businessKey);</span><br><span class="line">    processInstanceExecution.setScope(<span class="keyword">true</span>); <span class="comment">// process instance is always a scope for all child executions</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Inherit tenant id (if any)</span></span><br><span class="line">    <span class="keyword">if</span> (tenantId != <span class="keyword">null</span>) &#123;</span><br><span class="line">        processInstanceExecution.setTenantId(tenantId);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    String authenticatedUserId = Authentication.getAuthenticatedUserId();</span><br><span class="line"></span><br><span class="line">    processInstanceExecution.setStartTime(Context.getProcessEngineConfiguration().getClock().getCurrentTime());</span><br><span class="line">    processInstanceExecution.setStartUserId(authenticatedUserId);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Store in database</span></span><br><span class="line">    insert(processInstanceExecution, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (initiatorVariableName != <span class="keyword">null</span>) &#123;</span><br><span class="line">        processInstanceExecution.setVariable(initiatorVariableName, authenticatedUserId);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Need to be after insert, cause we need the id</span></span><br><span class="line">    processInstanceExecution.setProcessInstanceId(processInstanceExecution.getId());</span><br><span class="line">    processInstanceExecution.setRootProcessInstanceId(processInstanceExecution.getId());</span><br><span class="line">    <span class="keyword">if</span> (authenticatedUserId != <span class="keyword">null</span>) &#123;</span><br><span class="line">        getIdentityLinkEntityManager().addIdentityLink(processInstanceExecution, authenticatedUserId, <span class="keyword">null</span>, IdentityLinkType.STARTER);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Fire events</span></span><br><span class="line">    <span class="keyword">if</span> (getEventDispatcher().isEnabled()) &#123;</span><br><span class="line">        getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, processInstanceExecution));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> processInstanceExecution;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>创建一个新的 <code>ExecutionEntity</code> 对象并初始化</li><li>获取创建人 ID 和开始时间</li><li>插入该 <code>ExecutionEntity</code></li><li>触发事件</li></ol><h3 id="2-4-2-DefaultHistoryManager-recordProcessInstanceStart-ExecutionEntity-processInstance-FlowElement-startElement"><a href="#2-4-2-DefaultHistoryManager-recordProcessInstanceStart-ExecutionEntity-processInstance-FlowElement-startElement" class="headerlink" title="2.4.2. DefaultHistoryManager#recordProcessInstanceStart(ExecutionEntity processInstance, FlowElement startElement)"></a>2.4.2. DefaultHistoryManager#recordProcessInstanceStart(ExecutionEntity processInstance, FlowElement startElement)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recordProcessInstanceStart</span><span class="params">(ExecutionEntity processInstance, FlowElement startElement)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isHistoryLevelAtLeast(HistoryLevel.ACTIVITY)) &#123;</span><br><span class="line">        HistoricProcessInstanceEntity historicProcessInstance = getHistoricProcessInstanceEntityManager().create(processInstance);</span><br><span class="line">        historicProcessInstance.setStartActivityId(startElement.getId());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Insert historic process-instance</span></span><br><span class="line">        getHistoricProcessInstanceEntityManager().insert(historicProcessInstance, <span class="keyword">false</span>);</span><br><span class="line">      </span><br><span class="line">        <span class="comment">// Fire event</span></span><br><span class="line">        ActivitiEventDispatcher activitiEventDispatcher = getEventDispatcher();</span><br><span class="line">        <span class="keyword">if</span> (activitiEventDispatcher != <span class="keyword">null</span> &amp;&amp; activitiEventDispatcher.isEnabled()) &#123;</span><br><span class="line">            activitiEventDispatcher.dispatchEvent(</span><br><span class="line">                    ActivitiEventBuilder.createEntityEvent(ActivitiEventType.HISTORIC_PROCESS_INSTANCE_CREATED, historicProcessInstance));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>根据传入的 <code>processInstance</code> 构造 <code>HistoricProcessInstanceEntity</code> 对象</li><li>向历史表插入该对象</li><li>将给定的事件分派给任何已注册的侦听器</li></ol><h3 id="2-4-3-ExecutionEntityManagerImpl-createChildExecution-ExecutionEntity-parentExecutionEntity"><a href="#2-4-3-ExecutionEntityManagerImpl-createChildExecution-ExecutionEntity-parentExecutionEntity" class="headerlink" title="2.4.3. ExecutionEntityManagerImpl#createChildExecution(ExecutionEntity parentExecutionEntity)"></a>2.4.3. ExecutionEntityManagerImpl#createChildExecution(ExecutionEntity parentExecutionEntity)</h3><p>创建第一个将访问所有流程定义元素的执行对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ExecutionEntity <span class="title">createChildExecution</span><span class="params">(ExecutionEntity parentExecutionEntity)</span> </span>&#123;</span><br><span class="line">    ExecutionEntity childExecution = executionDataManager.create();</span><br><span class="line">    inheritCommonProperties(parentExecutionEntity, childExecution);</span><br><span class="line">    childExecution.setParent(parentExecutionEntity);</span><br><span class="line">    childExecution.setProcessDefinitionId(parentExecutionEntity.getProcessDefinitionId());</span><br><span class="line">    childExecution.setProcessDefinitionKey(parentExecutionEntity.getProcessDefinitionKey());</span><br><span class="line">    childExecution.setProcessInstanceId(parentExecutionEntity.getProcessInstanceId() != <span class="keyword">null</span> </span><br><span class="line">            ? parentExecutionEntity.getProcessInstanceId() : parentExecutionEntity.getId());</span><br><span class="line">    childExecution.setScope(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// manage the bidirectional parent-child relation</span></span><br><span class="line">    parentExecutionEntity.addChildExecution(childExecution);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Insert the child execution</span></span><br><span class="line">    insert(childExecution, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">        logger.debug(<span class="string">"Child execution &#123;&#125; created with parent &#123;&#125;"</span>, childExecution, parentExecutionEntity.getId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (getEventDispatcher().isEnabled()) &#123;</span><br><span class="line">        getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, childExecution));</span><br><span class="line">        getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_INITIALIZED, childExecution));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> childExecution;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol><li>创建一个新的 <code>ExecutionEntity</code> 对象, 并继承父 ExecutionEntity 的公共配置</li><li>设置父子关系</li><li>插入子 ExecutionEntity</li><li>将指定事件分派给已注册的监听器</li></ol><h3 id="2-4-4-ExecutionEntityManagerImpl-startProcessInstance-ExecutionEntity-processInstance-CommandContext-commandContext-Map-lt-String-Object-gt-variables"><a href="#2-4-4-ExecutionEntityManagerImpl-startProcessInstance-ExecutionEntity-processInstance-CommandContext-commandContext-Map-lt-String-Object-gt-variables" class="headerlink" title="2.4.4. ExecutionEntityManagerImpl#startProcessInstance(ExecutionEntity processInstance, CommandContext commandContext, Map&lt;String, Object&gt; variables)"></a>2.4.4. ExecutionEntityManagerImpl#startProcessInstance(ExecutionEntity processInstance, CommandContext commandContext, Map&lt;String, Object&gt; variables)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startProcessInstance</span><span class="params">(ExecutionEntity processInstance, CommandContext commandContext, Map&lt;String, Object&gt; variables)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Process process = ProcessDefinitionUtil.getProcess(processInstance.getProcessDefinitionId());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Event sub process handling</span></span><br><span class="line">    List&lt;MessageEventSubscriptionEntity&gt; messageEventSubscriptions = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (FlowElement flowElement : process.getFlowElements()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (flowElement <span class="keyword">instanceof</span> EventSubProcess) &#123;</span><br><span class="line">            EventSubProcess eventSubProcess = (EventSubProcess) flowElement;</span><br><span class="line">            <span class="keyword">for</span> (FlowElement subElement : eventSubProcess.getFlowElements()) &#123;</span><br><span class="line">                <span class="keyword">if</span> (subElement <span class="keyword">instanceof</span> StartEvent) &#123;</span><br><span class="line">                    StartEvent startEvent = (StartEvent) subElement;</span><br><span class="line">                    <span class="keyword">if</span> (CollectionUtil.isNotEmpty(startEvent.getEventDefinitions())) &#123;</span><br><span class="line">                        EventDefinition eventDefinition = startEvent.getEventDefinitions().get(<span class="number">0</span>);</span><br><span class="line">                        <span class="keyword">if</span> (eventDefinition <span class="keyword">instanceof</span> MessageEventDefinition) &#123;</span><br><span class="line">                            MessageEventDefinition messageEventDefinition = (MessageEventDefinition) eventDefinition;</span><br><span class="line">                            BpmnModel bpmnModel = ProcessDefinitionUtil.getBpmnModel(processInstance.getProcessDefinitionId());</span><br><span class="line">                            <span class="keyword">if</span> (bpmnModel.containsMessageId(messageEventDefinition.getMessageRef())) &#123;</span><br><span class="line">                                messageEventDefinition.setMessageRef(bpmnModel.getMessage(messageEventDefinition.getMessageRef()).getName());</span><br><span class="line">                            &#125;</span><br><span class="line">                            ExecutionEntity messageExecution = commandContext.getExecutionEntityManager().createChildExecution(processInstance);</span><br><span class="line">                            messageExecution.setCurrentFlowElement(startEvent);</span><br><span class="line">                            messageExecution.setEventScope(<span class="keyword">true</span>);</span><br><span class="line">                            messageEventSubscriptions</span><br><span class="line">                                    .add(commandContext.getEventSubscriptionEntityManager().insertMessageEvent(messageEventDefinition.getMessageRef(), messageExecution));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ExecutionEntity execution = processInstance.getExecutions().get(<span class="number">0</span>); <span class="comment">// There will always be one child execution created</span></span><br><span class="line">    commandContext.getAgenda().planContinueProcessOperation(execution);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (Context.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123;</span><br><span class="line">    ActivitiEventDispatcher eventDispatcher = Context.getProcessEngineConfiguration().getEventDispatcher();</span><br><span class="line">        eventDispatcher.dispatchEvent(ActivitiEventBuilder.createProcessStartedEvent(execution, variables, <span class="keyword">false</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (MessageEventSubscriptionEntity messageEventSubscription : messageEventSubscriptions) &#123;</span><br><span class="line">            commandContext.getProcessEngineConfiguration().getEventDispatcher()</span><br><span class="line">                    .dispatchEvent(ActivitiEventBuilder.createMessageEvent(ActivitiEventType.ACTIVITY_MESSAGE_WAITING, messageEventSubscription.getActivityId(),</span><br><span class="line">                            messageEventSubscription.getEventName(), <span class="keyword">null</span>, messageEventSubscription.getExecution().getId(),</span><br><span class="line">                            messageEventSubscription.getProcessInstanceId(), messageEventSubscription.getProcessDefinitionId()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>获取流程对象</li><li>找到所有的子流程的开始事件, 并查找开始事件的事件定义来收集所有的消息事件</li><li>获取当前 ExecutionEntity 的第一个子对象, 并由该子对象开始执行</li><li>开始流程后, 继续进行将给定的事件分派给任何已注册的侦听器的操作</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-概念&quot;&gt;&lt;a href=&quot;#1-概念&quot; class=&quot;headerlink&quot; title=&quot;1. 概念&quot;&gt;&lt;/a&gt;1. 概念&lt;/h1&gt;&lt;h2 id=&quot;1-1-启动流程&quot;&gt;&lt;a href=&quot;#1-1-启动流程&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="Activiti" scheme="https://destinywang.github.io/blog/categories/Activiti/"/>
    
      <category term="源码" scheme="https://destinywang.github.io/blog/categories/Activiti/%E6%BA%90%E7%A0%81/"/>
    
    
      <category term="Activiti" scheme="https://destinywang.github.io/blog/tags/Activiti/"/>
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(6)--RepositoryService(仓库服务类)模型校验</title>
    <link href="https://destinywang.github.io/blog/2019/03/09/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-6-RepositoryService-%E4%BB%93%E5%BA%93%E6%9C%8D%E5%8A%A1%E7%B1%BB-%E6%A8%A1%E5%9E%8B%E6%A0%A1%E9%AA%8C/"/>
    <id>https://destinywang.github.io/blog/2019/03/09/Activiti源码分析-6-RepositoryService-仓库服务类-模型校验/</id>
    <published>2019-03-09T05:38:16.000Z</published>
    <updated>2019-03-09T06:31:00.160Z</updated>
    
    <content type="html"><![CDATA[<h4 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testBpmnModel</span><span class="params">()</span> <span class="keyword">throws</span> UnsupportedEncodingException </span>&#123;</span><br><span class="line">        BpmnModel bpmnModel = <span class="keyword">new</span> BpmnModel();</span><br><span class="line">        Process process = <span class="keyword">new</span> Process();</span><br><span class="line">        process.setId(<span class="string">"my-process"</span>);</span><br><span class="line"></span><br><span class="line">        StartEvent startEvent = <span class="keyword">new</span> StartEvent();</span><br><span class="line">        startEvent.setId(<span class="string">"startEvent"</span>);</span><br><span class="line"></span><br><span class="line">        UserTask someTask = <span class="keyword">new</span> UserTask();</span><br><span class="line">        someTask.setId(<span class="string">"someTask"</span>);</span><br><span class="line">        someTask.setName(<span class="string">"Activiti is awesome!"</span>);</span><br><span class="line">        someTask.setAssignee(<span class="string">"$&#123;user&#125;"</span>);</span><br><span class="line">        MultiInstanceLoopCharacteristics multiInstanceLoopCharacteristics = <span class="keyword">new</span> MultiInstanceLoopCharacteristics();</span><br><span class="line">        multiInstanceLoopCharacteristics.setSequential(<span class="keyword">false</span>);</span><br><span class="line">        multiInstanceLoopCharacteristics.setInputDataItem(<span class="string">"$&#123;usersBean.getUsers(name)&#125;"</span>);</span><br><span class="line">        multiInstanceLoopCharacteristics.setElementVariable(<span class="string">"user"</span>);</span><br><span class="line">        multiInstanceLoopCharacteristics.setCompletionCondition(<span class="string">"$&#123;nrOfCompletedInstances &gt; 0&#125;"</span>);</span><br><span class="line"></span><br><span class="line">        someTask.setLoopCharacteristics(multiInstanceLoopCharacteristics);</span><br><span class="line"></span><br><span class="line">        EndEvent endEvent = <span class="keyword">new</span> EndEvent();</span><br><span class="line">        endEvent.setId(<span class="string">"endEvent"</span>);</span><br><span class="line"></span><br><span class="line">        SequenceFlow flow1 = createSequence(<span class="string">"startEvent"</span>, <span class="string">"someTask"</span>, <span class="string">"flow1"</span>, <span class="string">"flow1"</span>, <span class="keyword">null</span>);</span><br><span class="line">        SequenceFlow flow2 = createSequence(<span class="string">"someTask"</span>, <span class="string">"endEvent"</span>, <span class="string">"flow2"</span>, <span class="string">"flow2"</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">        process.addFlowElement(startEvent);</span><br><span class="line">        process.addFlowElement(someTask);</span><br><span class="line">        process.addFlowElement(endEvent);</span><br><span class="line">        process.addFlowElement(flow1);</span><br><span class="line">        process.addFlowElement(flow2);</span><br><span class="line"></span><br><span class="line">        bpmnModel.addProcess(process);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> BpmnXMLConverter().convertToXML(bpmnModel);</span><br><span class="line">        String s = <span class="keyword">new</span> String(bytes, <span class="string">"utf-8"</span>);</span><br><span class="line">        log.info(s);</span><br><span class="line"></span><br><span class="line">        ProcessValidatorFactory processValidatorFactory = <span class="keyword">new</span> ProcessValidatorFactory();</span><br><span class="line">        ProcessValidator defaultProcessValidator = processValidatorFactory.createDefaultProcessValidator();</span><br><span class="line">        List&lt;ValidationError&gt; validate = defaultProcessValidator.validate(bpmnModel);</span><br><span class="line">        log.info(<span class="string">"validate: &#123;&#125;"</span>, validate);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="生成的-XMl-文件"><a href="#生成的-XMl-文件" class="headerlink" title="生成的 XMl 文件:"></a>生成的 XMl 文件:</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">definitions</span> <span class="attr">xmlns</span>=<span class="string">"http://www.omg.org/spec/BPMN/20100524/MODEL"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> <span class="attr">xmlns:xsd</span>=<span class="string">"http://www.w3.org/2001/XMLSchema"</span> <span class="attr">xmlns:activiti</span>=<span class="string">"http://activiti.org/bpmn"</span> <span class="attr">xmlns:bpmndi</span>=<span class="string">"http://www.omg.org/spec/BPMN/20100524/DI"</span> <span class="attr">xmlns:omgdc</span>=<span class="string">"http://www.omg.org/spec/DD/20100524/DC"</span> <span class="attr">xmlns:omgdi</span>=<span class="string">"http://www.omg.org/spec/DD/20100524/DI"</span> <span class="attr">typeLanguage</span>=<span class="string">"http://www.w3.org/2001/XMLSchema"</span> <span class="attr">expressionLanguage</span>=<span class="string">"http://www.w3.org/1999/XPath"</span> <span class="attr">targetNamespace</span>=<span class="string">"http://www.activiti.org/test"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">process</span> <span class="attr">id</span>=<span class="string">"my-process"</span> <span class="attr">isExecutable</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">startEvent</span> <span class="attr">id</span>=<span class="string">"startEvent"</span>&gt;</span><span class="tag">&lt;/<span class="name">startEvent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">userTask</span> <span class="attr">id</span>=<span class="string">"someTask"</span> <span class="attr">name</span>=<span class="string">"Activiti is awesome!"</span> <span class="attr">activiti:assignee</span>=<span class="string">"$&#123;user&#125;"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">multiInstanceLoopCharacteristics</span> <span class="attr">isSequential</span>=<span class="string">"false"</span> <span class="attr">activiti:collection</span>=<span class="string">"$&#123;usersBean.getUsers(name)&#125;"</span> <span class="attr">activiti:elementVariable</span>=<span class="string">"user"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">completionCondition</span>&gt;</span>$&#123;nrOfCompletedInstances &amp;gt; 0&#125;<span class="tag">&lt;/<span class="name">completionCondition</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">multiInstanceLoopCharacteristics</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">userTask</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">endEvent</span> <span class="attr">id</span>=<span class="string">"endEvent"</span>&gt;</span><span class="tag">&lt;/<span class="name">endEvent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">sequenceFlow</span> <span class="attr">id</span>=<span class="string">"flow1"</span> <span class="attr">name</span>=<span class="string">"flow1"</span> <span class="attr">sourceRef</span>=<span class="string">"startEvent"</span> <span class="attr">targetRef</span>=<span class="string">"someTask"</span>&gt;</span><span class="tag">&lt;/<span class="name">sequenceFlow</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">sequenceFlow</span> <span class="attr">id</span>=<span class="string">"flow2"</span> <span class="attr">name</span>=<span class="string">"flow2"</span> <span class="attr">sourceRef</span>=<span class="string">"someTask"</span> <span class="attr">targetRef</span>=<span class="string">"endEvent"</span>&gt;</span><span class="tag">&lt;/<span class="name">sequenceFlow</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">process</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">bpmndi:BPMNDiagram</span> <span class="attr">id</span>=<span class="string">"BPMNDiagram_my-process"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bpmndi:BPMNPlane</span> <span class="attr">bpmnElement</span>=<span class="string">"my-process"</span> <span class="attr">id</span>=<span class="string">"BPMNPlane_my-process"</span>&gt;</span><span class="tag">&lt;/<span class="name">bpmndi:BPMNPlane</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">bpmndi:BPMNDiagram</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">definitions</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="validate-的结果"><a href="#validate-的结果" class="headerlink" title="validate 的结果"></a>validate 的结果</h4><pre><code>validate: []</code></pre><p>代表当前流程正常, 没有错误</p><h1 id="1-ProcessValidatorFactory-createDefaultProcessValidator"><a href="#1-ProcessValidatorFactory-createDefaultProcessValidator" class="headerlink" title="1. ProcessValidatorFactory#createDefaultProcessValidator()"></a>1. ProcessValidatorFactory#createDefaultProcessValidator()</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessValidator <span class="title">createDefaultProcessValidator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ProcessValidatorImpl processValidator = <span class="keyword">new</span> ProcessValidatorImpl();</span><br><span class="line">    processValidator.addValidatorSet(<span class="keyword">new</span> ValidatorSetFactory().createActivitiExecutableProcessValidatorSet());</span><br><span class="line">    <span class="keyword">return</span> processValidator;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;测试代码&quot;&gt;&lt;a href=&quot;#测试代码&quot; class=&quot;headerlink&quot; title=&quot;测试代码&quot;&gt;&lt;/a&gt;测试代码&lt;/h4&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(5)--RepositoryService(仓库服务类)classpath资源部署</title>
    <link href="https://destinywang.github.io/blog/2019/03/09/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-5-RepositoryService-%E4%BB%93%E5%BA%93%E6%9C%8D%E5%8A%A1%E7%B1%BB-classpath%E8%B5%84%E6%BA%90%E9%83%A8%E7%BD%B2/"/>
    <id>https://destinywang.github.io/blog/2019/03/09/Activiti源码分析-5-RepositoryService-仓库服务类-classpath资源部署/</id>
    <published>2019-03-09T04:29:31.000Z</published>
    <updated>2019-03-09T08:31:21.248Z</updated>
    
    <content type="html"><![CDATA[<p>RepositoryService 是 Activiti 的仓库服务类, 仓库指的是流程定义文档的两个文件: BPMN 文件和流程图片</p><p>获得方式:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RepositoryService repositoryService = processEngine.getRepositoryService();</span><br></pre></td></tr></table></figure><ul><li>其实现类为: RepositoryServiceImpl</li><li>可以产生 DeploymentBuilder, 用来产生定义流程部署的相关参数</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deployment deployment = repositoryService.createDeployment();</span><br></pre></td></tr></table></figure><h1 id="1-classpath-部署方式说明"><a href="#1-classpath-部署方式说明" class="headerlink" title="1. classpath 部署方式说明"></a>1. classpath 部署方式说明</h1><ol><li>先获取流程引擎对象, 在创建时会自动加载 classpath 下的 <code>activiti.cfg.xml</code></li><li>首先获得默认的流程引擎, 通过流程引擎获取一个 RepositoryService 对象</li><li>由仓库的服务对象产生一个部署对象配置对象, 用来封装部署操作的相关配置</li><li>链式编程, 在部署的配置对象中设置显示名, 上传流程定义规则文件</li><li>向数据库中存放流程定义的规则信息</li></ol><p>测试代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();</span><br><span class="line">    Deployment deployment = processEngine.getRepositoryService()</span><br><span class="line">            .createDeployment()</span><br><span class="line">            .name(<span class="string">"my-process"</span>)</span><br><span class="line">            .addClasspathResource(<span class="string">"process/my-process.bpmn20.xml"</span>)</span><br><span class="line">            .deploy();</span><br><span class="line"></span><br><span class="line">    log.info(<span class="string">"deployment: &#123;&#125;"</span>, deployment);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-1-DeploymentBuilderImpl-addClasspathResource-String-resource"><a href="#1-1-DeploymentBuilderImpl-addClasspathResource-String-resource" class="headerlink" title="1.1. DeploymentBuilderImpl#addClasspathResource(String resource)"></a>1.1. DeploymentBuilderImpl#addClasspathResource(String resource)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DeploymentBuilder <span class="title">addClasspathResource</span><span class="params">(String resource)</span> </span>&#123;</span><br><span class="line">    InputStream inputStream = ReflectUtil.getResourceAsStream(resource);</span><br><span class="line">    <span class="keyword">if</span> (inputStream == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiIllegalArgumentException(<span class="string">"resource '"</span> + resource + <span class="string">"' not found"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> addInputStream(resource, inputStream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>通过资源路径获取输入流</li><li>添加输入流并返回</li></ul><h3 id="1-1-1-ReflectUtil-getResourceAsStream-String-name"><a href="#1-1-1-ReflectUtil-getResourceAsStream-String-name" class="headerlink" title="1.1.1. ReflectUtil.getResourceAsStream(String name)"></a>1.1.1. ReflectUtil.getResourceAsStream(String name)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> InputStream <span class="title">getResourceAsStream</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    InputStream resourceStream = <span class="keyword">null</span>;</span><br><span class="line">    ClassLoader classLoader = getCustomClassLoader();</span><br><span class="line">    <span class="keyword">if</span> (classLoader != <span class="keyword">null</span>) &#123;</span><br><span class="line">        resourceStream = classLoader.getResourceAsStream(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (resourceStream == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// Try the current Thread context classloader</span></span><br><span class="line">        classLoader = Thread.currentThread().getContextClassLoader();</span><br><span class="line">        resourceStream = classLoader.getResourceAsStream(name);</span><br><span class="line">        <span class="keyword">if</span> (resourceStream == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// Finally, try the classloader for this class</span></span><br><span class="line">            classLoader = ReflectUtil.class.getClassLoader();</span><br><span class="line">            resourceStream = classLoader.getResourceAsStream(name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> resourceStream;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>获取自定义类加载器</li><li>如果类加载器不为空, 获取 classpath 路径下的资源</li><li>如果资源为空, 重新获取当前线程的类加载器, 再次尝试获取 classpath 下的资源</li><li>如果资源依然为空, 再获取当前类的类加载器再次尝试获取 classpath 下的资源</li><li>返回 </li></ol><h2 id="1-2-DeploymentBuilderImpl-addInputStream-String-resourceName-InputStream-inputStream"><a href="#1-2-DeploymentBuilderImpl-addInputStream-String-resourceName-InputStream-inputStream" class="headerlink" title="1.2. DeploymentBuilderImpl#addInputStream(String resourceName, InputStream inputStream)"></a>1.2. DeploymentBuilderImpl#addInputStream(String resourceName, InputStream inputStream)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DeploymentBuilder <span class="title">addInputStream</span><span class="params">(String resourceName, InputStream inputStream)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (inputStream == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiIllegalArgumentException(<span class="string">"inputStream for resource '"</span> + resourceName + <span class="string">"' is null"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">byte</span>[] bytes = IoUtil.readInputStream(inputStream, resourceName);</span><br><span class="line">    ResourceEntity resource = resourceEntityManager.create();</span><br><span class="line">    resource.setName(resourceName);</span><br><span class="line">    resource.setBytes(bytes);</span><br><span class="line">    deployment.addResource(resource);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>将输入流转化为字节数组</li><li>创建一个 ResourceEntity 实例对象, 并设置名称和字节数组</li><li>为 <code>deployment</code> 对象添加资源, 其内部包含一个 <code>Map&lt;String, ResourceEntity&gt;</code> 的属性</li><li>返回当前对象(DeploymentBuilder)</li></ol><h3 id="1-2-1-IoUtil-readInputStream-InputStream-inputStream-String-inputStreamName"><a href="#1-2-1-IoUtil-readInputStream-InputStream-inputStream-String-inputStreamName" class="headerlink" title="1.2.1. IoUtil#readInputStream(InputStream inputStream, String inputStreamName)"></a>1.2.1. IoUtil#readInputStream(InputStream inputStream, String inputStreamName)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] readInputStream(InputStream inputStream, String inputStreamName) &#123;</span><br><span class="line">    ByteArrayOutputStream outputStream = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">    <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">16</span> * <span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> bytesRead = inputStream.read(buffer);</span><br><span class="line">        <span class="keyword">while</span> (bytesRead != -<span class="number">1</span>) &#123;</span><br><span class="line">            outputStream.write(buffer, <span class="number">0</span>, bytesRead);</span><br><span class="line">            bytesRead = inputStream.read(buffer);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"couldn't read input stream "</span> + inputStreamName, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> outputStream.toByteArray();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-3-DeploymentEntityImpl-addResource-ResourceEntity-resource"><a href="#1-3-DeploymentEntityImpl-addResource-ResourceEntity-resource" class="headerlink" title="1.3. DeploymentEntityImpl#addResource(ResourceEntity resource)"></a>1.3. DeploymentEntityImpl#addResource(ResourceEntity resource)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addResource</span><span class="params">(ResourceEntity resource)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (resources == <span class="keyword">null</span>) &#123;</span><br><span class="line">        resources = <span class="keyword">new</span> HashMap&lt;String, ResourceEntity&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    resources.put(resource.getName(), resource);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="1-4-RepositoryServiceImpl-deploy"><a href="#1-4-RepositoryServiceImpl-deploy" class="headerlink" title="1.4. RepositoryServiceImpl#deploy()"></a>1.4. RepositoryServiceImpl#deploy()</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Deployment <span class="title">deploy</span><span class="params">(DeploymentBuilderImpl deploymentBuilder)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> commandExecutor.execute(<span class="keyword">new</span> DeployCmd&lt;Deployment&gt;(deploymentBuilder));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-5-DeployCmd-execute-CommandContext-commandContext"><a href="#1-5-DeployCmd-execute-CommandContext-commandContext" class="headerlink" title="1.5. DeployCmd#execute(CommandContext commandContext)"></a>1.5. DeployCmd#execute(CommandContext commandContext)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Deployment <span class="title">execute</span><span class="params">(CommandContext commandContext)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Backwards compatibility with Activiti v5</span></span><br><span class="line">    <span class="keyword">if</span> (commandContext.getProcessEngineConfiguration().isActiviti5CompatibilityEnabled()</span><br><span class="line">        &amp;&amp; deploymentBuilder.getDeploymentProperties() != <span class="keyword">null</span> </span><br><span class="line">        &amp;&amp; deploymentBuilder.getDeploymentProperties().containsKey(DeploymentProperties.DEPLOY_AS_ACTIVITI5_PROCESS_DEFINITION)</span><br><span class="line">        &amp;&amp; deploymentBuilder.getDeploymentProperties().get(DeploymentProperties.DEPLOY_AS_ACTIVITI5_PROCESS_DEFINITION).equals(Boolean.TRUE)) &#123;</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> deployAsActiviti5ProcessDefinition(commandContext);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> executeDeploy(commandContext);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-6-DeployCmd-executeDeploy-CommandContext-commandContext"><a href="#1-6-DeployCmd-executeDeploy-CommandContext-commandContext" class="headerlink" title="1.6. DeployCmd#executeDeploy(CommandContext commandContext)"></a>1.6. DeployCmd#executeDeploy(CommandContext commandContext)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Deployment <span class="title">executeDeploy</span><span class="params">(CommandContext commandContext)</span> </span>&#123;</span><br><span class="line">    DeploymentEntity deployment = deploymentBuilder.getDeployment();</span><br><span class="line"></span><br><span class="line">    deployment.setDeploymentTime(commandContext.getProcessEngineConfiguration().getClock().getCurrentTime());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (deploymentBuilder.isDuplicateFilterEnabled()) &#123;</span><br><span class="line"></span><br><span class="line">        List&lt;Deployment&gt; existingDeployments = <span class="keyword">new</span> ArrayList&lt;Deployment&gt;();</span><br><span class="line">        <span class="keyword">if</span> (deployment.getTenantId() == <span class="keyword">null</span> || ProcessEngineConfiguration.NO_TENANT_ID.equals(deployment.getTenantId())) &#123;</span><br><span class="line">            DeploymentEntity existingDeployment = commandContext.getDeploymentEntityManager().findLatestDeploymentByName(deployment.getName());</span><br><span class="line">            <span class="keyword">if</span> (existingDeployment != <span class="keyword">null</span>) &#123;</span><br><span class="line">                existingDeployments.add(existingDeployment);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            List&lt;Deployment&gt; deploymentList = commandContext.getProcessEngineConfiguration().getRepositoryService().createDeploymentQuery().deploymentName(deployment.getName())</span><br><span class="line">                    .deploymentTenantId(deployment.getTenantId()).orderByDeploymentId().desc().list();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!deploymentList.isEmpty()) &#123;</span><br><span class="line">                existingDeployments.addAll(deploymentList);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        DeploymentEntity existingDeployment = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (!existingDeployments.isEmpty()) &#123;</span><br><span class="line">            existingDeployment = (DeploymentEntity) existingDeployments.get(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((existingDeployment != <span class="keyword">null</span>) &amp;&amp; !deploymentsDiffer(deployment, existingDeployment)) &#123;</span><br><span class="line">            <span class="keyword">return</span> existingDeployment;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    deployment.setNew(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Save the data</span></span><br><span class="line">    commandContext.getDeploymentEntityManager().insert(deployment);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (commandContext.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123;</span><br><span class="line">        commandContext.getProcessEngineConfiguration().getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, deployment));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Deployment settings</span></span><br><span class="line">    Map&lt;String, Object&gt; deploymentSettings = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">    deploymentSettings.put(DeploymentSettings.IS_BPMN20_XSD_VALIDATION_ENABLED, deploymentBuilder.isBpmn20XsdValidationEnabled());</span><br><span class="line">    deploymentSettings.put(DeploymentSettings.IS_PROCESS_VALIDATION_ENABLED, deploymentBuilder.isProcessValidationEnabled());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Actually deploy</span></span><br><span class="line">    commandContext.getProcessEngineConfiguration().getDeploymentManager().deploy(deployment, deploymentSettings);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (deploymentBuilder.getProcessDefinitionsActivationDate() != <span class="keyword">null</span>) &#123;</span><br><span class="line">        scheduleProcessDefinitionActivation(commandContext, deployment);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (commandContext.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) &#123;</span><br><span class="line">        commandContext.getProcessEngineConfiguration().getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_INITIALIZED, deployment));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> deployment;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>设置部署时间</li><li></li></ol><h1 id="2-资源部署涉及到的表"><a href="#2-资源部署涉及到的表" class="headerlink" title="2. 资源部署涉及到的表"></a>2. 资源部署涉及到的表</h1><ol><li>ACT_RE_DEPLOYMENT: 存放流程定义的显示名称和部署时间, 每部署一次增加一条记录;</li><li>ACT_RE_PROCDEF: 流程定义表, 存放流程定义的属性信息, 部署每个新的流程定义都会在这张表中增加一条记录, 当流程定义的 key 相同的时候, 使用的是版本升级</li><li>ACT_GE_BYTEARRAY: 资源文件表, 存储流程定义相关的二进制文件, 包括 XML 和图片.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;RepositoryService 是 Activiti 的仓库服务类, 仓库指的是流程定义文档的两个文件: BPMN 文件和流程图片&lt;/p&gt;
&lt;p&gt;获得方式:&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(4)--CommandExecutor(命令执行器)</title>
    <link href="https://destinywang.github.io/blog/2019/02/21/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4-CommandExecutor-%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%99%A8/"/>
    <id>https://destinywang.github.io/blog/2019/02/21/Activiti源码分析-4-CommandExecutor-命令执行器/</id>
    <published>2019-02-21T15:01:25.000Z</published>
    <updated>2019-03-09T02:44:39.404Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-commandExecutor-对象的构造"><a href="#1-commandExecutor-对象的构造" class="headerlink" title="1. commandExecutor 对象的构造"></a>1. commandExecutor 对象的构造</h1><h2 id="1-1-ProcessEngineConfigurationImpl-ProcessEngineConfigurationImpl"><a href="#1-1-ProcessEngineConfigurationImpl-ProcessEngineConfigurationImpl" class="headerlink" title="1.1. ProcessEngineConfigurationImpl#ProcessEngineConfigurationImpl()"></a>1.1. ProcessEngineConfigurationImpl#ProcessEngineConfigurationImpl()</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initCommandExecutors</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    initDefaultCommandConfig();</span><br><span class="line">    initSchemaCommandConfig();</span><br><span class="line">    initCommandInvoker();</span><br><span class="line">    initCommandInterceptors();</span><br><span class="line">    initCommandExecutor();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该方法由 <code>ProcessEngineConfigurationImpl#init()</code> 调用, init 在创建 ProcessEngineConfigurationImpl 对象的时候已经分析过</p><ul><li>第 5 行, 初始化命令拦截器</li><li>第 6 行, 初始化命令执行器</li></ul><h3 id="1-1-1-initCommandInterceptors-方法"><a href="#1-1-1-initCommandInterceptors-方法" class="headerlink" title="1.1.1. initCommandInterceptors() 方法"></a>1.1.1. initCommandInterceptors() 方法</h3><p>Activiti 提供了命令拦截器的功能, 通过 API 对 Activiti 流程各个实例的操作本质上都是对 DB 的操作. 因此 Activiti 将每一个 CRUD 操作都封装为一个 <code>Command</code>, 然后交由命令执行器 <code>CommandExecutor</code> 去执行. </p><p>为了能让使用者可以对命令进行拦截, Activiti 还是用了 <code>责任链模式</code>, 使用者可以在其中添加相应的拦截器. 职责链让多个对象都有机会处理请求, 从而避免了请求发送者和接受者之间的耦合, 这些请求接受者将组成一条链, 并沿着这条链传递下去, 直到有一个对象处理了这个请求为止.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initCommandInterceptors</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (commandInterceptors == <span class="keyword">null</span>) &#123;</span><br><span class="line">        commandInterceptors = <span class="keyword">new</span> ArrayList&lt;CommandInterceptor&gt;();</span><br><span class="line">        <span class="keyword">if</span> (customPreCommandInterceptors != <span class="keyword">null</span>) &#123;</span><br><span class="line">            commandInterceptors.addAll(customPreCommandInterceptors);</span><br><span class="line">        &#125;</span><br><span class="line">        commandInterceptors.addAll(getDefaultCommandInterceptors());</span><br><span class="line">        <span class="keyword">if</span> (customPostCommandInterceptors != <span class="keyword">null</span>) &#123;</span><br><span class="line">            commandInterceptors.addAll(customPostCommandInterceptors);</span><br><span class="line">        &#125;</span><br><span class="line">        commandInterceptors.add(commandInvoker);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该方法完成对所有拦截器的初始化 </p><ul><li>自定义前置拦截器: 需要开发者实现 <code>CommandInterceptor</code> 接口, 并配置到 Activiti 配置文件(<code>activiti.cfg.xml</code>)中</li><li>默认的拦截器:<ol><li>LogInterceptor: 日志拦截器, 用于打印执行的日志</li><li>TransactionInterceptor: 事务拦截器</li><li>CommandContextInterceptor: 命令上下文拦截器</li></ol></li><li>自定义后置拦截器: 需要开发者实现 <code>CommandInterceptor</code> 接口, 并配置到 Activiti 配置文件中.</li></ul><h3 id="1-1-2-getDefaultCommandInterceptors"><a href="#1-1-2-getDefaultCommandInterceptors" class="headerlink" title="1.1.2. getDefaultCommandInterceptors()"></a>1.1.2. getDefaultCommandInterceptors()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Collection&lt;? extends CommandInterceptor&gt; getDefaultCommandInterceptors() &#123;</span><br><span class="line">    List&lt;CommandInterceptor&gt; interceptors = <span class="keyword">new</span> ArrayList&lt;CommandInterceptor&gt;();</span><br><span class="line">    interceptors.add(<span class="keyword">new</span> LogInterceptor());</span><br><span class="line"></span><br><span class="line">    CommandInterceptor transactionInterceptor = createTransactionInterceptor();</span><br><span class="line">    <span class="keyword">if</span> (transactionInterceptor != <span class="keyword">null</span>) &#123;</span><br><span class="line">        interceptors.add(transactionInterceptor);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (commandContextFactory != <span class="keyword">null</span>) &#123;</span><br><span class="line">        interceptors.add(<span class="keyword">new</span> CommandContextInterceptor(commandContextFactory, <span class="keyword">this</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (transactionContextFactory != <span class="keyword">null</span>) &#123;</span><br><span class="line">        interceptors.add(<span class="keyword">new</span> TransactionContextInterceptor(transactionContextFactory));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> interceptors;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-2-ProcessEngineConfigurationImpl-initCommandExecutor"><a href="#1-2-ProcessEngineConfigurationImpl-initCommandExecutor" class="headerlink" title="1.2. ProcessEngineConfigurationImpl#initCommandExecutor()"></a>1.2. ProcessEngineConfigurationImpl#initCommandExecutor()</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initCommandExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (commandExecutor == <span class="keyword">null</span>) &#123;</span><br><span class="line">      CommandInterceptor first = initInterceptorChain(commandInterceptors);</span><br><span class="line">      commandExecutor = <span class="keyword">new</span> CommandExecutorImpl(getDefaultCommandConfig(), first);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>将命令拦截器列表初始化为职责链</li><li>色织第一个拦截器</li></ul><h2 id="1-2-1-ProcessEngineConfigurationImpl-initInterceptorChain-List-chain"><a href="#1-2-1-ProcessEngineConfigurationImpl-initInterceptorChain-List-chain" class="headerlink" title="1.2.1 ProcessEngineConfigurationImpl#initInterceptorChain(List chain)"></a>1.2.1 ProcessEngineConfigurationImpl#initInterceptorChain(List<commandinterceptor> chain)</commandinterceptor></h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CommandInterceptor <span class="title">initInterceptorChain</span><span class="params">(List&lt;CommandInterceptor&gt; chain)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (chain == <span class="keyword">null</span> || chain.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"invalid command interceptor chain configuration: "</span> + chain);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; chain.size() - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        chain.get(i).setNext(chain.get(i + <span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> chain.get(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>初始化命令拦截器链, 并返回其中的第一个拦截器</p><p><img src="https://user-images.githubusercontent.com/17758731/54065183-e995b000-4257-11e9-9005-4a4f5f6ae568.png" alt="image"></p><h1 id="2-ProcessEngineConfigurationImpl-initService-Object-service"><a href="#2-ProcessEngineConfigurationImpl-initService-Object-service" class="headerlink" title="2. ProcessEngineConfigurationImpl#initService(Object service)"></a>2. ProcessEngineConfigurationImpl#initService(Object service)</h1><p>在各个服务对象(如 <code>RuntimeService</code>, <code>RepositoryService</code>等)中, 都可以直接使用 CommandExecutor 来执行命令<br>commandExecutor 对象由 RepositoryServiceImpl 的基类 <code>ServiceImpl</code> 声明</p><p>在 ProcessEngineConfigurationImpl 类的 initService(Object service) 方法中完成各个服务类的属性注入</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initService</span><span class="params">(Object service)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (service <span class="keyword">instanceof</span> ServiceImpl) &#123;</span><br><span class="line">        ((ServiceImpl) service).setCommandExecutor(commandExecutor);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-commandExecutor-对象的构造&quot;&gt;&lt;a href=&quot;#1-commandExecutor-对象的构造&quot; class=&quot;headerlink&quot; title=&quot;1. commandExecutor 对象的构造&quot;&gt;&lt;/a&gt;1. commandExecut
      
    
    </summary>
    
      <category term="activiti" scheme="https://destinywang.github.io/blog/categories/activiti/"/>
    
      <category term="源码" scheme="https://destinywang.github.io/blog/categories/activiti/%E6%BA%90%E7%A0%81/"/>
    
    
      <category term="activiti" scheme="https://destinywang.github.io/blog/tags/activiti/"/>
    
  </entry>
  
  <entry>
    <title>Activiti源码分析(3)--Spring配置风格源码分析1</title>
    <link href="https://destinywang.github.io/blog/2019/02/20/Activiti%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3-Spring%E9%85%8D%E7%BD%AE%E9%A3%8E%E6%A0%BC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901/"/>
    <id>https://destinywang.github.io/blog/2019/02/20/Activiti源码分析-3-Spring配置风格源码分析1/</id>
    <published>2019-02-20T14:01:01.000Z</published>
    <updated>2019-02-20T15:25:32.556Z</updated>
    
    <content type="html"><![CDATA[<p>在分析源码之前, 先贴出一个典型的 Activiti 与 Spring 整合的配置文件:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 ProcessEngineConfiguration  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"processEngineConfiguration"</span> <span class="attr">class</span>=<span class="string">"org.activiti.spring.SpringProcessEngineConfiguration"</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Spring 需要单独配置 DataSource --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"transactionManager"</span> <span class="attr">ref</span>=<span class="string">"transactionManager"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"databaseSchemaUpdate"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 数据源 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"dataSource"</span> <span class="attr">class</span>=<span class="string">"com.alibaba.druid.pool.DruidDataSource"</span> <span class="attr">init-method</span>=<span class="string">"init"</span> <span class="attr">destroy-method</span>=<span class="string">"close"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClassName"</span> <span class="attr">value</span>=<span class="string">"org.h2.Driver"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"url"</span> <span class="attr">value</span>=<span class="string">"jdbc:h2:mem:activiti"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"username"</span> <span class="attr">value</span>=<span class="string">"sa"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">""</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 事务管理器 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"transactionManager"</span> <span class="attr">class</span>=<span class="string">"org.springframework.jdbc.datasource.DataSourceTransactionManager"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 流程引擎对象 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"processEngine"</span> <span class="attr">class</span>=<span class="string">"org.activiti.spring.ProcessEngineFactoryBean"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"processEngineConfiguration"</span> <span class="attr">ref</span>=<span class="string">"processEngineConfiguration"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 将服务暴露给 Spring --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"runtimeService"</span> <span class="attr">factory-bean</span>=<span class="string">"processEngine"</span> <span class="attr">factory-method</span>=<span class="string">"getRuntimeService"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"repositoryService"</span> <span class="attr">factory-bean</span>=<span class="string">"processEngine"</span> <span class="attr">factory-method</span>=<span class="string">"getRepositoryService"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"formService"</span> <span class="attr">factory-bean</span>=<span class="string">"processEngine"</span> <span class="attr">factory-method</span>=<span class="string">"getFormService"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"taskService"</span> <span class="attr">factory-bean</span>=<span class="string">"processEngine"</span> <span class="attr">factory-method</span>=<span class="string">"getTaskService"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"historyService"</span> <span class="attr">factory-bean</span>=<span class="string">"processEngine"</span> <span class="attr">factory-method</span>=<span class="string">"getHistoryService"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置 activitiRule 用于测试 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"activitiRule"</span> <span class="attr">class</span>=<span class="string">"org.activiti.engine.test.ActivitiRule"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"processEngine"</span> <span class="attr">ref</span>=<span class="string">"processEngine"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="1-ProcessEngines-类"><a href="#1-ProcessEngines-类" class="headerlink" title="1. ProcessEngines 类"></a>1. ProcessEngines 类</h1><h2 id="1-1-init-方法"><a href="#1-1-init-方法" class="headerlink" title="1.1. init() 方法"></a>1.1. init() 方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    resources = classLoader.getResources(<span class="string">"activiti-context.xml"</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiIllegalArgumentException(<span class="string">"problem retrieving activiti-context.xml resources on the classpath: "</span> + System.getProperty(<span class="string">"java.class.path"</span>), e);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (resources.hasMoreElements()) &#123;</span><br><span class="line">    URL resource = resources.nextElement();</span><br><span class="line">    log.info(<span class="string">"Initializing process engine using Spring configuration '&#123;&#125;'"</span>, resource.toString());</span><br><span class="line">    initProcessEngineFromSpringResource(resource);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在前两篇文章中, 我们主要对常规模式(即不与 Spring 整合的初始化模式)做了简单介绍, 这篇文章我们对于 Spring 整合方式下的 ProcessEngine 初始化做一个简单分析.</p><ol><li>读取 classpath 下的 <code>activiti-context.xml</code> 文件</li><li>将资源列表依次交由 <code>initProcessEngineFromSpringResource(resource)</code> 方法完成初始化</li></ol><h2 id="1-2-initProcessEngineFromSpringResource-URL-resource-方法"><a href="#1-2-initProcessEngineFromSpringResource-URL-resource-方法" class="headerlink" title="1.2. initProcessEngineFromSpringResource(URL resource) 方法"></a>1.2. initProcessEngineFromSpringResource(URL resource) 方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">initProcessEngineFromSpringResource</span><span class="params">(URL resource)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Class&lt;?&gt; springConfigurationHelperClass = ReflectUtil.loadClass(<span class="string">"org.activiti.spring.SpringConfigurationHelper"</span>);</span><br><span class="line">        Method method = springConfigurationHelperClass.getDeclaredMethod(<span class="string">"buildProcessEngine"</span>, <span class="keyword">new</span> Class&lt;?&gt;[] &#123; URL.class &#125;);</span><br><span class="line">        ProcessEngine processEngine = (ProcessEngine) method.invoke(<span class="keyword">null</span>, <span class="keyword">new</span> Object[] &#123; resource &#125;);</span><br><span class="line"></span><br><span class="line">        String processEngineName = processEngine.getName();</span><br><span class="line">        ProcessEngineInfo processEngineInfo = <span class="keyword">new</span> ProcessEngineInfoImpl(processEngineName, resource.toString(), <span class="keyword">null</span>);</span><br><span class="line">        processEngineInfosByName.put(processEngineName, processEngineInfo);</span><br><span class="line">        processEngineInfosByResourceUrl.put(resource.toString(), processEngineInfo);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"couldn't initialize process engine from spring configuration resource "</span> + resource.toString() + <span class="string">": "</span> + e.getMessage(), e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>通过反射的方式加载目标类 <code>org.activiti.spring.SpringConfigurationHelper</code> 的 class 对象</li><li>通过反射的方式获取该类名为 <code>buildProcessEngine</code> , 参数列表为 <code>URL</code> 的方法对象</li><li>反射调用 <code>org.activiti.spring.SpringConfigurationHelper#buildProcessEngine(URL resource)</code> 方法</li></ol><h1 id="2-SpringConfigurationHelper-类"><a href="#2-SpringConfigurationHelper-类" class="headerlink" title="2. SpringConfigurationHelper 类"></a>2. SpringConfigurationHelper 类</h1><h2 id="2-1-buildProcessEngine-URL-resource-方法"><a href="#2-1-buildProcessEngine-URL-resource-方法" class="headerlink" title="2.1. buildProcessEngine(URL resource) 方法"></a>2.1. buildProcessEngine(URL resource) 方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ProcessEngine <span class="title">buildProcessEngine</span><span class="params">(URL resource)</span> </span>&#123;</span><br><span class="line">    log.debug(<span class="string">"==== BUILDING SPRING APPLICATION CONTEXT AND PROCESS ENGINE ========================================="</span>);</span><br><span class="line"></span><br><span class="line">    ApplicationContext applicationContext = <span class="keyword">new</span> GenericXmlApplicationContext(<span class="keyword">new</span> UrlResource(resource));</span><br><span class="line">    Map&lt;String, ProcessEngine&gt; beansOfType = applicationContext.getBeansOfType(ProcessEngine.class);</span><br><span class="line">    <span class="keyword">if</span> ((beansOfType == <span class="keyword">null</span>) || (beansOfType.isEmpty())) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ActivitiException(<span class="string">"no "</span> + ProcessEngine.class.getName() + <span class="string">" defined in the application context "</span> + resource.toString());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ProcessEngine processEngine = beansOfType.values().iterator().next();</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"==== SPRING PROCESS ENGINE CREATED =================================================================="</span>);</span><br><span class="line">    <span class="keyword">return</span> processEngine;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol><li>使用传入的 <code>activiti-context.xml</code> 文件创建 ApplicationContext 对象</li><li>通过 ApplicationContext 获取类型为 <code>ProcessEngine</code> 的所有对象, 返回值为 Map&lt;beanId, ProcessEngine 对象&gt;</li><li>通过遍历获取其中第一个 value 并返回</li></ol><p>在执行第 1 步的时候, 就会触发 Spring Application Context 管理的对应对象的初始化.</p><p>对应开始时贴出来的配置文件范例, 在初始化 <code>&lt;processEngine, ProcessEngineFactoryBean&gt;</code> 前, 需要先初始化 <code>&lt;processEngineConfiguration, SpringProcessEngineConfiguration&gt;</code> 对象</p><h2 id="2-2-SpringProcessEngineConfiguration-对象的默认构造方法"><a href="#2-2-SpringProcessEngineConfiguration-对象的默认构造方法" class="headerlink" title="2.2 SpringProcessEngineConfiguration 对象的默认构造方法"></a>2.2 SpringProcessEngineConfiguration 对象的默认构造方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SpringProcessEngineConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.transactionsExternallyManaged = <span class="keyword">true</span>;</span><br><span class="line">    deploymentStrategies.add(<span class="keyword">new</span> DefaultAutoDeploymentStrategy());</span><br><span class="line">    deploymentStrategies.add(<span class="keyword">new</span> SingleResourceAutoDeploymentStrategy());</span><br><span class="line">    deploymentStrategies.add(<span class="keyword">new</span> ResourceParentFolderAutoDeploymentStrategy());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-3-ProcessEngine-对象的-getObject-方法"><a href="#2-3-ProcessEngine-对象的-getObject-方法" class="headerlink" title="2.3. ProcessEngine 对象的 getObject() 方法"></a>2.3. ProcessEngine 对象的 getObject() 方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ProcessEngine <span class="title">getObject</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    configureExpressionManager();</span><br><span class="line">    configureExternallyManagedTransactions();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (processEngineConfiguration.getBeans() == <span class="keyword">null</span>) &#123;</span><br><span class="line">      processEngineConfiguration.setBeans(<span class="keyword">new</span> SpringBeanFactoryProxyMap(applicationContext));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.processEngine = processEngineConfiguration.buildProcessEngine();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.processEngine;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在分析源码之前, 先贴出一个典型的 Activiti 与 Spring 整合的配置文件:&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/s
      
    
    </summary>
    
    
  </entry>
  
</feed>
